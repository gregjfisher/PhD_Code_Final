# -*- coding: utf-8 -*-
"""
Created on Sunday 8 March 2015 17.25

This file sets up a simple economic system, including resources which are 'collected'
by agents who forage.  These agents then trade the resources, which they also
'consume' for survival.  Agents also adjust their foraging and trading strategies
through simulated cognitive processes.

@author: Greg Fisher (gjf1g13@soton.ac.uk and gregfisherhome@gmail.com)
"""

import numpy as np
import random
import datetime as dt
import copy
import math
import statsmodels.api as sm
import os
import threading
import plotly
import chart_studio.plotly as py
import plotly.graph_objs as go

from gjf_lib_v1_0 import print_chart as print_chart, print_SD_chart as print_SD_chart, print_chart_cc as print_chart_cc, print_chart_prices as print_chart_prices, send_mail as send_mail, pause as pause, length_of_time as length_of_time,\
generate_MA_array as generate_MA_array, plot_scatter_2d as plot_scatter_2d, gini as gini, print_turnover_breakdown_charts as print_turnover_breakdown_charts, print_turnover_charts as print_turnover_charts,\
print_prices_charts as print_prices_charts, find_location_furthest_away as find_location_furthest_away, abs_dist_on_torus as abs_dist_on_torus, within_striking_dist as within_striking_dist, print_3d_histogram as print_3d_histogram,\
create_heat_map_double_plotly as create_heat_map_double_plotly, create_heat_map_double as create_heat_map_double, create_heat_map as create_heat_map, print_3d_SD_planes as print_3d_SD_planes,\
plot_single_plane_plotly as plot_single_plane_plotly, plot_3d_SD_planes_plotly as plot_3d_SD_planes_plotly, find_best_box as find_best_box, print_histogram as print_histogram, print_scatter_1d as print_scatter_1d,\
print_scatter_1d_MRS_moves as print_scatter_1d_MRS_moves, plot_non_policy_lines_and_errors as plot_non_policy_lines_and_errors, plot_policy_lines_and_errors as plot_policy_lines_and_errors,\
create_supply_demand_charts as create_supply_demand_charts, text_col as text_col, text_col_html as text_col_html, fan_chart as fan_chart, total_size as total_size, create_plotly_2d_histogram as create_plotly_2d_histogram,\
create_plotly_2_heatmaps as create_plotly_2_heatmaps, cap_floor_value as cap_floor_value, create_plotly_2d_scatter as create_plotly_2d_scatter, add_time_stamp_string as add_time_stamp_string,\
print_contributions_to_total_chart as print_contributions_to_total_chart, print_contributions_to_tot_2_axes as print_contributions_to_tot_2_axes

# Global Variables:

# Core structural parameters
num_res_founts = 2

# Agent
num_agents = 25

# Foraging
prob_res_detection = 0.5

wait_at_target_til_end = 1

#### CREATE SOME DIRECTORIES FOR DATA FROM SIMS
# Note the following code identifies the directory this file is located in and then creates relevant data folders.

# This is the project directory in which this file is located and data will be output to
project_directory = os.getcwd()

# create top level data_folder inside project_directory if it doesn't exist already:
project_data_folder = "%s/project_data" % project_directory

# create data folders for sim_sets and also single_sims within project_data_folder:
sim_sets_data_folder = "%s/sim_sets" % project_data_folder
single_sims_data_folder = "%s/single_sims" % project_data_folder

# create all three folders if they don't exist:
for new_folder in [project_data_folder, sim_sets_data_folder, single_sims_data_folder]:
    if not os.path.exists(new_folder):
        print(' --> creating folder to place data into: ', new_folder)
        os.makedirs(new_folder)
#### END OF DIRECTORY CREATION ########

# Note on main files: the main function is run_sim(), which manages a single simulation.  multi_sims() manages a set of simulations; and run_sim_suite() manages
# a suite of (sets of) simulations.
# All the other functions and objects mostly provide code that supports these three functions.


def run_sim_suite(rounds=2000, num_runs=20, readme_notes='none', heatmap_days_show=100, SD_charts_freq=100):

    """This function runs a suite of simulations where parameters vary over the suite. Each simulation set has fixed
    parameters. Each simulation has a number of runs ('num_runs') and each run is given a certain number of rounds ('rounds')."""

    # Note that a wide range of simulation are included but commented out below: these include experiments and also exploration of the parameter space.

    # scenario where agents could not trade - to test the steady state population without any trading
    # rounds = 5000
    # init_res_lev_per_agent = 3.6
    # readme_notes = 'no_trading_cc_search_L_%2.2s_%d' % (init_res_lev_per_agent * 25, rounds)
    #
    # multi_sims(respect_property_rights=1, agents_trade=0, readme_notes=readme_notes, rounds=rounds, num_runs=20, init_res_lev_per_agent=init_res_lev_per_agent)

    # iteration loop for each sim set:
    # for scenario in ['default']:      # ['null', 'two', 'three', 'default']
    #
    #     rounds = 200
    #     num_runs = 4
    #     const_mkt_opens = 0
    #     run_dist_to_mkt_OLS = 1
    #     OLS_include = ['moves_to_target', 'max_det_dummy', 'life_span']
    #     # ['intercept', 'moves_to_target', 'max_det_dummy', 'res_spec_A', 'res_spec_B', 'birth_dummy', 'life_span']  'max_det_prob' also
    #
    #     readme_notes = scenario
    #
    #     if rounds != 1000:
    #         readme_notes += '_rds_%d' % rounds
    #
    #     if const_mkt_opens != 0:
    #         readme_notes += '_mkt_open_%d' % const_mkt_opens
    #
    #     if run_dist_to_mkt_OLS:
    #         readme_notes += '_OLS_%d' % len(OLS_include)
    #
    #         for dep_var in OLS_include:
    #             readme_notes += '_%s' % dep_var
    #
    #     multi_sims(respect_property_rights=1, scenario=scenario, readme_notes=readme_notes, const_mkt_opens=const_mkt_opens, run_dist_to_mkt_OLS=run_dist_to_mkt_OLS, rounds=rounds, num_runs=num_runs, OLS_include=OLS_include)

#    for mem in [1]:
#
#        readme_notes = 'adjust_mem_length_mem_%s' % (mem)
#
#        multi_sims(num_runs=num_runs, rounds=rounds, agent_mem_length=mem, readme_notes=readme_notes)

    # for mem_decay in [0.9751]:     # [0.2, 0.05, 0.1, 0.15, 0.7, 0.75, 0.8, 0.9, 0.9374]
    #
    #     rounds = 1000
    #     readme_notes = 'adjust_mem_decay_%1.6s_rounds_%d' % (mem_decay, rounds)
    #
    #     multi_sims(num_runs=num_runs, rounds=rounds, respect_property_rights=1, memory_decay_rate=mem_decay, readme_notes=readme_notes)

#     for density in [110]:      # [4, 5, 6, 7, 8, 9]
#
# #        wait_at_tgt_moves = 400
# #        trade_moves = 800
#
#         wait_at_tgt_moves = np.max([density * 2.5, 8])
#         trade_moves = (density * 2.5) + wait_at_tgt_moves
#
#         readme_notes = 'change_dim_density_%s_wait_%s' % (density, wait_at_tgt_moves)
#
# #        print('sim_suite: wait_at_tgt_moves =', wait_at_tgt_moves, 'trade_moves =', trade_moves)
#
#         if type(trade_moves) is not 'int':
#             trade_moves = int(trade_moves)
#
#         # record data returned from 'run_sim()' function
#         multi_sims(respect_property_rights=1, num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, dimen_density=density, trade_moves=trade_moves, wait_at_tgt_moves=wait_at_tgt_moves, readme_notes=readme_notes, scenario='adjust_travel_dist')

    # here we explore agents dying of old age (note agents will be born with an agent of between 0 and 'max_age_at_birth' (uniform distribution) and they all die at the age of death_age)
    # rounds = 1000
    # max_age_at_birth = 150
    # death_age = max_age_at_birth
    # agents_trade = 1
    #
    # if agents_trade:
    #
    #     readme_notes = 'old_age_deaths_born_(max_%s_die_at_%s)_rounds_%d' % (max_age_at_birth, death_age, rounds)
    #     init_res_lev_per_agent = 2.0
    #
    # else:
    #
    #     init_res_lev_per_agent = 2.1
    #     readme_notes = 'old_age_deaths_born_(max_%s_die_at_%s)_no_trading_L_%2.2s' % (max_age_at_birth, death_age, init_res_lev_per_agent * 25)
    #
    # multi_sims(respect_property_rights=1, num_runs=num_runs, rounds=rounds, readme_notes=readme_notes, agents_die_old_age=death_age, max_age_at_birth=max_age_at_birth, agents_trade=agents_trade, init_res_lev_per_agent=init_res_lev_per_agent)

    # readme_notes = 'no_comms_rounds_1000'
    #
    # # record data returned from 'run_sim()' function
    # multi_sims(respect_property_rights=1, num_runs=5, rounds=1000, agents_comm_prob=0.0, readme_notes=readme_notes)

    # rounds = 1000
    # comms_prob = 0.001
    # readme_notes = 'comms_rounds_%d_prob_%1.4f' % (rounds, comms_prob)
    #
    # # record data returned from 'run_sim()' function
    # multi_sims(respect_property_rights=1, num_runs=5, rounds=rounds, agents_comm_prob=comms_prob, readme_notes=readme_notes)

#    mem = 0
#
#    for density in [1, 2, 4, 12, 20]:   # 1, 2, 4, 12, 20
#
#        wait_at_tgt_moves = np.max([density * 2, 8])
#        trade_moves = (density * 2) + wait_at_tgt_moves
#
#        for comms_prob in [0.0]:       # [0.0, 0.0025, 0.005, 0.0075, 0.01]
#
#            readme_notes = 'ch_mem_%d_den_%d_comms_%1.4f_random' % (mem, density, comms_prob)
#
#            # record data returned from 'run_sim()' function
#            multi_sims(num_runs=num_runs, rounds=5000, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, agent_mem_length=mem, dimen_density=density, trade_moves=trade_moves, wait_at_tgt_moves=wait_at_tgt_moves, agents_comm_prob=comms_prob, scenario='adjust_travel_dist', readme_notes=readme_notes, trade_movemnt='random')

#    for mem in [1]:
#
#        for density in [40]:   # 1, 2, 4, 12, 20
#
#            wait_at_tgt_moves = np.max([density * 2, 8])
#            trade_moves = (density * 2) + wait_at_tgt_moves
#
#            for comms_prob in [0.0, 0.0025, 0.005, 0.0075, 0.01]:       # [0.0, 0.0025, 0.005, 0.0075, 0.01]
#
#                readme_notes = 'ch_mem_%d_den_%d_comms_%f' % (mem, density, comms_prob)
#
#                # record data returned from 'run_sim()' function
#                multi_sims(num_runs=num_runs, rounds=5000, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, agent_mem_length=mem, dimen_density=density, trade_moves=trade_moves, wait_at_tgt_moves=wait_at_tgt_moves, agents_comm_prob=comms_prob, scenario='adjust_travel_dist', readme_notes=readme_notes)
#
#    for wait in range(11):
#
#        readme_notes = 'wait_at_trgt_%d' % (wait)
#
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, trade_moves=20+wait, wait_at_tgt_moves=wait, scenario='adjust_travel_dist', readme_notes=readme_notes, wait_at_target_til_end=0)

    # readme_notes = 'transact_otw_tgt'
    #
    # multi_sims(respect_property_rights=1, num_runs=num_runs, rounds=rounds, trade_when_trgt=0, readme_notes=readme_notes)
#
   # iteration loop for each sim set:
   #  for r in [0.01]:      # 0.0025, 0.005, 0.0075, 0.01
   #
   #      readme_notes = 'r_speed_of_skill_ch_%s' % (r)
   #
   #      # record data returned from 'run_sim()' function
   #      multi_sims(respect_property_rights=1, num_runs=5, rounds=1000, for_skill_r=r, readme_notes=readme_notes)
   #
   # readme_notes = 'randomize_home_locs'
   #
   # multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, agent_homes='random', readme_notes=readme_notes)

#    for density in [60]:
#
#        readme_notes = 'randomize_home_locs_ch_den_%s' % (density)
#    
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, agent_homes='random', dimen_density=density, readme_notes=readme_notes)

#    readme_notes = 'pop_variation'
#
#    multi_sims(num_runs=num_runs, readme_notes=readme_notes, popn_ch='vary', rounds=1000, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, )

#    for intel in [0.75]:   # [0.0, 0.5, 1.0, 1.5, 2.0, 100.0]
#
#        readme_notes = 'intelligence_change_%s' % (intel)
#
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, cognition_factor=intel, readme_notes=readme_notes)

    # for weight in [0.06]:     # 0.25, 0.75, 1.0, 1.25, 1.50
    #
    #     readme_notes = 'other_agent_trans_weight_%s' % (weight)
    #
    #     multi_sims(respect_property_rights=1, num_runs=num_runs, rounds=rounds, readme_notes=readme_notes, cp_trans_weight=weight)

#   serviced_grids

    # for dist in [16]:     # [6, 8, 10, 12, 14, 16, 18, 20, 22, 24]
    #
    #     rounds = 1000
    #     readme_notes = 'travel_dist_change_%s_rounds_%d' % (dist, rounds)
    #
    #     multi_sims(respect_property_rights=1, num_runs=20, rounds=rounds, readme_notes=readme_notes, wait_at_tgt_moves=25, trade_moves=(dist + 25), scenario='adjust_travel_dist', print_serviced_locations=1)

#    readme_notes = 'WTA'
#
#    multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, readme_notes=readme_notes, trgt_sel=readme_notes)

#    readme_notes = 'force_prices_power'
#
#    multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=heatmap_days_show, readme_notes=readme_notes, force_prices='power')

    # for res in [0.0]:
    #
    #     sd = 0.0
    #     readme_notes = 'initial_res_%s_sd_%s' % (res, sd)
    #
    #     multi_sims(respect_property_rights=1, num_runs=4, rounds=4000, readme_notes=readme_notes, agent_res_init=res, agent_res_init_std=sd)

    # readme_notes = 'initial_res_std_%s' % (0.0)
    #
    # multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, readme_notes=readme_notes, agent_res_init_std=0.0)

    # readme_notes = 'fountain_home_locs'
    #
    # multi_sims(respect_property_rights=1, num_runs=num_runs, rounds=rounds, trade_loc='fountain', readme_notes=readme_notes, SD_charts_freq=5)        #, trgt_sel='WTA', trade_when_trgt=0)

#    readme_notes = 'fountain_home_locs_otw'
#
#    multi_sims(num_runs=num_runs, rounds=5000, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, trade_loc='fountain', readme_notes=readme_notes, trade_when_trgt=0, SD_charts_freq=20)        #agents_comm_prob=0.0, trgt_sel='WTA', trade_when_trgt=0)

    # for ag_mean in [2.0]:       # 0.5, 0.6, 0.7, 0.8, 0.9
    #
    #     rounds = 200
    #     num_runs = 20
    #
    #     readme_notes = 'fountain_res_per_agent_%s' % (ag_mean)
    #
    #     multi_sims(respect_property_rights=1, num_runs=num_runs, rounds=rounds, readme_notes=readme_notes, init_res_lev_per_agent=ag_mean)

    # here we try to engineer new markets
    # KI_round = 500
    # rounds = 1000
    # num_runs = 20
    #
    # for ratio in [2.75, 3.0]:               # [1.5, 1.25, 1.0, 0.75, 0.5]
    #
    #     for prop_agents in [0.4, 0.2]:         # [1.0, 0.8, 0.6, 0.4, 0.2]
    #
    #         readme_notes = 'Keynes_Inst_%d_Kratio_%1.4s_prop_ags_%1.4s' % (KI_round, ratio, prop_agents)
    #
    #         multi_sims(respect_property_rights=1, num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, readme_notes=readme_notes, allow_Keynes_Inst='total', Keynes_round=KI_round,
    #                    keynesian_ratio=ratio, prop_KI_agents=prop_agents, print_end_of_round_charts=1)

    # For exploring parameter space: changing foraging skills change to linear
    # readme_notes = 'for_skill_ch_lin'
    # rounds = 1000
    #
    # for slope_factor in [0.0002]:      # 0.0001, 0.0005, 0.002, 0.01
    #
    #     readme_notes += '_%s' % slope_factor
    #
    #     multi_sims(respect_property_rights=1, readme_notes=readme_notes, rounds=rounds, num_runs=num_runs, for_skill_change='linear', for_skill_slope=slope_factor)

    # Famine experiments
    # rounds = 3000
    # start_famine = 1000
    # famine_duration = 1000
    # cognition_factor = 0.0              # default 0.1
    # for_skill_r = 0.01                  # default 0.01
    # max_prob_det = 1.0                  # default 1.0
    # min_prob_det = 0.2                  # default 0.2
    # mating_thresh = 125                 # default 125
    # child_res = 'proportional'          # default is 'proportional' (alt is 'gross')
    # force_prices = 'float'              # default is 'float' (alt is 'optimal')
    # for_skill_change = 'linear'         # default is 'logistic' (alt is 'linear' is we want to use a linear change in skill, which will require a slope)
    # for_skill_slope = 0.004             # default is 0.001 but irrelevant if for_skill_change == 'logistic'
    # thresh_probs_charts_show_thresh = 0 # default is 1, which means the threshold probs are shown in the agent spec'n charts
    #
    # for fam_ress in [[0]]:  # , [0, 1]
    #
    #     readme_notes = 'famine_%d_res_st_%d_end_%d' % (len(fam_ress), start_famine, start_famine + famine_duration)
    #
    #     if cognition_factor != 0.1:
    #         readme_notes += '_cogn_fact_%s' % cognition_factor
    #
    #     if for_skill_r != 0.01:
    #         readme_notes += '_for_%s' % for_skill_r
    #
    #     if max_prob_det != 1.0:
    #         readme_notes += '_max_det_%s' % max_prob_det
    #
    #     if min_prob_det != 0.2:
    #         readme_notes += '_min_det_%s' % min_prob_det
    #
    #     if mating_thresh != 125:
    #         readme_notes += '_mat_thr_%d' % mating_thresh
    #
    #     if child_res == 'gross':
    #         readme_notes += '_ch_res_gross'
    #
    #     if force_prices == 'optimal':
    #         readme_notes += '_pr_opt'
    #
    #     if for_skill_change == 'linear':
    #         readme_notes += '_for_ch_lin_sl_%s' % for_skill_slope
    #
    #     multi_sims(respect_property_rights=1, readme_notes=readme_notes, rounds=rounds, res_depletion=start_famine, tot_rounds_depl=famine_duration, fount_dep=fam_ress, fount_depl_ratio=0.5,
    #                cognition_factor=cognition_factor, for_skill_r=for_skill_r, max_prob_det=max_prob_det, min_prob_det=min_prob_det, mating_thresh=mating_thresh, child_res=child_res, force_prices=force_prices,
    #                for_skill_change=for_skill_change, for_skill_slope=for_skill_slope, thresh_probs_charts_show_thresh=thresh_probs_charts_show_thresh)

    # here we try to engineer local market

    # default:
#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [4]:    # 4, 20
#
#            for res in [50]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.01
#                allow_Keynes_Inst = 'none' # 'sparse'
#                chart_freq = 500
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=chart_freq, SD_charts_freq=chart_freq, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)

    # default with policy intervention
#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [4]:    # 4, 20
#
#            for res in [50]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.01
#                allow_Keynes_Inst = 'sparse' # 'sparse'
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=500, SD_charts_freq=500, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)
#

#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [20]:    # 4, 20
#
#            for res in [50]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.01
#                allow_Keynes_Inst = 'none' # 'sparse'
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=500, SD_charts_freq=500, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)

#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [4]:    # 4, 20
#
#            for res in [50]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.5
#                allow_Keynes_Inst = 'none' # 'sparse'
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=500, SD_charts_freq=500, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)

#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [4]:    # 4, 20
#
#            for res in [200]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.01
#                allow_Keynes_Inst = 'none' # 'sparse'
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=500, SD_charts_freq=500, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)

#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [20]:    # 4, 20
#
#            for res in [200]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.5
#                allow_Keynes_Inst = 'none' # 'sparse'
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=500, SD_charts_freq=500, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)

   # here we fix prices - note this is the chart price of resource 0
   #  for price in [1.0]:
   #
   #      # forced_prices == 'optimal', 'fixed', 'floating'
   #      fixed_price_day = 500
   #      cognition_factor = 0.0
   #      write_detailed_S_D_data = [fixed_price_day - 1, fixed_price_day + 200]
   #      rounds = 1000
   #
   #      readme_notes = 'fixed_price_at_%s_from_day_%d_cogn_%s' % (price, fixed_price_day, cognition_factor)
   #
   #      multi_sims(respect_property_rights=1, rounds=rounds, num_runs=num_runs, readme_notes=readme_notes, fixed_price_day=fixed_price_day, force_prices='fixed', fixed_price=price, cognition_factor=cognition_factor,
   #                 write_detailed_S_D_data=write_detailed_S_D_data)

    # for optimal prices (ie Walrasian)
    # readme_notes = 'fixed_price_at_optimal'
    # num_runs = 20
    # rounds = 1000
    # const_mkt_opens = 0                 # default 0, test is 25
    # gen_equ_thresh = 0.01               # default is 0.01, make smaller to reduce error
    # limit_agent_interaction = 5         # default is 5, increase if want to eliminate the limitation of this
    # run_dist_to_mkt_OLS = 0             # default is 0, switch to 1 if want OLS test
    # trade_moves = 50                    # default = 50
    # min_trans_Q = 0.01                  # default = 0.01
    #
    # if const_mkt_opens != 0:
    #     readme_notes += '_mkt_opens_%d' % const_mkt_opens
    #
    # if gen_equ_thresh != 0.01:
    #     readme_notes += '_GE_thresh_%s' % gen_equ_thresh
    #
    # if limit_agent_interaction != 5:
    #
    #     if limit_agent_interaction == None:
    #         readme_notes += '_lim_ag_intn_None'
    #
    #     else:
    #         readme_notes += '_lim_ag_intn_%d' % limit_agent_interaction
    #
    # if trade_moves != 50:
    #     readme_notes += '_trade_movs_%d' % trade_moves
    #
    # if min_trans_Q != 0.01:
    #     readme_notes += '_min_trans_Q_%s' % min_trans_Q
    #
    # if run_dist_to_mkt_OLS:
    #     readme_notes += '_add_OLS'
    #
    # multi_sims(respect_property_rights=1, num_runs=num_runs, rounds=rounds, force_prices='optimal', readme_notes=readme_notes, const_mkt_opens=const_mkt_opens, gen_equ_thresh=gen_equ_thresh, limit_agent_interaction=limit_agent_interaction,
    #            run_dist_to_mkt_OLS=run_dist_to_mkt_OLS, trade_moves=trade_moves, min_trans_Q=min_trans_Q)

#     applied_constitutions = [1, 2, 3, 4, 5]         # [1, 2, 3, 4, 5]
#
#     num_experiments = len(applied_constitutions)
#
#     start_const_proces = 1000
#     const_proc_test_period = 1000
#     rounds = int(start_const_proces + (const_proc_test_period * num_experiments))
#
#     readme_notes = 'constitution_test_start_%d_periods_%d_%s' % (start_const_proces, const_proc_test_period, applied_constitutions)
# #    readme_notes = 'constitution_test_null_rounds_%d' % (rounds)
#
#     multi_sims(respect_property_rights=1, num_runs=100, rounds=rounds, readme_notes=readme_notes, constitutional_voting=1, applied_constitutions=applied_constitutions, start_const_proces=start_const_proces,
#                const_proc_test_period=const_proc_test_period, num_experiments=num_experiments)

    # in this experiment we vary the population and the agents walk around randomly
    # readme_notes = 'pop_home_loc_random_random_walk'
    #
    # multi_sims(respect_property_rights=1, num_runs=20, rounds=10000, readme_notes=readme_notes, agent_homes='random', trade_movemnt='random')

#    readme_notes = 'test_steady_state_start'
#
#    multi_sims(rounds=5000, num_runs=5, ststst=[1, 22, [1.0, 0.2], [20, 20]], popn_ch='vary', readme_notes=readme_notes)

#    send_mail(send_from='gregfisherhome@gmail.com', send_to='greg.fisher@synthesisips.net',
#              subject='Testing email', text='test', files=[], server='smtp.gmail.com',
#              port=587, username='gregfisherhome@gmail.com', password='NewW0rld)rdergmail', isTls=True)  

##############################################################################################################################################################################################################################################################
##############################################################################################################################################################################################################################################################
  ###################################################################################################################### SECOND MODEL ######################################################################################################################
##############################################################################################################################################################################################################################################################
##############################################################################################################################################################################################################################################################

    # first set of tests

    # Null models
    # readme_notes = 'no_prop_rights_null_ps_0'
    #
    # multi_sims(readme_notes=readme_notes, fix_ps_fb_0=1)

    # readme_notes = 'no_prop_rights_null_ps_1.0'
    #
    # multi_sims(readme_notes=readme_notes, fixed_prop_steal=1.0, fix_prop_fb=1.0, num_runs=5)        # , rounds=20000

    # readme_notes = 'no_prop_rights_null_rational_full'
    #
    # multi_sims(readme_notes=readme_notes, strat_choice='rational', stranger_int='full')

    # readme_notes = 'no_prop_rights_null_rational_fb'
    #
    # multi_sims(readme_notes=readme_notes, strat_choice='rational', stranger_int='fb')

    # readme_notes = 'no_prop_rights_null_rational_acq'
    #
    # multi_sims(readme_notes=readme_notes, strat_choice='rational', stranger_int='acq')

    # ps = 0.03
    # pfb = 1.0
    # readme_notes = 'no_prop_rights_null_fix_ps_%1.3f_pfb_%1.3f' % (ps, pfb)   # tested ok run_sim_suite()
    #
    # multi_sims(readme_notes=readme_notes, adjust_props_r_linear=0.0, start_prop_steal_mean=ps, start_prop_steal_std=0.0, start_prop_fight_back_mean=pfb, start_prop_fight_back_std=0.0, child_prop_std=0.0, rounds=500)         # heatmap_days_show=100

    # fix pfb
    # pfb = 0.95
    # readme_notes = 'no_prop_rights_fix_pfb_%s' % pfb
    #
    # multi_sims(readme_notes=readme_notes, fix_prop_fb=pfb, PR_res_init=1000, rounds=1000, num_runs=20)

    # fixed ps
    # ps = 0.9
    # readme_notes = 'no_prop_rights_fix_ps_%s' % ps
    #
    # multi_sims(readme_notes=readme_notes, fixed_prop_steal=ps, PR_res_init=1000, PR_mating_threshold=1500, rounds=1000, num_runs=20)

    # default
    # PR_res_init = 500
    # rnds = 1000
    # alcap = 1
    #
    # readme_notes = 'no_prop_rights_default_r_%d_res_%d_alcap_%d' % (rnds, PR_res_init, alcap)
    #
    # multi_sims(readme_notes=readme_notes, rounds=rnds, PR_res_init=PR_res_init, PR_mating_threshold=PR_res_init*1.5, heatmap_days_show=20, show_al_capones=0)        # PR_res_init=400, PR_mating_threshold=600, outcome_error_std=0.0 loss_aversion_degree=2.0

    # default
    # rnds = 1000
    # PR_res_init = 300
    # readme_notes = 'no_prop_rights_default_rounds_%d_res_%d' % (rounds, PR_res_init)
    #
    # multi_sims(readme_notes=readme_notes, rounds=rounds, heatmap_days_show=100, num_runs=20, PR_res_init=PR_res_init, PR_mating_threshold=PR_res_init*1.5)         # , rounds=300, heatmap_days_show=10, , outcome_error_std=0.0

    # # Change one agent only
    # for props in [(0.6, 0.0)]:     # [(0.0, 0.0), (0.0, 1.0), (1.0, 1.0)]
    #
    #     start_ps, start_fb = props
    #
    #     for beta in [0.5]:
    #
    #         readme_notes = 'no_prop_rights_change_one_ag_ps_%1.2f_pfb_%1.2f_beta_%1.1f' % (start_ps, start_fb, beta)
    #
    #         multi_sims(readme_notes=readme_notes, change_one_only=1, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5, agent_intn_beta=beta,
    #                    start_prop_steal_mean=start_ps, start_prop_steal_std=0.0, start_prop_fight_back_mean=start_fb, start_prop_fight_back_std=0.0,
    #                    rounds=500, num_runs=10, heatmap_days_show=100)            # , adjust_props_r_linear=0.0

    # Exploring the Parameter Space

    # ps and pfb start randomly (uniform distribution)
    # readme_notes = 'no_prop_rights_starts_random_uniform'
    #
    # multi_sims(readme_notes=readme_notes, start_props='random')

    # now high and low ps and pfb
    # readme_notes = 'no_prop_rights_starts_ps_0.1_pf_0.1'
    #
    # multi_sims(readme_notes=readme_notes, start_prop_steal_mean=0.1, start_prop_fight_back_mean=0.1)

    # readme_notes = 'no_prop_rights_starts_ps_0.9_pf_0.1'
    #
    # multi_sims(readme_notes=readme_notes, start_prop_steal_mean=0.9, start_prop_fight_back_mean=0.1)

    # readme_notes = 'no_prop_rights_starts_ps_0.9_pf_0.9'
    #
    # multi_sims(readme_notes=readme_notes, start_prop_steal_mean=0.9, start_prop_fight_back_mean=0.9)

    # readme_notes = 'no_prop_rights_starts_ps_0.1_pf_0.9'
    #
    # multi_sims(readme_notes=readme_notes, start_prop_steal_mean=0.1, start_prop_fight_back_mean=0.9)

    # third point from Seth meeting - play with simpler content for communication: last place transacted told to c/p.

    # res_start = 400
    # readme_notes = 'no_prop_rights_starts_ps_0.9_pf_0.1_res_%d' % res_start    # tested ok
    #
    # multi_sims(respect_property_rights=0, readme_notes=readme_notes, start_prop_steal_mean=0.9, start_prop_fight_back_mean=0.1, PR_res_init=res_start, PR_mating_threshold=res_start*1.5)

    # res_start = 400
    # readme_notes = 'no_prop_rights_starts_ps_0.1_pf_0.1_res_%d' % res_start    # tested ok
    #
    # multi_sims(respect_property_rights=0, readme_notes=readme_notes, start_prop_steal_mean=0.1, start_prop_fight_back_mean=0.1, PR_res_init=res_start, PR_mating_threshold=res_start*1.5)

    # fight costs
    # fight_cost = -0.05     # -0.0, -0.1, -0.25, -0.75, -0.9, -1.0
    # outcome_error_std = 0.05
    # rounds = 2000
    #
    # readme_notes = 'no_prop_rights_fight_cost_%1.3f_error_%1.3f_rounds_%d' % (fight_cost, outcome_error_std, rounds)
    #
    # multi_sims(readme_notes=readme_notes, fight_cost=fight_cost, outcome_error_std=outcome_error_std, rounds=rounds, num_runs=5)              # outcome_error_std, rounds

   # # # agent_intn_beta

   #  # outcome_error_std
   #  test_array = [0.95]                # [0.0, 0.1, 0.2, 0.5, 1.0, 10.0]
   #  rounds = 1000
   #  PR_res_init = 200
   #
   #  for error in test_array:
   #
   #      readme_notes = 'no_prop_rights_outcome_error_std_%1.2f_init_res_%d_rounds_%d' % (error, PR_res_init, rounds)
   #
   #      multi_sims(readme_notes=readme_notes, outcome_error_std=error, rounds=rounds, PR_res_init=PR_res_init, PR_mating_threshold=PR_res_init*1.5)

   # # child_prop_std
   #  rounds=5000
   #  for child_prop_std in [10.0]:    # default = 0 [0.5, 1.0, 2.0, 5.0, 10.0]
   #
   #      readme_notes = 'no_prop_rights_child_prop_std_%1.2f_rounds_%d' % (child_prop_std, rounds)
   #
   #      multi_sims(readme_notes=readme_notes, child_prop_std=child_prop_std, rounds=rounds)

    # initial resources
    # PR_res_init = 180
    # rnds = 500
    #
    # readme_notes = 'no_prop_rights_init_res_rounds_%d_res_%d' % (rnds, PR_res_init)
    #
    # multi_sims(readme_notes=readme_notes, rounds=rnds, PR_res_init=PR_res_init, PR_mating_threshold=PR_res_init*1.5)        # PR_res_init=400, PR_mating_threshold=600, outcome_error_std=0.0 loss_aversion_degree=2.0

    # adjust_props_r_linear
    # test_array = [0.2]           # 0.001, 0.0025, 0.005, 0.02, 0.04, 0.05
    #
    # for r in test_array:
    #
    #     readme_notes = 'no_prop_rights_adjust_r_%1.4f' % r
    #
    #     multi_sims(readme_notes=readme_notes, adjust_props_r_linear=r)

    # delta: learning_feedback_scale
    # lfs = 1.5     # default=(1/2.0)
    #
    # if type(lfs) == float:
    #     readme_notes = 'no_prop_rights_learning_fbs_%1.3f' % lfs
    #
    # else:
    #     readme_notes = 'no_prop_rights_learning_fbs_+-1'
    #
    # multi_sims(readme_notes=readme_notes, learning_feedback_scale=lfs)

    # net_benefit_feedback
    # nbf = 'relative'       # relative, absolute  PR_res_init=PR_res_init, PR_mating_threshold=PR_res_init*1.5
    # res = 400
    #
    # readme_notes = 'no_prop_rights_net_ben_%s_res_%d_r_002' % (nbf, res)
    #
    # multi_sims(readme_notes=readme_notes, net_benefit_feedback=nbf, PR_res_init=res, PR_mating_threshold=res*1.5)       # , adjust_props_r_linear=0.02

    # strangers if unknown
    # readme_notes = 'no_prop_rights_str_if_unknown'
    #
    # multi_sims(readme_notes=readme_notes, strangers_if_unknown=1, stranger_int='full')

    # assumed_props
    # ass_prop = 1.0
    # readme_notes = 'no_prop_rights_ass_props_%1.2f' % (ass_prop)
    #
    # multi_sims(readme_notes=readme_notes, assumed_props=ass_prop)

    # len_reputations_mem
    # mem_len = 1
    # ass_prop = 0.5
    # readme_notes = 'no_prop_rights_len_rep_mem_%d_ass_props_%1.2f' % (mem_len, ass_prop)
    #
    # multi_sims(readme_notes=readme_notes, len_reputations_mem=mem_len, assumed_props=ass_prop)

    # new paramter test: gossip.  when gossip == 0, agents did not exchange repution information about each other
    # readme_notes = 'no_prop_rights_gossip_0'
    #
    # multi_sims(readme_notes=readme_notes, gossip=0)

    # gossip and memory length - I suspect that gossip matters more for shorter memory lengths
    # mem_len = 5
    # readme_notes = 'no_prop_rights_gossip_0_mem_len_%d' % mem_len
    #
    # multi_sims(readme_notes=readme_notes, gossip=0, len_reputations_mem=mem_len)

    # target_location_weights  (default = 'crude', also 'reduced_value' poss)
    # readme_notes = 'no_prop_rights_trgt_loc_weights_red_val'
    #
    # multi_sims(readme_notes=readme_notes, target_location_weights='reduced_value')

    # local_fight (default = 'none', also 'minus_one')
    # readme_notes = 'no_prop_rights_local_fight_minus_one'
    #
    # multi_sims(readme_notes=readme_notes, local_fight='minus_one')

    # agents_can_head_home (default = 'none')
    # readme_notes = 'no_prop_rights_ags_can_head_home'
    #
    # multi_sims(readme_notes=readme_notes, agents_can_head_home=1)

    # both local_fight = 'minus_one' and agents_can_head_home

    # res = 500
    # r = 0.05
    # readme_notes = 'no_prop_rights_local_fight_minus_one_and_hh_ch_props_abs_res_%d_r_%1.2f' % (res, r)
    #
    # multi_sims(readme_notes=readme_notes, local_fight='minus_one', agents_can_head_home=1, net_benefit_feedback='absolute', adjust_props_r_linear=r, PR_res_init=res, PR_mating_threshold=res*1.5, rounds=2000, heatmap_days_show=10)


    # EXPERIMENTS

    # (i) Yellow Agents
    # res = 1000
    # readme_notes = 'no_prop_rights_yellow_agents_res_%d' % res
    #
    # multi_sims(readme_notes=readme_notes, fix_prop_fb=0, rounds=5000, PR_res_init=res, PR_mating_threshold=res*1.5)         # heatmap_days_show=100

    # (ii) Fighting Skills
    # for r in [0.04]:     # default is 0.01
    #
    #     fs = 10
    #     fs_floor = 0.0
    #     child_prop_std = 0.0
    #     res = 400
    #     rnds = 2000
    #
    #     readme_notes = 'no_prop_rights_fight_skill_fsr_%1.3f_fs_%d_fs_fl_%1.1f_ch_std_%1.2f_res_%d' % (r, fs, fs_floor, child_prop_std, res)
    #
    #     multi_sims(readme_notes=readme_notes, fight_skill=fs, fight_skill_r=r, child_prop_std=child_prop_std, PR_res_init=res, PR_mating_threshold=res*1.5, fs_floor=fs_floor,
    #     rounds=rnds, heatmap_days_show=100)      # PR_res_init=300, PR_mating_threshold=300, start_prop_steal_mean=p_s, start_prop_fight_back_mean=p_fb

    # (iii) Fight Power = resource reserves
    # (a) no Rich Agent:
    # res = 400
    # readme_notes = 'no_prop_rights_fight_bal_res_%d' % res
    #
    # multi_sims(readme_notes=readme_notes, fight_balance='res_power', PR_res_init=res, PR_mating_threshold=res*1.5, agent_intn_beta=0.0, rounds=1000, heatmap_days_show=100)

    # (b) Rich Agent
    # most_ag_res = 400
    # rich_ag_res = 8000
    #
    # readme_notes = 'no_prop_rights_fight_bal_res_%d_rich_agent_res_%d' % (most_ag_res, rich_ag_res)
    #
    # multi_sims(readme_notes=readme_notes, fight_balance='res_power', agent_intn_beta=0.0, start_1_rich_agent=rich_ag_res, PR_res_init=most_ag_res, PR_mating_threshold=most_ag_res*1.5, rounds=1000, heatmap_days_show=100)          # PR_res_init=200, PR_mating_threshold=10000, local_fight='minus_one',


#   # LAWS & CORRUPTION

    # (i) Yellow Agents
    # for inst_type in ['compensate']:         # 'fine_only', 'compensate'
    #     for fine in [-0.6]:
    #
    #         PR_res_init = 500
    #         rnds = 2000
    #
    #         # without corruption
    #         readme_notes = 'no_prop_rights_laws_yellow_agents_formal_inst_%s_fine_%1.2f_res_%d_rnds_%d' % (inst_type, fine, PR_res_init, rnds)
    #
    #         multi_sims(readme_notes=readme_notes, fix_prop_fb=0, formal_inst=inst_type, fine=fine, PR_res_init=PR_res_init, PR_mating_threshold=PR_res_init*1.5,
    #                    rounds=rnds, num_runs=5, heatmap_days_show=10)

    # Change one agent only
    # for inst_type in ['compensate']:         # 'fine_only', 'compensate'
    #     for fine in [-0.4]:
    #         for props in [(0.0, 0.0)]:     # [(1.0, 1.0), (0.0, 0.0)]
    #
    #             start_ps, start_fb = props
    #
    #             PR_res_init = 500
    #             rnds = 1000
    #
    #             readme_notes = 'no_prop_rights_laws_yellow_agents_single_ag_formal_inst_%s_fine_%1.2f_res_%d_ps_%1.1f_rnds_%d' % (inst_type, fine, PR_res_init, start_ps, rnds)
    #
    #             multi_sims(readme_notes=readme_notes, fix_prop_fb=0, formal_inst=inst_type, fine=fine, PR_res_init=PR_res_init, PR_mating_threshold=PR_res_init*1.5,
    #                        change_one_only=1, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.0, start_prop_steal_mean=start_ps, start_prop_steal_std=0.0, agent_intn_beta=0.0,
    #                        rounds=rnds, num_runs=5, heatmap_days_show=10)

    # with corruption
    # for cpc in [0.25]:
    #
    #     inst_type = 'compensate'            # 'fine_only', 'compensate'
    #     fine = -0.6
    #     PR_res_init = 500
    #     rnds = 2000
    #
    #     for start_ps in [0.5]:          # [0.4, 0.3, 0.2, 0.1]
    #
    #         readme_notes = 'no_prop_rights_laws_n_corr_yellow_agents_formal_inst_%s_fine_%1.2f_ps_%1.2f_corr_%1.2f_med_res_%d_rnds_%d' % (inst_type, fine, start_ps, cpc, PR_res_init, rnds)
    #         # readme_notes = 'no_prop_rights_laws_n_corr_yellow_agents_formal_inst_THRESHOLD_TEST_fine_%1.2f' % fine
    #         # readme_notes = 'no_prop_rights_laws_n_corr_yellow_agents_id_sims_formal_inst_%s_fine_%1.2f_ps_%1.2f_corr_%1.2f_med_res_%d_rnds_%d' % (inst_type, fine, start_ps, cpc, PR_res_init, rnds)
    #
    #         multi_sims(readme_notes=readme_notes, fix_prop_fb=0, formal_inst=inst_type, fine=fine, corruption_prop_charge=cpc, pop_av='median', PR_res_init=PR_res_init,
    #                    PR_mating_threshold=PR_res_init*1.5, start_prop_steal_mean=start_ps, rounds=rnds, num_runs=10, heatmap_days_show=100,)
    #                    # same_agents=1)

    # (ii) Fight Cost
    # for fine in [-0.09]:
    #     for inst_type in ['fine_only']:         # 'fine_only', 'compensate'
    #
    #         fc = -0.05
    #         rnds = 500
    #
    #         # straight laws, no corruption
    #         readme_notes = 'no_prop_rights_laws_fight_cost_%1.2f_formal_inst_%s_fine_%1.3f_rnds_%d' % (fc, inst_type, fine, rnds)
    #
    #         multi_sims(respect_property_rights=0, readme_notes=readme_notes, fight_cost=fc, agent_intn_beta=0.5, fine=fine, formal_inst=inst_type, rounds=rnds, heatmap_days_show=10, num_runs=5)        # corruption_prop_charge=1.0

    # change one agent only
    # for fine in [-0.1]:
    #     for inst_type in ['compensate']:         # 'fine_only', 'compensate'
    #         for props in [(1.0, 1.0), (0.0, 0.0), (0.0, 1.0)]:     # [(0.0, 0.0), (0.0, 1.0), (1.0, 1.0)]
    #
    #             start_ps, start_fb = props
    #
    #             fc = -0.05
    #             rnds = 500
    #
    #             # straight laws, no corruption
    #             readme_notes = 'no_prop_rights_laws_fight_cost_%1.2f_single_ag_formal_inst_%s_fine_%1.3f_ps_%1.1f_pfb_%1.1f_rnds_%d' % (fc, inst_type, fine, start_ps, start_fb, rnds)
    #
    #             multi_sims(respect_property_rights=0, readme_notes=readme_notes, fight_cost=fc, fine=fine, formal_inst=inst_type,
    #                        change_one_only=1, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5, start_prop_steal_mean=start_ps, start_prop_steal_std=0.0, start_prop_fight_back_mean=start_fb, start_prop_fight_back_std=0.0, agent_intn_beta=0.0,
    #                        rounds=rnds, heatmap_days_show=10, num_runs=5)        # corruption_prop_charge=1.0

    # with corruption (note corruption_prop_charge is the amount paid to a corrupt policing agent expressed as a % of the fine)
    # for cpc in [0.0]:          # [0.0, 0.05, 0.25, 0.5, 0.75, 0.95]
    #
    #     fine = -0.10
    #     inst_type = 'fine_only'   # 'fine_only', 'compensate'
    #     fc = -0.05
    #     rnds = 500
    #     start_pfb = 0.0
    #     for start_ps in [1.0]:            # [1.0, 0.95, 0.75, 0.5, 0.25, 0.05, 0.0]
    #
    #         # readme_notes = 'no_prop_rights_laws_n_corr_fight_cost_%1.2f_formal_inst_%s_fine_%1.3f_corr_%1.4f_ps_%1.2f_pfb_%1.2f_rnds_%d' % (fc, inst_type, fine, cpc, start_ps, start_pfb, rnds)
    #         readme_notes = 'no_prop_rights_laws_n_corr_fight_cost_THRESHOLD_TEST_formal_inst_%s_fine_%1.3f' % (inst_type, fine)
    #
    #         multi_sims(respect_property_rights=0, readme_notes=readme_notes, fight_cost=fc, formal_inst=inst_type, fine=fine, corruption_prop_charge=cpc, start_prop_steal_mean=start_ps, start_prop_fight_back_mean=start_pfb,
    #                    heatmap_days_show=100, rounds=rnds, num_runs=10)

    # (iii) Fighting Skills
    # for r in [0.01]:
    #     for inst_type in ['fine_only']:         # 'fine_only', 'compensate'
    #         for fine in [-0.18]:     # [-1.2, -1.4, -1.6]
    #
    #             fs = 10
    #             child_prop_std = 3.0
    #             rnds = 400     # this needs to be at least 1000
    #
    #             # straight law, no corruption
    #             readme_notes = 'no_prop_rights_laws_fight_skill_fsr_%1.3f_fs_%d_ch_std_%1.2f_formal_inst_%s_fine_%1.3f_rnds_%d' % (r, fs, child_prop_std, inst_type, fine, rnds)
    #
    #             multi_sims(readme_notes=readme_notes, agent_intn_beta=0.0, fight_skill=fs, fight_skill_r=r, child_prop_std=child_prop_std, formal_inst=inst_type, fine=fine, num_runs=10, rounds=rnds,
    #                        heatmap_days_show=10)      # PR_res_init=300, PR_mating_threshold=300, start_prop_steal_mean=p_s, start_prop_fight_back_mean=p_fb

    # change one agent only
    # for r in [0.01]:
    #     for inst_type in ['compensate']:         # 'fine_only', 'compensate'
    #         for fine in [-0.5]:     # [-1.2, -1.4, -1.6]
    #
    #             for props in [(0.0, 0.0), (0.0, 1.0)]:  # [(0.0, 0.0), (0.0, 1.0), (1.0, 1.0)]
    #
    #                 start_ps, start_fb = props
    #
    #                 fs = 10
    #                 child_prop_std = 3.0
    #                 rnds = 500     # this needs to be at least 1000
    #
    #                 # straight law, no corruption
    #                 readme_notes = 'no_prop_rights_laws_fight_skill_single_ag_fsr_%1.3f_fs_%d_ch_std_%1.2f_formal_inst_%s_fine_%1.3f_ps_%1.1f_pfb_%1.1f_rnds_%d' % (r, fs, child_prop_std, inst_type, fine, start_ps, start_fb, rnds)
    #
    #                 multi_sims(readme_notes=readme_notes, agent_intn_beta=0.0, fight_skill=fs, fight_skill_r=r, child_prop_std=child_prop_std, formal_inst=inst_type, fine=fine,
    #                            change_one_only=1, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5, start_prop_steal_mean=start_ps, start_prop_steal_std=0.0, start_prop_fight_back_mean=start_fb, start_prop_fight_back_std=0.0,
    #                            num_runs=5, rounds=rnds, heatmap_days_show=10)      # PR_res_init=300, PR_mating_threshold=300, start_prop_steal_mean=p_s, start_prop_fight_back_mean=p_fb

    # with corruption
    # for cpc in [0.0]:
    #
    #     r = 0.01
    #     inst_type = 'compensate'            # need to find optimal - 'fine_only', 'compensate'
    #     fine = -0.5                         # need to find optimal
    #     fs = 10
    #     child_prop_std = 3.0
    #     start_ps = 1.0
    #     start_pfb = 0.0
    #     rnds = 1000     # this needs to be at least 1000
    #     res = 1000
    #
    #     readme_notes = 'no_prop_rights_laws_n_corr_fight_skill_fsr_%1.3f_fs_%d_ch_std_%1.2f_formal_inst_%s_fine_%1.3f_corr_%1.1f_ps_%1.2f_pfb_%1.2f_rnds_%d' % (r, fs, child_prop_std, inst_type, fine, cpc, start_ps, start_pfb, rnds)
    #
    #     multi_sims(readme_notes=readme_notes, agent_intn_beta=0.0, fight_skill=fs, fight_skill_r=r, child_prop_std=child_prop_std, formal_inst=inst_type, fine=fine, corruption_prop_charge=cpc, pop_av='median',
    #                start_prop_steal_mean=start_ps, start_prop_fight_back_mean=start_pfb, PR_res_init=res, PR_mating_threshold=res*1.5, rounds=rnds, num_runs=10, heatmap_days_show=10)  # PR_res_init=300, PR_mating_threshold=300, start_prop_steal_mean=p_s, start_prop_fight_back_mean=p_fb

    # (iv) Wealthy Agent
    # for rich_ag_res in [8000]:
    #     for inst_type in ['compensate']:         # 'fine_only', 'compensate'
    #         for fine in [-0.4]:
    #
    #             rnds = 200
    #
    #             # straight law, no corruption
    #             readme_notes = 'no_prop_rights_laws_rich_agent_res_%d_formal_inst_%s_fine_%1.3f_rnds_%d' % (rich_ag_res, inst_type, fine, rnds)
    #
    #             multi_sims(readme_notes=readme_notes, agent_intn_beta=0.0, fight_balance='res_power', PR_res_init=400, PR_mating_threshold=10000, start_1_rich_agent=rich_ag_res, formal_inst=inst_type, fine=fine,
    #                        rounds=rnds, num_runs=10, heatmap_days_show=10)

    # single change agent only
    # for rich_ag_res in [8000]:
    #     for inst_type in ['compensate']:         # 'fine_only', 'compensate'
    #         for fine in [-0.3]:
    #
    #             for props in [(1.0, 1.0), (0.0, 0.0), (0.0, 1.0)]:  # [(0.0, 0.0), (0.0, 1.0), (1.0, 1.0)]
    #
    #                 start_ps, start_fb = props
    #
    #                 rnds = 500
    #
    #                 # straight law, no corruption
    #                 readme_notes = 'no_prop_rights_laws_rich_agent__single_ag_res_%d_formal_inst_%s_fine_%1.3f_ps_%1.1f_pfb_%1.1f_rnds_%d' % (rich_ag_res, inst_type, fine, start_ps, start_fb, rnds)
    #
    #                 multi_sims(readme_notes=readme_notes, agent_intn_beta=0.0, fight_balance='res_power', PR_res_init=400, PR_mating_threshold=10000, start_1_rich_agent=rich_ag_res, formal_inst=inst_type, fine=fine,
    #                            change_one_only=1, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5, start_prop_steal_mean=start_ps, start_prop_steal_std=0.0, start_prop_fight_back_mean=start_fb, start_prop_fight_back_std=0.0,
    #                            rounds=rnds, num_runs=5, heatmap_days_show=10)

    # with corruption
    # for cpc in [0.001]:     # 0.1, 0.3, 0.5, 0.7, 0.9  [0.05, 0.2, 0.4, 0.6, 0.8, 0.95]
    #     for start_ps in [1.0]:
    #
    #         p_fb = 0.0
    #         rich_ag_res = 8000
    #         inst_type = 'compensate'            # 'fine_only', 'compensate'
    #         fine = -0.5
    #         rnds = 1000
    #
    #         readme_notes = 'no_prop_rights_laws_n_corr_rich_agent_res_%d_formal_inst_%s_fine_%1.3f_ps_%1.2f_corr_%1.3f_rnds_%d' % (rich_ag_res, inst_type, fine, start_ps, cpc, rnds)
    #         # readme_notes = 'no_prop_rights_laws_n_corr_rich_agent_res_THRESHOLD_TEST_fine_%1.3f' % fine
    #
    #         multi_sims(readme_notes=readme_notes, agent_intn_beta=0.0, fight_balance='res_power', PR_res_init=400, PR_mating_threshold=10000, start_1_rich_agent=rich_ag_res, formal_inst=inst_type, fine=fine, pop_av='median',
    #                    corruption_prop_charge=cpc, start_prop_steal_mean=start_ps, start_prop_fight_back_mean=p_fb, rounds=rnds, num_runs=10, heatmap_days_show=100)

    # Now for a fifth experiment, which is when we use net_benefit_feedback = 'absolute' and we employ a formal rule to see if we can counter the fact pfbs get stuck at around 0.73
    # my guess is that only a small fine is necessary
    # nbf = 'absolute'       # relative, absolute  PR_res_init=PR_res_init, PR_mating_threshold=PR_res_init*1.5
    # res = 400
    # inst = 'fine_only'  # 'compensate', 'fine_only'
    # fn = -0.35
    #
    # readme_notes = 'no_prop_rights_net_ben_%s_res_%d_inst_%s_fine_%1.2f' % (nbf, res, inst, fn)
    #
    # multi_sims(readme_notes=readme_notes, net_benefit_feedback=nbf, PR_res_init=res, PR_mating_threshold=res*1.5, formal_inst=inst, fine=fn, heatmap_days_show=10)       # , adjust_props_r_linear=0.02


# Neural Networks - NOT USED

    # readme_notes = 'no_prop_rights_NNs'  # tested ok
    #
    # multi_sims(respect_property_rights=0, readme_notes=readme_notes, use_NNs=1, num_NNs=2, PR_res_init=200, PR_mating_threshold=200, agent_intn_beta=0.5, NN_learning_rate=0.2, learning_feedback_scale=1.0,
    #            fight_cost=-0.15, start_child_births=100, rounds=2000)


    # readme_notes = 'no_prop_rights_default'  # tested ok
    # rounds = 2000
    #
    # if rounds != 2000:
    #     readme_notes += '_rounds_%d' % rounds
    #
    # multi_sims(readme_notes=readme_notes, rounds=rounds, agree_location='weak')

    # NN parameter tests

    # readme_notes = 'z_no_prop_rights_NNs_tests_NNirm_0.1'
    #
    # multi_sims(readme_notes=readme_notes, num_runs=10, rounds=1000, use_NNs=1, num_NNs=2, NN_initial_random_multiplier=0.1)

    # readme_notes = 'old_sim_new_defaults'
    #
    # multi_sims(readme_notes=readme_notes, respect_property_rights=1)

    # habituation experiment
    # habit_val_props = 0.01
    # readme_notes = 'habituation_res_800_PR_%5.4f' % (habit_val_props)
    # multi_sims(num_runs=20, rounds=1000, habit_val_props=habit_val_props, readme_notes=readme_notes, PR_res_init=800, PR_mating_threshold=1200)

    # adjust_props_r_linear = 0.01             # default 0.01
    # habit_val_props = 0.0
    # props_std = 2.0
    # res = 1000000000
    # readme_notes = 'habituation_PR_r_%3.2f_h_%5.4f_pr_std_%3.2f_res_%d' % (adjust_props_r_linear, habit_val_props, props_std, res)
    # multi_sims(num_runs=40, rounds=10000, habit_val_props=habit_val_props, adjust_props_r_linear=adjust_props_r_linear,
    #            readme_notes=readme_notes, PR_res_init=res, PR_mating_threshold=res*2,
    #            start_prop_steal_std=props_std, start_prop_fight_back_std=props_std
    #            # learning_feedback_scale=1.0,
    #            # agent_intn_beta=0.0              # , learning_feedback_scale=1.0
    # )

    # habituation experiment - markets model
    # memory_decay_rate = 0.2
    # habit_val_mkts = 100.0
    # habit_deteriorates_mkts = 1
    # num_runs = 20
    # rounds = 1000
    # readme_notes = 'first_model_mem_dec_%2.1f_det_%d_habit_val_mkts_%2.1f' % (memory_decay_rate, habit_deteriorates_mkts, habit_val_mkts)
    #
    # multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq,
    #            memory_decay_rate=memory_decay_rate, target_location_weights='crude', habit_val_mkts=habit_val_mkts,
    #            readme_notes=readme_notes, habit_deteriorates_mkts=habit_deteriorates_mkts)

    # habituation experiment - property rights
    # habit_val_props = 0.01
    # start_prop_fight_back_mean = 1.0
    # start_prop_fight_back_std = 0.0
    # # readme_notes = 'default_PR_fix_pfb_%2.1f' % (start_prop_fight_back_mean)
    # readme_notes = 'habituation_PR_%5.4f_fix_pfb_%2.1f' % (habit_val_props, start_prop_fight_back_mean)
    # multi_sims(num_runs=5, rounds=1000, habit_val_props=habit_val_props, readme_notes=readme_notes, start_prop_fight_back_mean=start_prop_fight_back_mean, start_prop_fight_back_std=start_prop_fight_back_std)

    # readme_notes = 'default_res_init_800_lfb_1'
    # multi_sims(num_runs=20, rounds=1000, readme_notes=readme_notes, PR_res_init=800, PR_mating_threshold=1200, learning_feedback_scale=1.0)

    # readme_notes = 'default_res_init_800'
    # multi_sims(num_runs=20, rounds=500, readme_notes=readme_notes, PR_res_init=800, PR_mating_threshold=1200)
    #
    # multi_sims()

def multi_sims(num_runs=20, rounds=1000, agents_trade=1, scenario='default', mov_av_days_threshold_chart=10, cognition_factor=0.1, agents_comm_prob=0.01, dimen_density=10, readme_notes='default', for_skill_r=0.01,
               agent_mem_length=4, agent_homes='even', trade_when_trgt=1, mating_thresh=125, popn_ch='vary', min_trans_Q=0.01, agent_res_init=50, agent_res_init_std=5, vision_len=1,
               cp_trans_weight=0.5, res_depletion=0, tot_rounds_depl=200, fount_dep=[0, 1], fount_depl_ratio=0.5, wait_at_tgt_moves=25, trade_moves=50, force_prices='float', fixed_price=1.0,
               trgt_sel='roulette', allow_Keynes_Inst=0, Keynes_round=200, keynesian_ratio=0.5, heatmap_days_show=100, trade_movemnt='mixed', trade_loc='home', init_res_lev_per_agent=2,
               constitutional_voting=0, applied_constitutions=[1, 2, 3, 4, 5], constitutional_exp=0, start_const_proces=1000, const_proc_test_period=1000, num_experiments=5, SD_charts_freq=100, num_KI_agents=0, print_end_of_round_charts=1, Walrasian_Trading=0,
               ststst=[0, 25, [1.0, 0.2], [20, 20]], const_mkt_opens=0, print_voting_only=0, loc_mkt='avoid_interference', restrict_by_district=0, prop_KI_agents=0.0, fixed_price_day=0,
               homes_spacing='hex', print_local_policy_data=0, for_strat_parts=5, price_mean='geometric', print_fine_dets=0, printed_segment_size=100, gen_equ_wh_lps=100, stop_trading=False, child_res='proportional',
               respect_property_rights=0, fight_cost=-0.3, file_type='html', black_shoop_exp=0, black_shoop_pop='low', black_shoop_prop_start=1.0, adjust_props_r=0.06, agent_intn_beta=0.5, intn_error_std=0.0, outcome_error_std=0.05, agent_avoid_muggers=1,
               child_prop_std=0.0, prop_steal_ceil=1.0, prop_steal_floor=0.0, prop_fight_back_ceil=1.0, prop_fight_back_floor=0.0, start_prop_steal_mean=0.5, start_prop_steal_std=0.1, start_prop_fight_back_mean=0.5, start_prop_fight_back_std=0.1,
               formal_inst=0, prob_fine=1.0, fine=-0.5, agree_location='none', fight_balance='50_50', new_mkt_round=1000, two_tribes=0, two_tribes_inst=0, fight_skill=None, agents_die_old_age=None, fix_prop_fb=None, fixed_prop_steal=None,
               fix_ps_fb_0=None, start_child_births=100, plotly_online=0, change_one_only=0, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5, PR_mating_threshold=300, PR_res_init=200, fight_skill_r=0.01, start_1_rich_agent=0,
               clear_of_fights_radius=5, print_agents_interact=0, stranger_int=None, corruption_prop_charge=1.0, strat_choice='propensities', strangers_if_unknown=0, track_agent=None, local_fight='none', limit_agent_interaction=5,
               track_game_types=1, calc_timings=0, target_location_weights='crude', use_NNs=0, num_NNs=2, NN_dimensions=[14, 14, 14, 2], NN_learning_rate=0.1, NN_mid_activation='sigmoid', learning_feedback_scale=(1/2.0),
               agents_can_head_home=None, net_benefit_feedback='relative_fb_only', NN_initial_random_multiplier=0.01, NN_inputs='game_6', sigmoid_coefficient=1.0, memory_decay_rate=0.2, print_serviced_locations=0, print_MRS_std_charts=0,
               max_age_at_birth=250, write_detailed_S_D_data=0, run_dist_to_mkt_OLS=0, max_prob_det=1.0, min_prob_det=0.2, for_skill_change='logistic', for_skill_slope=0.001, gen_equ_thresh=0.01, thresh_probs_charts_show_thresh=1,
               OLS_include=[], propensities_change='linear', adjust_props_r_linear=0.01, trade_at_trgt_precise=0, loss_aversion_degree=None, print_PTP_effect=None, limit_props=0, limit_child_props=0, start_props='set', show_al_capones=0,
               len_reputations_mem=20, assumed_props=0.5, fs_floor=0.0, pop_av='median', show_res_conc_charts=[], gossip=1, same_agents=0, habit_deteriorates_mkts=0, habit_val_mkts=0.0, habit_val_props=0.0):

    """This function organises a single set of simulations, which will have a
    single set of parameters.  Individual simulation data is generated by
    calling the function 'run_sim()'.  These data are compiled in to a
    database."""

    print('\n time stamp at start of multi_sims(): ', dt.datetime.now())

    # careful with number of rounds when running constitutional voting experiment - this adjusts the number of rounds to the correct number
    if constitutional_voting:
        rounds = start_const_proces + (len(applied_constitutions) * const_proc_test_period)

    if respect_property_rights == 0:

        agents_comm_prob = 0.25

        if agree_location == 'super_strong':
            
            agents_comm_prob = 1.0

        agent_mem_length = 20
        agent_res_init = 100
        printed_segment_size = 20

        if propensities_change == 'linear':

            prop_steal_ceil = 1.0
            prop_steal_floor = 0.0
            prop_fight_back_ceil = 1.0
            prop_fight_back_floor = 0.0

        elif propensities_change == 'logistic':

            prop_steal_ceil = 0.999
            prop_steal_floor = 0.001
            prop_fight_back_ceil = 0.999
            prop_fight_back_floor = 0.001

    else:

        track_game_types = 0

    SSO = Sim_Suite_Object(allow_Keynes_Inst, print_voting_only, print_local_policy_data, num_experiments, applied_constitutions, popn_ch, num_runs, track_game_types, respect_property_rights, run_dist_to_mkt_OLS, OLS_include)

    sim_set_folder = "%s/%s_%d_%d_%d_%d_%d_%d_%d" % (sim_sets_data_folder, readme_notes,
                                                 dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day,
                                                 dt.datetime.now().hour, dt.datetime.now().minute, dt.datetime.now().second,
                                                 dt.datetime.now().microsecond / 100000)

    if scenario == 'null':

        for_skill_r = 0.0          # 0.01 by default
        agent_mem_length = 0
        memory_decay_rate = 1.0
        trade_movemnt = 'random'

    if scenario == 'two':

        for_skill_r = 0.0          # 0.01 by default

    if scenario == 'three':

        agent_mem_length = 0        # 2 by default (1 is a bit fragile - agents lose memory is they don't transact and communicate)
        memory_decay_rate = 1.0
        trade_movemnt = 'random'

    if SSO.numb_of_sims == 0:

        SSO.add_sub_folder(sim_set_folder)
        SSO.add_segment_size(printed_segment_size)
        os.makedirs(SSO.sub_folder)

    # create folder for prop steal charts
    ps_sub_folder = "%s/PS_sub_folder" % sim_set_folder

    if os.path.exists(ps_sub_folder) == False:
        os.makedirs(ps_sub_folder)

    total_runs = num_runs - SSO.numb_of_sims

    # place all of the paramters in to a dictionary, which helps when we record these in data files:
    param_dict = locals()

    # straight away we write a read_me file to record parameters in a single file (this is done at the beginning in case
    # of errors in the code - having this data might help us find bugs)
    write_text_file_readme(SSO.sub_folder, param_dict, scenario, readme_notes)

    monthDict={1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'June', 7:'July', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}

    for i in range(num_runs - SSO.numb_of_sims):

        if i == 0:

            start_time = dt.datetime.now()
            run_end_time = start_time

        print('\n time stamp in multi_sims() about to start run_sim(): ', dt.datetime.now())

        single_sim_data = run_sim(track_agent=track_agent, rounds=rounds, agents_trade=agents_trade, agents_comm_prob=agents_comm_prob,
                                   trade_movemnt=trade_movemnt, for_skill_r=for_skill_r,
                                   dimen_density=dimen_density, price_mean=price_mean, SD_charts_freq=SD_charts_freq,
                                   trade_when_trgt=trade_when_trgt, sim_no=i, total_runs=total_runs, init_res_lev_per_agent=init_res_lev_per_agent,
                                   min_trans_Q=min_trans_Q, cp_trans_weight=cp_trans_weight, trade_loc=trade_loc,
                                   vision_len=vision_len, agent_mem_length=agent_mem_length, gen_equ_wh_lps=gen_equ_wh_lps,
                                   res_depletion=res_depletion, tot_rounds_depl=tot_rounds_depl, fount_dep=fount_dep,
                                   fount_depl_ratio=fount_depl_ratio, allow_Keynes_Inst=allow_Keynes_Inst, Keynes_round=Keynes_round,
                                   keynesian_ratio=keynesian_ratio, homes_spacing=homes_spacing, agent_homes=agent_homes,
                                   popn_ch=popn_ch, mating_thresh=mating_thresh,
                                   cognition_factor=cognition_factor, save_folder=SSO.sub_folder, for_strat_parts=for_strat_parts,
                                   save_ps_cloud_folder=ps_sub_folder,
                                   printed_segment_size=printed_segment_size, mov_av_days_threshold_chart=mov_av_days_threshold_chart,
                                   scenario=scenario, readme_notes=readme_notes, agent_res_init=agent_res_init, agent_res_init_std=agent_res_init_std,
                                   wait_at_tgt_moves=wait_at_tgt_moves, trade_moves=trade_moves,
                                   force_prices=force_prices, fixed_price=fixed_price, trgt_sel=trgt_sel, heatmap_days_show=heatmap_days_show,
                                   constitutional_voting=constitutional_voting, applied_constitutions=applied_constitutions, start_const_proces=start_const_proces,
                                   const_proc_test_period=const_proc_test_period, num_experiments=num_experiments,
                                   num_KI_agents=num_KI_agents, print_end_of_round_charts=print_end_of_round_charts, constitutional_exp=constitutional_exp,
                                   Walrasian_Trading=Walrasian_Trading, fixed_price_day=fixed_price_day,
                                   ststst=ststst, const_mkt_opens=const_mkt_opens, loc_mkt=loc_mkt, restrict_by_district=restrict_by_district,
                                   respect_property_rights=respect_property_rights, fight_cost=fight_cost, black_shoop_exp=black_shoop_exp,
                                   black_shoop_pop=black_shoop_pop, adjust_props_r=adjust_props_r,
                                   agent_intn_beta=agent_intn_beta, intn_error_std=intn_error_std, agent_avoid_muggers=agent_avoid_muggers,
                                   child_prop_std=child_prop_std, print_agents_interact=print_agents_interact, prop_steal_ceil=prop_steal_ceil, prop_steal_floor=prop_steal_floor,
                                   prop_fight_back_ceil=prop_fight_back_ceil, prop_fight_back_floor=prop_fight_back_floor,
                                   start_prop_steal_mean=start_prop_steal_mean, start_prop_fight_back_mean=start_prop_fight_back_mean,
                                   black_shoop_prop_start=black_shoop_prop_start, formal_inst=formal_inst, prob_fine=prob_fine, fine=fine,
                                   agree_location=agree_location, fight_balance=fight_balance, two_tribes_inst=two_tribes_inst, two_tribes=two_tribes,
                                   new_mkt_round=new_mkt_round, fight_skill=fight_skill, agents_die_old_age=agents_die_old_age, fix_prop_fb=fix_prop_fb,
                                   fixed_prop_steal=fixed_prop_steal, fix_ps_fb_0=fix_ps_fb_0, start_prop_steal_std=start_prop_steal_std,
                                   start_prop_fight_back_std=start_prop_fight_back_std, start_child_births=start_child_births, plotly_online=plotly_online,
                                   change_one_only=change_one_only, ch_ag_prop_steal=ch_ag_prop_steal, ch_ag_prop_fb=ch_ag_prop_fb, PR_mating_threshold=PR_mating_threshold,
                                   PR_res_init=PR_res_init, fight_skill_r=fight_skill_r, start_1_rich_agent=start_1_rich_agent,
                                   clear_of_fights_radius=clear_of_fights_radius, stranger_int=stranger_int, corruption_prop_charge=corruption_prop_charge,
                                   strat_choice=strat_choice, strangers_if_unknown=strangers_if_unknown, local_fight=local_fight, limit_agent_interaction=limit_agent_interaction,
                                   track_game_types=track_game_types, calc_timings=calc_timings, use_NNs=use_NNs, num_NNs=num_NNs, NN_dimensions=NN_dimensions,
                                   NN_learning_rate=NN_learning_rate, NN_mid_activation=NN_mid_activation, learning_feedback_scale=learning_feedback_scale, agents_can_head_home=agents_can_head_home,
                                   net_benefit_feedback=net_benefit_feedback, NN_initial_random_multiplier=NN_initial_random_multiplier, NN_inputs=NN_inputs, sigmoid_coefficient=sigmoid_coefficient,
                                   memory_decay_rate=memory_decay_rate, print_serviced_locations=print_serviced_locations, print_MRS_std_charts=print_MRS_std_charts,
                                   max_age_at_birth=max_age_at_birth, prop_KI_agents=prop_KI_agents, stop_trading=stop_trading, write_detailed_S_D_data=write_detailed_S_D_data,
                                   run_dist_to_mkt_OLS=run_dist_to_mkt_OLS, max_prob_det=max_prob_det, min_prob_det=min_prob_det, child_res=child_res,
                                   for_skill_change=for_skill_change, for_skill_slope=for_skill_slope, gen_equ_thresh=gen_equ_thresh, thresh_probs_charts_show_thresh=thresh_probs_charts_show_thresh,
                                   OLS_include=OLS_include, propensities_change=propensities_change, adjust_props_r_linear=adjust_props_r_linear, trade_at_trgt_precise=trade_at_trgt_precise,
                                   loss_aversion_degree=loss_aversion_degree, print_PTP_effect=print_PTP_effect, outcome_error_std=outcome_error_std, limit_props=limit_props, limit_child_props=limit_child_props,
                                   start_props=start_props, show_al_capones=show_al_capones, len_reputations_mem=len_reputations_mem, fs_floor=fs_floor, pop_av=pop_av,
                                   show_res_conc_charts=show_res_conc_charts, gossip=gossip, same_agents=same_agents, habit_deteriorates_mkts=habit_deteriorates_mkts, habit_val_mkts=habit_val_mkts,
                                   habit_val_props=habit_val_props
                                   )

        print('\n time stamp in multi_sims() directly after run_sim() completed: ', dt.datetime.now())

        st = dt.datetime.now()

        # This method updates the various databases
        SSO.add_to_dbs(single_sim_data)
        SSO.numb_of_sims += 1

        print('\n time stamp in multi_sims() after SSO.add_to_dbs: ', dt.datetime.now())

        add_to_dbs_time = dt.datetime.now() - st

        print('\n add_to_dbs_time =', length_of_time(add_to_dbs_time))

        if print_fine_dets == 1:
            print('\n\n single_sim_data =\n', single_sim_data)

#        print('\n SSO.population_data[-1][-1] =', SSO.population_data[-1][-1])

        st = dt.datetime.now()

        if (SSO.numb_of_sims % 1 == 0 or SSO.numb_of_sims == num_runs) or print_voting_only == 1:   #  and SSO.population_data[-1][-1] > 0

            SSO.save_sim_set_data(sim_set_folder, rounds, for_strat_parts, constitutional_voting, start_const_proces, const_proc_test_period, constitutional_exp,
                                  respect_property_rights, file_type, black_shoop_exp, two_tribes, fight_skill, plotly_online=0, print_fine_dets=0)

        save_sim_set_time = dt.datetime.now() - st

        print('\n time stamp in multi_sims() after SSO.save_sim_set_data: ', dt.datetime.now())

        print('\n save_sim_set_time =', length_of_time(save_sim_set_time))


def run_sim(
            # name scenario
            scenario='default', readme_notes='default',
            # Core structural parameters formal_inst
            rounds=1000, dimen_density=10, agent_homes='even', homes_spacing='hex', popn_ch='vary', mating_thresh=125, agents_die_old_age=None, max_age_at_birth=250,
            # - agents
            agent_res_init=50, agent_res_init_std=5, local_net_rad=11, agents_comm_prob=0.01, cognition_factor=0.1, for_strat_parts=5, start_child_births=100, child_res='proportional', memory_decay_rate=0.2,
            # - foraging
            init_res_lev_per_agent=2, for_skill_r=0.01, max_prob_det=1.0, min_prob_det=0.2, for_skill_change='logistic', for_skill_slope=0.001,
            # - searching & trading
            trade_moves=50, agents_trade=1, wait_at_tgt_moves=25, trade_prob_mem=5, trade_choice='full', goods_signal='none', vision_len=1,
            trade_loc='home', agent_mem_length=4, cp_trans_weight=0.5, granular_mem=0, limit_agent_interaction=5,
            trade_prices='variable', trgt_sel='roulette', trade_when_trgt=1, trade_movemnt='mixed', min_trans_Q=0.01, must_update_neighs=1,

            # Pricing & General Equilibrium Issues
            price_mean='geometric', force_prices='float', fixed_price=1.0, fixed_price_day=0, find_gen_equ_PQ=1, gen_equ_wh_lps=100, gen_equ_thresh=0.01, Walrasian_Trading=0,

            # Parallelism
            use_parallel_code=0, price_grid_dimen=10, test_par_code=1,

            # Famine
            res_depletion=0, tot_rounds_depl=200, fount_dep=[0, 1], fount_depl_ratio=0.5, stop_trading=False,

            # Keynesian Institution
            allow_Keynes_Inst=0, Keynes_round=200, keynesian_ratio=0.5, num_KI_agents=25, loc_mkt='avoid_interference', restrict_by_district=0, prop_KI_agents=0.0,

            # Constitutional Issues
            constitutional_voting=0, applied_constitutions=[1, 2, 3, 4, 5], constitutional_exp=0, start_const_proces=1000, const_proc_test_period=1000, num_experiments=5, const_mkt_opens=0,

            # Second Model: Main Params
            respect_property_rights=1, fight_cost=-0.3, PR_res_init=200, PR_mating_threshold=300,
            propensities_change='linear', adjust_props_r_linear=0.01, adjust_props_r=0.06, net_benefit_feedback='relative_fb_only', learning_feedback_scale=(1/2.0), loss_aversion_degree=None,
            start_props='set', start_prop_steal_mean=0.5, start_prop_steal_std=0.1, start_prop_fight_back_mean=0.5, start_prop_fight_back_std=0.1,
            limit_props=0, prop_steal_ceil=0.999, prop_steal_floor=0.001, prop_fight_back_ceil=0.999, prop_fight_back_floor=0.001,
            strat_choice='propensities', strangers_if_unknown=0, stranger_int=None,
            fight_balance='50_50', agent_intn_beta=0.5,
            agree_location='none', len_reputations_mem=20, target_location_weights='crude', local_fight='none', trade_at_trgt_precise=0, gossip=1,
            intn_error_std=0.0, outcome_error_std=0.05,
            agent_avoid_muggers=1, agents_can_head_home=None,
            limit_child_props=0, children_props='mean_props_and_dev', child_prop_std=0.0,
            allow_retarget=0,
            delib='habit', run_habit_timings_exps=0,

            # Second Model: param space and experiments
            change_one_only=0, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5,
            black_shoop_exp=0, black_shoop_pop='low', black_shoop_prop_start=1.00,
            formal_inst=0, prob_fine=1.0, fine=-0.5,
            fight_skill=None, fs_floor=0.0, fight_skill_r=0.01,
            fix_prop_fb=None, fixed_prop_steal=None, fix_ps_fb_0=None,
            assumed_props=0.5,
            start_1_rich_agent=0,
            clear_of_fights_radius=5,
            corruption_prop_charge=0, pop_av='median',
            two_tribes=0, new_mkt_round=1000, initial_fount_stock_high=72, single_tribe=0, two_tribes_inst=0,
            same_agents=0,

            # Neural Networks
            use_NNs=0, num_NNs=2, NN_dimensions=[14, 14, 14, 2], NN_learning_rate=0.1, NN_mid_activation='sigmoid', children_inherit_parents_NNs=1, NN_initial_random_multiplier=0.01,
            NN_inputs='game_6', NN_dimensions_ps=[10, 10, 10, 2], NN_dimensions_pfb=[4, 4, 4, 2], sigmoid_coefficient=1.0,

            # Steady state starts
            ststst=[0, 25, [1.0, 0.2], [20, 20]],

            # Habituation
            habit_deteriorates_mkts=0, habit_val_mkts=0.0, habit_val_props=0.0,

            # Admin
            suite_no=0, num_sim_sets=0, sim_no=0, total_runs=1, create_dir=1, record_dead_agents=1, save_folder=single_sims_data_folder,
            save_ps_cloud_folder=None, calc_timings=0, run_code_tests=0, track_game_types=1, run_dist_to_mkt_OLS=0, OLS_include=[],

            # Printing & charts
            track_agent=None, heatmap_days_show=100, print_dets=0, print_fine_dets=0, print_charts=1, print_det_charts=0, print_histo=1, print_3d_histo=0, print_heat_map=1, heatmap_story=1,
            heatmap_story_segs=20, random_rounds_start=0, cluster_lag=5, print_round_trans=0,
            print_move_heat_maps=0, SD_charts_freq=100, end_of_round_rpt=0, print_plotly_charts=1, plotly_online=0, printed_segment_size=100, mov_av_days_threshold_chart=10,
            print_MRS_std_charts=0, print_end_of_round_charts=1, sign_mkt_thresh=2, plotly_sharing='private', file_type='html', print_for=0, print_agents_interact=0, print_serviced_locations=0,
            write_detailed_S_D_data=0, print_gross_trans_data=1, thresh_probs_charts_show_thresh=1, proportion_in_plotly_charts=1.0, track_interactions_detailed=0, use_original_model_struct=0,
            print_PTP_effect=None, show_res_conc_charts=[0, 24, 49], show_al_capones=0, ps_corr=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 250, 300, 350, 400, 450]
            ):

    """This function controls a single run - it is the main function in the whole file.  Note the default parameters correspond to the first (markets) model
    but the code at the start of this function changes the default parameters to those of the second model, when respect_property_rights=0."""

    # Important variables:
    #
    # - num_agents is the number of starting agents: note that if agents_home == 'even' then the square root of this number
    # must be an integer e.g. 144 => 12.
    # - dimen_density controls the dimensions of the grid: the grid's x and y dimensions = sqrt(num_agents) * dimen_density.
    # This number controls the overall density of the agents on the grid.
    # - for_strat_parts is the number of parts in agents' foraging strategies.  This is also the number of time slots in a day.
    # - agent_res_init is the mean initial level of reserves of each of the resources given to all agents.
    # = agent_res_init_std is the standard deviation of the initial level of reserves (mean and std are combined to form a
    # normal distribution from which each agent's reserve level for each resource is chosen).
    # - num_res_founts.  The number of resources in the environment (i.e. number of fountains).
    # - init_res_level is the initial level given to each resource fountain.
    # - prob_res_detection. Agents' skill at detecting the resources is given by a probability of detection. In the first
    # simulation, I start with a fixed probability for all fountains (e.g. prob = 0.3).
    # - min_prob_det gives a floor to the prob of detection: the idea is that agents do not become totally useless at foraging
    # for a particular resource - there is a minimum level of detection.
    # - max_prob_det gives a ceiling to the prob of detection: agents' cognition is limited to this maximum skill level.
    # - dimen denoted the dimensions of the town_grid (dimen x dimen).
    # - vision_len is the distance an agent can see in the town_grid (when trying to look for agents with which to trade).
    # - trade_moves is the number of rounds in which agents attempting to trade get to move around the town_grid.
    # - trade_movemnt == 'random' means the agents don't set a target, they just move randomly; and 'set' means they move to a
    # set target.  'mixed' means they initally have random then they switch to set after 'random_rounds_start' rounds.
    # - agents_trade is a variable which controls whether the agents trade or not (0 = they don't, 1 = they do).
    # - wait_at_tgt_moves is the number of moves an agent will wait at its target location before moving away.
    # - for_skill_r is used as a parameter in the logistic equation associated with changes in skill levels (see below).
    # - track_agent == 1 means we track a randomly chosen agent during its 'life'.
    # - print_histo == 1 means a histogram of trading data (locations) will be printed.
    # - print_3d_histo == 1 means a 3d histogram is printed showing trades in each town grid cell.
    # - print_heat_map == 1 means a 2d heat map is printed showing trades in each town grid cell.
    # - trade_loc concerns the starting location of agent who are trading: if == 'home' then they start from their home
    # location; if == 'random' then they start from a random location in each round; if 'fountain' they start from the last fountain visited.
    # - result_main_fold is the main folder where data is kept - we use sub-folders below to organise further.
    # - local_net_rad determines the radius of an agent's local network, from which they judge the likelihood of trading. They
    # take an average of transactions / goods being sold from their 'neighbour' agents over the past [5] rounds.
    # - print_dets = 1 means the higher level details are printed.
    # - print_fine_dets = 1 means a finer level of detail of output is printed.
    # - trade_prob_mem is the length of memory (in rounds) over which an agent assesses the likelihood of trading.
    # - create_dir = 1 creates a directory for saving data & charts.
    # - agent_homes='even' means agents' homes are distributed evenly across the grid and also the population is kept constant.
    # If agent_homes='random' then homes locations are randomly distributed on the grid.
    # - trgt_sel is about target selection: = 'WTA' is winner takes all (the location with the most trades is selected); and
    # == 'roulette' is a 'roulette wheel' (weighted random) selection of location from a relevant array.
    # - end_of_round_rpt prints the end of round report corresponding to the tracking_agent.
    # - trade_when_trgt == 1 means the agent only trades when it gets to its target location on the grid; otherwise it moves to
    # the target. wait_at_tgt_moves still applies.
    # - cluster_lag is the number of periods over which the cluster data are averaged i.e. the lag.
    # - print_round_trans allows us to print transactions data in each round (= frequency of printing e.g. 10) or not (= 0).
    # - trade_choice is about whether agents can sell and buy multiple goods or whether they are restricted to a single pair:
    # 'full' means they can buy & sell any combination of goods; and 'pair' means they are restricted to one pair.
    # - goods_signal is about whether agents can see what other agents are buying and selling.  If == 'sale' then an agent can
    # only tell what other agents are selling; whereas if == 'both' then it knows both selling and buying.
    # - popn_ch is a parameter which decides if the population can vary or not. = 'fixed' or 'vary'.
    # - agent_mem_length is the number of rounds the agent can remember, used when setting a location target to head toward
    # when trading.
    # - cp_trans_weight is used when setting the target location ahead of trading: it is the weight attached to transaction
    # locations the agent has heard about from others, with the weight of transactions it was involved in getting weight = 1.
    # - agents_comm_likld is the number of agents any agent is expected to communicate with in order to exchange information
    # about transaction locations.
    # - granular_mem represents 'granular memory': if == 1 then the agents access their memory of transaction locations by
    # goods sold / bought; if == 0 then they do not.
    # - print_move_heat_maps = 1 means we print off move-by-move heatmaps.
    # - trade_prices determines whether the agents trade at a fixed price ('fixed') or at a variable price ('variable').
    # - min_trans_Q is the minimum quantity of resources which must be traded by agents (stops infintesimally small amounts
    # being traded).
    # - gen_equ_thresh is 'general equilibrium threshold', which is a measure of accuracy for the market clearing quantities
    # in the function which estimates these via a while loop.  The smaller the number, the more accurate but the longer the
    # will take.  Default = 0.01.
    # - gen_equ_wh_lps is the number of while loops in the function which finds general equilibrium prices.
    # - find_gen_equ_PQ controls whether we bother to find the gen equ prices and quantities.
    # - res_depletion is a number corresponding to the round when fountain resources become depleted i.e. famine. If the
    # number == 0 then we don't have any sort of resource depletion; if > 0 then this corresponds to the round a depletion
    # starts.
    # - tot_rounds_depl is the number of rounds the fountain(s) will be depleted for.
    # - fount_dep corresponds to which resources are depleted - this is an array of numbers.
    # - fount_depl_ratio is the rate of depletion of the Fountain resource i.e. new starting reserve level is
    # initial level * fount_depl_ratio.
    # - allow_Keynes_Inst creates a Keynesian Instition (unless == 0). 'sparse' means a KI is created in areas which agents
    # who cannot get to a market can get to; and 'total' means we try to shift a pre-existing instititon for all agents.
    # - homes_spacing is about the spacing of agents on the grid: this can be 'square' or 'hex'.
    # - use_parallel_code switches parallel code on or off.  Off means the code will run slower.
    # - price_grid_dimen is the size of the price grid dimension used for the optimization process.
    # - test_par_code = 1 means we deploy lots of testing aparatus for the parallel proces (= 0 we do not).
    # - note that to print a chart with high graphic density, go to the function call and set dpi = 'high'.
    # - force_prices determines whether the agents use the market clearing prices in transactions, if forced_prices == 'optimal' then
    # any value of price_mean is ignored.
    # - fixed_price: if force_prices == 'fixed' then we use this value to fix the price.
    # - constitutional_voting means agents go through a process of evaluating 4 different constitutions and then vote on their preference.
    # - Walrasian_Trading == 1 means the trading process is ignored in place of a Walrasian auctioneer approach, i.e., the price is market
    # clearing and the volume transacted is determined by the agents' ideal trades at that price.
    # - ststst is about a steady state start: if ststst[0] == 1 then we force specific start conditions on the agents; ststst[1] is the
    # number of agents; ststst[2] is max and min detection probs; the ststst[3] starting market location, which is a grid location; and
    # [4] is about the resource distribution of agents: if == 'even' then the population start off with a uniform distribution.
    # - respect_property_rights: if == 1 then the agents only trade; they don't fight; however, if == 0 they might try to steal from each other.
    # - adjust_props_r is the 'malthus r' for adjusting the prop_steal and prop_fight_back values of each agent via a logistic equation.
    # - start_props determines of the agents' prop_steal and prop_fight_back values are instantiated: 'random' or 'set'.
    # - if start_props == 'set' then start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std are used to
    # create initial values of prop_steal and prop_fight_back via a normal distribution with relevant mean and std.
    # - fight_cost is the gross deduction in both resources to the agents' agent_res_array when they fight.
    # - agent_intn_beta is 'agent interaction beta': when updating their prop_steal and prop_fight_back, agents don't just learn from their own benefit
    # or cost of the interaction - they also observe their counterparty's benefit or cost.  This is incorporated in to the agent's learning but with
    # a weight of agent_intn_beta (relative to the weight given to the agent's direct benefit / cost.
    # - len_reputations_mem: we restrict the agents' memories v-a-v recalling the reputation of other agents.  len_reputations_mem is the number
    # of rounds which covers the agents' memories (i.e. memories start at day - len_reputations_mem).
    # - intn_error_std: when the agents don't respect property rights they must form expectations about about the expected benefit of interacting
    # with other agents.  They use a variety of information about themselves and agent - intn_error_std is an error term added to any expectation
    # formed (using a normal distribution with this as standard deviation).
    # - outcome_error_std adds an error to each of the 12 outputs in interactions - outcome_error_std is the standard deviation of that error term.
    # - record_dead_agents = 1 means we record all the dead agents - turn this off when we are running v long sims (e.g. > 20k rounds).
    # - agent_avoid_muggers = 1: if an agent believes their expected gain from an interaction with a counterpart is negative and that counterpart's
    # expected gain is positive then they will actively avoid that agent, i.e., move away from it.
    # - agree_location can be 'weak', 'strong', 'super_strong', or 'none': if 'strong', two agents who communicate (they are known to each other and their expected gains / loss
    # from transacting are both positive) will exchange trans location and then agree up front to meet somewhere in the next round.  If they transacted
    # in the previous round, this location will be at the same location; else it will be randomly chosen.  If 'weak' then 2 agents exchange trans and
    # fight information and they will select a location to meet at randomly (if neither have any + fight locations) or they will select a location furthest away
    # from any known (-) fight locations.  If 'super_strong' then the agents run a sophisticated self-organisation process at the end of each round.  If 'none'
    # then the agent reverts to the original approach to choosing a target location ie no incorpration of fight information.
    # - trade_at_trgt_precise: if the agent is heading to a target location, if this == 0 then the agent can trade on the move before getting to the target; if
    # == 1 then it can only trade at target.
    # - fight_balance: if two agents fight, this dictates the balance of power in the fight.  if == '50_50' then agents have an equal chance, whereas if
    # == res_power then the advantage is with the agent with the most resources.
    # - use_original_model_struct == 1 means we use the original model structure while not respecting property rights, which is to replicate that approach at key points.
    # - sign_mkt_thresh is the threshold number of agents for any location to be printed out, e.g., if sign_mkt_thresh == 3 then any location which saw more than or
    # equal to 3 agents trade will be recorded as significant.
    # - proportion_in_plotly_charts helps to make the plotly charts showing prop_steal and prop_fight_back less busy.  We will include only this proportion (e.g. 0.3)
    # of the total number of agents.
    # - two_tribes: if == 1 then the population is split in to 2 communities, each in diagonally opposite quadrants of the grid.  This is to experiment with
    # formal property rights enabling trade between strangers.  The communities are called the 'sharks' and the 'jets'.
    # - black_shoop_exp is where two parents give birth to a black shoop (singular of sheep!) child, which has prop_steal and prop_fight_back = 1.  The question is whether it can survive: this
    # is the equivalent to the invading defector in the iterated prisoners' dilemma game.  == 1 means only one shoop is born.  == 'all' means all children are black shoops.
    # - black_shoop_pop defines the conditions under which a black shoop is born: == 0 means the black shoop will be the first child born in a sim (the
    # easiest conditions); whereas == 54 means it will be born when the population is that size and a new baby is then born (54 is close to max when fountain
    # stocks = 72).
    # - formal_inst == 0 means no formal institution; == 'fine_only' means the offender is fined with no compenation to the damaged party; and == 'compensate' means
    # the offender is fined and the damaged party compensated.
    # - fight_skill is about whether we allow agents to be skilled (or not) at fighting, which can be used in interactions when respect_property_rights == 0.
    # if fight_skill == None then we don't use it; otherwise we use a number (like 0.5, as a starting skill).
    # - agents_die_old_age = int means the agents die of old age at this age.
    # - fix_prop_fb helps us fix prop_fb at zero, making the agents' interaction a simpler 2-strategy affair.  If == None then we ignore this, if == 0 then we fix prop_fb at zero.
    # - fixed_prop_steal helps us fixed the propensity to steal at 1.0 for all agents at instantiation and any children.  If == None this is ignored, if == 1.0 then this
    # fixes prop_steal at 1.0 with 0 std.
    # - fix_ps_fb_0 allows us to set ps and p_fb = 0; if == 1 then this is done, if None it is ignored.
    # - change_one_only allows us to change the propensities of one agent only, to test 'social construction' in the model.
    # - ch_ag_prop_steal and ch_ag_prop_fb are the change agent's starting props.
    # - PR_mating_threshold allows us to change the mating threshold when the agents don't respect property rights.
    # - PR_res_init allows us to change initial res endownments when agents dont respect property rights.
    # - start_1_rich_agent = 1 allows us to explore fight power issues: we allow one agent 1,000 resources.
    # - clear_of_fights_radius: if we use super_strong agreed_location then agents will avoid any location and squares around it (determined by this radius).
    # - corruption_prop_charge is used when formal institutions are in effect: if == 1.0 then there is no corruption; otherwise, when a fine is being levvied, the propbability of
    # corruption in the process is taken as the mean prop to steal in the population, and corruption_prop_charge is multipled by the fine to arrive at the bribe.
    # - strat_choice is 'strategic choice' in game interactions: 'propensities' means use propensities; and 'rational' means use rational choice approach.
    # - strangers_if_unknown: if strat_choice == 'propensities' we have two options wrt strangers: either the agents interact assuming ps and pfb = 0.5 (strangers_if_unknown = 0)
    # or strangers_if_unknown = 1: they interact depending on whether the agents know of each other or not.  If they don't then we have 3 ways to decide the outcomes - stranger_int
    # decides this: either = 'acq' in which case the agents always acquiesce in Q2 & 3; = 'fb' so they fight back in Q2 & 3; or = 'full' in which case they use full rationality to decide.
    # - start_child_births is the minimum age of agents to be parents.
    # - local_fight concerns agents' targetting: if 'zeroed' then agents will ignore grid squares around any location where they have a negative score; and if 'minus_one' then they
    # will reduce the scores in nearby squares by 1.
    # - target_location_weights is used when agents are setting weights in their locations_dicts: == 'crude' means +1 for transactions where goods changed hands, cp_trans_weight
    # for transactions heard about (and where goods changed hands), -1 for fights lost, +1 for fights won, -1 * cp_trans_weight for fights heard about.  If == 'reduced_value' then
    # the agents use the reduced values of fights / transactions.
    # - must_update_neighs: we only call update_neighbours if we have to, i.e., when there have been new agents born.
    # - use_NNs == 1 means the agents use their neural networks to make theft / trading / fight back decisions (== 0 means they don't)
    # - NN_dimensions is an array dictating the dimensions of the NN.
    # - NN_learning_rate is the learning rate for the neural networks.
    # - learning_feedback_scale - if '+/-1' then the gains & losses applied to NN arte either +1 or -1.  Otherwise, we take the sign * (net gain ** learning_feedback_scale).
    # - NN_initial_random_multiplier: when W parameters are initialised, np.random.randn is used and then each entry is multiplied by NN_initial_random_multiplier (default = 0.01)
    # to bring these values closer to zero.
    # - NN_inputs concerns the input variables in to the NN: 'game_6' is the default and uses all 12 of the full-game 6 scenarios; 'mixed' uses a 4-way reduced game to decide ps
    # and a 2-way game to decide pfb; and 'ress' uses the agents' resources and baskets.
    # - net_benefit_feedback is about whether the agents consider their net gain (loss) from a transaction in absolute terms or relative terms (relative to expectations).  Options:
    # absolute (just use crude benefit / loss to agents), relative (relative to expected outcomes), and relative_fb_only (absolute with ps and pfb is relative to what we would have expected
    # from quadrant 2 or 3 - this accommodates benefit of fighting back relative to potential loss of not).
    # - run_dist_to_mkt_OLS runs code which runs an OLS regression on the distance to market versus resource accumulation.
    # - child_res is concerned with how the childrens' resources are instantiated.  If 'proportional' then the child gets a propoertion of the parents' resources; if 'gross', the
    # children get agent_res_init (varied by sd).  The amount taken by the child from each parent is deducted from the parents' res arrays.
    # - for_skill_change determines how the agents' foraging skills change: if 'logistic' (default) a logistic equation is used; and if 'linear' then they change linearly.
    # - for_skill_slope: if for_skill_change is 'linear' then this slop is used to determine the speed of skill change (default of 0.001 is meant to allow change from 0.5 to 0.99
    # in 200 rounds if all slots are for same resource - approx. the same as when using 'logistic' change).
    # - OLS_include is an array which contains all the elements of an OLS to include.
    # - propensities_change determines the way propensities change - they can be 'linear' or 'logistic'.
    # - adjust_props_r_linear is the rate of change when propensities change in a linear way.
    # - two_tribes - this was an experiment which had two different tribes who met and interacted during the sims - it is now redundant but I've kept the code in case I decide to try it.
    # - initial_fount_stock_high: when we have 2 tribes, each forages for 2 resources but 'sharks' have more of res 0 and 'jets' have more of res 1 (twice as much as the other).
    # This variable sets the stock for each fountain.
    # - new_mkt_round links to two tribes, which is now redundant.
    # - single_tribe is for testing what happens to one tribe when its resources are imbalanced.
    # - print_PTP_effect prints data related to the 'pass the pacel' effect.  Note default is None, if not None, it determines the total resources acquired by one agent above which
    # certain data is printed.
    # - limit_props means we limit the agents' propensities within ceiling and floor; if not, we allow p_s and p_fb to go above 1 and below 0 but apply an 'effective' p_s and p_fb
    # which == 0 when < 0 and == 1 when > 1.
    # - show_res_conc_charts allows us to see resource concentration in the form of bar charts during the trading phase.  show_res_conc_charts must be an array with move numbers in
    # so we see the bar charts for those moves in each round.
    # - assumed_props is the assumed propensities to steal and fb when agents have no memories of other agents.
    # - pop_av relates to corruption: what is the average ps used to determine proby of corruption ('median' or 'mean').
    # - gossip was included to have a parameter which prevented agents from communicating about reputations in sims using the seond model, i.e., gossip = 0 switches this off.  Note
    # this meant they could still retain their own information about other agents, from direct experience.
    # - same_agents makes the agents identical in all sims, so same resources, propensities, and for strats.
    # - delib relates to the nature of agents' deliberation when deciding whether to steal or trade: full_delib means `full deliberation' which means agents always compare a
    # random number to their propensity to steal; whereas `habit' means we first ask if p_s is above 1 or below 0, and use a random number if not. If 'both' then we run both sets
    # of code as an experiment to compare run times.
    # - ps_corr is about the correlation between props to steal. The numbers in the list designate the `base' round number against which other ps data is compared.

    print('\n time stamp at start of run_sim(): ', dt.datetime.now(), '\n')

    if calc_timings:

        start_time = dt.datetime.now()

    if constitutional_voting:
        rounds = start_const_proces + (len(applied_constitutions) * const_proc_test_period)

    dimen = int(math.sqrt(num_agents) * dimen_density)
    init_res_level = init_res_lev_per_agent * num_agents

    # if this is true, we change these default parameters:
    if respect_property_rights == 0:

        target_location_weights = 'reduced_value'
        memory_decay_rate = 0.2

        agents_comm_prob = 0.25

        if agree_location == 'super_strong':
            
            agents_comm_prob = 1.0

        agent_mem_length = 20
        agent_res_init = PR_res_init
        mating_thresh = PR_mating_threshold

        if propensities_change == 'linear':

            prop_steal_ceil = 1.0
            prop_steal_floor = 0.0
            prop_fight_back_ceil = 1.0
            prop_fight_back_floor = 0.0

        elif propensities_change == 'logistic':

            prop_steal_ceil = 0.999
            prop_steal_floor = 0.001
            prop_fight_back_ceil = 0.999
            prop_fight_back_floor = 0.001

        if two_tribes == 1:
            
            # note: must change num_agents manually
            dimen = int(math.sqrt(num_agents / 2.0) * dimen_density * 2.0)
            
            init_res_level = init_res_lev_per_agent * num_agents / 2.0
            initial_fount_stock_high = init_res_level * 2

        if single_tribe == 1:
            
            init_res_level = init_res_lev_per_agent * num_agents / 2.0
            initial_fount_stock_high = init_res_level * 2

    # if scenario != 'adjust_travel_dist' and two_tribes == 0:
    #
    #     wait_at_tgt_moves = int((dimen_density * (num_agents ** 0.5)) / 2.0)    # this ensures the first agents to arrive at a market wait for the last agent
    #     trade_moves = wait_at_tgt_moves * 2

    if two_tribes:

        wait_at_tgt_moves = int(dimen_density * (num_agents ** 0.5))        
        trade_moves = wait_at_tgt_moves * 2

    local_net_rad = dimen_density + 1

    # if ststst[0] == 1:
    #
    #     num_agents = ststst[1]

    # place all of the paramters in to a dictionary, which helps when we record these in data files:
    params_dict = locals()

    # create an object which saves all starting parameters
    params = Parameters_Object(params_dict, ststst, fount_dep, applied_constitutions, NN_dimensions, NN_dimensions_ps,
                               NN_dimensions_pfb, write_detailed_S_D_data, child_res, show_res_conc_charts, learning_feedback_scale,
                               pop_av)

    # we start by creating folders in a directory in which we save charts and data (we create 'blank' variables first as they
    # will be passed to functions below):
#    data_folder = ""
    df_daily = ""

    if create_dir:

        # designate a folder which is the variable 'result_main_fold' plus a date/time stamp:
        run_folder = "%s/%d_%d_%d_%d_%d_%d_%d_%d" % (save_folder, sim_no,
                                                 dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day,
                                                 dt.datetime.now().hour, dt.datetime.now().minute, dt.datetime.now().second,
                                                 dt.datetime.now().microsecond / 100000)

        params.run_folder = run_folder

        # this is a folder for prop steal cloud charts, at the multi-sim level
        params.save_ps_cloud_folder = save_ps_cloud_folder
        params.sim_no = sim_no

        # this line creates the directory
        if os.path.exists(run_folder) == False:
            os.makedirs(run_folder)

        # create correlation coefficient directory
        run_corr_coeff_folder = "%s/Correlation_Coefficients" % run_folder
        params.run_corr_coeff_folder = run_corr_coeff_folder

        if os.path.exists(run_corr_coeff_folder) == False:
            os.makedirs(run_corr_coeff_folder)

        # create directory for periodic charts (daily data in certain rounds)
        run_periodic_day_charts_folder = "%s/Daily_Periodic" % run_folder
        params.run_periodic_day_charts_folder = run_periodic_day_charts_folder

        if os.path.exists(run_periodic_day_charts_folder) == False:
            os.makedirs(run_periodic_day_charts_folder)

        # create directory for interaction contributions
        run_contributions_to_props_folder = "%s/Contributions_to_PS_PFB" % run_folder
        params.run_contributions_to_props_folder = run_contributions_to_props_folder

        if os.path.exists(run_contributions_to_props_folder) == False:
            os.makedirs(run_contributions_to_props_folder)

        # create directory for propensities charts
        run_propensities_charts_folder = "%s/Propensities_Charts" % run_folder
        params.run_propensities_charts_folder = run_propensities_charts_folder

        if os.path.exists(run_propensities_charts_folder) == False:
            os.makedirs(run_propensities_charts_folder)

        # create directory for fights charts
        run_fights_charts_folder = "%s/Fights_Charts" % run_folder
        params.run_fights_charts_folder = run_fights_charts_folder

        if os.path.exists(run_fights_charts_folder) == False:
            os.makedirs(run_fights_charts_folder)

        # create directory for game types
        run_game_types_folder = "%s/Game_Types" % run_folder
        params.run_game_types_folder = run_game_types_folder

        if os.path.exists(run_game_types_folder) == False:
            os.makedirs(run_game_types_folder)

        # create directory for prices
        run_prices_folder = "%s/Prices" % run_folder
        params.run_prices_folder = run_prices_folder

        if os.path.exists(run_prices_folder) == False:
            os.makedirs(run_prices_folder)

        # create directory for target locations
        run_target_locations_folder = "%s/Target_Locations" % run_folder
        params.run_target_locations_folder = run_target_locations_folder

        if os.path.exists(run_target_locations_folder) == False:
            os.makedirs(run_target_locations_folder)

        # create directory for transactions data
        run_transactions_folder = "%s/Transactions" % run_folder
        params.run_transactions_folder = run_transactions_folder

        if os.path.exists(run_transactions_folder) == False:
            os.makedirs(run_transactions_folder)

        # create directory for turnover data
        run_turnover_folder = "%s/Turnover" % run_folder
        params.run_turnover_folder = run_turnover_folder

        if os.path.exists(run_turnover_folder) == False:
            os.makedirs(run_turnover_folder)

        # create directory for specialisation data
        run_specialisation_folder = "%s/Specialisation" % run_folder
        params.run_specialisation_folder = run_specialisation_folder

        if os.path.exists(run_specialisation_folder) == False:
            os.makedirs(run_specialisation_folder)

        # create directory for population and home data
        run_population_folder = "%s/Population" % run_folder
        params.run_population_folder = run_population_folder

        if os.path.exists(run_population_folder) == False:
            os.makedirs(run_population_folder)

        # create directory for habituation experiment data:
        run_habituation_folder = "%s/Habituation_Exps" % run_folder
        params.run_habituation_folder = run_habituation_folder

        if os.path.exists(run_habituation_folder) == False:
            os.makedirs(run_habituation_folder)

        # if we want to store charts printed every round then we create a sub-directory in this data_folder:
        if print_round_trans != 0 or print_move_heat_maps != 0 or track_agent:

            df_daily = "%s/daily_data" % (run_folder)

            # indent this after finished track_agent exp
            os.makedirs(df_daily)

    # df_daily = "%s/daily_data" % (run_folder)
    # os.makedirs(df_daily)

    # straight away we write a read_me file to record parameters in a single file (this is done at the beginning in case
    # of errors in the code - having this data might help us find bugs)
    write_text_file_readme(run_folder, params_dict, scenario, readme_notes)

    # for parallelism: here in these two lines we copy num_agents to a constant variable in the c code
#    num_agents_ptr, num_agents_const_size = mod.get_global("num_agents")
#    driver.memcpy_htod(num_agents_ptr, int32(num_agents))

    ################################################################################################################
    ############################################ Instantiation #####################################################

    # Here we set up 5 objects: a population of databases, an agent population, a population of fountains, a town_grid and a Keynesian_Object_Population

    # First we set up an object which contains all of the databases we will use:
    dbs = Databases(params, rounds, dimen, for_strat_parts, trade_moves, run_folder, init_res_level, print_MRS_std_charts, constitutional_voting, num_experiments,
                    two_tribes, black_shoop_exp, agree_location)

    # Second, we set up a population of agents (this returns an object):
    agent_population = create_agents(params, dbs, print_dets, for_strat_parts, agent_res_init, agent_res_init_std, vision_len, dimen, print_fine_dets, rounds, trade_moves, trade_when_trgt, agent_homes, agent_mem_length, homes_spacing,
                                     cp_trans_weight, wait_at_tgt_moves, trade_prices, min_trans_Q, cognition_factor, trade_movemnt, start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean,
                                     start_prop_fight_back_std, prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, two_tribes, black_shoop_exp, fight_skill,  agents_die_old_age, fix_prop_fb,
                                     fixed_prop_steal, fix_ps_fb_0, stranger_int, corruption_prop_charge, popn_ch, must_update_neighs)

    dbs.rc_sub_folder = "%s/Resource_Concentration_Charts" % (run_folder)
    os.makedirs(dbs.rc_sub_folder)

    if start_1_rich_agent:
        
        agent_population.pop[-1].agent_res_array[0] = np.array([[start_1_rich_agent, start_1_rich_agent]], dtype=float)
        agent_population.wealthy_agent = agent_population.pop[-1]

        params.show_al_capones = 1

    # if we want to change the propensities of one agent only, to test social construction, we do this
    if change_one_only:

        if start_1_rich_agent:
            agent_population.change_agent = agent_population.pop[0]
        else:
            agent_population.change_agent = agent_population.pop[-1]

        agent_population.change_agent.prop_steal = ch_ag_prop_steal
        agent_population.change_agent.prop_fight_back = ch_ag_prop_fb
        
        agent_population.black_shoop_list.append(agent_population.change_agent)

        # create a data file to record change agent data
        black_shoop_file = '%s/change_agent_file.txt' % (run_folder)       

        with open(black_shoop_file, 'a') as myfile:
            myfile.write("This text file is for recording notes concerning a change_agent \n")

        agent_population.change_agent.black_shoop_file = black_shoop_file

        # this is a switch so we don't create any more black shoops after the first
#            agent_population.black_shoop_seen = 1

        print('\n A change_agent was born!!!! - dum dum duuuuum')

        text = '\n\nThe change agent was born on day 0  |  home = %s\n' % (agent_population.change_agent.home)
        with open(agent_population.change_agent.black_shoop_file, 'a') as myfile:
            myfile.write(text)

#    for agent in agent_population.pop:
#        
#        print('\n agent.agent_res_array =', agent.agent_res_array[0])


#    input("Press Enter to continue...")

    # show this agent's home if we are tracking this agent during the simulation
    if track_agent:
        print('\n agent_population.tracking_agent.home =', agent_population.tracking_agent.home, '\n')

    # if we want to force a steady state start, we apply the agents' detection prob conditions here
    if ststst[0] == 1:

        if ststst[4] == 'even':

            pop_res_distr = np.linspace(10, mating_thresh - 10, num_agents)

        for agent_num in range(num_agents):

            agent = agent_population.pop[agent_num]
    
            if agent_num == 0 or agent_num % 2 == 0:

                agent.detect_skills_array[0][0] = ststst[2][0]
                agent.detect_skills_array[0][1] = ststst[2][1]

                for res in range(for_strat_parts):

                    agent.for_strat_array[0][res] = 0

            else:      
    
                agent.detect_skills_array[0][1] = ststst[2][0]
                agent.detect_skills_array[0][0] = ststst[2][1]      

                for res in range(for_strat_parts):

                    agent.for_strat_array[0][res] = 1

            if agent_num == 0:

                agent.home = np.array([5, 5])

            else:

                agent.home = np.array([None, None])

            if ststst[4] == 'even':

                agent.agent_res_array[0][0] = pop_res_distr[agent_num]
                agent.agent_res_array[0][1] = pop_res_distr[agent_num]

            print('agent_num =', agent_num, 'detect_skills_array =', agent.detect_skills_array, 'for_strat_array =', agent.for_strat_array, 'home =', agent.home, 'agent.agent_res_array =', agent.agent_res_array, 'age', agent.age)

    # Third we set up a population of resource fountains:
    fountain_population = create_fountains(agent_population, print_dets, init_res_level, rounds, dimen, trade_loc, two_tribes, initial_fount_stock_high, single_tribe)

    # Fourth, create a class to manage a town in around which agents look for other agents with whom they might trade:
    town_grid = TownGrid(rounds, dimen, trade_moves, print_dets)

    # if we are forcing a steady state start we must locate the agents in the following way:
    if ststst[0] == 1 and agent_homes == 'even':

        for agent_num in range(num_agents):

#            print('agent_num ', agent_num, 'of', num_agents)

            # the first agent's location has already been declared as 5, 5
            if agent_num > 0:

                agent = agent_population.pop[agent_num]

                agent.home = place_agent_in_best_spot(agent_population, town_grid, two_tribes)
        
    # now illustrate homes_array via a heatmap if we're printing charts
    if print_charts == 1:

        # now we look at the home locations of the agents and plot these on a heatmap
        # create an array to record the locations
        homes_array = np.zeros(shape=(dimen, dimen))
    
        for agent in agent_population.pop:
    
            x_coord = int(agent.home[0])
            y_coord = int(agent.home[1])
    
            homes_array[x_coord][y_coord] += 1

        create_heat_map(dimen, homes_array, params.run_population_folder, 'Greys', '', "agent_homes_start", dpi='high')

    KO_pop = Keynesian_Object_Population()

    # before starting the iteration loop we create a new variable in order to change the variable trade_movemnt if it was
    # mixed to start
    if trade_movemnt == 'mixed':

        trade_movemnt_start = 'mixed'

    else:

        trade_movemnt_start = copy.copy(trade_movemnt)

    # Create a counter so we propose a KI for 10 days only
    KI_before = 0

#    print 'before iteration starts: trade_movemnt =', trade_movemnt
#    print 'before iteration starts: trade_movemnt_start =', trade_movemnt_start

    # if we are running the constitutional voting experiment, we need to set this counter at zero - it them counts upward through the rounds
    if constitutional_voting == 1:

        constitution_counter = 0

    # create a dict for str(agent) -> home locations
    str_agent_to_home_dict = dict()

    for agent in agent_population.pop:

        str_agent_to_home_dict[str(agent)] = agent.home

    # if we are using NNs, we create databases and also run the first set of tests on the new agents
    if use_NNs:

        dbs.NN_tests_rounds = []

        dbs.NN_tests_ps_ag_res_0 = []
        dbs.NN_tests_ps_ag_res_1 = []
        dbs.NN_tests_ps_ag_bsk_0 = []
        dbs.NN_tests_ps_ag_bsk_1 = []

        dbs.NN_tests_ps_cp_res_0 = []
        dbs.NN_tests_ps_cp_res_1 = []
        dbs.NN_tests_ps_cp_bsk_0 = []
        dbs.NN_tests_ps_cp_bsk_1 = []

        dbs.NN_tests_ps_cp_ps = []
        dbs.NN_tests_ps_cp_pfb = []

        dbs.NN_tests_pfb_ag_res_0 = []
        dbs.NN_tests_pfb_ag_res_1 = []
        dbs.NN_tests_pfb_ag_bsk_0 = []
        dbs.NN_tests_pfb_ag_bsk_1 = []

        dbs.NN_tests_pfb_cp_res_0 = []
        dbs.NN_tests_pfb_cp_res_1 = []
        dbs.NN_tests_pfb_cp_bsk_0 = []
        dbs.NN_tests_pfb_cp_bsk_1 = []

        dbs.NN_tests_pfb_cp_ps = []
        dbs.NN_tests_pfb_cp_pfb = []

        dbs.final_layer_ps_breakdown = []
        dbs.final_layer_pfb_breakdown = []

        # create a dictionary for names, pointers and iteration values
        dbs.NNs_names_dict = dict()
        dbs.NNs_iterations_dict = dict()
        dbs.index_values_dict = dict()

        dbs.NNs_names_dict['NN_tests_ps_ag_res_0'] = dbs.NN_tests_ps_ag_res_0
        dbs.NNs_names_dict['NN_tests_ps_ag_res_1'] = dbs.NN_tests_ps_ag_res_1
        dbs.NNs_names_dict['NN_tests_ps_ag_bsk_0'] = dbs.NN_tests_ps_ag_bsk_0
        dbs.NNs_names_dict['NN_tests_ps_ag_bsk_1'] = dbs.NN_tests_ps_ag_bsk_1

        dbs.NNs_names_dict['NN_tests_ps_cp_res_0'] = dbs.NN_tests_ps_cp_res_0
        dbs.NNs_names_dict['NN_tests_ps_cp_res_1'] = dbs.NN_tests_ps_cp_res_1
        dbs.NNs_names_dict['NN_tests_ps_cp_bsk_0'] = dbs.NN_tests_ps_cp_bsk_0
        dbs.NNs_names_dict['NN_tests_ps_cp_bsk_1'] = dbs.NN_tests_ps_cp_bsk_1

        dbs.NNs_names_dict['NN_tests_ps_cp_ps'] = dbs.NN_tests_ps_cp_ps
        dbs.NNs_names_dict['NN_tests_ps_cp_pfb'] = dbs.NN_tests_ps_cp_pfb

        dbs.NNs_names_dict['NN_tests_pfb_ag_res_0'] = dbs.NN_tests_pfb_ag_res_0
        dbs.NNs_names_dict['NN_tests_pfb_ag_res_1'] = dbs.NN_tests_pfb_ag_res_1
        dbs.NNs_names_dict['NN_tests_pfb_ag_bsk_0'] = dbs.NN_tests_pfb_ag_bsk_0
        dbs.NNs_names_dict['NN_tests_pfb_ag_bsk_1'] = dbs.NN_tests_pfb_ag_bsk_1

        dbs.NNs_names_dict['NN_tests_pfb_cp_res_0'] = dbs.NN_tests_pfb_cp_res_0
        dbs.NNs_names_dict['NN_tests_pfb_cp_res_1'] = dbs.NN_tests_pfb_cp_res_1
        dbs.NNs_names_dict['NN_tests_pfb_cp_bsk_0'] = dbs.NN_tests_pfb_cp_bsk_0
        dbs.NNs_names_dict['NN_tests_pfb_cp_bsk_1'] = dbs.NN_tests_pfb_cp_bsk_1

        dbs.NNs_names_dict['NN_tests_pfb_cp_ps'] = dbs.NN_tests_pfb_cp_ps
        dbs.NNs_names_dict['NN_tests_pfb_cp_pfb'] = dbs.NN_tests_pfb_cp_pfb

        dbs.NNs_iterations_dict['NN_tests_ps_ag_res_0'] = [75, 80, 85, 90, 95, 100, 105, 110, 115]
        dbs.NNs_iterations_dict['NN_tests_ps_ag_res_1'] = [85, 90, 95, 100, 105, 110, 115, 120, 125]
        dbs.NNs_iterations_dict['NN_tests_ps_ag_bsk_0'] = [0, 2, 4, 6, 8, 10, 50, 100]
        dbs.NNs_iterations_dict['NN_tests_ps_ag_bsk_1'] = [0, 2, 4, 6, 8, 10, 50, 100]

        dbs.NNs_iterations_dict['NN_tests_ps_cp_res_0'] = [85, 90, 95, 100, 105, 110, 115, 120, 125]
        dbs.NNs_iterations_dict['NN_tests_ps_cp_res_1'] = [75, 80, 85, 90, 95, 100, 105, 110, 115]
        dbs.NNs_iterations_dict['NN_tests_ps_cp_bsk_0'] = [0, 2, 4, 6, 8, 10, 50, 100]
        dbs.NNs_iterations_dict['NN_tests_ps_cp_bsk_1'] = [0, 2, 4, 6, 8, 10, 50, 100]

        dbs.NNs_iterations_dict['NN_tests_ps_cp_ps'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
        dbs.NNs_iterations_dict['NN_tests_ps_cp_pfb'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]

        dbs.NNs_iterations_dict['NN_tests_pfb_ag_res_0'] = [75, 80, 85, 90, 95, 100, 105, 110, 115]
        dbs.NNs_iterations_dict['NN_tests_pfb_ag_res_1'] = [85, 90, 95, 100, 105, 110, 115, 120, 125]
        dbs.NNs_iterations_dict['NN_tests_pfb_ag_bsk_0'] = [0, 2, 4, 6, 8, 10, 50, 100]
        dbs.NNs_iterations_dict['NN_tests_pfb_ag_bsk_1'] = [0, 2, 4, 6, 8, 10, 50, 100]

        dbs.NNs_iterations_dict['NN_tests_pfb_cp_res_0'] = [75, 80, 85, 90, 95, 100, 105, 110, 115]
        dbs.NNs_iterations_dict['NN_tests_pfb_cp_res_1'] = [85, 90, 95, 100, 105, 110, 115, 120, 125]
        dbs.NNs_iterations_dict['NN_tests_pfb_cp_bsk_0'] = [0, 2, 4, 6, 8, 10, 50, 100]
        dbs.NNs_iterations_dict['NN_tests_pfb_cp_bsk_1'] = [0, 2, 4, 6, 8, 10, 50, 100]

        dbs.NNs_iterations_dict['NN_tests_pfb_cp_ps'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
        dbs.NNs_iterations_dict['NN_tests_pfb_cp_pfb'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]

        dbs.index_values_dict['NN_tests_ps_ag_res_0'] = 4
        dbs.index_values_dict['NN_tests_ps_ag_res_1'] = 4
        dbs.index_values_dict['NN_tests_ps_ag_bsk_0'] = 1
        dbs.index_values_dict['NN_tests_ps_ag_bsk_1'] = 1

        dbs.index_values_dict['NN_tests_ps_cp_res_0'] = 4
        dbs.index_values_dict['NN_tests_ps_cp_res_1'] = 4
        dbs.index_values_dict['NN_tests_ps_cp_bsk_0'] = 1
        dbs.index_values_dict['NN_tests_ps_cp_bsk_1'] = 1

        dbs.index_values_dict['NN_tests_ps_cp_ps'] = 5
        dbs.index_values_dict['NN_tests_ps_cp_pfb'] = 5

        dbs.index_values_dict['NN_tests_pfb_ag_res_0'] = 4
        dbs.index_values_dict['NN_tests_pfb_ag_res_1'] = 4
        dbs.index_values_dict['NN_tests_pfb_ag_bsk_0'] = 1
        dbs.index_values_dict['NN_tests_pfb_ag_bsk_1'] = 1

        dbs.index_values_dict['NN_tests_pfb_cp_res_0'] = 4
        dbs.index_values_dict['NN_tests_pfb_cp_res_1'] = 4
        dbs.index_values_dict['NN_tests_pfb_cp_bsk_0'] = 1
        dbs.index_values_dict['NN_tests_pfb_cp_bsk_1'] = 1

        dbs.index_values_dict['NN_tests_pfb_cp_ps'] = 5
        dbs.index_values_dict['NN_tests_pfb_cp_pfb'] = 5

        dbs.NN_tests_rounds.append(0)

        test_NN_coefficients(params, 0, agent_population, fountain_population, dbs, use_start_basket=0, print_dets=0, print_fine_dets=0)

    if track_agent:
        track_agent_copy = copy.copy(track_agent)
    else:
        track_agent_copy = None

    if calc_timings:

        dbs.timings_dict = dict()

        overheads_time = dt.datetime.now() - start_time

        dbs.timings_dict['overheads'] = overheads_time
        dbs.timings_dict['foraging'] = []
        dbs.timings_dict['trading'] = []
        dbs.timings_dict['three_updates'] = []
        dbs.timings_dict['comms'] = []
        dbs.timings_dict['for_strats'] = []
        dbs.timings_dict['new_births'] = []

        dbs.timings_dict['trading_overhead'] = []

        dbs.timings_dict['trading_move_overhead'] = []
        dbs.timings_dict['trading_move_agent_mtt'] = []
        dbs.timings_dict['trading_move_agent_eval_own_grid_sq'] = []
        dbs.timings_dict['trading_move_agent_eval_exp_gains_own_square'] = []
        dbs.timings_dict['trading_move_agent_agents_interact'] = []
        dbs.timings_dict['trading_move_agent_eval_all_grid_sqs'] = []
        dbs.timings_dict['trading_move_agent_retargetting'] = []
        dbs.timings_dict['trading_move_agent_bilat_eval'] = []

    ################################################################################################################
    ######################################## start iteration loop ##################################################

    for round in np.arange(rounds, dtype=int):

        if track_agent_copy and round >= track_agent_copy:

            track_agent = params.track_agent = 1

        else:

            track_agent = params.track_agent = None

        # num_ps_pos = 0
        #
        # for ag in agent_population.pop:
        #     if ag.prop_steal > 0.0:
        #         num_ps_pos += 1
        #
        # if num_ps_pos == 1:
        #
        #     track_agent = params.track_agent = 1
        #     print('\n\n OK so there is one agent with positive prop_steal - let us take a look at its behaviour')
        #     pause()
        #
        # else:
        #
        #     track_agent = params.track_agent = None

        # when we are fixing prices:
        if fixed_price_day:

            if fixed_price_day == round:            # change the variable trade_prices to 'fixed'. note don't change params.trade_prices.

                trade_prices = 'fixed'

        # this is for an experiment within the famine experiment - we stop the trading early in te famine to see if agents become generalists
        if res_depletion and stop_trading:

            if round >= stop_trading:

                agents_trade = 0

                if round == stop_trading:

                    print('\n\n ---> agents stopped trading \n\n')

        # find the population's mean propensity to steal if there is corruption
        if agent_population.corruption_prop_charge != 1.0:
        
            # summation variable
            total_ps = 0

            pop_ps_array = []
            for agent in agent_population.pop:
                pop_ps_array.append(agent.prop_steal)

            if len(agent_population.pop) > 0:

                if params.pop_av == 'mean':

                    agent_population.mean_ps = np.mean(pop_ps_array)

                elif params.pop_av == 'median':

                    agent_population.mean_ps = np.median(pop_ps_array)

                mean_ps_actual = copy.copy(agent_population.mean_ps)
                agent_population.mean_ps = cap_floor_value(agent_population.mean_ps, 0.0, 1.0)

            else:

                agent_population.mean_ps = 0.0
                mean_ps_actual = None

            dbs.medians_ts[round] = agent_population.mean_ps
            dbs.medians_actual_ts[round] = mean_ps_actual

        # if we are allowing the agents to test and choose a constitution:
        if constitutional_voting == 1:

            if round == start_const_proces + (const_proc_test_period * constitution_counter):        # we create arrays to record agents' resources and we record the agent alive and their min level of resource

                experiment = applied_constitutions[constitution_counter]

                if experiment == 1:

                    print('\n ---> Changing to Experiment 1 in Constitutional Voting: force_prices = float, const_mkt_opens = 0')

                    force_prices = 'float'
                    const_mkt_opens = 0

                if experiment == 2:

                    print('\n ---> Changing to Experiment 2 in Constitutional Voting: force_prices = float, const_mkt_opens = 25')

                    force_prices = 'float'
                    const_mkt_opens = 25

                if experiment == 3:

                    print('\n ---> Changing to Experiment 3 in Constitutional Voting: force_prices = optimal, const_mkt_opens = 0')

                    force_prices = 'optimal'
                    const_mkt_opens = 0

                if experiment == 4:

                    print('\n ---> Changing to Experiment 4 in Constitutional Voting: force_prices = optimal, const_mkt_opens = 25')

                    force_prices = 'optimal'
                    const_mkt_opens = 25

                if experiment == 5:

                    print('\n ---> Changing to Experiment 5 in Constitutional Voting: Walrasian_Trading')

                    Walrasian_Trading = 1

                print('\n round =', round, 'constitution_counter', constitution_counter, 'applied_constitutions', applied_constitutions, 'experiment', experiment, 'force_prices', force_prices, 'const_mkt_opens', const_mkt_opens, 'Walrasian_Trading', Walrasian_Trading)

                constitution_counter += 1

        # here we need to adjust the parameter trade_movemnt if == 'mixed', which is when agents move around randomly
        # for some rounds and then moved to set locations subsequently.  Note the code
        if trade_movemnt_start == 'mixed':

            if round < random_rounds_start:
                trade_movemnt = 'random'

            else:
                trade_movemnt = 'set'

        # print basic information so sim is tracked neatly daily_succ_trans
        if round % 10 == 0:     # prints every 10 rounds

            if round == 0:
                last_time_stamp = dt.datetime.now()
                time_passed = 0
            else:
                time_passed = dt.datetime.now() - last_time_stamp
                last_time_stamp = dt.datetime.now()

            print('sim_suite:', readme_notes, ' |  sim set = ', sim_no + 1, ' of ', total_runs, '  |  round ', round, '\tof', rounds, '  |  time passed:', time_passed, '  |  popn', len(agent_population.pop))

        # this is for tracking agents when only one agent left with positive ps xxxx
        # if track_agent == None:
        #
        #     num_pos_ps_test = 0
        #     max_ps = -2.0
        #
        #     for alive_agent in agent_population.pop:
        #
        #         if alive_agent.prop_steal > 0.0:
        #             num_pos_ps_test += 1
        #         if alive_agent.prop_steal > max_ps:
        #             max_ps = alive_agent.prop_steal
        #
        #     if num_pos_ps_test == 1:
        #
        #         # we don't want to track straight away: do it in 20 rounds
        #         track_agent = round
        #         track_agent_copy = round
        #
        #         # which agent has the positive ps?
        #         for ag in agent_population.pop:
        #             if ag.prop_steal == max_ps:
        #                 agent_population.tracking_agent = ag

        if round % heatmap_days_show == 0:

            print('\n Running Data Report:\n')
            aggr_prop_steal = 0
            aggr_prop_fb = 0
            aggr_res_0 = 0
            aggr_res_1 = 0
            aggr_det_max = 0
            aggr_det_min = 0

            # def colour_text(value, equal_width=7):
            #
            #     if value > 0.0:
            #
            #         return '\x1b[1;31;47m +%6.3f \x1b[0m' % value
            #
            #     elif value < 0.0:
            #
            #         return '\x1b[1;34;47m -%6.3f \x1b[0m' % np.abs(value)
            #
            #     else:
            #
            #         equal_text = ' ' * int(equal_width / 2)
            #         equal_text += '='
            #         equal_text += ' ' * (equal_width - int(equal_width / 2))
            #
            #         return equal_text

            ps_array = []
            pfb_array = []
            num_pos_ps = 0
            num_neg_ps = 0

            for alive_agent in agent_population.pop:

                ps_array.append(alive_agent.prop_steal)
                pfb_array.append(alive_agent.prop_fight_back)

                if alive_agent.prop_steal >= 0.0:
                    num_pos_ps += 1
                else:
                    num_neg_ps += 1

                aggr_prop_steal += alive_agent.prop_steal
                aggr_prop_fb += alive_agent.prop_fight_back
                aggr_res_0 += alive_agent.agent_res_array[0][0]
                aggr_res_1 += alive_agent.agent_res_array[0][1] 
                aggr_det_max += np.max(alive_agent.detect_skills_array)
                aggr_det_min += np.min(alive_agent.detect_skills_array)

                if round == 0:

                    prop_steal_change = 0.0
                    prop_fb_change = 0.0
                    res_0_change = 0.0
                    res_1_change = 0.0
                    det_0_change = 0.0
                    det_1_change = 0.0

                if round > 0:
                    
                    prop_steal_change = alive_agent.prop_steal - alive_agent.prop_steal_record
                    # prop_steal_change = colour_text(prop_steal_change, equal_width=8)
                    # prop_steal_change = text_col(prop_steal_change, bkg_cols=0) + ' \033[0;30;48m'

                    prop_fb_change = alive_agent.prop_fight_back - alive_agent.prop_fight_back_record
                    # prop_fb_change = colour_text(prop_fb_change, equal_width=8)
                    # prop_fb_change = text_col(prop_fb_change, bkg_cols=0) + ' \033[0;30;48m'

                    res_0_change = alive_agent.agent_res_array[0][0] - alive_agent.agent_res_array_record[0][0]
                    # res_0_change = colour_text(res_0_change, equal_width=8)
                    # res_0_change = text_col(res_0_change, bands=[0, 5, 10, 20, 30], bkg_cols=0) + ' \033[0;30;48m'

                    res_1_change = alive_agent.agent_res_array[0][1] - alive_agent.agent_res_array_record[0][1]
                    # res_1_change = colour_text(res_1_change, equal_width=8)
                    # res_1_change = text_col(res_1_change, bands=[0, 5, 10, 20, 30], bkg_cols=0) + ' \033[0;30;48m'

                    det_0_change = alive_agent.detect_skills_array[0][0] - alive_agent.detect_skills_array_record[0][0]
                    # det_0_change = colour_text(det_0_change, equal_width=9)
                    # det_0_change = text_col(det_0_change, bands=[0, 0.025, 0.05, 0.075, 0.1], bkg_cols=0) + ' \033[0;30;48m'

                    det_1_change = alive_agent.detect_skills_array[0][1] - alive_agent.detect_skills_array_record[0][1]
                    # det_1_change = colour_text(det_1_change, equal_width=9)
                    # det_1_change = text_col(det_1_change, bands=[0, 0.025, 0.05, 0.075, 0.1], bkg_cols=0) + ' \033[0;30;48m'

                alive_agent.prop_steal_record = copy.copy(alive_agent.prop_steal)
                alive_agent.prop_fight_back_record = copy.copy(alive_agent.prop_fight_back )  
                alive_agent.agent_res_array_record = copy.copy(alive_agent.agent_res_array)
                alive_agent.detect_skills_array_record = copy.copy(alive_agent.detect_skills_array)

                if alive_agent.fight_skill is not None:
                    fs = '%4.2f' % alive_agent.fight_skill
                else:
                    fs = 'n/a'

                print(' ag home [%3.0d, %3.0d]' % (alive_agent.home[0], alive_agent.home[1]), ' pr_st  %1.3f (%1.3f)' % (alive_agent.prop_steal, prop_steal_change), ' pr_fb %1.3f (%1.3f)' % (alive_agent.prop_fight_back, prop_fb_change),
                      'res [%6.2f, %6.2f]' % (alive_agent.agent_res_array[0][0], alive_agent.agent_res_array[0][1]), '[%6.2f, %6.2f]' % (res_0_change, res_1_change), ' det p [%5.3f %5.3f]' % (alive_agent.detect_skills_array[0][0], alive_agent.detect_skills_array[0][1]),
                      '[%6.2f, %6.2f]' % (det_0_change, det_1_change), ' for', alive_agent.for_strat_array[0], ' fight_skill ', fs, ' |  target:', alive_agent.grid_trgt,' age', alive_agent.age)

            if len(agent_population.pop) > 0:

                mean_prop_steal = np.mean(ps_array)
                mean_prop_fb = np.mean(pfb_array)
                mean_res_0 = aggr_res_0 / float(len(agent_population.pop))
                mean_res_1 = aggr_res_1 / float(len(agent_population.pop))
                mean_det_min = aggr_det_min / float(len(agent_population.pop))
                mean_det_max = aggr_det_max / float(len(agent_population.pop))

            else:

                mean_prop_steal = None
                mean_prop_fb = None
                mean_res_0 = None
                mean_res_1 = None
                mean_det_min = None
                mean_det_max = None

            if round == 0:

                mean_prop_steal_change = '  =   '
                mean_prop_fb_change = '  =   '
                mean_res_0_change = '  =   '
                mean_res_1_change = '  =   '
                mean_det_min_change = '  =   '
                mean_det_max_change = '  =   '

            else:

                if len(agent_population.pop) > 0:

                    mean_prop_steal_change = mean_prop_steal - dbs.mean_prop_steal_record
                    mean_prop_fb_change = mean_prop_fb - dbs.mean_prop_fb_record
                    mean_res_0_change = mean_res_0 - dbs.mean_res_0_record
                    mean_res_1_change = mean_res_1 - dbs.mean_res_1_record
                    mean_det_min_change = mean_det_min - dbs.mean_det_min_record
                    mean_det_max_change = mean_det_max - dbs.mean_det_max_record

                else:

                    mean_prop_steal_change = 0
                    mean_prop_fb_change = 0
                    mean_res_0_change = 0
                    mean_res_1_change = 0
                    mean_det_min_change = 0
                    mean_det_max_change = 0

                # mean_prop_steal_change = colour_text(mean_prop_steal_change, equal_width=6)
                # mean_prop_fb_change = colour_text(mean_prop_fb_change, equal_width=6)
                # mean_res_0_change = colour_text(mean_res_0_change, equal_width=6)
                # mean_res_1_change = colour_text(mean_res_1_change, equal_width=6)
                # mean_det_min_change = colour_text(mean_det_min_change, equal_width=6)
                # mean_det_max_change = colour_text(mean_det_max_change, equal_width=6)

                # mean_prop_steal_change = text_col(mean_prop_steal_change, bkg_cols=0) + ' \033[0;30;48m'
                # mean_prop_fb_change = text_col(mean_prop_fb_change, bkg_cols=0) + ' \033[0;30;48m'
                # mean_res_0_change = text_col(mean_res_0_change, bkg_cols=0) + ' \033[0;30;48m'
                # mean_res_1_change = text_col(mean_res_1_change, bkg_cols=0) + ' \033[0;30;48m'
                # mean_det_min_change = text_col(mean_det_min_change, bkg_cols=0) + ' \033[0;30;48m'
                # mean_det_max_change = text_col(mean_det_max_change, bkg_cols=0) + ' \033[0;30;48m'

            dbs.mean_prop_steal_record = copy.copy(mean_prop_steal)
            dbs.mean_prop_fb_record = copy.copy(mean_prop_fb)
            dbs.mean_res_0_record = copy.copy(mean_res_0)
            dbs.mean_res_1_record = copy.copy(mean_res_1)
            dbs.mean_det_min_record = copy.copy(mean_det_min)
            dbs.mean_det_max_record = copy.copy(mean_det_max)

            if round == 0:
                dbs.min_ps_record = copy.copy(np.min(ps_array))
                dbs.max_ps_record = copy.copy(np.max(ps_array))
                dbs.min_pfb_record = copy.copy(np.min(pfb_array))
                dbs.max_pfb_record = copy.copy(np.max(pfb_array))

            if len(agent_population.pop) > 0:
                print('\n mean prop_steal = %1.3f' % mean_prop_steal, mean_prop_steal_change, 'mean prop_fb = %1.3f' % mean_prop_fb, mean_prop_fb_change, '  mean res: [%4.2f, %4.2f]' % (mean_res_0, mean_res_1), '[', mean_res_0_change, mean_res_1_change, ']',
                      '   det skills min, max: [%1.3f, %1.3f]' % (mean_det_min, mean_det_max), '[', mean_det_min_change, mean_det_max_change, ']')

                min_ps_ch = np.min(ps_array) - dbs.min_ps_record
                max_ps_ch = np.max(ps_array) - dbs.max_ps_record
                min_pfb_ch = np.min(pfb_array) - dbs.min_pfb_record
                max_pfb_ch = np.max(pfb_array) - dbs.max_pfb_record

                # min_ps_ch = text_col(np.min(ps_array) - dbs.min_ps_record, bands=[0.0, 0.05, 0.1, 0.15, 0.2], bkg_cols=0, num_dps=3) + ' \033[0;30;48m'
                # max_ps_ch = text_col(np.max(ps_array) - dbs.max_ps_record, bands=[0.0, 0.05, 0.1, 0.15, 0.2], bkg_cols=0, num_dps=3) + ' \033[0;30;48m'
                # min_pfb_ch = text_col(np.min(pfb_array) - dbs.min_pfb_record, bands=[0.0, 0.05, 0.1, 0.15, 0.2], bkg_cols=0, num_dps=3) + ' \033[0;30;48m'
                # max_pfb_ch = text_col(np.max(pfb_array) - dbs.max_pfb_record, bands=[0.0, 0.05, 0.1, 0.15, 0.2], bkg_cols=0, num_dps=3) + ' \033[0;30;48m'

                print('\n ps range: [%1.3f (%s)' % (np.min(ps_array), min_ps_ch), 'to %1.3f (%s)]' % (np.max(ps_array), max_ps_ch), ' num -ve = %d num +ve = %d' % (num_neg_ps, num_pos_ps), ' median %1.3f' % np.median(ps_array), ' std %1.3f' % np.std(ps_array),
                      ' \t\t pfb range [%1.3f (%s)' % (np.min(pfb_array), min_pfb_ch), 'to %1.3f (%s)]' % (np.max(pfb_array), max_pfb_ch), ' median %1.3f' % np.median(pfb_array), ' std %1.3f' % np.std(pfb_array))

                if round == 0:
                    print('')

                if round > 9:
                    start_day = round - 10
                    turnover_data = []
                    turnover_string = ''
                    for i in dbs.net_turnover_prop[start_day:round]:
                        turnover_data.append(i[0])
                        turnover_string += '%5.5s ' % i[0]
                    if round > 0:
                        mean_to = np.mean(turnover_data)
                    else:
                        mean_to = 0.0
                    print('\n turnover ratios last 10 rounds:', turnover_string, 'mean = %5.5s' % mean_to, '\n')

            if round > 0 and len(agent_population.pop) > 0:
                dbs.min_ps_record = copy.copy(np.min(ps_array))
                dbs.max_ps_record = copy.copy(np.max(ps_array))
                dbs.min_pfb_record = copy.copy(np.min(pfb_array))
                dbs.max_pfb_record = copy.copy(np.max(pfb_array))

            if len(agent_population.pop) > 0 and mean_prop_steal <= 0.2 and params.track_agent is not None:
                params.track_agent = 1
                track_agent = 1

            # if len(dbs.games_type_considered_dict) > 0:
            #
            #     print(' game type scenarios:\n')
            #
            #     counter = 0
            #
            #     for scenario_name in dbs.games_type_considered_dict:
            #
            #         counter += sum(dbs.games_type_considered_dict[scenario_name])
            #
            #         print(' scenario name: ', scenario_name, 'num interactions =', sum(dbs.games_type_considered_dict[scenario_name]))
            #
            #     print('\n total =', counter)
            #
            #     print('\n')
            #
            # if len(dbs.games_type_dict) > 0:
            #
            #     counter = 0
            #
            #     for scenario_name in dbs.games_type_dict:
            #
            #         counter += sum(dbs.games_type_dict[scenario_name])
            #         print(' scenario name: ', scenario_name, 'num interactions =', sum(dbs.games_type_dict[scenario_name]))
            #
            #     print('\n total =', counter)
            #
            #     print('\n')

            if agent_population.change_agent is not None and len(agent_population.pop) > 1:

                print(' change_agent journey that day:', agent_population.change_agent.trade_loc_rec)
                print('\n change_agent targets that day:', agent_population.change_agent.trgt_loc_rec)
#                print('\n')
                
                print('\n first agent journey:', agent_population.pop[0].trade_loc_rec)
                print('\n first agent targets:', agent_population.pop[0].trgt_loc_rec)

                print('\n 2nd agent journey:', agent_population.pop[1].trade_loc_rec)
                print('\n 2nd agent targets:', agent_population.pop[1].trgt_loc_rec)

#        pause()

        # wipe the following two arrays, which record foraging data:
        if two_tribes == 0:

            dbs.res_level_array = np.zeros(shape=(for_strat_parts, num_res_founts))
            dbs.res_level_array_ends = np.zeros(shape=(for_strat_parts, num_res_founts))

        elif two_tribes == 1:
            
            dbs.res_level_array = np.zeros(shape=(for_strat_parts, 4))
            dbs.res_level_array_ends = np.zeros(shape=(for_strat_parts, 4))

        # update each living agent's list of neighbours
        if agent_population.must_update_neighs:

            update_neighbours(town_grid, agent_population, local_net_rad, print_dets, print_fine_dets, dimen, agent_population.tracking_agent, track_agent, round)

            agent_population.must_update_neighs = 0

        # at the start of every day we set equal to zero each agent's baskets, and their sell_array and buy_array:
        for agent in agent_population.pop:
            for fount in np.arange(num_res_founts):
                agent.basket_array[0][fount] = 0
            agent.sell_array = []
            agent.buy_array = []
            agent.fights_array = []
            agent.trades_array = []
            agent.trans_known_about = []

        # Now set the fountain resource levels back to fully stocked unless...
        # We change the Fountain Resource levels if res_depletion > 0
        if res_depletion > 0 and res_depletion <= round < res_depletion + tot_rounds_depl:

            for resource in np.arange(num_res_founts):

                if resource in fount_dep:

                    fountain_population.pop[resource].res_level = init_res_level * fount_depl_ratio

#                    if round % 10 == 0:
#                        print('\n fountain_population.pop[%d].res_level' % (resource), fountain_population.pop[resource].res_level)

                    # Record the fountains' initial levels
                    dbs.init_res_levels[round][resource] = init_res_level * fount_depl_ratio
                    dbs.fountains_init_levels_hist[resource][round] = init_res_level * fount_depl_ratio

                else:

                    fountain_population.pop[resource].res_level = init_res_level

                    # Record the fountains' initial levels
                    dbs.init_res_levels[round][resource] = init_res_level

        else:

            if two_tribes == 0:

                for res in np.arange(num_res_founts):
    
                    fountain_population.pop[res].res_level = init_res_level

                    # Record the fountains' initial levels
                    dbs.init_res_levels[round][res] = init_res_level
                    
                if single_tribe == 1:
                    
                    fountain_population.pop[0].res_level = init_res_level
                    fountain_population.pop[1].res_level = initial_fount_stock_high

            elif two_tribes == 1:

                # the foutains are set like this where 0 and 3 have higher stocks than 1 and 2
                fountain_population.pop[0].res_level = initial_fount_stock_high
                fountain_population.pop[1].res_level = init_res_level
                fountain_population.pop[2].res_level = init_res_level
                fountain_population.pop[3].res_level = initial_fount_stock_high                

                # Record the fountains' initial levels
                dbs.init_res_levels[round][0] = initial_fount_stock_high
                dbs.init_res_levels[round][1] = init_res_level
                dbs.init_res_levels[round][2] = init_res_level
                dbs.init_res_levels[round][3] = initial_fount_stock_high

        if calc_timings:
            foraging_start_time = dt.datetime.now()

        # FORAGING: the following line calls the function which manages the foraging process
        if two_tribes == 0:

            agents_forage(round, for_strat_parts, print_dets, print_fine_dets, agent_population,
                          fountain_population.pop, dbs, print_for, two_tribes, tribe='none')

        elif two_tribes == 1:

            agents_forage(round, for_strat_parts, print_dets, print_fine_dets, agent_population,
                          fountain_population.pop_0, dbs, print_for, two_tribes, tribe='sharks')

            agents_forage(round, for_strat_parts, print_dets, print_fine_dets, agent_population,
                          fountain_population.pop_1, dbs, print_for, two_tribes, tribe='jets')

        if track_agent and track_agent <= round:
            print('\n day', round, ' - post-foraging agent_population.tracking_agent.basket_array', agent_population.tracking_agent.basket_array, 'skills:', agent_population.tracking_agent.detect_skills_array, 'foraging:', agent_population.tracking_agent.for_strat_array, '\n')
            pause()

        if calc_timings:
            dbs.timings_dict['foraging'].append(dt.datetime.now() - foraging_start_time)

        # TRADING: whether the agents trade or not is a parameter of the simulation (agents_trade)

        # before trading (or not), we need to set trade_prob = 0.  This is used later to update foraging strategies - the default
        # should be 0, which can change if there is trading (this is done in the code below)
        trade_prob = 0

        # record this agent data
        for agent in agent_population.pop:

            dbs.for_strat_db[round].append(copy.copy(agent.for_strat_array[0]))
            agent.for_strat_hist[round] = copy.copy(agent.for_strat_array[0])
            agent.agent_res_array_start = copy.copy(agent.agent_res_array)
            agent.basket_array_start = copy.copy(agent.basket_array)
            agent.basket_array_start_hist[round] = copy.copy(agent.basket_array[0])

        if two_tribes:

            for agent in agent_population.pop:

                if agent.tribe == 'sharks':
                    dbs.for_strat_db_sharks[round].append(copy.copy(agent.for_strat_array[0]))

                if agent.tribe == 'jets':
                    dbs.for_strat_db_jets[round].append(copy.copy(agent.for_strat_array[0]))

        if agents_trade:

            if print_dets == 1:
                print('\n\n**** agents now trade ****\n\n')

            # tidy this up idc - there used to be a function here: agent_trading_decision, which has been removed.  now all agents trade.
            dbs.agent_list = list(copy.copy(agent_population.pop))

            if print_dets == 1:
                print('\nagent_list ahead of trading =', dbs.agent_list)
                print('number of trading agents =', len(dbs.agent_list))

            # use a seperate function to manage agents trading - note it returns the total number of trades
            if len(agent_population.pop) > 1:

#                # this is reuired below: test whether any agent MRS is > 4 before trading occurs
#                high_MRS = 0
#
#                for agent in agent_population.pop:
#
#                    agent.update_agent_MRS_array(print_dets, print_fine_dets, agent_population)
#
#                    for res_1 in range(num_res_founts):
#                        for res_2 in range(num_res_founts):
#
#                            if agent.MRS_array[res_1][res_2] > 4.0:
#
#                                high_MRS = 1
#
#                if high_MRS == 1 and round < 9000:
#
#                    # Here we create an alternative reality trading scenario - we copy all agent data and databases and use these in an alternative trading approach
#                    new_agent_population = copy.deepcopy(agent_population)
#                    new_fountain_population = copy.deepcopy(fountain_population)
#                    new_dbs = copy.deepcopy(dbs)
#                    new_town_grid = copy.deepcopy(town_grid)
#                    new_run_folder = '%s/alt' % (run_folder)
#    
#                    # this line creates the directory
#                    if os.path.exists(new_run_folder) == False:
#                        os.makedirs(new_run_folder)

                if Walrasian_Trading == 1:

                    gen_equ_thresh = 0.0001

                    agents_trading_Walras_Style(params, KO_pop, town_grid, agent_population, print_dets, trade_moves, trade_movemnt, vision_len, round, trade_loc, print_fine_dets, agent_population.tracking_agent,
                                   wait_at_target_til_end, wait_at_tgt_moves, track_agent, trgt_sel, dimen, trade_when_trgt, goods_signal, run_folder, print_round_trans, df_daily, dbs, granular_mem,
                                   fountain_population, print_move_heat_maps, trade_prices, rounds, gen_equ_thresh, gen_equ_wh_lps, SD_charts_freq, price_mean, force_prices, fixed_price, keynesian_ratio,
                                   find_gen_equ_PQ, use_parallel_code, price_grid_dimen, test_par_code, print_plotly_charts, print_MRS_std_charts, const_mkt_opens)

                else:

                    if calc_timings:
                        start_trading_time = dt.datetime.now()

                    agents_trading(params, KO_pop, town_grid, agent_population, print_dets, trade_moves, trade_movemnt,
                                   vision_len, round, trade_loc, print_fine_dets, agent_population.tracking_agent,
                                   wait_at_target_til_end, wait_at_tgt_moves, track_agent, trgt_sel, dimen, trade_when_trgt, goods_signal,
                                   run_folder, print_round_trans, df_daily, dbs, granular_mem,
                                   fountain_population, print_move_heat_maps, trade_prices, rounds,
                                   gen_equ_thresh, gen_equ_wh_lps, SD_charts_freq, price_mean, force_prices, fixed_price,
                                   keynesian_ratio, find_gen_equ_PQ, use_parallel_code, price_grid_dimen, test_par_code,
                                   print_plotly_charts, print_MRS_std_charts, const_mkt_opens, ststst, respect_property_rights,
                                   adjust_props_r, fight_cost, agent_intn_beta, rounds, len_reputations_mem, intn_error_std, agent_avoid_muggers,
                                   prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, trade_at_trgt_precise,
                                   fight_balance, agree_location, use_original_model_struct, two_tribes, formal_inst, prob_fine, fine,
                                   print_agents_interact, fight_skill, fix_ps_fb_0, stranger_int, two_tribes_inst, strat_choice, strangers_if_unknown)

                    if calc_timings:
                        dbs.timings_dict['trading'].append(dt.datetime.now() - start_trading_time)

#                # here we test a theory that new agents get better prices when Gen Equ used, when they are close to death and their MRSs are v high / v low
#                if high_MRS == 1 and round < 9000:
#
#                    gen_equ_thresh = 0.0000000001
#
#                    # this is our alt reality trading:
#                    agents_trading_Walras_Style(KO_pop, new_town_grid, new_agent_population, print_dets, trade_moves, trade_movemnt,
#                                   vision_len, round, pause, trade_loc, print_fine_dets, agent_population.tracking_agent,
#                                   wait_at_target_til_end, wait_at_tgt_moves, track_agent, trgt_sel, dimen, trade_when_trgt, goods_signal,
#                                   new_run_folder, print_round_trans, df_daily, new_dbs, granular_mem,
#                                   new_fountain_population, print_move_heat_maps, trade_prices, rounds,
#                                   gen_equ_thresh, gen_equ_wh_lps, SD_charts_freq, price_mean, force_prices, fixed_price,
#                                   keynesian_ratio, find_gen_equ_PQ, use_parallel_code, price_grid_dimen, test_par_code,
#                                   print_plotly_charts, print_MRS_std_charts, const_mkt_opens)
#
#                    res_0_diff = 0.0
#                    res_1_diff = 0.0
#
#                    for ag_num in range(len(agent_population.pop)):
#
#                        real_agent = agent_population.pop[ag_num]
#                        alt_agent = new_agent_population.pop[ag_num]
#
#                        print('home', real_agent.home, 'res', real_agent.agent_res_array[0], 'start basket', real_agent.basket_array_start, 'real_basket = ', real_agent.basket_array[0], 'alt_agent basket', alt_agent.basket_array[0], 'diff (real - alt):', real_agent.basket_array - alt_agent.basket_array)
#
#                        res_0_diff += real_agent.basket_array[0][0] - alt_agent.basket_array[0][0]
#                        res_1_diff += real_agent.basket_array[0][1] - alt_agent.basket_array[0][1]
#
##                        print('\n aggreg res_0_diff = %1.15f' % (res_0_diff))
##                        print(' aggreg res_1_diff = %1.15f' % (res_1_diff))
#
#                    input("Press Enter to continue...")

            if len(agent_population.pop) == 1:
                agent_population.pop[0].start_trgt_loc_rec[round].append([None, None])

            # Update each agent's basket_array_hist
            for agent in agent_population.pop:
                agent.basket_array_hist[round] = copy.copy(agent.basket_array[0])

            # here we update the database trading_db with various data

            # we would like to add the total_on_sale to trading_db[2]:
            dbs.trading_db[4][round] = dbs.total_on_sale

            # update trading_db with the number of agents attempting to trade
            dbs.trading_db[1][round] = len(dbs.agent_list)

            # add population size to the trading_db
            dbs.trading_db[0][round] = len(agent_population.pop)

            # find the average trade proportion over the past 5 periods
            if round < trade_prob_mem:
                trade_prob = np.mean(dbs.trading_db[6][:(round + 1)])
            else:
                trade_prob = np.mean(dbs.trading_db[6][(round - 5) : (round + 1)])

        #*************************************************************************************************************
        #******* after trading (or not), the agents then consume their baskets and forfeit the cost of living ********

        if print_dets == 1:
            print('\n\n---------------------------- END OF DAY ADJUSTMENTS ----------------------------------\n')

        # add one to each agent's age
        for agent in agent_population.pop:
            
            agent.age += 1

        if calc_timings:
            start_three_updates = dt.datetime.now()

        # now we must also update each agent's subjective perceived trade_proby, which is taken from their neighbours
        update_trade_probys(params, agent_population, trade_prob_mem, round, print_dets, print_fine_dets, rounds, track_agent, trade_prices, Walrasian_Trading, ststst, fight_skill, fight_skill_r, dbs)

        # this function organises end-of-day consumption and metabolism, and also removes dead agents from the population
        end_of_day_cons_metab(track_agent, KO_pop, agent_population, print_fine_dets, dbs, round, allow_Keynes_Inst, respect_property_rights, record_dead_agents, black_shoop_exp, agents_die_old_age)

        # Now we update forraging skills before updating the population with new births
        update_foraging_skills(params, for_strat_parts, print_dets, print_fine_dets, agent_population.tracking_agent, track_agent, for_skill_r, agent_population, round)

        if calc_timings:
            dbs.timings_dict['three_updates'].append(dt.datetime.now() - start_three_updates)

        here = 0

        update_locations_dicts(params, town_grid, dbs, agent_population, round, wait_at_target_til_end, wait_at_tgt_moves)

        if len(agent_population.pop) > 1 and Walrasian_Trading != 1:

            if calc_timings:
                start_comms = dt.datetime.now()

            agents_communicate(params, agent_population, fountain_population, dbs, agents_comm_prob, round, town_grid, print_dets, print_fine_dets, respect_property_rights,
                               rounds, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, agree_location, agent_mem_length, prop_steal_floor,
                               fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0, clear_of_fights_radius, rounds, stranger_int,
                               strat_choice, two_tribes_inst, strangers_if_unknown, track_agent)

            if calc_timings:
                dbs.timings_dict['comms'].append(dt.datetime.now() - start_comms)

        if calc_timings:
            start_update_for_strat = dt.datetime.now()

        # now we need to update agents' foraging strategies.  we do this by randomly selecting one element in the agent's
        # strategy and asking if they ought to change this to a different resource fountain.
        update_for_strats(params, fountain_population, for_strat_parts, agent_population, print_dets,
                          agent_population.tracking_agent, trade_prob, track_agent, print_fine_dets, trade_loc, round, dbs,
                          trade_prices, Walrasian_Trading, two_tribes)

        if calc_timings:
            dbs.timings_dict['for_strats'].append(dt.datetime.now() - start_update_for_strat)

        if calc_timings:
            start_new_births = dt.datetime.now()

        # update the population given agent deaths and possible increase of whole population
        new_births(params, agent_population, print_dets, print_fine_dets, agent_homes, init_res_level, dbs, round,
                   for_strat_parts, agent_res_init,
                   vision_len, dimen, rounds, trade_moves, trade_when_trgt, popn_ch, agent_mem_length,
                   cp_trans_weight, wait_at_tgt_moves, trade_prices, agent_res_init_std, mating_thresh,
                   cognition_factor, town_grid, run_folder, trade_movemnt, agents_comm_prob, respect_property_rights,
                   start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                   children_props, child_prop_std, prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor,
                   adjust_props_r, agent_intn_beta, two_tribes, black_shoop_exp, black_shoop_pop, fight_skill, agents_die_old_age,
                   black_shoop_prop_start, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, start_child_births, price_mean, force_prices,
                   fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
                   fight_balance, formal_inst, prob_fine, fine, clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst)

        # update number of children each agent has had
        for agent in agent_population.pop:
            agent.num_children_hist[round] = agent.num_children

        if calc_timings:
            dbs.timings_dict['new_births'].append(dt.datetime.now() - start_new_births)

        # update this dict:
        for agent in agent_population.pop:

            if str(agent) not in str_agent_to_home_dict:

                str_agent_to_home_dict[str(agent)] = agent.home

        # here we do some data manipulation to generate trading data

        # extract the 2d array from town_grid's all_trans_array
        this_round_trans_grid = town_grid.all_trans_array[round]

        # create a blank array to work out gini coefficient
        oned_trans_grid = np.array([])

        mean_transs = np.mean(this_round_trans_grid)

        std_transs = np.std(this_round_trans_grid)

        mean_plus_5stds = mean_transs + (5 * std_transs)

        mean_plus_10stds = mean_transs + (5 * std_transs)

        # count the number of squares with transactions
        trans_sq_tot = 0
        over_5stds = 0
        over_10stds = 0

        # we want to record peak locations (where transs > mean_plus_10stds)
        peak_locs_array = []
#        print '\nthis_round_trans_grid =\n\n'
        for row in np.arange(dimen):
#            print this_round_trans_grid[row]
            for col in np.arange(dimen):
                if this_round_trans_grid[row][col] > 0:
                    trans_sq_tot += 1
                if this_round_trans_grid[row][col] > mean_plus_5stds:
                    over_5stds += 1
                if this_round_trans_grid[row][col] > mean_plus_10stds:
                    over_10stds += 1
                    peak_locs_array.append([row, col])
                if this_round_trans_grid[row][col] > 0:
                    oned_trans_grid = np.append(oned_trans_grid, this_round_trans_grid[row][col])

        # update various key_trading_db cells
        dbs.key_trading_db[1][round] = trans_sq_tot

        if print_dets == 1:
            print('oned_trans_grid =', oned_trans_grid)
            print('dbs.key_trading_db =', dbs.key_trading_db)

        # print chart of individual round trans's
        if print_round_trans != 0 and round % print_round_trans == 0:

            create_heat_map(dimen, this_round_trans_grid, df_daily, 'Blues', 'Trans round %s' % (round), 'daily_chart_%s' % (round), dpi='low')

            write_key_agent_data_round(dbs, agent_population, df_daily, vision_len, round, peak_locs_array, town_grid)

        # now we update for_spec_db, which records the degrees of specialisation among agents
        if len(agent_population.pop) > 0:

            num_agens = len(agent_population.pop)
    
            max_for_counter = 0
            for agen in agent_population.pop:
                track_ress_array = np.zeros(shape=(num_res_founts), dtype=int)
                for i in np.arange(for_strat_parts):
                    for j in np.arange(num_res_founts):
                        if agen.for_strat_array[0][i] == j:
                            track_ress_array[j] += 1

                # find highest number of resources being foraged, add to for_spec_db and add to the counter:
                max_for = np.max(track_ress_array)
                dbs.for_spec_db[max_for + 1][round] += 1

#                print('\n agent', agen, 'agen.for_strat_array', agen.for_strat_array, 'track_ress_array', track_ress_array, 'max_for', max_for)

                max_for_counter += max_for

            # record the average number of max foraging strat
            dbs.for_spec_db[for_strat_parts + 2][round] = max_for_counter / float(num_agens)

        # now we update min_res_levels_db with the min res levels of each agent
        for agent in agent_population.pop:
            x_coord = int(agent.home[0])
            y_coord = int(agent.home[1])
            min_res_lev = np.min(agent.agent_res_array)

            agent.agent_res_array_hist[round] = copy.copy(agent.agent_res_array)
            agent.agent_res_array_start_hist[round] = copy.copy(agent.agent_res_array_start)

            dbs.min_res_levels_db[round][x_coord][y_coord] = min_res_lev

        # now we update the database counting the number of perfect specialists (skill > 0.99)
        for agent in agent_population.pop:

            if np.any(agent.detect_skills_array[0] > 0.95):

                dbs.num_perfect_specs[1][round] += 1

            if np.any(agent.detect_skills_array[0] > 0.99):

                dbs.num_perfect_specs[2][round] += 1

            if np.any(agent.detect_skills_array[0] >= 0.999):

                dbs.num_perfect_specs[3][round] += 1

        # update dbs.clustering_db and dbs.cluster_centre_db:

#        if round > cluster_lag - 2:
#
#            last_5_days_trades = np.zeros(shape=(dimen, dimen))
#
#            for i in np.arange(5):
#                for j in np.arange(dimen):
#                    for l in np.arange(dimen):
#                        last_5_days_trades[j][l] += town_grid.all_trans_array[round - i][j][l]
#    
#            cluster_data = clustering_coefficient(last_5_days_trades, dimen, print_dets)
#
#            dbs.clustering_db[1][round] = cluster_data[0]
#            dbs.cluster_centre_db[1][round] = cluster_data[1][0]
#            dbs.cluster_centre_db[2][round] = cluster_data[1][1]

        # record agents' average age

        if len(agent_population.pop) > 0:

            tot_age = 0
            for agent in agent_population.pop:
                ag_age = round - agent.birth_date + 1       # we add 1 as this is the end of the round so the agent has lived a whole round, in effect
                tot_age += ag_age

                dbs.ag_age_db[1][round] = tot_age / float(len(agent_population.pop))

        # Update detect_skills_array_hist
        for agent in agent_population.pop:
            agent.detect_skills_array_hist[round] = copy.copy(agent.detect_skills_array[0])

        # Update two bits of agent data at the end of the round
#        dbs.live_agents[round] = agent_population.pop

        max_det_probs_array = []
        agents_res_array = np.zeros(shape=(len(agent_population.pop), num_res_founts))

#        print('\n agent_population.pop =', agent_population.pop)
#        print('\n agents_res_array =', agents_res_array)

        agent_num = 0

        for agent in agent_population.pop:

            max_det_prob = np.max(agent.detect_skills_array)
            max_det_probs_array.append(max_det_prob)

            agents_res_array[agent_num] = agent.agent_res_array[0]

            agent_num += 1

        dbs.copy_ags_max_det_probs[round] = max_det_probs_array

        dbs.copy_ags_res_arrays[round] = agents_res_array

        # Here we update dbs.serviced_locations
        # start by evaluating the trading on the town grid:
        trades_array_vis_seg = np.zeros(shape=(dimen, dimen), dtype=float)
        # this is for evaluating fights:
        fights_array_grid = np.zeros(shape=(dimen, dimen), dtype=int)

        # This array counts the number of agents that have transacted on the grid square
        dbs.trades_array_ags = [[[] for j in range(dimen)] for i in range(dimen)]
        # This is the same but for the fights in the locations
        dbs.fights_array_ags = [[[] for j in range(dimen)] for i in range(dimen)]

        start_round = np.max([0, round - agent_mem_length + 1])     # inclusive counting eg if mem length is 4 and round = 10 then we want 7, 8, 9, 10

        days_transs = []
        days_fights = []

        for day in np.arange(start_round, round + 1):

#            print('\n round =', round, 'day', day, 'dbs.transs_daily_db[day]', dbs.transs_daily_db[day])

            for trans in dbs.transs_daily_db[day]:

                days_transs.append(trans)

            for fight in dbs.fights_daily_db[day]:

                days_fights.append(fight)

#        print('\n days_transs', days_transs)

#        days_transs = dbs.transs_daily_db[round]

        for trans_num in days_transs:

            trans = dbs.trans_db[trans_num]

            if trans.tot_trans_ag_sell is not None:
    
                x_coord = trans.location[0]
                y_coord = trans.location[1]
                trades_array_vis_seg[x_coord][y_coord] += ((trans.tot_trans_ag_sell + trans.tot_trans_ag_buy) / 2.0)
    
                for agent in agent_population.pop:
    
                    if agent.home[0] == trans.agent_a_home[0] and agent.home[1] == trans.agent_a_home[1] and agent not in dbs.trades_array_ags[x_coord][y_coord]:
    
                        dbs.trades_array_ags[x_coord][y_coord].append(agent)
    
                    if agent.home[0] == trans.agent_b_home[0] and agent.home[1] == trans.agent_b_home[1] and agent not in dbs.trades_array_ags[x_coord][y_coord]:
    
                        dbs.trades_array_ags[x_coord][y_coord].append(agent)

        tot_grid_trans = np.sum(trades_array_vis_seg)

        for fight_num in days_fights:

            fight = dbs.fights_db[fight_num]
            
            x_coord = fight.location[0]
            y_coord = fight.location[1]
            
            fights_array_grid[x_coord][y_coord] += 1
            
            if fight.initiator not in dbs.fights_array_ags[x_coord][y_coord]:

                dbs.fights_array_ags[x_coord][y_coord].append(fight.initiator)

            if fight.counterpart not in dbs.fights_array_ags[x_coord][y_coord]:

                dbs.fights_array_ags[x_coord][y_coord].append(fight.counterpart)
                
#        print('\n dbs.trades_array_ags =\n', dbs.trades_array_ags)

        # We consider a market significant if >= 2 agents transact at a particular location
#        sign_mkt_thresh = 2

        for x_coord in np.arange(dimen):
            for y_coord in np.arange(dimen):

                if len(dbs.trades_array_ags[x_coord][y_coord]) >= sign_mkt_thresh:
                    dbs.sign_mkt_locs[round].append([x_coord, y_coord])

                if len(dbs.trades_array_ags[x_coord][y_coord]) >= sign_mkt_thresh or len(dbs.fights_array_ags[x_coord][y_coord]) >= sign_mkt_thresh:
                    dbs.sign_locs[round].append([x_coord, y_coord])

#        print '\n dbs.sign_mkt_locs[round] =', dbs.sign_mkt_locs[round]

        serviced_grid = np.zeros(shape=(dimen, dimen), dtype=int)
        for x_coord in np.arange(dimen):
            for y_coord in np.arange(dimen):

                for sign_mkt_loc in dbs.sign_mkt_locs[round]:

                    # print('\n 1 wait_at_tgt_moves', wait_at_tgt_moves)

                    if within_striking_dist(wait_at_target_til_end, town_grid, [x_coord, y_coord], wait_at_tgt_moves, vision_len, sign_mkt_loc, move=0, has_acted=0, print_dets=0):

                        serviced_grid[x_coord][y_coord] += 1

#        print '\n serviced_grid =\n', serviced_grid
        if len(agent_population.pop) > 0:

            serviced_agents_counter = 0
            for agent in agent_population.pop:
    
                x_coord = agent.home[0]
                y_coord = agent.home[1]
    
                if serviced_grid[x_coord][y_coord] > 0:
    
                    serviced_agents_counter += 1
    
    #        print '\n serviced_agents_counter =', serviced_agents_counter
    
            ratio_serviced_agents = serviced_agents_counter / float(len(agent_population.pop))
    
            dbs.serviced_locations[round] = ratio_serviced_agents

        # if we are using NNs, here we test out the impact of different input variables on agents' ps and pfb, and also try out different classic games & see what ps and pfb arise
        if use_NNs:

            # in each round we record the agents' prop steal and fb, which gets recorded at the beginning of the next round
            res_array_0 = np.array([[95, 105]])
            bskt_array_0 = np.array([[2, 2]])

            res_array_1 = np.array([[105, 95]])
            bskt_array_1 = np.array([[2, 2]])

            cp_ps = 0.5
            cp_pfb = 0.5

            for agent in agent_population.pop:

                # print('\n agent.home', agent.home, '\n')

                flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket=0, print_dets=0, print_fine_dets=0)

                if params.num_NNs == 1:

                    agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    agent.prop_steal = agent.intn_probs[0][0]
                    agent.prop_fight_back = agent.intn_probs[1][0]

                elif params.num_NNs == 2:

                    if params.NN_inputs == 'game_6':

                        agent.intn_prob_ps, agent.caches_ps = L_model_forward(flatten_rtns_matrix, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                        agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(flatten_rtns_matrix, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        agent.prop_steal = agent.intn_prob_ps[0][0]
                        agent.prop_fight_back = agent.intn_prob_pfb[0][0]

                    elif params.NN_inputs == 'mixed':

                        ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                        agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        agent.prop_fight_back = agent.intn_prob_pfb[0][0]

                        ag_ps_inputs = np.zeros(shape=(10, 1))

                        ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                        ag_ps_inputs[2] = (flatten_rtns_matrix[2] * agent.prop_fight_back) + (flatten_rtns_matrix[4] * (1 - agent.prop_fight_back))
                        ag_ps_inputs[3] = (flatten_rtns_matrix[3] * agent.prop_fight_back) + (flatten_rtns_matrix[5] * (1 - agent.prop_fight_back))
                        ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                        ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                        ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                        agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        agent.prop_steal = agent.intn_prob_ps[0][0]

                        if print_fine_dets:
                            print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                            print('\n ag_fb_inputs \n', ag_fb_inputs)
                            print('\n pfb \n', pfb)
                            print('\n ag_ps_inputs \n', ag_ps_inputs)
                            print('\n ps \n', ps)

            if (round + 1) % 100 == 0:

                dbs.NN_tests_rounds.append(round)

                test_NN_coefficients(params, round, agent_population, fountain_population, dbs, use_start_basket=0, print_dets=0, print_fine_dets=0)

        # Here we update the Keynesian Institutions Data, if there are any, but only if there are agents with resources < 100 and for the first 200 rounds of the KI's life
        min_res_value = 1000

        for agent in agent_population.pop:
        
            if np.min(agent.agent_res_array) < min_res_value:

                min_res_value = np.min(agent.agent_res_array)

        if min_res_value < 100:

            for KI in KO_pop.pop:

#                if round - KI.day_created <= 200:

                text = '\n\nDay = %d\n' % (round)
                KI.write_to_notes(text)
    
                todays_transs = dbs.transs_daily_db[round]
    
                tot_trans_today = 0
    
                for trans_num in todays_transs:
    
                    trans = dbs.trans_db[trans_num]

                    if trans.good_a is not None:
    
                        if trans.location[0] == KI.loc[0] and trans.location[1] == KI.loc[1]:
        
                            text = '\ntransaction number = %d:' % (trans_num)
                            KI.write_to_notes(text)
        
                            text = ' move_num = %s  |  agent A (home = %s tribe %s) sold %s of Res %d |  agent B (home = %s tribe %s) sold %s of Res %d' % (trans.move_num, trans.agent_a_home, trans.agent_a_tribe, trans.tot_trans_ag_sell, trans.good_a, trans.agent_b_home, trans.agent_b_tribe, trans.tot_trans_ag_buy, trans.good_b)
                            KI.write_to_notes(text)
        
                            tot_trans_today += 1
        
                if tot_trans_today == 0:
    
                    text = '\nThere were no transactions today.'
                    KI.write_to_notes(text)
    
                text = '\n\n'
                KI.write_to_notes(text)
    
                for agent in KI.target_agents:
    
                    if agent.birth_date < round and agent.death_date > round:
    
                        if len(agent.trade_loc_rec) == 0:
    
                            agent.trade_loc_rec = np.array([[1000, 1000], [1000, 1000]])
    
    #                        input("Press Enter to continue...")
    
                        text = 'agent = %s (home %s tribe %s) start basket [%d, %d] optimal trans [%2.2f %2.2f] end basket [%1.2f %1.2f] res array = [%3.2f %3.2f] skills = [%1.2f %1.2f] | journey on grid start [%d %d] end [%d %d] \n' % (agent, agent.home, agent.tribe, agent.basket_array_start[0][0], agent.basket_array_start[0][1], agent.optimal_transs_systemic[round][0], agent.optimal_transs_systemic[round][1], agent.basket_array[0][0], agent.basket_array[0][1], agent.agent_res_array[0][0], agent.agent_res_array[0][1], agent.detect_skills_array[0][0], agent.detect_skills_array[0][1], agent.trade_loc_rec[0][0], agent.trade_loc_rec[0][1], agent.trade_loc_rec[-1][0], agent.trade_loc_rec[-1][1])
                        KI.write_to_notes(text)
    
                    else:
    
                        text = 'agent = %s (home %s tribe %s) is dead (death date = %s)\n' % (agent, agent.home, agent.tribe, agent.death_date)
                        KI.write_to_notes(text)

#                    if round == KI.day_created + 200:
#    
#                        text = '\n\nThis institution is now 200 rounds old so the reporting will now stop'
#                        KI.write_to_notes(text)
                
        # put Keynesian institution here: there are two cases - 'total' where we try to move a single market and 'sparse'
        # where we create a new market for agents in repeatedly dying location
        if (allow_Keynes_Inst == 'total' and round == Keynes_round) or (two_tribes == 1 and round == new_mkt_round):

            # print_fine_dets = 1

#            formal_inst = two_tribes_inst
            agent_population.ignore_strangers = 0

            # find new proposed market location
            if two_tribes == 0:

                if print_fine_dets:
                    print('\n dbs.sign_mkt_locs[round]', dbs.sign_mkt_locs[round])

                # We take the first location in dbs.sign_mkt_locs and find the furthest point from this
                x_coord_mkt = dbs.sign_mkt_locs[round][0][0]
                y_coord_mkt = dbs.sign_mkt_locs[round][0][1]

                # the furthest point will be this
                KI_x = int((x_coord_mkt + town_grid.dimen / 2.0) % town_grid.dimen)
                KI_y = int((y_coord_mkt + town_grid.dimen / 2.0) % town_grid.dimen)

                new_keynesian_location = np.array([KI_x, KI_y], dtype=int)

                if print_fine_dets:
                    print('\n new_keynesian_location', new_keynesian_location)

            elif two_tribes == 1:

                new_keynesian_location = np.array([60, 60], dtype=int)

            new_ko_folder = '%s/KI_day_%s' % (run_folder, round)
        
            ko_notes_file = '%s/00_notes_file.txt' % (new_ko_folder)

            # this line creates the directory
            os.makedirs(new_ko_folder)

            dead_ags_copy = copy.copy(dbs.dead_ags_grid_counter)

            if print_fine_dets:
                print('\n dead_ags_copy', dead_ags_copy)

            influenced_agents = []

            KIagents = []
            trgt_locations = []
            dead_ags_at_trgt_locs = []

            if two_tribes:
                
                KIagents = copy.copy(agent_population.pop)

            else:

                # ony some of the agents will be subject to the KI - we add them to an array like so, which becomes part of the KI object
                num_KI_agents = int(prop_KI_agents * len(agent_population.pop))     # note int will round this number down

                for agent_num in range(num_KI_agents):

                    KIagents.append(agent_population.pop[agent_num])

                if prop_KI_agents == 1.0 and (len(agent_population.pop) != num_KI_agents):
                    print('\n ODD: prop_KI_agents == 1.0 and (len(agent_population.pop) != num_KI_agents)')
                    print(' len(agent_population.pop) =', len(agent_population.pop))
                    print(' num_KI_agents =', num_KI_agents)
                    pause()

            if print_fine_dets:
                print('\n len(KIagents) =', len(KIagents))
                print('\n KIagents =', KIagents)

            for agent in agent_population.pop:

                trgt_locations.append(agent.home)
                dead_ags_at_trgt_locs.append(agent)

            # Create a new Keynesian Object
            new_ko = Keynesian_Object(round, copy.copy(new_keynesian_location), new_ko_folder, ko_notes_file, dead_ags_copy, copy.copy(dbs.dead_ags_grid_counter),
                                      copy.copy(KIagents), trgt_locations)

            KO_pop.pop.append(new_ko)
        
            # Append new_ko text_file
            add_text = "This is a Notes File pertaining to a proposed Keynesian Institution.\n\nThe Institution was proposed on day %s at location %s" % (round, new_keynesian_location)
        
            new_ko.write_to_notes(add_text)
        
            new_ko.add_initial_text(fountain_population, trade_prices, granular_mem, print_fine_dets, print_dets, dbs, town_grid, round, wait_at_tgt_moves)

            # print_dine_dets = 0

        # Here we propose a Keynesian institution if on any grid square more than two agents have died, which is an indicator of poverty at that location
        # the condition that len([cell for line in dbs.dead_ags_grid_counter for cell in line if cell > 0]) >= 2 means there must be more than one location for the dead agents
        # the condition len([cell for line in dbs.dead_ags_grid_counter for cell in line if cell > 0]) > 1 means there is more than one location
        if allow_Keynes_Inst == 'sparse':

            if np.max(dbs.dead_ags_grid_counter) >= 2:  # and len([cell for line in dbs.dead_ags_grid_counter for cell in line if cell > 0]) > 1:

                if min_res_value < 60:

                    propose_keynesian_inst(KO_pop, dbs, agent_population, dbs.min_res_levels_db, round, agent_res_init, town_grid,
                                           print_fine_dets, print_dets, run_folder, trade_moves, wait_at_tgt_moves,
                                           vision_len, fountain_population, trade_prices, granular_mem, loc_mkt, restrict_by_district)

        # record a load of data of not respecting property rights
        if respect_property_rights == 0:

            daily_prop_steal = []
            daily_prop_fight_back = []

            prop_steal_round_aggr = 0
            prop_fb_round_aggr = 0

            if two_tribes:
                daily_prop_steal_sharks = []
                daily_prop_fight_back_sharks = []

                daily_prop_steal_jets = []
                daily_prop_fight_back_jets = []

                prop_steal_round_aggr_sharks = 0
                prop_fb_round_aggr_sharks = 0

                prop_steal_round_aggr_jets = 0
                prop_fb_round_aggr_jets = 0

            num_above_50_steal = 0
            num_above_50_fb = 0

            num_below_50_steal = 0
            num_below_50_fb = 0

            prop_steal_round_aggr_above_50 = 0
            prop_fb_round_aggr_above_50 = 0

            prop_steal_round_aggr_below_50 = 0
            prop_fb_round_aggr_below_50 = 0

            if two_tribes:
                num_sharks = 0
                num_jets = 0

            # record historical prop_steal and prop_fight_back
            for agent in agent_population.pop:

                mean_prop_steal = 0
                mean_prop_fight_back = 0

                agent.prop_steal_history[round] = copy.copy(agent.prop_steal)
                agent.prop_fight_back_history[round] = copy.copy(agent.prop_fight_back)

                if fight_skill is not None and agent.death_date > round:
                    agent.fight_skill_history[round] = copy.copy(agent.fight_skill)

                # record all the agents' props
                daily_prop_steal.append(agent.prop_steal)
                daily_prop_fight_back.append(agent.prop_fight_back)

                prop_steal_round_aggr += agent.prop_steal
                prop_fb_round_aggr += agent.prop_fight_back

                if agent.tribe == 'sharks':
                    num_sharks += 1
                    prop_steal_round_aggr_sharks += agent.prop_steal
                    prop_fb_round_aggr_sharks += agent.prop_fight_back

                    daily_prop_steal_sharks.append(agent.prop_steal)
                    daily_prop_fight_back_sharks.append(agent.prop_fight_back)

                if agent.tribe == 'jets':
                    num_jets += 1
                    prop_steal_round_aggr_jets += agent.prop_steal
                    prop_fb_round_aggr_jets += agent.prop_fight_back

                    daily_prop_steal_jets.append(agent.prop_steal)
                    daily_prop_fight_back_jets.append(agent.prop_fight_back)

            #                if agent.prop_steal >= 0.5:
            #
            #                    prop_steal_round_aggr_above_50 += agent.prop_steal
            #                    num_above_50_steal += 1
            #
            #                else:
            #
            #                    prop_steal_round_aggr_below_50 += agent.prop_steal
            #                    num_below_50_steal += 1
            #
            #                if agent.prop_fight_back >= 0.5:
            #
            #                    prop_fb_round_aggr_above_50 += agent.prop_fight_back
            #                    num_above_50_fb += 1
            #
            #                else:
            #
            #                    prop_fb_round_aggr_below_50 += agent.prop_fight_back
            #                    num_below_50_fb += 1

            dbs.prop_steal_db[round] = daily_prop_steal
            dbs.prop_fight_back_db[round] = daily_prop_fight_back

            #            if two_tribes:
            #
            #                dbs.prop_steal_db_sharks[round] = daily_prop_steal_sharks
            #                dbs.prop_fight_back_db_sharks[round] = daily_prop_fight_back_sharks
            #
            #                dbs.prop_steal_db_jets[round] = daily_prop_steal_jets
            #                dbs.prop_fight_back_db_jets[round] = daily_prop_fight_back_jets

            if len(daily_prop_steal) > 0:

                dbs.prop_steal_std_db[round] = np.std(daily_prop_steal)

            else:

                dbs.prop_steal_std_db[round] = None

            if len(daily_prop_fight_back) > 0:

                dbs.prop_fb_std_db[round] = np.std(daily_prop_fight_back)

            else:

                dbs.prop_fb_std_db[round] = None

            if two_tribes:

                # sharks
                if len(daily_prop_steal_sharks) > 0:

                    dbs.prop_steal_std_db_sharks[round] = np.std(daily_prop_steal_sharks)

                else:

                    dbs.prop_steal_std_db_sharks[round] = None

                if len(daily_prop_fight_back_sharks) > 0:

                    dbs.prop_fb_std_db_sharks[round] = np.std(daily_prop_fight_back_sharks)

                else:

                    dbs.prop_fb_std_db_sharks[round] = None

                # jets
                if len(daily_prop_steal_jets) > 0:

                    dbs.prop_steal_std_db_jets[round] = np.std(daily_prop_steal_jets)

                else:

                    dbs.prop_steal_std_db_jets[round] = None

                if len(daily_prop_fight_back_jets) > 0:

                    dbs.prop_fb_std_db_jets[round] = np.std(daily_prop_fight_back_jets)

                else:

                    dbs.prop_fb_std_db_jets[round] = None

            # when appointing these values to databases, we need to be careful the denominators are not zero (if they are => None)
            if len(agent_population.pop) > 0:

                dbs.prop_steal_mean_db[round] = prop_steal_round_aggr / float(len(agent_population.pop))
                dbs.prop_fb_mean_db[round] = prop_fb_round_aggr / float(len(agent_population.pop))

            else:

                dbs.prop_steal_mean_db[round] = None
                dbs.prop_fb_mean_db[round] = None

            if two_tribes:

                if num_sharks > 0:

                    dbs.prop_steal_mean_db_sharks[round] = prop_steal_round_aggr_sharks / float(num_sharks)
                    dbs.prop_fb_mean_db_sharks[round] = prop_fb_round_aggr_sharks / float(num_sharks)

                else:

                    dbs.prop_steal_mean_db_sharks[round] = None
                    dbs.prop_fb_mean_db_sharks[round] = None

                if num_jets > 0:

                    dbs.prop_steal_mean_db_jets[round] = prop_steal_round_aggr_jets / float(num_jets)
                    dbs.prop_fb_mean_db_jets[round] = prop_fb_round_aggr_jets / float(num_jets)

                else:

                    dbs.prop_steal_mean_db_jets[round] = None
                    dbs.prop_fb_mean_db_jets[round] = None

        # update dbs.num_specialists
        for agent in agent_population.pop:

            # print('\n agent.detect_skills_array', agent.detect_skills_array)

            if agent.detect_skills_array[0][0] > 0.95:  # then the agent has 4 or 5 slots devoted to res 0 and its detection prob is above 0.95
                dbs.num_specialists[0][round] += 1

                if agent.detect_skills_array[0][0] == 1.0:
                    dbs.num_specialists_tot[0][round] += 1

            elif agent.detect_skills_array[0][1] > 0.95:  # then the agent has 4 or 5 slots devoted to res 1 and its detection prob is above 0.95

                dbs.num_specialists[1][round] += 1

                if agent.detect_skills_array[0][1] == 1.0:
                    dbs.num_specialists_tot[1][round] += 1

            else:

                dbs.num_specialists[2][round] += 1

            if agent.detect_skills_array[0][0] != 1.0 and agent.detect_skills_array[0][1] != 1.0:
                dbs.num_specialists_tot[2][round] += 1

    #            if num_above_50_steal > 0:
    #
    #                dbs.prop_steal_mean_above_50_db[round] = prop_steal_round_aggr_above_50 / float(num_above_50_steal)
    #
    #            else:
    #
    #                dbs.prop_steal_mean_above_50_db[round] = None
    #
    #            if num_above_50_fb > 0:
    #
    #                dbs.prop_fb_mean_above_50_db[round] = prop_fb_round_aggr_above_50 / float(num_above_50_fb)
    #
    #            else:
    #
    #                dbs.prop_fb_mean_above_50_db[round] = None
    #
    #            if num_below_50_steal > 0:
    #
    #                dbs.prop_steal_mean_below_50_db[round] = prop_steal_round_aggr_below_50 / float(num_below_50_steal)
    #
    #            else:
    #
    #                dbs.prop_steal_mean_below_50_db[round] = None
    #
    #            if num_below_50_fb > 0:
    #
    #                dbs.prop_fb_mean_below_50_db[round] = prop_fb_round_aggr_below_50 / float(num_below_50_fb)
    #
    #            else:
    #
    #                dbs.prop_fb_mean_below_50_db[round] = None

    #                mean_prop_steal += agent.prop_steal / float(len(agent_population.pop))
    #                mean_prop_fight_back += agent.prop_fight_back / float(len(agent_population.pop))
    #
    #                dbs.mean_prop_steal_hist[round] = mean_prop_steal
    #                dbs.mean_prop_fight_back_hist[round] = mean_prop_fight_back


        # Print some charts to track the progress of the run
    
        # We create a 'heatmap story' by looking at heatmaps created during successive periods over all rounds
        if heatmap_story == 1 and (round + 1) % heatmap_days_show == 0:          # then we show a chart
    
            segment_size = heatmap_days_show
            start_round = round - heatmap_days_show + 1
            end_round = round
    
            # evaluate trading on the town grid:
            trades_array_vis_seg = np.zeros(shape=(dimen, dimen), dtype=float)

            # this is for evaluating fights:
            fights_array_grid = np.zeros(shape=(dimen, dimen), dtype=int)

            for b in np.arange(start_round, end_round + 1):

                days_transs = dbs.transs_daily_db[b]

                for trans_num in days_transs:
    
                    trans = dbs.trans_db[trans_num]

                    if trans.tot_trans_ag_sell is not None:

                        x_coord = trans.location[0]
                        y_coord = trans.location[1]
                        trades_array_vis_seg[x_coord][y_coord] += ((trans.tot_trans_ag_sell + trans.tot_trans_ag_buy) / 2.0)

                days_fights = dbs.fights_daily_db[b]

                for fight_num in days_fights:
                    
                    fight = dbs.fights_db[fight_num]
                    
                    x_coord = fight.location[0]
                    y_coord = fight.location[1]
                    fights_array_grid[x_coord][y_coord] += 1

            # print transactions on last day only
            if round == rounds - 1:

                b = round - round - 1
                
                last_day_transs = dbs.transs_daily_db[b]

                trades_array_last_day = np.zeros(shape=(dimen, dimen), dtype=float)

                for trans_num in days_transs:
    
                    trans = dbs.trans_db[trans_num]

                    if trans.tot_trans_ag_sell is not None:

                        x_coord = trans.location[0]
                        y_coord = trans.location[1]
                        trades_array_last_day[x_coord][y_coord] += ((trans.tot_trans_ag_sell + trans.tot_trans_ag_buy) / 2.0)

            # transactions heatmap:
            title = 'Total Transactions : Rounds %s to %s' % (start_round, end_round)
            title = ''

#            create_heat_map(dimen, trades_array_vis_seg, run_folder, 'Blues', '', 'trading_segmented %s_to_%s' % (start_round, end_round), dpi='high')

            # Record the data for the last round:
            if round == rounds - 1:

                dbs.last_round_trans_data = trades_array_vis_seg

                create_heat_map(dimen, trades_array_vis_seg, params.run_transactions_folder, 'Blues', title, 'trading_segmented_rnd_%d' % round, dpi='high')
                create_heat_map(dimen, trades_array_last_day, params.run_transactions_folder, 'Blues', 'Total Transactions - Last Round', 'trading_segmented_last_day', dpi='high')

            else:

                create_heat_map(dimen, trades_array_vis_seg, params.run_transactions_folder, 'Blues', title, 'trading_segmented_rnd_%d' % round, dpi='high')

            title_2 = 'Agent Min Res Levels: Round %s' % (end_round)
            create_heat_map(dimen, dbs.min_res_levels_db[end_round - 1], params.run_population_folder, 'Reds', title_2, 'min_res_levs', dpi='low')
            #
            # Fights heatmap
            if respect_property_rights == 0:

                title = 'Total Fights : Rounds %s to %s' % (start_round, end_round)

                if round == rounds - 1:

                    create_heat_map(dimen, fights_array_grid, params.run_fights_charts_folder, 'Reds', title, 'fights_heatmap_rnd_%d' % round, dpi='high')

                else:

                    create_heat_map(dimen, fights_array_grid, params.run_fights_charts_folder, 'Reds', title, 'fights_heatmap_rnd_%d' % round, dpi='low')

            # create a chart with 2 heatmaps, show side-by-side
            # create_plotly_2_heatmaps(fights_array_grid, trades_array_vis_seg, folder=run_folder, filename='heatmaps', labels=['Fights', 'Transactions'])

             # Now we create a heatmap to show dead agents
#            if np.max(dbs.dead_ags_grid_counter) > 0:
#                title = 'Dead Agents Heatmap - Day %s' % (round)
#                create_heat_map(dimen, dbs.dead_ags_grid_counter, run_folder, 'Greens', title, 'dead_ags', dpi='low')

            # Now we create a heatmap to show which areas of the grid are serviced by markets and which are not.  Here we
            # consider a market significant if >= 2 agents have transacted at a particular location
#            sign_mkt_thresh = 2

            sign_mkt_locs = []
            sign_fights_locs = []
            sign_locs = []
            num_agents_at_sign_locs = []

            for x_coord in np.arange(dimen):
                for y_coord in np.arange(dimen):

                    if len(dbs.trades_array_ags[x_coord][y_coord]) >= sign_mkt_thresh:
                        sign_mkt_locs.append([x_coord, y_coord])

                        # we need to count the number of agents transacting at each sign loc
                        num_agents_at_sign_locs.append(len(dbs.trades_array_ags[x_coord][y_coord]))

                    if len(dbs.fights_array_ags[x_coord][y_coord]) >= sign_mkt_thresh:
                        sign_fights_locs.append([x_coord, y_coord])

                    if len(dbs.trades_array_ags[x_coord][y_coord]) >= sign_mkt_thresh or len(dbs.fights_array_ags[x_coord][y_coord]) >= sign_mkt_thresh:
                        sign_locs.append([x_coord, y_coord])

            if print_serviced_locations:

                serviced_grid = np.zeros(shape=(dimen, dimen), dtype=int)
                for x_coord in np.arange(dimen):
                    for y_coord in np.arange(dimen):

                        for sign_mkt_loc in sign_mkt_locs:

                            # print('\n 2 wait_at_tgt_moves', wait_at_tgt_moves)

                            if within_striking_dist(wait_at_target_til_end, town_grid, [x_coord, y_coord], wait_at_tgt_moves, vision_len, sign_mkt_loc, move=0, has_acted=0, print_dets=0):

                                serviced_grid[x_coord][y_coord] += 1

                name = 'serviced_grids %s_to_%s' % (start_round, end_round)

                create_heat_map_double(dimen, serviced_grid, homes_array, run_folder, 'Greens', 'Purples', '', name, dpi='high')

                # title = 'Locations Serviced by Markets: Rounds %s - %s' % (start_round, end_round)
                # create_heat_map_double(dimen, serviced_grid, homes_array, run_folder, 'Greens', 'Purples', 'Serviced Locations', name, dpi='low')

            # Update dbs.agent_summary_notes_file with agent foraging data
            total_forag_slots_array = np.zeros(shape=(num_res_founts))

            for for_strat_array in dbs.for_strat_db[round]:
                for strat in for_strat_array:
                    total_forag_slots_array[strat] += 1

            text = '\n\n\nday %s - total time slots devoted to foraging for resources:\n\n' % (round)
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            for res in np.arange(num_res_founts):

                text = 'resource %s = %3.0f\t' % (res, total_forag_slots_array[res])
                with open(dbs.agent_summary_notes_file, 'a') as myfile:
                    myfile.write(text)

            text = '\ttotal = %3.0f\t' % (np.sum(total_forag_slots_array))
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            num_ags_full_spec = np.zeros(shape=(num_res_founts))
            num_ags_max_det_prob = np.zeros(shape=(num_res_founts))

            for agent in agent_population.pop:

                tally_array = np.zeros(shape=(num_res_founts))

                for res in np.arange(num_res_founts):

                    if all(x == res for x in agent.for_strat_array[0]) == True:

                        num_ags_full_spec[res] += 1

                for slot in np.arange(for_strat_parts):

#                    print('\n slot =', slot, 'agent.for_strat_array ', agent.for_strat_array)

                    fount = agent.for_strat_array[0][slot]

                    tally_array[fount] += 1

                max_tally = np.max(tally_array)

#                print('tally_array', tally_array)
#                print('max_tally', max_tally)

                max_res = 0

                for res in np.arange(num_res_founts):

                    if tally_array[res] == max_tally:

                        max_res = res

#                print('max_res', max_res)
#                print('agent.detect_skills_array[0]', agent.detect_skills_array[0])

                if agent.detect_skills_array[0][max_res] > 0.99:

                    num_ags_max_det_prob[max_res] += 1

            text = '\n\n---> number of agents with maxed out foraging strats (all time slots devoted to one resource):\n\n' % (round)
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            for res in np.arange(num_res_founts):

                text = 'resource %s: %3.0f agents\t' % (res, num_ags_full_spec[res])
                with open(dbs.agent_summary_notes_file, 'a') as myfile:
                    myfile.write(text)

            text = '\ttotal = %3.0f of %3.0f agents (= %3.1fpct)\t' % (np.sum(num_ags_full_spec), len(agent_population.pop), (np.sum(num_ags_full_spec) * 100 / len(agent_population.pop)))
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            text = '\n\n---> number of agents with max detection probs > 99.9pct by resource:\n\n' % (round)
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            for res in np.arange(num_res_founts):

                text = 'resource %s: %3.0f agents\t' % (res, num_ags_max_det_prob[res])
                with open(dbs.agent_summary_notes_file, 'a') as myfile:
                    myfile.write(text)

            text = '\ttotal = %3.0f of %3.0f agents (= %3.1fpct)\t' % (np.sum(num_ags_max_det_prob), len(agent_population.pop), (np.sum(num_ags_max_det_prob) * 100 / len(agent_population.pop)))
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            # We add a note regarding significant market locations: number of agents transacting and fighting on each
            text = '\n\nSignificant Market Locations:\n'
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            for loc_num in range(len(sign_mkt_locs)):

                loc = sign_mkt_locs[loc_num]

                text = '\nLocation = %s  |  Num of traders = %d' % (loc, num_agents_at_sign_locs[loc_num])
                with open(dbs.agent_summary_notes_file, 'a') as myfile:
                    myfile.write(text)

            text = '\n\nTotal Number of Traders = %d' % (np.sum(num_agents_at_sign_locs))
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            text = '\n\n---------------------------------------------------------------------------------------------------------------'
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            # here we print out key data for agents who were alive - we are interested in all agents, dead or alive
            agents_dead_or_alive = list(copy.copy(agent_population.pop))

            # if end_round == 599:
            #     print_fine_dets = 1

            if print_fine_dets:
                print('\n initial agents_dead_or_alive', agents_dead_or_alive)
                print(' len(agents_dead_or_alive)', len(agents_dead_or_alive))
                print(' len(agent_population.dead_agent_array)', len(agent_population.dead_agent_array), '\n')

            for dead_ag in agent_population.dead_agent_array:

                if print_fine_dets:
                    print(' dead_ag', dead_ag, 'home', dead_ag.home, ' death_date', dead_ag.death_date)

                if start_round <= dead_ag.death_date <= end_round:

                    if print_fine_dets:
                        print(' start_round < agent.death_date < end_round + 1')

                    agents_dead_or_alive.append(dead_ag)

            if print_fine_dets:
                print('\n final agents_dead_or_alive', agents_dead_or_alive)
                print('\n len(agents_dead_or_alive)', len(agents_dead_or_alive), '\n')

            # if end_round == 599:
            #     print_fine_dets = 0

            # now write to dbs.sign_locs_notes_file: in this file we want a structure which has day first, then move, then significant location and then the transactions at that location followed by fights there
            for day in range(start_round, end_round + 1):

                # print('\n\n day', day)

                gross_net_scens_ps_changes = {'TRADE TRADE' : np.zeros(shape=3, dtype=float), 'TRADE STEAL' : np.zeros(shape=3, dtype=float), 'F_BCK STEAL' : np.zeros(shape=3, dtype=float), 'STEAL F_BCK' : np.zeros(shape=3, dtype=float),
                                              'STEAL TRADE' : np.zeros(shape=3, dtype=float), 'STEAL STEAL' : np.zeros(shape=3, dtype=float)}
                gross_net_scens_pfb_changes = {'TRADE TRADE' : np.zeros(shape=3, dtype=float), 'TRADE STEAL' : np.zeros(shape=3, dtype=float), 'F_BCK STEAL' : np.zeros(shape=3, dtype=float), 'STEAL F_BCK' : np.zeros(shape=3, dtype=float),
                                              'STEAL TRADE' : np.zeros(shape=3, dtype=float), 'STEAL STEAL' : np.zeros(shape=3, dtype=float)}

                todays_transs = dbs.transs_daily_db[day]
                todays_fights = dbs.fights_daily_db[day]

                if len(agents_dead_or_alive) > 0:

                    # if we want to track the gross transaction data we first have to find gross purchases and sales of each resource for each agent
                    if params.print_gross_trans_data:

                        # we need this dictionary to identify agents below
                        agent_home_dict = {}

                        # create array for
                        gross_sales = np.zeros(shape=(2), dtype=float)            # note [0] res 0, [1] is res 1

                        # first zero the arrays
                        for agent in agents_dead_or_alive:
                            agent.gross_trans = np.zeros(shape=(2, 2), dtype=float)         # note [0] res 0, [1] is res 1; and [][0] is sales, [][1] is purchases
                            agent.num_transs = 0
                            agent.num_fights = 0

                            agent_home_dict[str(agent.home)] = agent

                            # print('agent is ', agent)

                        # print('\n agent_home_dict =', agent_home_dict)

                        for trans_num in todays_transs:

                            trans = dbs.trans_db[trans_num]

                            # print('\n trans_num ', trans_num, 'trans.agent_a_home', trans.agent_a_home)

                            init_agent = agent_home_dict[str(trans.agent_a_home)]
                            cp_agent = agent_home_dict[str(trans.agent_b_home)]

                            init_agent.gross_trans[trans.good_a][0] += trans.tot_trans_ag_sell
                            init_agent.gross_trans[trans.good_b][1] += trans.tot_trans_ag_buy
                            init_agent.num_transs += 1

                            cp_agent.gross_trans[trans.good_b][0] += trans.tot_trans_ag_buy
                            cp_agent.gross_trans[trans.good_a][1] += trans.tot_trans_ag_sell
                            cp_agent.num_transs += 1

                            gross_sales[trans.good_a] += trans.tot_trans_ag_sell
                            gross_sales[trans.good_b] += trans.tot_trans_ag_buy

                        # count number of fights for each agent
                        for fight_num in todays_fights:

                            fight = dbs.fights_db[fight_num]

                            # dbs.str_ag_to_ag_dict[str(agent)] = agent

                            init_ag = dbs.str_ag_to_ag_dict[fight.initiator]
                            init_ag.num_fights += 1

                            cp_ag = dbs.str_ag_to_ag_dict[fight.counterpart]
                            cp_ag.num_fights += 1

                            # print('\n gross_sales =', gross_sales)

                    # here we write to dbs.sign_locs_notes_file to start the 'day' - the agents' target locations then follow
                    text = '<h2>Day = %d </h2>' % (day)
                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                        myfile.write(text)

                    # add title bar
                    text = '<p>'
                    text += 'home &nbsp;&nbsp; '
                    text += 'age &nbsp;&nbsp;&nbsp; '
                    text += 'target &nbsp;&nbsp;&nbsp; '
                    text += 'dist &nbsp; '
                    text += 'for strat &nbsp;&nbsp;&nbsp;&nbsp; '
                    text += 'det probs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '
                    text += 'res (start) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '
                    text += '(change) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '
                    text += 'bskt start -> end &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '
                    text += 'ch &nbsp; '
                    text += 'p_s st &nbsp;&nbsp;&nbsp; '
                    text += '(ch) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '
                    text += 'p_fb &nbsp;&nbsp;&nbsp; '
                    text += '(ch) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '
                    text += 'trns &nbsp; '
                    text += 'fhts &nbsp; '
                    text += 'gross trans'
                    text += '</p>'

                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                        myfile.write(text)

                    # record which agents born and died
                    new_births_array = []
                    new_deaths_array = []
                    gross_ress_held = np.zeros(shape=2, dtype=float)

                    # record total amount collected during foraging
                    total_res_coll = np.zeros(shape=2, dtype=float)

                    # we now wanqt to sort these agents according to the order they reached the magrket; agnd second bzy their resource specialksaqtion
                    # first creaqte a lkst which has dimensions len(agents_dead_or_alive) x 3
                    sorted_agents_dead_or_alive = []

                    for agent in agents_dead_or_alive:

                        agent_data_array = []

                        if (agent.birth_date <= day <= agent.death_date) or (agent.birth_date == day == 0):

                            # find distance to target
                            if len(agent.start_trgt_loc_rec[day]) > 0 and agent.start_trgt_loc_rec[day][0][0] is not None:
                                dist_to_mkt = np.max(abs_dist_on_torus(agent.home, agent.start_trgt_loc_rec[day][0], town_grid.dimen))

                            else:
                                dist_to_mkt = 26

                            agent_data_array.append(dist_to_mkt)

                            # find res spec
                            if agent.detect_skills_array_hist[day][0] > 0.95:

                                spec = 0

                            elif agent.detect_skills_array_hist[day][1] > 0.95:

                                spec = 1

                            else:

                                spec = np.median(agent.for_strat_hist[day])

                            agent_data_array.append(spec)

                            # now add the agent
                            agent_data_array.append(agent)

                        else:           # for agents who died in a previous day

                            agent_data_array = [26, 3, agent]

                        sorted_agents_dead_or_alive.append(agent_data_array)

                        # print('\n agent_data_array =', agent_data_array)

                # print('\n pre-sorted sorted_agents_dead_or_alive', sorted_agents_dead_or_alive)

                sorted_agents_dead_or_alive = sorted(sorted_agents_dead_or_alive, key=lambda x: (x[0],x[1]))

                # print('\n post-sorted sorted_agents_dead_or_alive', sorted_agents_dead_or_alive)

                alive_agent_tally = 0

                text = '<p>'

                for line in sorted_agents_dead_or_alive:

                    agent = line[2]

                    if (agent.birth_date < day < agent.death_date) or (agent.birth_date == day == 0):     # so we don't include dead or unborn agents

                        # tresting for error here
                        if len(agent.start_trgt_loc_rec[day]) == 0:
                            print('\n day =', day, 'agent.home', agent.home, 'agent.birth_date', agent.birth_date, 'agent.death_date', agent.death_date, 'agent.agent_res_array last known', agent.agent_res_array)
                            print('\n agent.start_trgt_loc_rec:\n', agent.start_trgt_loc_rec)
                            print('\n agent.agent_res_array_start_hist', agent.agent_res_array_start_hist)
                            print('\n agent.basket_array_start_hist', agent.basket_array_start_hist)
                            pause()

                        # find distance to target
                        if len(agent.start_trgt_loc_rec[day]) > 0 and agent.start_trgt_loc_rec[day][0][0] is not None:
                            dist_to_mkt = '%02d' % np.max(abs_dist_on_torus(agent.home, agent.start_trgt_loc_rec[day][0], town_grid.dimen))

                        else:
                            dist_to_mkt = 'na'

                        if agent.start_trgt_loc_rec[day][0][0] is None:
                            target_loc = '[na na]'

                        else:
                            target_loc = '[%02d %02d]' % (agent.start_trgt_loc_rec[day][0][0], agent.start_trgt_loc_rec[day][0][1])

                        res_0_ch = text_col_html(agent.agent_res_array_hist[day][0] - agent.agent_res_array_start_hist[day][0], bands=[0.0, 1.0, 2.0, 3.0, 4.0])
                        res_1_ch = text_col_html(agent.agent_res_array_hist[day][1] - agent.agent_res_array_start_hist[day][1], bands=[0.0, 1.0, 2.0, 3.0, 4.0])

                        if day > 0:

                            ag_start_ps = agent.prop_steal_history[day - 1]
                            ag_start_pfb = agent.prop_fight_back_history[day - 1]

                        else:

                            ag_start_ps = agent.prop_steal_history[day]
                            ag_start_pfb = agent.prop_fight_back_history[day]

                        ps_ch = text_col_html(agent.prop_steal_history[day] - ag_start_ps)
                        pfb_ch = text_col_html(agent.prop_fight_back_history[day] - ag_start_pfb)

                        text += '%02d %02d &nbsp;&nbsp;&nbsp;' % (agent.home[0], agent.home[1])
                        text += '%04d &nbsp;&nbsp;' % (day - agent.birth_date)
                        text += '%s &nbsp;&nbsp;' % target_loc
                        text += '%s &nbsp;&nbsp;' % dist_to_mkt
                        text += '%s &nbsp;&nbsp;' % agent.for_strat_hist[day]
                        text += '[%1.4f, %1.4f] &nbsp;&nbsp;' % (agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1])
                        text += '[%5.5s, %5.5s] &nbsp;&nbsp;' % (agent.agent_res_array_start_hist[day][0], agent.agent_res_array_start_hist[day][1])
                        text += '[%s, %s] &nbsp;&nbsp;' % (res_0_ch, res_1_ch)
                        text += '[%d, %d] &nbsp;&nbsp;' % (agent.basket_array_start_hist[day][0], agent.basket_array_start_hist[day][1])
                        text += '[%1.3f, %1.3f] &nbsp;&nbsp;' % (agent.basket_array_hist[day][0], agent.basket_array_hist[day][1])
                        text += '%02d &nbsp;&nbsp;' % agent.num_children_hist[day]
                        text += '%5.5s &nbsp; (%s) &nbsp;&nbsp;'  % (ag_start_ps, ps_ch)
                        text += '%5.5s &nbsp; (%s) &nbsp;&nbsp;' % (ag_start_pfb, pfb_ch)
                        text += '%02d &nbsp;&nbsp;' % agent.num_transs
                        text += '%02d &nbsp;&nbsp;' % agent.num_fights
                        text += '[%1.5f  %1.5f (%1.5f) &nbsp;&nbsp;' % (-1 * agent.gross_trans[0][0], agent.gross_trans[0][1], (agent.gross_trans[0][1] - agent.gross_trans[0][0]))
                        text += '%1.5f   %1.5f (%1.5f)]<br>' % (-1 * agent.gross_trans[1][0], agent.gross_trans[1][1], (agent.gross_trans[1][1] - agent.gross_trans[1][0]))

                        total_res_coll += agent.basket_array_start_hist[day]
                        gross_ress_held += agent.agent_res_array_start_hist[day]

                        alive_agent_tally += 1

                    if agent.birth_date == day and day != 0:
                        new_births_array.append(agent)

                    if day == agent.death_date:

                        # print('\n day = ', day, 'agent died - agent home loc =', agent.home)
                        new_deaths_array.append(agent)

                        total_res_coll += agent.basket_array_start_hist[day]
                        gross_ress_held += agent.agent_res_array_start_hist[day]
                        alive_agent_tally += 1

                text += '</p>'

                with open(dbs.sign_locs_notes_file, 'a') as myfile:
                    myfile.write(text)

                # note any new deaths
                if len(new_deaths_array) > 0:

                    # print('\n len(new_deaths_array) > 0', len(new_deaths_array))

                    text = '\n\nDeaths on this day<br><br>\n'
                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                        myfile.write(text)

                    for agent in new_deaths_array:

                        if agent.start_trgt_loc_rec[day][0][0] is None:
                            target_loc = '[NA NA]'
                            dist_to_mkt = 'n/a'

                        else:
                            target_loc = '[%2d %2d]' % (agent.start_trgt_loc_rec[day][0][0], agent.start_trgt_loc_rec[day][0][1])
                            dist_to_mkt = np.max(abs_dist_on_torus(agent.home, agent.start_trgt_loc_rec[day][0], town_grid.dimen))

                        text = '<p>%s &nbsp;&nbsp; %4d &nbsp;&nbsp; %s &nbsp;&nbsp; %s &nbsp;&nbsp; %s &nbsp;&nbsp; [%5.5s, %5.5s] &nbsp;&nbsp; [%5.5s, %5.5s] &nbsp;&nbsp; [%d, %d] &nbsp;&nbsp; [%5.5s, %5.5s] &nbsp;&nbsp; ' \
                               '%2d &nbsp;&nbsp; %5.5s &nbsp;&nbsp; %5.5s</p>' %\
                              (agent.home, day - agent.birth_date,
                              target_loc, str(dist_to_mkt),
                              agent.for_strat_hist[day],
                              agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1],
                              agent.agent_res_array_start_hist[day][0], agent.agent_res_array_start_hist[day][1],
                              agent.basket_array_start_hist[day][0], agent.basket_array_start_hist[day][1],
                              agent.basket_array_hist[day][0], agent.basket_array_hist[day][1],
                              agent.num_children_hist[day],
                              agent.prop_steal_history[day], agent.prop_fight_back_history[day])

                        with open(dbs.sign_locs_notes_file, 'a') as myfile:
                            myfile.write(text)

                # note any new births
                if len(new_births_array) > 0:

                    text = '\n\nBirths on this day<br><br>\n'
                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                        myfile.write(text)

                    # add title bar
                    text = '\nhome\tage\tfor strat\tdet probs\tres (start)\tparental homes\tp_s\tp_fb\n'
                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                        myfile.write(text)

                    for agent in new_births_array:

                        text = '<p>%s &nbsp;&nbsp; %4d &nbsp;&nbsp; %s &nbsp;&nbsp; [%5.5s, %5.5s] &nbsp;&nbsp; [%5.5s, %5.5s] &nbsp;&nbsp; %s &nbsp;&nbsp; %s &nbsp;&nbsp; %4.4s &nbsp;&nbsp; %4.4s</p>' %\
                               (agent.home, day - agent.birth_date, agent.for_strat_hist[day],
                                agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1],
                                agent.agent_res_array_start_hist[day][0], agent.agent_res_array_start_hist[day][1],
                                agent.parents[0].home, agent.parents[1].home,
                                agent.prop_steal_history[day], agent.prop_fight_back_history[day])

                        with open(dbs.sign_locs_notes_file, 'a') as myfile:
                            myfile.write(text)

                # now write how many of each resource collected
                if dbs.main_db[3][day] > 0.0:            # population should be > 0

                    mean_for = total_res_coll / float(alive_agent_tally)
                    mean_ress_held = gross_ress_held / float(alive_agent_tally)

                    # print('\n total_res_coll =', total_res_coll)
                    # print(' mean_for =', mean_for)
                    # print(' mean_ress_held =', gross_sales)
                    # print(' dbs.mean_price_history[1][0][day] =', dbs.mean_price_history[1][0][day])
                    # print(' alive_agent_tally =', alive_agent_tally)
                    # print(' len(dbs.transs_daily_db[day]) =', len(dbs.transs_daily_db[day]))
                    # print(' gross_sales =', gross_sales)

                    text = '<p>Tot for: &nbsp;&nbsp; [%3d %3d] &nbsp;&nbsp; (mn [%4.4s %4.4s] / ag) &nbsp;&nbsp; | &nbsp;&nbsp; mn res [%6.6s %6.6s] &nbsp;&nbsp; rat %5.5s &nbsp;&nbsp; | &nbsp;&nbsp; mn wkg pr: res A / res B  %5.5s &nbsp;&nbsp; |'\
                           ' &nbsp;&nbsp; no ags %d &nbsp;&nbsp; | &nbsp;&nbsp; tot_trans %d' %\
                           (total_res_coll[0], total_res_coll[1],
                            mean_for[0], mean_for[1],
                            mean_ress_held[0], mean_ress_held[1],
                            mean_ress_held[0] / float(mean_ress_held[1]),
                            dbs.mean_price_history[1][0][day],
                            alive_agent_tally,
                            len(dbs.transs_daily_db[day]))

                    text += ' &nbsp;&nbsp; | &nbsp;&nbsp; gr sales [%6.6s %6.6s]<br></p>' % (gross_sales[0] * -1, gross_sales[1] * -1)

                    if params.respect_property_rights == 0:

                        if day > 0 and dbs.prop_steal_mean_db[day] is not None and dbs.prop_fb_mean_db[day] is not None:
                            mn_ps_hist = dbs.prop_steal_mean_db[day - 1]
                            mn_ps_hist_ch = text_col_html(dbs.prop_steal_mean_db[day] - dbs.prop_steal_mean_db[day - 1])
                            mn_pfb_hist = dbs.prop_fb_mean_db[day - 1]
                            mn_pfb_hist_ch = text_col_html(dbs.prop_fb_mean_db[day] - dbs.prop_fb_mean_db[day - 1])

                        else:
                            mn_ps_hist = dbs.prop_steal_mean_db[day]
                            mn_ps_hist_ch = '0.00000'
                            mn_pfb_hist = dbs.prop_fb_mean_db[day]
                            mn_pfb_hist_ch = '0.00000'

                        # print(' mn_ps_hist =', mn_ps_hist)
                        # print(' mn_ps_hist_ch =', mn_ps_hist_ch)
                        # print(' mn_pfb_hist =', mn_pfb_hist)
                        # print(' mn_pfb_hist_ch =', mn_pfb_hist_ch)
                        # print(' len(todays_fights) =', len(todays_fights))

                        text += ' &nbsp;&nbsp; mn ps %1.4f (ch %s)' % (mn_ps_hist, mn_ps_hist_ch)
                        text += ' &nbsp;&nbsp; mn pfb %1.4f (ch %s)' % (mn_pfb_hist, mn_pfb_hist_ch)
                        text += ' &nbsp;&nbsp; tot_fights %d' % len(todays_fights)

                    text += '<br></p>'

                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                        myfile.write(text)

                # # create a bit of space
                # text = '\n'
                # with open(dbs.sign_locs_notes_file, 'a') as myfile:
                #     myfile.write(text)

                if (black_shoop_exp == 1 or agent_population.change_agent is not None) and len(agent_population.black_shoop_list) > 0:
                    
                    for black_shoop in agent_population.black_shoop_list:

                        black_shoop.trans = []
                        black_shoop.fights = []
                        black_shoop.move_nums = []

                # print('\n writing: ', text)

                # find move numbers in which agents fought or traded, and put the corresponding transaction numbers in a dictionary
                move_nums = []
                trans_move_nums_dict = {}
                fight_move_nums_dict = {}

                # print('\n todays_transs:', todays_transs)

                for trans_num in todays_transs:

                    trans = dbs.trans_db[trans_num]

                    if trans.move_num not in move_nums:

                        move_nums.append(trans.move_num)

                    if trans.move_num not in trans_move_nums_dict:

                        trans_move_nums_dict[trans.move_num] = [trans_num]

                    else:

                        trans_move_nums_dict[trans.move_num].append(trans_num)

                    # add this location to dbs.transaction_locations if it's not there already
                    if str(trans.location) not in dbs.transaction_locations:

                        dbs.transaction_locations[str(trans.location)] = [[] for i in range(rounds)]

                    # now add the agents in the transaction to dbs.transaction_locations[str(trans.location)][day] if not already there
                    if trans.agent_a not in dbs.transaction_locations[str(trans.location)][day]:
                        dbs.transaction_locations[str(trans.location)][day].append(trans.agent_a)

                    if trans.agent_b not in dbs.transaction_locations[str(trans.location)][day]:
                        dbs.transaction_locations[str(trans.location)][day].append(trans.agent_b)

                    if (black_shoop_exp == 1 or agent_population.change_agent is not None) and len(agent_population.black_shoop_list) > 0:

                        for black_shoop in agent_population.black_shoop_list:
                        
                            if trans.agent_a == str(black_shoop) or trans.agent_b == str(black_shoop):

                                black_shoop.trans.append(trans_num)
        
                                if trans.move_num not in black_shoop.move_nums:
                                    
                                    black_shoop.move_nums.append(trans.move_num)

                for fight_num in todays_fights:

                    fight = dbs.fights_db[fight_num]

                    if fight.move_num not in move_nums:

                        move_nums.append(fight.move_num)

                    if fight.move_num not in fight_move_nums_dict:

                        fight_move_nums_dict[fight.move_num] = [fight_num]

                    else:

                        fight_move_nums_dict[fight.move_num].append(fight_num)

                    if (black_shoop_exp == 1 or agent_population.change_agent is not None) and len(agent_population.black_shoop_list) > 0:
                        
                        for black_shoop in agent_population.black_shoop_list:
                                                    
                            if fight.initiator == str(black_shoop) or fight.counterpart == str(black_shoop):

                                black_shoop.fights.append(fight_num)
        
                                if fight.move_num not in black_shoop.move_nums:
                                    
                                    black_shoop.move_nums.append(fight.move_num)

#                print('\n black_shoop.trans', black_shoop.trans)
#                print('\n black_shoop.fights', black_shoop.fights)

                # print('\n move_nums =', move_nums)
                # print('\n trans_move_nums_dict =', trans_move_nums_dict)
                # print('\n fight_move_nums_dict =', fight_move_nums_dict)

                # place them in order
                move_nums.sort()

                # print('\n move_nums sorted =', move_nums)
#                 print('\n move_nums =', move_nums)
#                 print('\n todays_transs =', todays_transs)
#                 print(' todays_fights =', todays_fights)

                # pause()

                for move in move_nums:

                    # print('\n\n ---> move =', move)

                    sign_locs_move = []

                    text = '<p> ---> Move Number = %d:<br>' % (move)
                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                        myfile.write(text)

                    # print('\n writing: ', text)

                    # sign_locs_move_copy = []

                    if move in trans_move_nums_dict:

                        for trans_num in trans_move_nums_dict[move]:

                            trans = dbs.trans_db[trans_num]

                            # print('\n sign_locs_move', sign_locs_move)

                            if list(trans.location) not in sign_locs_move:
                                sign_locs_move.append(list(trans.location))

                    if move in fight_move_nums_dict:

                        for fight_num in fight_move_nums_dict[move]:

                            fight = dbs.fights_db[fight_num]

                            if list(fight.location) not in sign_locs_move:
                                sign_locs_move.append(list(fight.location))

                    # print('\n sign_locs_move', sign_locs_move)

                    # if len(sign_locs_move) > 1:
                    #     pause()

                    # we want to list the locations with transactions or fights in order of location when we want to list the transactions first and then the fights
                    for loc in sign_locs_move:

                        # print('\n loc', loc)
                        
                        fight_at_loc = 0
                        trans_at_loc = 0
                        fight_or_trans_at_loc = 0
    
                        # work out if there was a fight and / or transaction at this location
                        if move in trans_move_nums_dict:
                            for trans_num in trans_move_nums_dict[move]:

                                trans = dbs.trans_db[trans_num]

                                if trans.location[0] == loc[0] and trans.location[1] == loc[1]:

                                    trans_at_loc = 1
                                    fight_or_trans_at_loc = 1

                        if move in fight_move_nums_dict:
                            for fight_num in fight_move_nums_dict[move]:

                                fight = dbs.fights_db[fight_num]

                                if fight.location[0] == loc[0] and fight.location[1] == loc[1]:

                                    fight_at_loc = 1
                                    fight_or_trans_at_loc = 1
    
#                        print(' fight_at_loc =', fight_at_loc)
#                        print(' trans_at_loc =', trans_at_loc)
#                        print(' fight_or_trans_at_loc =', fight_or_trans_at_loc)
    
                        if fight_or_trans_at_loc:
    
                            text = '<br>Location = %s:</p>' % (loc)
                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                myfile.write(text)

                            # print('\n writing: ', text)

                        # print('\n trans_at_loc', trans_at_loc)
                        # print(' fight_at_loc', fight_at_loc)
                        # print(' fight_or_trans_at_loc', fight_or_trans_at_loc)

                        if trans_at_loc:

                            # print('\n trans_at_loc')

                            for trans_num in trans_move_nums_dict[move]:
        
                                trans = dbs.trans_db[trans_num]

                                # dbs.check_trans.append(trans_num)

                                # print('\n -> trans_num =', trans_num)
                                # print(' trans =', trans)
                                # print(' trans.good_a =', trans.good_a)
                                # print(' trans.location =', trans.location)
                                # print(' loc =', loc)

                                if trans.good_a is not None:

                                    text = ''

                                    if trans.location[0] == loc[0] and trans.location[1] == loc[1]:

                                        text += 'trans num = %d: &nbsp; day = %d &nbsp; | &nbsp; agent A (home = %s) sold %1.3f of Res %d &nbsp; | &nbsp; agent B (home = %s) sold %1.3f of Res %d<br>'\
                                                % (trans_num, trans.day, trans.agent_a_home, trans.tot_trans_ag_sell, trans.good_a, trans.agent_b_home, trans.tot_trans_ag_buy, trans.good_b)

                                        if respect_property_rights == 0:

                                            # now add to gross_net_scens_ps_changes and gross_net_scens_pfb_changes
                                            dict_str = 'TRADE TRADE'

                                            # print('\n trans.initiator_new_prop_steal - trans.initiator_start_prop_steal =', trans.initiator_new_prop_steal - trans.initiator_start_prop_steal)

                                            # initiator - ps -ve and net:
                                            gross_net_scens_ps_changes[dict_str][1] += trans.initiator_new_prop_steal - trans.initiator_start_prop_steal
                                            gross_net_scens_ps_changes[dict_str][2] += trans.initiator_new_prop_steal - trans.initiator_start_prop_steal

                                            # counterpart - ps -ve and net:
                                            gross_net_scens_ps_changes[dict_str][1] += trans.counterpart_new_prop_steal - trans.counterpart_start_prop_steal
                                            gross_net_scens_ps_changes[dict_str][2] += trans.counterpart_new_prop_steal - trans.counterpart_start_prop_steal

                                    # text += '</p>'

                                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                        myfile.write(text)

                            # text = '\n'
                            # with open(dbs.sign_locs_notes_file, 'a') as myfile:
                            #     myfile.write(text)

                            # print('\n writing: ', text)

                        if fight_at_loc:

                            text = ''

                            for fight_num in fight_move_nums_dict[move]:
    
#                                print('\n fight_num', fight_num)
    
                                fight = dbs.fights_db[fight_num]
    
#                                print(' fight.location =', fight.location, 'loc', loc)
    
                                if fight.location[0] == loc[0] and fight.location[1] == loc[1]:      # Fight

                                    # dbs.check_fights.append(fight_num)

#                                    print(' fight.location[0] == loc[0] and fight.location[1] == loc[1]')
    
                                    # text = '\nft num = %d:' % (fight_num)
                                    # with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                    #     myfile.write(text)

                                    # print('\n writing: ', text)

                                    if str(fight.winner) == fight.initiator:
                                        winner_text = 'ag'
                                    elif str(fight.winner) == fight.counterpart:
                                        winner_text = 'cp'
                                    else:
                                        winner_text = 'n/a'

                                    # print('\n fight.winner', fight.winner)
                                    # print(' fight.initiator', fight.initiator)
                                    # print(' fight.counterpart', fight.counterpart)

                                    if fight.initiator_dec == 'steal':
                                        init_dec = 'STEAL'

                                    elif fight.initiator_dec == 'trade':
                                        init_dec = 'TRADE'

                                    elif fight.initiator_dec == 'fight_back':
                                        init_dec = 'F_BCK'

                                    # create a string for adding ps and pfb values to dictionary
                                    dict_str = '%s ' % init_dec

                                    if fight.counterpart_dec == 'steal':
                                        cp_dec = 'STEAL'

                                    elif fight.counterpart_dec == 'trade':
                                        cp_dec = 'TRADE'

                                    elif fight.counterpart_dec == 'fight_back':
                                        cp_dec = 'F_BCK'

                                    dict_str += '%s' % cp_dec

                                    # now add to gross_net_scens_ps_changes and gross_net_scens_pfb_changes counterpart - start with initiator (ps and pfb) then counterpart
                                    # initiator ps: gross positive values:
                                    if fight.initiator_new_prop_steal - fight.initiator_start_prop_steal > 0.0:
                                        gross_net_scens_ps_changes[dict_str][0] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                                    # gross negative values:
                                    elif fight.initiator_new_prop_steal - fight.initiator_start_prop_steal < 0.0:
                                        gross_net_scens_ps_changes[dict_str][1] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                                    # net
                                    gross_net_scens_ps_changes[dict_str][2] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                                    # initiator pfb: gross positive values:
                                    if dict_str != 'STEAL STEAL':       # pfb will not change so this speeds things up

                                        if fight.initiator_new_prop_fight_back - fight.initiator_start_prop_fight_back > 0.0:
                                            gross_net_scens_pfb_changes[dict_str][0] += fight.initiator_new_prop_fight_back - fight.initiator_start_prop_fight_back
                                        # gross negative values:
                                        if fight.initiator_new_prop_fight_back - fight.initiator_start_prop_fight_back < 0.0:
                                            gross_net_scens_pfb_changes[dict_str][1] += fight.initiator_new_prop_fight_back - fight.initiator_start_prop_fight_back
                                        # net
                                        gross_net_scens_pfb_changes[dict_str][2] += fight.initiator_new_prop_fight_back - fight.initiator_start_prop_fight_back

                                    # counterpart ps: gross positive values:
                                    if fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal > 0.0:
                                        gross_net_scens_ps_changes[dict_str][0] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                                    # gross negative values:
                                    elif fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal < 0.0:
                                        gross_net_scens_ps_changes[dict_str][1] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                                    # net
                                    gross_net_scens_ps_changes[dict_str][2] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

                                    # initiator pfb: gross positive values:

                                    if dict_str != 'STEAL STEAL':

                                        if fight.counterpart_new_prop_fight_back - fight.counterpart_start_prop_fight_back > 0.0:
                                            gross_net_scens_pfb_changes[dict_str][0] += fight.counterpart_new_prop_fight_back - fight.counterpart_start_prop_fight_back
                                        # gross negative values:
                                        if fight.counterpart_new_prop_fight_back - fight.counterpart_start_prop_fight_back < 0.0:
                                            gross_net_scens_pfb_changes[dict_str][1] += fight.counterpart_new_prop_fight_back - fight.counterpart_start_prop_fight_back
                                        # net
                                        gross_net_scens_pfb_changes[dict_str][2] += fight.counterpart_new_prop_fight_back - fight.counterpart_start_prop_fight_back

                                    text += 'ft num = %d: &nbsp; ag @ [%02d %02d] &nbsp; bsk [%2.2f %2.2f] &nbsp; | &nbsp; cp @ [%02d %02d] &nbsp; bsk [%2.2f %2.2f] &nbsp; | &nbsp; ag dec: "%s" &nbsp; cp dec: "%s" &nbsp;' \
                                            '| &nbsp; win %s &nbsp; | &nbsp; ag gain [%2.3f %2.3f] &nbsp; | &nbsp; ag ps st %1.5f &nbsp; ch %s &nbsp; pfb %1.5f &nbsp; ch %s &nbsp; cp ps st %1.5f &nbsp; ch %s &nbsp; pfb %1.5f &nbsp; ch %s<br>' %\
                                           (fight_num, str_agent_to_home_dict[fight.initiator][0], str_agent_to_home_dict[fight.initiator][1], fight.initiator_start_basket[0][0], fight.initiator_start_basket[0][1],
                                            str_agent_to_home_dict[fight.counterpart][0], str_agent_to_home_dict[fight.counterpart][1],
                                            fight.counterpart_start_basket[0][0], fight.counterpart_start_basket[0][1], init_dec, cp_dec, winner_text, fight.agent_res_gain[0],
                                            fight.agent_res_gain[1],
                                            fight.initiator_start_prop_steal, text_col_html(fight.initiator_new_prop_steal - fight.initiator_start_prop_steal),
                                            fight.initiator_start_prop_fight_back, text_col_html(fight.initiator_new_prop_fight_back - fight.initiator_start_prop_fight_back),
                                            fight.counterpart_start_prop_steal, text_col_html(fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal),
                                            fight.counterpart_start_prop_fight_back, text_col_html(fight.counterpart_new_prop_fight_back - fight.counterpart_start_prop_fight_back))

                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                myfile.write(text)

                                    # print('\n writing: ', text)

#                                    Fight_Object initiator_new_prop_steal, initiator_new_prop_fight_back, counterpart_new_prop_steal, counterpart_new_prop_fight_back
#                             text = '\n'
#                             with open(dbs.sign_locs_notes_file, 'a') as myfile:
#                                 myfile.write(text)

                            # print('\n writing: ', text)

                # Now print the gross and net changes in agents' propensities:
                text = '<p> <span style="font-weight:bold"> Gross (+/-) and Net Changes in Propensities: Propensity to Steal (alive and recently dead agents)</span><br><br>'

                # print('gross_net_scens_ps_changes:', gross_net_scens_ps_changes)

                bands_1 = [0, 1, 2, 5, 10]
                scenarios = ['TRADE TRADE', 'F_BCK STEAL', 'TRADE STEAL', 'STEAL F_BCK', 'STEAL TRADE', 'STEAL STEAL']
                scenarios_nums = ['1', '2F', '2A', '3F', '3A', '4']
                net_net_val = 0.0
                scen_counter = 0

                for scen in scenarios:

                    # print('scen', scen)

                    text += 'Scenario %s: plus %s, minus %s, net %s<br>' % (scen, text_col_html(gross_net_scens_ps_changes[scen][0], bands=bands_1), text_col_html(gross_net_scens_ps_changes[scen][1], bands=bands_1),
                                                                      text_col_html(gross_net_scens_ps_changes[scen][2], bands=bands_1))

                    net_net_val += gross_net_scens_ps_changes[scen][2]

                    dbs.ps_net_contr_by_scen[scenarios_nums[scen_counter]][day] += gross_net_scens_ps_changes[scen][2]
                    dbs.ps_net_contr_by_scen_pos[scenarios_nums[scen_counter]][day] += abs(gross_net_scens_ps_changes[scen][2])

                    scen_counter += 1

                # this is a special bit of data, for comparing impact of 2F and 3F on ps:
                dbs.ps_net_contr_by_scen_pos['3F + 2F'][day] += (gross_net_scens_ps_changes['STEAL F_BCK'][2] + gross_net_scens_ps_changes['F_BCK STEAL'][2])

                text += '<br>Net net value = %1.6f | per agent: %s<br>' % (net_net_val, text_col_html(net_net_val / float(len(agents_dead_or_alive)), bands=[0, 0.001, 0.005, 0.01, 0.02]))
                text += '<p> <span style="font-weight:bold"> Gross (+/-) and Net Changes in Propensities: Propensity to Fight Back (alive and recently dead agents)</span><br><br>'

                # print('gross_net_scens_pfb_changes:', gross_net_scens_pfb_changes)

                net_net_val = 0.0
                scen_counter = 0

                for scen in scenarios:

                    text += 'Scenario %s: %s, %s, %s<br>' % (scen, text_col_html(gross_net_scens_pfb_changes[scen][0], bands=bands_1), text_col_html(gross_net_scens_pfb_changes[scen][1], bands=bands_1),
                                                                      text_col_html(gross_net_scens_pfb_changes[scen][2], bands=bands_1))

                    net_net_val += gross_net_scens_pfb_changes[scen][2]

                    dbs.pfb_net_contr_by_scen[scenarios_nums[scen_counter]][day] += gross_net_scens_pfb_changes[scen][2]

                    scen_counter += 1

                text += '<br>Net net value = %1.6f | per agent: %s<br>' % (net_net_val, text_col_html(net_net_val / float(len(agents_dead_or_alive)), bands=[0, 0.001, 0.005, 0.01, 0.02]))

                with open(dbs.sign_locs_notes_file, 'a') as myfile:
                    myfile.write(text)

                # now print out number of interactions in each scenario
                text = '<p> <span style="font-weight:bold"> Number of Transactions in Each Scenario:</span><br><br>'

                # find total interaction in the day
                tot_ints = 0
                for scen in scenarios_nums:
                    tot_ints += dbs.quadrants_tallies_actual[scen][day]

                # tot_ints make 1 if 0 (for division) and float
                tot_ints = float(np.max([tot_ints, 1]))

                for scen in scenarios_nums:

                    text += ' Scenario %s: Number = %d (pct = %1.2f)<br>' % (scen, dbs.quadrants_tallies_actual[scen][day], (100 * dbs.quadrants_tallies_actual[scen][day]) / tot_ints)

                text += '<br>Total Interactions = %d<br><br><br>' % tot_ints

                with open(dbs.sign_locs_notes_file, 'a') as myfile:
                    myfile.write(text)

                # pause()

                # record the equivalent data for the black shoop, if it's alive
                if (black_shoop_exp == 1 or agent_population.change_agent is not None) and len(agent_population.black_shoop_list) > 0:

                    for black_shoop in agent_population.black_shoop_list:

                        # place them in order
                        black_shoop.move_nums.sort()
                        
    #                    print('\n black_shoop_move_nums =', black_shoop_move_nums)
    #                    print(' black_shoop_trans =', black_shoop_trans)
    #                    print(' black_shoop_fights =', black_shoop_fights)
    
                        for move_num in black_shoop.move_nums:
    
                            sign_locs_move = []
        
                            trans_grid = np.zeros(shape=(town_grid.dimen, town_grid.dimen))
                            fights_grid = np.zeros(shape=(town_grid.dimen, town_grid.dimen))
        
                            for trans_num in black_shoop.trans:
                
                                trans = dbs.trans_db[trans_num]
        
                                if trans.move_num == move_num:
        
                                    x_coord = trans.location[0]
                                    y_coord = trans.location[1]
                
                                    trans_grid[x_coord][y_coord] += 1
                
                            for fight_num in black_shoop.fights:
            
                                fight = dbs.fights_db[fight_num]
        
                                if fight.move_num == move_num:
        
                                    x_coord = fight.location[0]
                                    y_coord = fight.location[1]
                
                                    fights_grid[x_coord][y_coord] += 1
            
                            for x_coord in range(town_grid.dimen):
                                for y_coord in range(town_grid.dimen):
            
                                    if trans_grid[x_coord][y_coord] > 0 or fights_grid[x_coord][y_coord] > 0:
            
                                        sign_locs_move.append([x_coord, y_coord])
        
        #                    print('\n move =', move)
            
                            text = '\n\n---> Day %d Move Number = %d:\n' % (day, move_num)
                            with open(black_shoop.black_shoop_file, 'a') as myfile:
                                myfile.write(text)
            
                            for loc in sign_locs_move:

        #                        print('\n loc', loc)
                                
                                fight_at_loc = 0
                                trans_at_loc = 0
                                fight_or_trans_at_loc = 0
            
                                # work out if there was a fight and / or transaction at this location
                                for trans_num in black_shoop.trans:
            
                                    trans = dbs.trans_db[trans_num]
            
                                    if trans.move_num == move_num:
            
                                        trans_at_loc = 1
                                        fight_or_trans_at_loc = 1
            
                                for fight_num in black_shoop.fights:
            
                                    fight = dbs.fights_db[fight_num]
            
                                    if fight.move_num == move_num:
            
                                        fight_at_loc = 1
                                        fight_or_trans_at_loc = 1
            
        #                        print(' fight_at_loc =', fight_at_loc)
        #                        print(' trans_at_loc =', trans_at_loc)
        #                        print(' fight_or_trans_at_loc =', fight_or_trans_at_loc)
            
                                if fight_or_trans_at_loc:
            
                                    text = '\nLocation = %s:\n' % (loc)
                                    with open(black_shoop.black_shoop_file, 'a') as myfile:
                                        myfile.write(text) 
            
                                if trans_at_loc:
            
                                    for trans_num in black_shoop.trans:
                
                                        trans = dbs.trans_db[trans_num]
            
                                        if trans.tot_trans_ag_sell is not None:
            
                                            if move_num == trans.move_num and trans.location[0] == loc[0] and trans.location[1] == loc[1]:
                
                                                text = '\ntrans num = %d:' % (trans_num)
                                                with open(black_shoop.black_shoop_file, 'a') as myfile:
                                                    myfile.write(text)
                            
                                                text = ' day = %d  |  move_num = %s  |  agent A (home = %s) sold %1.3f of Res %d |  agent B (home = %s) sold %1.3f of Res %d' % (trans.day, trans.move_num, trans.agent_a_home, trans.tot_trans_ag_sell, trans.good_a, trans.agent_b_home, trans.tot_trans_ag_buy, trans.good_b)
                                                with open(black_shoop.black_shoop_file, 'a') as myfile:
                                                    myfile.write(text)                
        
                                    text = '\n'
                                    with open(black_shoop.black_shoop_file, 'a') as myfile:
                                        myfile.write(text)  
        
                                if fight_at_loc:
            
                                    for fight_num in black_shoop.fights:
            
        #                                print('\n fight_num', fight_num)
            
                                        fight = dbs.fights_db[fight_num]
            
        #                                print(' fight.location =', fight.location, 'loc', loc)
            
                                        if move_num == fight.move_num and fight.location[0] == loc[0] and fight.location[1] == loc[1]:
            
        #                                    print(' fight.location[0] == loc[0] and fight.location[1] == loc[1]')
            
                                            text = '\nfight num = %d:' % (fight_num)
                                            with open(black_shoop.black_shoop_file, 'a') as myfile:
                                                myfile.write(text)
            
                                            text = ' transfer to intiator (home %s) %s  |  new prop_steal = %1.4f  |  new prop_fight_back = %1.4f  |  cp home = %s  |  new cp prop_steal = %1.4f  |  new cp prop_fight_back = %1.4f ' % (str_agent_to_home_dict[fight.initiator], fight.agent_res_gain, fight.initiator_new_prop_steal, fight.initiator_new_prop_fight_back, str_agent_to_home_dict[fight.counterpart], fight.counterpart_new_prop_steal, fight.counterpart_new_prop_fight_back)
                                            with open(black_shoop.black_shoop_file, 'a') as myfile:
                                                myfile.write(text)
        #                                    Fight_Object initiator_new_prop_steal, initiator_new_prop_fight_back, counterpart_new_prop_steal, counterpart_new_prop_fight_back
                                    text = '\n'
                                    with open(black_shoop.black_shoop_file, 'a') as myfile:
                                        myfile.write(text)

#                        elif fight_at_loc == 0:
#            
#                            text = '\nThere were no fights here today.'
#                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
#                                myfile.write(text)
    
    
    #                    pause()
    
#                    for agent in dbs.trades_array_ags[loc[0]][loc[1]]:
#        
#                        if agent.birth_date < day and agent.death_date > day:
#    
#    #                        print('\n agent', agent, 'home', agent.home, 'loc_hit', agent.hist_trade_loc_rec[round])
#    
#                            if len(agent.hist_trade_loc_rec[day]) > 0:
#        
#                                text = '\nagent = %s (home %s) start basket [%d, %d] optimal trans [%2.2f %2.2f] end basket [%1.2f %1.2f] res array = [%3.2f %3.2f] skills = [%1.2f %1.2f] | journey on grid start %s end %s' % (agent, agent.home, agent.basket_array_start[0][0], agent.basket_array_start[0][1], agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1], agent.basket_array[0][0], agent.basket_array[0][1], agent.agent_res_array[0][0], agent.agent_res_array[0][1], agent.detect_skills_array[0][0], agent.detect_skills_array[0][1], agent.hist_trade_loc_rec[day][0], agent.hist_trade_loc_rec[day][-1])
#    
#                            else:
#        
#                                text = '\nagent = %s (home %s) start basket [%d, %d] optimal trans [%2.2f %2.2f] end basket [%1.2f %1.2f] res array = [%3.2f %3.2f] skills = [%1.2f %1.2f] | journey on grid start None end None' % (agent, agent.home, agent.basket_array_start[0][0], agent.basket_array_start[0][1], agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1], agent.basket_array[0][0], agent.basket_array[0][1], agent.agent_res_array[0][0], agent.agent_res_array[0][1], agent.detect_skills_array[0][0], agent.detect_skills_array[0][1])
#    
#                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
#                                myfile.write(text)
#    
#                        else:
#    
#                            text = '\nagent = %s (home %s) is dead (death date = %s)\n' % (agent, agent.home, agent.death_date)
#                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
#                                myfile.write(text)

            fileHandle = open(dbs.sign_locs_notes_file)
            fileHandle.close()

                # pause()

            # Here we create a daily report relating to the market locations nTarget
#            write_daily_market_report(run_folder, dbs, fountain_population, round, start_round, end_round, print_fine_dets)

#            create_heat_map_double_plotly(dimen, serviced_grid, homes_array, data_folder, 'Greens', 'Purples', title, 'serviced_grids', round, agent_population)

#            raw_input("Press Enter to continue...")

#        for sell_res in range(num_res_founts):
#            for buy_res in range(num_res_founts):
#
#                if sell_res < buy_res:
#
#                    print '\n dbs.latest_prices[sell_res][buy_res] =', dbs.latest_prices[sell_res][buy_res], '\n'
#                
#                    for agent in agent_population.pop:
#                        print 'agent', agent, 'wkg_prices_memory[sell_res][buy_res] =', agent.wkg_prices_memory[sell_res][buy_res]
    
#        raw_input("Press Enter to continue...")

#        # and create a text file showing agents' key data, including foraging strategies
#        if round > 100:
#
#            # write successful transactions data
#            write_succ_trans_data(dbs, round, town_grid, print_dets, run_folder, daily=0, daily_db=[])
#
#            write_key_agent_data(dbs, agent_population, fountain_population, run_folder, vision_len, town_grid, rounds)

        if constitutional_voting == 1:      # here we record all the consitutional voting data: we do this at the end of the round before the constitution is changed

            if (round - start_const_proces + 1) % const_proc_test_period == 0 and (round - start_const_proces + 1) / float(const_proc_test_period) >= 0:        # we create arrays to record agents' resources and we record the agent alive and their min level of resource

                experiment = int((round - start_const_proces + 1) / float(const_proc_test_period))

                print('\n round = ', round, 'experiment', experiment, '\n')
    
                # record resource levels
                for agent in agent_population.pop:

                    # note that we use pop variation in this exercise so we must account for the agent's resources lost through having children
                    agent_min_res = np.mean(agent.agent_res_array[0]) + np.mean(agent.resources_to_children)

                    print('agent', agent, 'res', agent.agent_res_array[0], 'agent.resources_to_children', agent.resources_to_children, 'add mean', np.mean(agent.resources_to_children))
    
                    dbs.constitutional_agents[experiment].append(agent)
                    dbs.constitutional_min_ress[experiment].append(agent_min_res)
    
                print('\n dbs.constitutional_agents:\n', dbs.constitutional_agents)
                print('\n dbs.constitutional_min_ress:\n', dbs.constitutional_min_ress)

        # we want to count the number of agents with prop_steals above 1 or below 0 if delib == 'both':
        if delib == 'both':

            for agent in agent_population.pop:

                if agent.prop_steal <= 0.0 or agent.prop_steal >= 1.0:

                    dbs.total_trans_habit[round] += 1

                else:

                    dbs.total_trans_delib[round] += 1

        # here we record the agents' props steal in their order in agent_population.pop for calculating correlation later on
        if respect_property_rights == 0 and len(ps_corr) > 0:

            if round == 0:

                dbs.ps_corr_array = []

            if len(agent_population.pop) == num_agents:

                agents_pss = []

                for agent in agent_population.pop:

                    agents_pss.append(agent.prop_steal)

                dbs.ps_corr_array.append(agents_pss)

        # add to database which records hawks and doves and PA agents
        num_doves = 0
        num_PA = 0
        num_hawks = 0

        for ag in agent_population.pop:
            if ag.prop_steal < 0.0:
                if ag.prop_fight_back > 1.0:
                    num_PA += 1
                elif ag.prop_fight_back < 0.0:
                    num_doves += 1
            elif ag.prop_steal > 1.0:
                num_hawks += 1

        dbs.num_doves[round] = num_doves
        dbs.num_PA[round] = num_PA
        dbs.num_hawks[round] = num_hawks

    #-->>
    #-->> This marks the end of the round iterations - everything below is data processing after all the round iterations <<--#
    #-->>

    # print('\n dbs.num_doves =', dbs.num_doves)
    # print('\n dbs.num_PA =', dbs.num_PA)
    # print('\n dbs.num_hawks =', dbs.num_hawks)

    # pause()     # xxxx

    if respect_property_rights == 0:

        if agree_location == 'super_strong' or agree_location == 'strong':
            
            write_agreed_locs(dbs, run_folder, rounds)
        
        # start with prop_steal and prop_fight_back
    #    prop_steal_array = np.zeros(shape=(2, rounds), dtype=float)
#        prop_steal_array = [np.arange(rounds)]

        data_prop_steal_cloud = []
        data_prop_steal_cloud_alive = []
        data_prop_steal_cloud_dead_scat = []
        data_prop_steal_cloud_dead_line = []

        data_prop_steal_cloud_2 = []
        data_prop_steal_cloud_2_alive = []
        data_prop_steal_cloud_2_dead_scat = []
        data_prop_steal_cloud_2_dead_line = []

        data_prop_fight_back_cloud = []
        data_prop_fight_back_cloud_alive = []
        data_prop_fight_back_cloud_dead_scat = []
        data_prop_fight_back_cloud_dead_line = []

        data_prop_fight_back_cloud_2 = []
        data_prop_fight_back_cloud_2_alive = []
        data_prop_fight_back_cloud_2_dead_scat = []
        data_prop_fight_back_cloud_2_dead_line = []

        data_prop_steal_pc = [np.arange(rounds)]
        data_prop_fight_back_pc = [np.arange(rounds)]

        # for saving all agents ps data:
        data_prop_steal_fan_chart = [[] for i in range(rounds)]
        data_prop_fb_fan_chart = [[] for i in range(rounds)]

        # for all agents alive at start and end
        data_prop_steal_alive_fan_chart = [[] for i in range(rounds)]
        data_prop_fb_alive_fan_chart = [[] for i in range(rounds)]

        # for scatter plot data (agents' propensities journey)
        scatter_props_x_data = []
        scatter_props_y_data = []

        # data_prop_steal_fan_chart = np.zeros(shape=(len(agent_population.pop) + len(agent_population.dead_agent_array), rounds))
        # data_prop_fb_fan_chart = np.zeros(shape=(len(agent_population.pop) + len(agent_population.dead_agent_array), rounds))

        if fight_skill is not None:
            
            data_fight_skill = [np.arange(rounds)]

        # ag_num_counter = 0

        prop_steal_collated = [[] for i in range(rounds)]
        prop_fb_collated = [[] for i in range(rounds)]

        for agent in agent_population.pop:

            for day in range(rounds):

                if agent.birth_date == 0:  # the agent is in agent_population.pop and has birth_date == 0 so they were alive throughout

                    data_prop_steal_alive_fan_chart[day].append(agent.prop_steal_history[day])
                    data_prop_fb_alive_fan_chart[day].append(agent.prop_fight_back_history[day])

                if agent.birth_date <= day:
                    data_prop_steal_fan_chart[day].append(agent.prop_steal_history[day])
                    data_prop_fb_fan_chart[day].append(agent.prop_fight_back_history[day])

                    prop_steal_collated[day].append(agent.prop_steal_history[day])
                    prop_fb_collated[day].append(agent.prop_fight_back_history[day])

                else:

                    agent.prop_steal_history[day] = None
                    agent.prop_fight_back_history[day] = None

                    if fight_skill is not None:
                        agent.fight_skill_history[day] = None

            # print('\n agent.fight_skill_history =', agent.fight_skill_history)

            # here we create traces for the wealthy agent
            if start_1_rich_agent and agent == agent_population.wealthy_agent:
                trace_prop_steal_wealthy_agent = go.Scatter(x=np.arange(rounds), y=agent.prop_steal_history, connectgaps=False, name='%s' % agent.home, line=dict(color='red', width=2))
                trace_prop_fight_back_wealthy_agent = go.Scatter(x=np.arange(rounds), y=agent.prop_fight_back_history, connectgaps=False, name='%s' % agent.home, line=dict(color='blue', width=2))

            else:
                trace_prop_steal_cloud = go.Scatter(x=np.arange(rounds), y=agent.prop_steal_history, connectgaps=False, name='%s' % agent.home, mode='markers', marker=dict(size=1, color='blue'))
                trace_prop_steal_cloud_2 = go.Scatter(x=np.arange(rounds), y=agent.prop_steal_history, connectgaps=False, name='%s' % agent.home, mode='markers', marker=dict(size=4, color='blue'))
                trace_prop_fight_back_cloud = go.Scatter(x=np.arange(rounds), y=agent.prop_fight_back_history, connectgaps=False, name='%s' % agent.home, mode='markers', marker=dict(size=2, color='red'))
                trace_prop_fight_back_cloud_alive = go.Scatter(x=np.arange(rounds), y=agent.prop_fight_back_history, connectgaps=False, name='%s' % agent.home, mode='markers', marker=dict(size=2, color='blue'))
                trace_prop_fight_back_cloud_2 = go.Scatter(x=np.arange(rounds), y=agent.prop_fight_back_history, connectgaps=False, name='%s' % agent.home, mode='markers', marker=dict(size=4, color='blue'))
                trace_prop_fight_back_cloud_2_alive = go.Scatter(x=np.arange(rounds), y=agent.prop_fight_back_history, connectgaps=False, name='%s' % agent.home, mode='markers', marker=dict(size=4, color='blue'))

                data_prop_steal_cloud.append(trace_prop_steal_cloud)
                data_prop_steal_cloud_alive.append(trace_prop_steal_cloud)

                data_prop_fight_back_cloud.append(trace_prop_fight_back_cloud)
                data_prop_fight_back_cloud_alive.append(trace_prop_fight_back_cloud_alive)

                data_prop_steal_cloud_2.append(trace_prop_steal_cloud_2)
                data_prop_steal_cloud_2_alive.append(trace_prop_steal_cloud_2)

                data_prop_fight_back_cloud_2.append(trace_prop_fight_back_cloud_2)
                data_prop_fight_back_cloud_2_alive.append(trace_prop_fight_back_cloud_2_alive)

            data_prop_steal_pc.append(agent.prop_steal_history)
            data_prop_fight_back_pc.append(agent.prop_fight_back_history)

            # for scatter plot charts:
            for x_datum in agent.prop_steal_history:
                scatter_props_x_data.append(x_datum)

            for y_datum in agent.prop_fight_back_history:
                scatter_props_y_data.append(y_datum)

            if fight_skill is not None:

                # trace_fight_skill = go.Scatter(x=np.arange(rounds), y=agent.fight_skill_history, connectgaps=False, name='%s' % agent.home)
                data_fight_skill.append(agent.fight_skill_history)

        # print('\n agent_population.dead_agent_array:', agent_population.dead_agent_array)

        for dead_agent in agent_population.dead_agent_array:

            # print('\n dead_agent ', dead_agent)
            # print(' dead_agent.prop_steal_history =', dead_agent.prop_steal_history)

            for day in range(rounds):

                if dead_agent.birth_date <= day < dead_agent.death_date:

                    data_prop_steal_fan_chart[day].append(dead_agent.prop_steal_history[day])
                    data_prop_fb_fan_chart[day].append(dead_agent.prop_fight_back_history[day])

                    prop_steal_collated[day].append(dead_agent.prop_steal_history[day])
                    prop_fb_collated[day].append(dead_agent.prop_fight_back_history[day])

                    # for scatter plot charts:
                    for x_datum in dead_agent.prop_steal_history:
                        scatter_props_x_data.append(x_datum)

                    for y_datum in dead_agent.prop_fight_back_history:
                        scatter_props_y_data.append(y_datum)

                else:

                    dead_agent.prop_steal_history[day] = None
                    dead_agent.prop_fight_back_history[day] = None

                    if fight_skill is not None:
                        dead_agent.fight_skill_history[day] = None

            # print('\n dead_agent.fight_skill_history =', dead_agent.fight_skill_history)
            # print('\n dead_agent.fight_skill_history[dead_agent.death_date] =', dead_agent.fight_skill_history[dead_agent.death_date])

            # here we create traces for the wealthy agent
            if start_1_rich_agent and dead_agent == agent_population.wealthy_agent:
                trace_prop_steal_wealthy_agent = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_steal_history, connectgaps=False, name='%s' % dead_agent.home, line=dict(color='red', width=4))
                trace_prop_fight_back_wealthy_agent = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_fight_back_history, connectgaps=False, name='%s' % dead_agent.home, line=dict(color='blue', width=2))

            trace_prop_steal_cloud = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_steal_history, connectgaps=False, name='%s' % dead_agent.home, mode='markers', marker=dict(size=1, color='blue'))
            trace_prop_steal_cloud_dead_scat = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_steal_history, connectgaps=False, name='%s' % dead_agent.home, mode='markers', marker=dict(size=1, color='red'))

            if show_al_capones == 1:
                if len(agent_population.dead_agent_array) > 0 and dead_agent == agent_population.dead_agent_array[-1]:
                    y_data = generate_MA_array(dead_agent.prop_steal_history, might_contain_None=True, last_datum=dead_agent.death_date)
                    # print('\n dead_agent ', dead_agent, 'y_data :\n\n', y_data)
                    # print(' dead_agent.death_date =', dead_agent.death_date)
                    # print(' y_data[dead_agent.death_date] =', y_data[dead_agent.death_date])
                    # if dead_agent.death_date < 99:
                    #     print(' y_data[dead_agent.death_date + 1] =', y_data[dead_agent.death_date + 1])
                    trace_prop_steal_cloud_dead_line = go.Scatter(x=np.arange(rounds), y=y_data, connectgaps=False, name='%s' % dead_agent.home, line=dict(color='red', width=2))
            else:
                y_data = generate_MA_array(dead_agent.prop_steal_history, might_contain_None=True, last_datum=dead_agent.death_date)
                trace_prop_steal_cloud_dead_line = go.Scatter(x=np.arange(rounds), y=y_data, connectgaps=False, name='%s' % dead_agent.home, line=dict(color='red', width=2))

            trace_prop_steal_cloud_2 = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_steal_history, connectgaps=False, name='%s' % dead_agent.home, mode='markers', marker=dict(size=4, color='blue'))

            trace_prop_steal_cloud_2_dead_scat = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_steal_history, connectgaps=False, name='%s' % dead_agent.home, mode='markers', marker=dict(size=4, color='red'))

            if show_al_capones == 1:
                if len(agent_population.dead_agent_array) > 0 and dead_agent == agent_population.dead_agent_array[-1]:
                    y_data = generate_MA_array(dead_agent.prop_steal_history, might_contain_None=True, last_datum=dead_agent.death_date)
                    trace_prop_steal_cloud_2_dead_line = go.Scatter(x=np.arange(rounds), y=y_data, connectgaps=False, name='%s' % dead_agent.home, line=dict(color='red', width=2))
                    # print('\n trace_prop_steal_cloud_2_dead_line =', trace_prop_steal_cloud_2_dead_line)
            else:
                y_data = generate_MA_array(dead_agent.prop_steal_history, might_contain_None=True, last_datum=dead_agent.death_date)
                trace_prop_steal_cloud_2_dead_line = go.Scatter(x=np.arange(rounds), y=y_data, connectgaps=False, name='%s' % dead_agent.home, line=dict(color='red', width=2))

            trace_prop_fight_back_cloud = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_fight_back_history, connectgaps=False, name='%s' % dead_agent.home, mode='markers', marker=dict(size=2, color='red'))

            trace_prop_fight_back_cloud_dead_scat = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_fight_back_history, connectgaps=False, name='%s' % dead_agent.home, mode='markers', marker=dict(size=2, color='red'))

            if show_al_capones == 1:
                if len(agent_population.dead_agent_array) > 0 and dead_agent == agent_population.dead_agent_array[-1]:
                    y_data = generate_MA_array(dead_agent.prop_fight_back_history, might_contain_None=True, last_datum=dead_agent.death_date)
                    trace_prop_fight_back_cloud_dead_line = go.Scatter(x=np.arange(rounds), y=y_data, connectgaps=False, name='%s' % dead_agent.home, line=dict(color='red', width=2))
            else:
                y_data = generate_MA_array(dead_agent.prop_fight_back_history, might_contain_None=True, last_datum=dead_agent.death_date)
                trace_prop_fight_back_cloud_dead_line = go.Scatter(x=np.arange(rounds), y=y_data, connectgaps=False, name='%s' % dead_agent.home, line=dict(color='red', width=2))

            trace_prop_fight_back_cloud_2 = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_fight_back_history, connectgaps=False, name='%s' % dead_agent.home, mode='markers', marker=dict(size=4, color='red'))

            trace_prop_fight_back_cloud_2_dead_scat = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_fight_back_history, connectgaps=False, name='%s' % dead_agent.home, mode='markers', marker=dict(size=4, color='red'))

            if show_al_capones == 1:
                if len(agent_population.dead_agent_array) > 0 and dead_agent == agent_population.dead_agent_array[-1]:
                    y_data = generate_MA_array(dead_agent.prop_fight_back_history, might_contain_None=True, last_datum=dead_agent.death_date)
                    trace_prop_fight_back_cloud_2_dead_line = go.Scatter(x=np.arange(rounds), y=y_data, connectgaps=False, name='%s' % dead_agent.home, line=dict(color='red', width=2))
            else:
                y_data = generate_MA_array(dead_agent.prop_fight_back_history, might_contain_None=True, last_datum=dead_agent.death_date)
                trace_prop_fight_back_cloud_2_dead_line = go.Scatter(x=np.arange(rounds), y=y_data, connectgaps=False, name='%s' % dead_agent.home, line=dict(color='red', width=2))

            # trace_fight_skill = go.Scatter(x=np.arange(rounds), y=dead_agent.fight_skill_history, connectgaps=False, name='%s' % dead_agent.home)

            data_prop_steal_cloud.append(trace_prop_steal_cloud)
            data_prop_steal_cloud_dead_scat.append(trace_prop_steal_cloud_dead_scat)

            if show_al_capones == 1:
                if len(agent_population.dead_agent_array) > 0 and dead_agent == agent_population.dead_agent_array[-1]:
                    data_prop_steal_cloud_dead_line.append(trace_prop_steal_cloud_dead_line)
            else:
                data_prop_steal_cloud_dead_line.append(trace_prop_steal_cloud_dead_line)

            data_prop_fight_back_cloud.append(trace_prop_fight_back_cloud)
            data_prop_fight_back_cloud_dead_scat.append(trace_prop_fight_back_cloud_dead_scat)

            if show_al_capones == 1:
                if len(agent_population.dead_agent_array) > 0 and dead_agent == agent_population.dead_agent_array[-1]:
                    data_prop_fight_back_cloud_dead_line.append(trace_prop_fight_back_cloud_dead_line)
            else:
                data_prop_fight_back_cloud_dead_line.append(trace_prop_fight_back_cloud_dead_line)

            data_prop_steal_cloud_2.append(trace_prop_steal_cloud_2)
            data_prop_steal_cloud_2_dead_scat.append(trace_prop_steal_cloud_2_dead_scat)

            if show_al_capones == 1:
                if len(agent_population.dead_agent_array) > 0 and dead_agent == agent_population.dead_agent_array[-1]:
                    data_prop_steal_cloud_2_dead_line.append(trace_prop_steal_cloud_2_dead_line)
                    # print('\n data_prop_steal_cloud_2_dead_line', data_prop_steal_cloud_2_dead_line)
            else:
                data_prop_steal_cloud_2_dead_line.append(trace_prop_steal_cloud_2_dead_line)

            data_prop_fight_back_cloud_2.append(trace_prop_fight_back_cloud_2)
            data_prop_fight_back_cloud_2_dead_scat.append(trace_prop_fight_back_cloud_2_dead_scat)

            if show_al_capones == 1:
                if len(agent_population.dead_agent_array) > 0 and dead_agent == agent_population.dead_agent_array[-1]:
                    data_prop_fight_back_cloud_2_dead_line.append(trace_prop_fight_back_cloud_2_dead_line)
            else:
                data_prop_fight_back_cloud_2_dead_line.append(trace_prop_fight_back_cloud_2_dead_line)

            data_prop_steal_pc.append(dead_agent.prop_steal_history)
            data_prop_fight_back_pc.append(dead_agent.prop_fight_back_history)

            if fight_skill is not None:

                data_fight_skill.append(dead_agent.fight_skill_history)

        # now take collated data and create means of ps and pfb
        ps_means = np.zeros(shape=rounds)
        pfb_means = np.zeros(shape=rounds)

        for day in range(rounds):
            ps_means[day] = np.mean(prop_steal_collated[day])
            pfb_means[day] = np.mean(prop_fb_collated[day])

        trace_ps_means = go.Scatter(x=np.arange(rounds), y=ps_means, connectgaps=False, name='mean', line=dict(color='blue', width=3))
        trace_pfb_means = go.Scatter(x=np.arange(rounds), y=pfb_means, connectgaps=False, name='mean', line=dict(color='red', width=3))

        if params.fight_skill == 0 and params.start_1_rich_agent == 0:
            data_prop_steal_cloud.append(trace_ps_means)
            data_prop_steal_cloud_2.append(trace_ps_means)
            data_prop_fight_back_cloud.append(trace_pfb_means)
            data_prop_fight_back_cloud_2.append(trace_pfb_means)

        if params.start_1_rich_agent:

            data_prop_steal_cloud.append(trace_prop_steal_wealthy_agent)
            data_prop_steal_cloud_2.append(trace_prop_steal_wealthy_agent)
            data_prop_fight_back_cloud.append(trace_prop_fight_back_wealthy_agent)
            data_prop_fight_back_cloud_2.append(trace_prop_fight_back_wealthy_agent)

        if params.corruption_prop_charge != 1.0:

            trace_median_data = go.Scatter(x=np.arange(rounds), y=dbs.medians_actual_ts, connectgaps=False, name='ps_median', line=dict(color='black', width=4))
            data_prop_steal_cloud.append(trace_median_data)
            data_prop_steal_cloud_2.append(trace_median_data)

        fig_prop_steal_cloud = dict(data=data_prop_steal_cloud)
        fig_prop_steal_cloud_2 = dict(data=data_prop_steal_cloud_2)
        fig_prop_fight_back_cloud = dict(data=data_prop_fight_back_cloud)
        fig_prop_fight_back_cloud_2 = dict(data=data_prop_fight_back_cloud_2)

        # now for the 2d scatter charts of props data
        create_plotly_2d_scatter(x_data=scatter_props_x_data, y_data=scatter_props_y_data, title='', x_axis_label='Propensity to Steal', y_axis_label='Propensity to Fight Back', dot_size=1, color='blue',
                                 line_x=dbs.prop_steal_mean_db, line_y=dbs.prop_fb_mean_db, data_folder=params.run_propensities_charts_folder, filename='props_scatter')

        if fight_skill is not None:
            
            # fig_fight_skill = dict(data=data_fight_skill)

            print_chart(data_fight_skill, axis_labels=['Rounds', 'Fighting Skill'], line_width=1, data_folder=run_folder, filename='fight_skills')

        if print_plotly_charts:

            filename_prop_steal_cloud = '%s/prop_steal_cloud_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_steal_cloud_2 = '%s/prop_steal_cloud_2_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_steal_cloud_2_copy = '%s/000_prop_steal_cloud_2_%d-%d-%d-%d-%d.html' % (params.run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            if params.save_ps_cloud_folder != None:
                filename_prop_steal_cloud_2_copy_ms = '%s/%d_prop_steal_cloud_2_%d-%d-%d-%d-%d.html' % (params.save_ps_cloud_folder, params.sim_no, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_fight_back_cloud = '%s/prop_fight_back_cloud_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_fight_back_cloud_2 = '%s/prop_fight_back_cloud_2_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

            # generate and save charts
            fig = go.Figure(fig_prop_steal_cloud)
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.agents_prop_steal_cloud_url = plotly.offline.plot(fig, filename=filename_prop_steal_cloud, auto_open=False)

            fig = go.Figure(fig_prop_steal_cloud_2)
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.agents_prop_steal_cloud_2_url = plotly.offline.plot(fig, filename=filename_prop_steal_cloud_2, auto_open=False)

            fig = go.Figure(fig_prop_steal_cloud_2)
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.agents_prop_steal_cloud_2_url = plotly.offline.plot(fig, filename=filename_prop_steal_cloud_2_copy, auto_open=False)

            if params.save_ps_cloud_folder != None:
                fig = go.Figure(fig_prop_steal_cloud_2)
                fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
                dbs.agents_prop_steal_cloud_2_url = plotly.offline.plot(fig, filename=filename_prop_steal_cloud_2_copy_ms, auto_open=False)

            fig = go.Figure(fig_prop_fight_back_cloud)
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.agents_prop_fb_cloud_url = plotly.offline.plot(fig, filename=filename_prop_fight_back_cloud, auto_open=False)

            fig = go.Figure(fig_prop_fight_back_cloud_2)
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.agents_prop_fb_cloud_2_url = plotly.offline.plot(fig, filename=filename_prop_fight_back_cloud_2, auto_open=False)

            print_chart(data_prop_steal_pc, axis_labels=['Rounds', 'Propensities'], data_folder=params.run_propensities_charts_folder, filename='prop_steal', show_legend=False)
            print_chart(data_prop_fight_back_pc, axis_labels=['Rounds', 'Propensities'], data_folder=params.run_propensities_charts_folder, filename='prop_fight_back', show_legend=False)

            # now create a version of this chart for prop_steal vs mean prop_steal
            ps_vs_mean = np.array(copy.copy(data_prop_steal_pc))

            # print('\n ps_vs_mean =', ps_vs_mean)
            # print('\n ps_vs_mean shape =', ps_vs_mean.shape)

            ps_means = np.zeros(shape=rounds)
            dead_alive_ags_means = np.zeros(shape=(7, rounds))      # [0] rounds, [1] dead_ags ps, [2] alive_ags ps, [3] mean ps, [4] dead_ags pfb, [5] dead_ags pfb, [6] mean pfb,
            dead_alive_ags_means[0] = np.arange(rounds)

            for i in range(rounds):

                tot_ps = 0.0
                counter = 0
                for j in range(1, len(ps_vs_mean)):
                    if (math.isnan(ps_vs_mean[j][i]) is False) or ps_vs_mean[j][i] is None:           # former should work but in case I transform the data idc I've included the latter condition
                        tot_ps += ps_vs_mean[j][i]
                        counter += 1
                if counter > 0:
                    mean_ps = tot_ps / float(counter)
                else:
                    mean_ps = 0.0
                ps_means[i] = mean_ps

                sum_ps_dead_ags = 0.0
                sum_ps_alive_ags = 0.0
                sum_pfb_dead_ags = 0.0
                sum_pfb_alive_ags = 0.0
                dead_ag_counter = 0
                alive_ag_counter = 0

                for dead_agent in agent_population.dead_agent_array:

                    if dead_agent.birth_date <= i <= dead_agent.death_date:

                        sum_ps_dead_ags += dead_agent.prop_steal_history[i]
                        sum_pfb_dead_ags += dead_agent.prop_fight_back_history[i]
                        dead_ag_counter += 1

                for agent in agent_population.pop:

                    if agent.birth_date <= i:

                        sum_ps_alive_ags += agent.prop_steal_history[i]
                        sum_pfb_alive_ags += agent.prop_fight_back_history[i]
                        alive_ag_counter += 1

                if dead_ag_counter > 0:

                    dead_alive_ags_means[1][i] = sum_ps_dead_ags / float(dead_ag_counter)
                    dead_alive_ags_means[4][i] = sum_pfb_dead_ags / float(dead_ag_counter)

                else:

                    dead_alive_ags_means[1][i] = None
                    dead_alive_ags_means[4][i] = None

                if alive_ag_counter > 0:

                    dead_alive_ags_means[2][i] = sum_ps_alive_ags / float(alive_ag_counter)
                    dead_alive_ags_means[5][i] = sum_pfb_alive_ags / float(alive_ag_counter)

                else:

                    dead_alive_ags_means[2][i] = None
                    dead_alive_ags_means[5][i] = None

                if (dead_ag_counter + alive_ag_counter) > 0:

                    dead_alive_ags_means[3][i] = (sum_ps_dead_ags + sum_ps_alive_ags)  / float(dead_ag_counter + alive_ag_counter)
                    dead_alive_ags_means[6][i] = (sum_pfb_dead_ags + sum_pfb_alive_ags)  / float(dead_ag_counter + alive_ag_counter)

                else:

                    dead_alive_ags_means[3][i] = None
                    dead_alive_ags_means[6][i] = None

            dead_alive_ps = dead_alive_ags_means[:4]

            dead_alive_pfb = np.zeros(shape=(4, rounds))
            dead_alive_pfb[0] = dead_alive_ags_means[0]
            dead_alive_pfb[1] = dead_alive_ags_means[4]
            dead_alive_pfb[2] = dead_alive_ags_means[5]
            dead_alive_pfb[3] = dead_alive_ags_means[6]

            print_chart(dead_alive_ps, labels_array=['dead ps', 'alive ps', 'means ps'], axis_labels=['Rounds', 'Propensity'], line_width=3,\
                        colors=['red', 'blue', 'black'], data_folder=params.run_propensities_charts_folder, filename='prop_ps_means_alive_dead')

            print_chart(dead_alive_pfb, labels_array=['dead pfb', 'alive pfb', 'means pfb'], axis_labels=['Rounds', 'Propensity'], line_width=3,\
                        colors=['red', 'blue', 'black'], data_folder=params.run_propensities_charts_folder, filename='prop_pfb_means_alive_dead')

            # now create charts with ps and pfb split in to two clouds each - one for alive agents, other for dead
            ps_data_2_clouds_i = data_prop_steal_cloud_dead_line + data_prop_steal_cloud_alive
            ps_data_2_clouds_ii = data_prop_steal_cloud_2_dead_line + data_prop_steal_cloud_2_alive
            ps_data_2_clouds_iii = data_prop_steal_cloud_dead_scat + data_prop_steal_cloud_alive
            ps_data_2_clouds_iv = data_prop_steal_cloud_2_dead_scat + data_prop_steal_cloud_2_alive

            # if params.show_al_capones == 0:

            # trace_ps_means_dead = go.Scatter(x=np.arange(rounds), y=dead_alive_ags_means[1], connectgaps=False, name='ps_dead', line=dict(color='red', width=3))
            # ps_data_2_clouds_iii.append(trace_ps_means_dead)
            # ps_data_2_clouds_iv.append(trace_ps_means_dead)

            # trace_ps_means_alive = go.Scatter(x=np.arange(rounds), y=dead_alive_ags_means[2], connectgaps=False, name='ps_alive', line=dict(color='blue', width=3))
            # ps_data_2_clouds_i.append(trace_ps_means_alive)
            # ps_data_2_clouds_ii.append(trace_ps_means_alive)
            # ps_data_2_clouds_iii.append(trace_ps_means_alive)
            # ps_data_2_clouds_iv.append(trace_ps_means_alive)

            pfb_data_2_clouds_i = data_prop_fight_back_cloud_dead_line + data_prop_fight_back_cloud_alive
            pfb_data_2_clouds_ii = data_prop_fight_back_cloud_2_dead_line + data_prop_fight_back_cloud_2_alive
            pfb_data_2_clouds_iii = data_prop_fight_back_cloud_dead_scat + data_prop_fight_back_cloud_alive
            pfb_data_2_clouds_iv = data_prop_fight_back_cloud_2_dead_scat + data_prop_fight_back_cloud_2_alive

            # if params.show_al_capones == 0:

            trace_pfb_means_dead = go.Scatter(x=np.arange(rounds), y=dead_alive_ags_means[4], connectgaps=False, name='pfb_dead', line=dict(color='red', width=3))
            pfb_data_2_clouds_iii.append(trace_pfb_means_dead)
            pfb_data_2_clouds_iv.append(trace_pfb_means_dead)

            trace_pfb_means_alive = go.Scatter(x=np.arange(rounds), y=dead_alive_ags_means[5], connectgaps=False, name='pfb_alive', line=dict(color='blue', width=3))
            pfb_data_2_clouds_i.append(trace_pfb_means_alive)
            pfb_data_2_clouds_ii.append(trace_pfb_means_alive)

            filename_prop_steal_cloud_i = '%s/prop_steal_2_clouds_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_steal_cloud_ii = '%s/prop_steal_2_clouds_ii_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_steal_cloud_iii = '%s/prop_steal_2_clouds_iii_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_steal_cloud_iv = '%s/prop_steal_2_clouds_iv_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_fight_back_cloud_i = '%s/prop_fight_back_2_clouds_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_fight_back_cloud_ii = '%s/prop_fight_back_2_clouds_ii_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_fight_back_cloud_iii = '%s/prop_fight_back_2_clouds_iii_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_fight_back_cloud_iv = '%s/prop_fight_back_2_clouds_iv_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

            # generate and save charts
            fig = go.Figure(dict(data=ps_data_2_clouds_i))
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.prop_steal_cloud_i = plotly.offline.plot(fig, filename=filename_prop_steal_cloud_i, auto_open=False)

            fig = go.Figure(dict(data=ps_data_2_clouds_ii))
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.ps_data_2_clouds_ii = plotly.offline.plot(fig, filename=filename_prop_steal_cloud_ii, auto_open=False)

            fig = go.Figure(dict(data=ps_data_2_clouds_iii))
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.prop_steal_cloud_iii = plotly.offline.plot(fig, filename=filename_prop_steal_cloud_iii, auto_open=False)

            fig = go.Figure(dict(data=ps_data_2_clouds_iv))
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.ps_data_2_clouds_iv = plotly.offline.plot(fig, filename=filename_prop_steal_cloud_iv, auto_open=False)

            fig = go.Figure(dict(data=pfb_data_2_clouds_i))
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.pfb_data_2_clouds_i = plotly.offline.plot(fig, filename=filename_prop_fight_back_cloud_i, auto_open=False)

            fig = go.Figure(dict(data=pfb_data_2_clouds_ii))
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.pfb_data_2_clouds_ii = plotly.offline.plot(fig, filename=filename_prop_fight_back_cloud_ii, auto_open=False)

            fig = go.Figure(dict(data=pfb_data_2_clouds_iii))
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.pfb_data_2_clouds_iii = plotly.offline.plot(fig, filename=filename_prop_fight_back_cloud_iii, auto_open=False)

            fig = go.Figure(dict(data=pfb_data_2_clouds_iv))
            fig.update_layout(showlegend=False, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
            dbs.pfb_data_2_clouds_iv = plotly.offline.plot(fig, filename=filename_prop_fight_back_cloud_iv, auto_open=False)

            # now what if there is a single change agent?  we want to show their props versus the others
            if change_one_only:

                other_ags_ps_hist = go.Scatter(x=np.arange(rounds), y=np.full(rounds, start_prop_steal_mean), connectgaps=False, name='Other Agents', line=dict(color='blue', width=2))

                ch_agent_chart_ps = [other_ags_ps_hist]

                y_data_ps_ch_ag = generate_MA_array(agent_population.change_agent.prop_steal_history, might_contain_None=True, last_datum=agent_population.change_agent.death_date)
                change_ag_ps_hist = go.Scatter(x=np.arange(rounds), y=y_data_ps_ch_ag, connectgaps=False, name='Change Agent', line=dict(color='red', width=2))

                ch_agent_chart_ps.append(change_ag_ps_hist)

                filename_prop_steal_ch_ag = '%s/ch_agent_prop_steal_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                fig = go.Figure(dict(data=ch_agent_chart_ps))
                fig.update_layout(showlegend=True, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
                dbs.prop_steal_ch_ag = plotly.offline.plot(fig, filename=filename_prop_steal_ch_ag, auto_open=False)

                other_ags_pfb_hist = go.Scatter(x=np.arange(rounds), y=np.full(rounds, start_prop_fight_back_mean), connectgaps=False, name='Other Agents', line=dict(color='blue', width=2))

                ch_agent_chart_pfb = [other_ags_pfb_hist]

                y_data_pfb_ch_ag = generate_MA_array(agent_population.change_agent.prop_fight_back_history, might_contain_None=True, last_datum=agent_population.change_agent.death_date)
                change_ag_pfb_hist = go.Scatter(x=np.arange(rounds), y=y_data_pfb_ch_ag, connectgaps=False, name='Change Agent', line=dict(color='red', width=2))

                ch_agent_chart_pfb.append(change_ag_pfb_hist)

                filename_prop_fight_back_ch_ag = '%s/ch_agent_prop_fb_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                fig = go.Figure(dict(data=ch_agent_chart_pfb))
                fig.update_layout(showlegend=True, xaxis_title="Rounds", yaxis_title="Propensities", font_size=40)
                dbs.prop_fb_ch_ag = plotly.offline.plot(fig, filename=filename_prop_fight_back_ch_ag, auto_open=False)

            # print('\n ps_means =', ps_means)
            # print('\n ps_means shape =', ps_means.shape)

            # deduct the mean of the ps's from each line from [1]
            for i in range(1, len(ps_vs_mean)):
                ps_vs_mean[i] = ps_vs_mean[i] - ps_means

            # spec_data_dict = {'data': ps_means, 'name': 'Mean', 'line_col': 'black', 'line_width': 4}

            print_chart(ps_vs_mean, axis_labels=['Rounds', 'Propensities'], data_folder=params.run_propensities_charts_folder, filename='prop_steal_vs_mean')  # , special_data=spec_data_dict)

            # now create a version of this chart for prop_fb vs mean prop_fb
            pfb_vs_mean = np.array(copy.copy(data_prop_fight_back_pc))

            pfb_means = np.zeros(shape=rounds)

            for i in range(rounds):
                tot_pfb = 0.0
                counter = 0
                for j in range(1, len(pfb_vs_mean)):
                    if (math.isnan(pfb_vs_mean[j][i]) is False) or pfb_vs_mean[j][i] is None:           # former should work but in case I transform the data idc I've included the latter condition
                        tot_pfb += pfb_vs_mean[j][i]
                        counter += 1
                if counter > 0:
                    mean_pfb = tot_pfb / float(counter)
                else:
                    mean_pfb = 0.0
                pfb_means[i] = mean_pfb

            # print('\n pfb_vs_mean =', pfb_vs_mean)
            # print('\n pfb_vs_mean shape =', pfb_vs_mean.shape)
            #
            # print('\n pfb_means =', pfb_means)
            # print('\n pfb_means shape =', pfb_means.shape)

            # deduct the mean of the ps's from each line from [1]
            for i in range(1, len(pfb_vs_mean)):
                pfb_vs_mean[i] = pfb_vs_mean[i] - pfb_means

            # spec_data_dict = {'data': pfb_means, 'name': 'Mean', 'line_col': 'black', 'line_width': 4}

            print_chart(pfb_vs_mean, axis_labels=['Rounds', 'Propensities'], data_folder=params.run_propensities_charts_folder, filename='prop_fb_vs_mean')  # , special_data=spec_data_dict)

            # if fight_skill is not None:
            #
            #     filename_fight_skill = '%s/fight_skill_%d-%d-%d-%d-%d.html' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            #
            #     dbs.fight_skill_url = plotly.offline.plot(fig_fight_skill, filename=filename_fight_skill, auto_open=False)

            # if plotly_online:
            #
            #     filename_prop_steal = '%s/prop_steal_%d-%d-%d-%d-%d.txt' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            #     filename_prop_fight_back = '%s/prop_fight_back_%d-%d-%d-%d-%d.txt' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            #
            #     if fight_skill is not None:
            #
            #         filename_fight_skill = '%s/fight_skill_%d-%d-%d-%d-%d.txt' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            #
            #     try:
            #
            #         dbs.agents_prop_steal_url = py.plot(fig_prop_steal, filename=filename_prop_steal, auto_open=False, sharing=plotly_sharing)
            #
            #     except Exception as e:
            #
            #         print('\n error:\n\n', e)
            #         print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')
            #
            #     try:
            #
            #         dbs.agents_prop_fb_url = py.plot(fig_prop_fight_back, filename=filename_prop_fight_back, auto_open=False, sharing=plotly_sharing)
            #
            #     except:
            #
            #         print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')
            #
            #     if fight_skill is not None:
            #
            #         try:
            #
            #             dbs.fight_skill_url = py.plot(fig_fight_skill, filename=filename_fight_skill, auto_open=False, sharing=plotly_sharing)
            #
            #         except:
            #
            #             print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

            # now for fan charts - start with prop steal
            if len(agent_population.pop) > 0:

                filename_ps_fan_ch = '%s/fan_chart_ps_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                fan_chart(data_prop_steal_fan_chart, colour='blue', include_max_min=0, file_name=filename_ps_fan_ch, num_rounds=rounds, median_data=dbs.medians_actual_ts, bands=True)

                filename_pfb_fan_ch = '%s/fan_chart_pfb_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                fan_chart(data_prop_fb_fan_chart, colour='red', include_max_min=0, file_name=filename_pfb_fan_ch, num_rounds=rounds, bands=True)

                filename_ps_alive_fan_ch = '%s/fan_chart_ps_alive_throughout_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                fan_chart(data_prop_steal_alive_fan_chart, colour='blue', include_max_min=0, file_name=filename_ps_alive_fan_ch, num_rounds=rounds, bands=True)

                filename_pfb_alive_fan_ch = '%s/fan_chart_pfb_alive_throughout_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                fan_chart(data_prop_fb_alive_fan_chart, colour='red', include_max_min=0, file_name=filename_pfb_alive_fan_ch, num_rounds=rounds, bands=True)

        # now work on the mean prop_steal and prop_fight_back data
        prop_steal_means_above_50 = []
        prop_steal_means_below_50 = []
        prop_fight_back_means_above_50 = []
        prop_fight_back_means_below_50 = [] 

#        prop_steal_means[0] = np.arange(rounds)
#        prop_fight_back_means[0] = np.arange(rounds)

        for one_day in range(rounds):

            prop_steal_above_50_pct = []
            prop_steal_below_50_pct = []

            if len(dbs.prop_steal_db[one_day]) > 0:

                for ag_prop in dbs.prop_steal_db[one_day]:

                    if ag_prop >= 0.5:

                        prop_steal_above_50_pct.append(ag_prop)

                    elif ag_prop < 0.5:

                        prop_steal_below_50_pct.append(ag_prop)

                if len(prop_steal_above_50_pct) > 0:

                    mean_above_50 = np.mean(prop_steal_above_50_pct)

                else:

                    mean_above_50 = None

                if len(prop_steal_below_50_pct) > 0:

                    mean_below_50 = np.mean(prop_steal_below_50_pct)

                else:

                    mean_below_50 = None

                prop_steal_means_above_50.append(mean_above_50)
                prop_steal_means_below_50.append(mean_below_50)

            elif len(dbs.prop_steal_db[one_day]) == 0:

                prop_steal_means_above_50.append(None)
                prop_steal_means_below_50.append(None)

            prop_fight_back_above_50_pct = []
            prop_fight_back_below_50_pct = []
            
            if len(dbs.prop_fight_back_db[one_day]) > 0:

                for ag_prop in dbs.prop_fight_back_db[one_day]:

                    if ag_prop >= 0.5:

                        prop_fight_back_above_50_pct.append(ag_prop)

                    elif ag_prop < 0.5:

                        prop_fight_back_below_50_pct.append(ag_prop)

                if len(prop_fight_back_above_50_pct) > 0:

                    mean_above_50 = np.mean(prop_fight_back_above_50_pct)

                else:

                    mean_above_50 = None

                if len(prop_fight_back_below_50_pct) > 0:

                    mean_below_50 = np.mean(prop_fight_back_below_50_pct)

                else:

                    mean_below_50 = None

                prop_fight_back_means_above_50.append(mean_above_50)
                prop_fight_back_means_below_50.append(mean_below_50)

            elif len(dbs.prop_steal_db[one_day]) == 0:

                prop_fight_back_means_above_50.append(None)
                prop_fight_back_means_below_50.append(None)

        data_prop_steal = []

        data_prop_steal.append(go.Scatter(x=np.arange(rounds), y=prop_steal_means_above_50, connectgaps=False, name='Steal Mean >= 0.5'))
        data_prop_steal.append(go.Scatter(x=np.arange(rounds), y=prop_steal_means_below_50, connectgaps=False, name='Steal Mean < 0.5'))

        data_prop_fight_back = []

        data_prop_fight_back.append(go.Scatter(x=np.arange(rounds), y=prop_fight_back_means_above_50, connectgaps=False, name='Fight Back Mean >= 0.5'))
        data_prop_fight_back.append(go.Scatter(x=np.arange(rounds), y=prop_fight_back_means_below_50, connectgaps=False, name='Fight Back Mean < 0.5'))

        fig_prop_steal = dict(data=data_prop_steal)
        fig_prop_fight_back = dict(data=data_prop_fight_back)

        if print_plotly_charts == 1:

            filename_prop_steal = '%s/prop_steal_means_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_prop_fight_back = '%s/prop_fight_back_means_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            
            dbs.prop_steal_above_below_50_url = plotly.offline.plot(fig_prop_steal, filename=filename_prop_steal, auto_open=False)
            dbs.prop_fb_above_below_50_url = plotly.offline.plot(fig_prop_fight_back, filename=filename_prop_fight_back, auto_open=False)

            if plotly_online:
                
                filename_prop_steal = '%s/prop_steal_means_%d-%d-%d-%d-%d' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                filename_prop_fight_back = '%s/prop_fight_back_means_%d-%d-%d-%d-%d' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                try:
    
                    dbs.prop_steal_above_below_50_url = py.plot(fig_prop_steal, filename=filename_prop_steal, auto_open=False, sharing=plotly_sharing)
           
                except:
        
                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.prop_steal_above_below_50_url\n')
    
                try:
    
                    dbs.prop_fb_above_below_50_url = py.plot(fig_prop_fight_back, filename=filename_prop_fight_back, auto_open=False, sharing=plotly_sharing)
    
                except:
        
                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.prop_fb_above_below_50_url \n')

        # now do the means of prop_steal and prop_fight_back
        data_prop_means = []

        data_prop_means.append(go.Scatter(x=np.arange(rounds), y=dbs.prop_steal_mean_db, connectgaps=False, name='Prop. Steal'))
        data_prop_means.append(go.Scatter(x=np.arange(rounds), y=dbs.prop_fb_mean_db, connectgaps=False, name='Prop. Fight Back'))

        if print_plotly_charts == 1:

            filename_prop_means = '%s/prop_means_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
    
            dbs.props_means_url = plotly.offline.plot(data_prop_means, filename=filename_prop_means, auto_open=False)

            if plotly_online:

                filename_prop_means = '%s/prop_means_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                try:

                    dbs.props_means_url = py.plot(data_prop_means, filename=filename_prop_means, auto_open=False, sharing=plotly_sharing)

                except:

                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.props_means_url\n')

        # here we create a seperate chart showing the prop steal and fb of agents who were born at instantiation and who were still alive at the end of the sim

        # we must first run through all the agents in the population

        dbs.prop_steal_means_end_agents = [[] for i in range(rounds)]
        dbs.prop_fb_means_end_agents = [[] for i in range(rounds)]

        for date in np.arange(rounds):

            tot_agents = 0

            aggr_ps = 0
            aggr_fb = 0

            for end_agent in agent_population.pop:

                if end_agent.birth_date == 0:

                    tot_agents += 1

                    aggr_ps += end_agent.prop_steal_history[date]
                    aggr_fb += end_agent.prop_fight_back_history[date]

            if tot_agents > 0:

                dbs.prop_steal_means_end_agents[date] = aggr_ps / float(tot_agents)
                dbs.prop_fb_means_end_agents[date] = aggr_fb / float(tot_agents)

            else:

                dbs.prop_steal_means_end_agents[date] = None
                dbs.prop_fb_means_end_agents[date] = None

        data_prop_means = []

        data_prop_means.append(go.Scatter(x=np.arange(rounds), y=dbs.prop_steal_means_end_agents, connectgaps=False, name='Prop. Steal'))
        data_prop_means.append(go.Scatter(x=np.arange(rounds), y=dbs.prop_fb_means_end_agents, connectgaps=False, name='Prop. Fight Back'))

        if print_plotly_charts == 1:

            filename_prop_means = '%s/prop_means_start_end_agents_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

            dbs.props_means_start_end_agents_url = plotly.offline.plot(data_prop_means, filename=filename_prop_means, auto_open=False)

            if plotly_online:

                filename_prop_means = '%s/prop_means_start_end_agents_%d-%d-%d-%d-%d.html' % (params.run_propensities_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                try:

                    dbs.props_means_start_end_agents_url = py.plot(data_prop_means, filename=filename_prop_means, auto_open=False, sharing=plotly_sharing)

                except:

                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.props_means_url\n')

        # Now we record the number of transactions and fights in each round by updating num_ints_each_round which has 7 arrays (1 for each scenario),
        # Note, however, we also add total number of fights to dbs.num_fight_each_round and that scearios 2 & 3 and 4 & 5 are lumped together in to indices 2 and 4 respectively
        for trans in dbs.trans_db:

            # note indices of num_ints_each_round aligned with my scneario numbers
            dbs.num_ints_each_round[6][trans.day] += 1

            if two_tribes:
                
                if trans.agent_a_tribe == 'sharks' and trans.agent_b_tribe == 'sharks':
                    
                    dbs.num_ints_each_round_sharks[6][trans.day] += 1

                elif trans.agent_a_tribe == 'jets' and trans.agent_b_tribe == 'jets':
                    
                    dbs.num_ints_each_round_jets[6][trans.day] += 1

                else:               # must be inter-tribe transaction
                    
                    dbs.num_ints_each_round_inter[6][trans.day] += 1

        for fight in dbs.fights_db:

            # note: agent_record = [str(cp_agent), 1, 0, 1, 0]  - [1] is whether cp_agent fought; [2] is whether cp_agent fought back; [3] is whether agent fought; [4] is whether agent fought back]
            
            if fight.agent_record[1] == 1 and fight.agent_record[3] == 1:       # then both tried to steal - scenario 1 only
            
                dbs.num_ints_each_round[1][fight.day] += 1
                dbs.num_fight_each_round[fight.day] += 1

                if two_tribes:
    
                    if fight.agent_a_tribe == 'sharks' and fight.agent_b_tribe == 'sharks':
                        
                        dbs.num_ints_each_round_sharks[1][fight.day] += 1
                        dbs.num_fight_each_round_sharks[fight.day] += 1
    
                    elif fight.agent_a_tribe == 'jets' and fight.agent_b_tribe == 'jets':
                        
                        dbs.num_ints_each_round_jets[1][fight.day] += 1
                        dbs.num_fight_each_round_jets[fight.day] += 1
    
                    else:               # must be inter-tribe transaction
                        
                        dbs.num_ints_each_round_inter[1][fight.day] += 1
                        dbs.num_fight_each_round_inter[fight.day] += 1

            elif (fight.agent_record[1] == 1 and fight.agent_record[3] == 0 and fight.agent_record[4] == 1) or \
                  fight.agent_record[1] == 0 and fight.agent_record[3] == 1 and fight.agent_record[2] == 1:      # then one agent tried to steal and the other fought back (scenarios 2 and 3)

                dbs.num_ints_each_round[2][fight.day] += 1
                dbs.num_fight_each_round[fight.day] += 1

                if two_tribes:
    
                    if fight.agent_a_tribe == 'sharks' and fight.agent_b_tribe == 'sharks':
                        
                        dbs.num_ints_each_round_sharks[2][fight.day] += 1
                        dbs.num_fight_each_round_sharks[fight.day] += 1
    
                    elif fight.agent_a_tribe == 'jets' and fight.agent_b_tribe == 'jets':
                        
                        dbs.num_ints_each_round_jets[2][fight.day] += 1
                        dbs.num_fight_each_round_jets[fight.day] += 1
    
                    else:               # must be inter-tribe transaction
                        
                        dbs.num_ints_each_round_inter[2][fight.day] += 1
                        dbs.num_fight_each_round_inter[fight.day] += 1

            elif (fight.agent_record[1] == 1 and fight.agent_record[3] == 0 and fight.agent_record[4] == 0) or \
                  fight.agent_record[1] == 0 and fight.agent_record[3] == 1 and fight.agent_record[2] == 0:     # one agent steals, the other acquieses (scenarios 4 and 5)

                dbs.num_ints_each_round[4][fight.day] += 1
                dbs.num_fight_each_round[fight.day] += 1

                if two_tribes:
    
                    if fight.agent_a_tribe == 'sharks' and fight.agent_b_tribe == 'sharks':
                        
                        dbs.num_ints_each_round_sharks[4][fight.day] += 1
                        dbs.num_fight_each_round_sharks[fight.day] += 1
    
                    elif fight.agent_a_tribe == 'jets' and fight.agent_b_tribe == 'jets':
                        
                        dbs.num_ints_each_round_jets[4][fight.day] += 1
                        dbs.num_fight_each_round_jets[fight.day] += 1
    
                    else:               # must be inter-tribe transaction
                        
                        dbs.num_ints_each_round_inter[4][fight.day] += 1
                        dbs.num_fight_each_round_inter[fight.day] += 1

        # now chart these trans and fight data - two charts: one with total fights and trans, and second with breakdown of fights by type (1, 2 & 3, and 4 & 5)
        total_trans_and_fights = []
    
        total_trans_and_fights.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round[6], connectgaps=False, name='Transactions'))
        total_trans_and_fights.append(go.Scatter(x=np.arange(rounds), y=dbs.num_fight_each_round, connectgaps=False, name='Fights'))

        fig_trans_and_fights = dict(data=total_trans_and_fights)

        if print_plotly_charts == 1:

            filename_trans_and_fights = '%s/trans_and_fights_%d-%d-%d-%d-%d.html' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
    
            dbs.trans_and_fights_url = plotly.offline.plot(fig_trans_and_fights, filename=filename_trans_and_fights, auto_open=False)
            
            if plotly_online:

                filename_trans_and_fights = '%s/trans_and_fights_%d-%d-%d-%d-%d' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                try:
    
                    dbs.trans_and_fights_url = py.plot(fig_trans_and_fights, filename=filename_trans_and_fights, auto_open=False, sharing=plotly_sharing)                  
                            
                except:
        
                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.trans_and_fights_url\n')

        # if we are counting the number of game types, we plot these data also.
        if len(dbs.games_type_dict) > 0:

            # print_fine_dets = 1
            filename_game_types = '%s/game_types_gross_num_%d-%d-%d-%d-%d.html' % (params.run_game_types_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            
            game_types_data = []

            if print_fine_dets:
                print('\n number of games =', len(dbs.games_type_dict), '\n')

            for game_type in dbs.games_type_dict:
                                
                MA_time_series = generate_MA_array(dbs.games_type_dict[game_type], 10)

                if print_fine_dets:
                    print(' game ', game_type, 'sum', np.sum(dbs.games_type_dict[game_type]))

                game_types_data.append(go.Scatter(x=np.arange(rounds), y=MA_time_series, connectgaps=False, name=game_type))

            print_fine_dets = 0
            dbs.trans_and_fights_url = plotly.offline.plot(game_types_data, filename=filename_game_types, auto_open=False)

            # now for the interesting type chart
            filename_game_types_2 = '%s/game_cats_ag_exp_gains_%d-%d-%d-%d-%d.html' % (params.run_game_types_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            
            game_types_data = []

            for game_type in dbs.games_type_dict_2:

                if print_fine_dets:
                    print('\n game ', game_type, 'sum', np.sum(dbs.games_type_dict_2[game_type]))
                
                MA_time_series = generate_MA_array(dbs.games_type_dict_2[game_type], 10)

                game_types_data.append(go.Scatter(x=np.arange(rounds), y=MA_time_series, connectgaps=False, name=game_type))

            dbs.trans_and_fights_url = plotly.offline.plot(game_types_data, filename=filename_game_types_2, auto_open=False)

            # third chart
            filename_game_types_3 = '%s/game_cats_gross_nums_%d-%d-%d-%d-%d.html' % (params.run_game_types_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

            game_types_data = []

            for game_type in dbs.games_type_dict_3:
                                
                MA_time_series = generate_MA_array(dbs.games_type_dict_3[game_type], 10)

                if print_fine_dets:
                    print('\n game ', game_type, 'sum', np.sum(dbs.games_type_dict_3[game_type]))

                game_types_data.append(go.Scatter(x=np.arange(rounds), y=MA_time_series, connectgaps=False, name=game_type))
            
            dbs.trans_and_fights_url = plotly.offline.plot(game_types_data, filename=filename_game_types_3, auto_open=False)

            # now for rational choice game types
            filename_game_types_RCT = '%s/game_types_RCT_%d-%d-%d-%d-%d.html' % (params.run_game_types_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

            game_types_data = []
            game_types_data_print_chart = [np.arange(rounds)]
            labels_array = []

            if print_fine_dets:
                print('\n number of games =', len(dbs.games_RCT_dict))

            for game_type in dbs.games_RCT_dict:

                MA_time_series = generate_MA_array(dbs.games_RCT_dict[game_type], 25)
                game_types_data_print_chart.append(MA_time_series)
                labels_array.append(game_type)

                if print_fine_dets:
                    print('\n game ', game_type, 'sum', np.sum(dbs.games_RCT_dict[game_type]))

                game_types_data.append(go.Scatter(x=np.arange(rounds), y=MA_time_series, connectgaps=False, name=game_type))

                # print('\n dbs.games_RCT_dict[game_type]', dbs.games_RCT_dict[game_type])
                # print('\n MA_time_series', MA_time_series)
                #
                # pause()

            dbs.RCT_types = plotly.offline.plot(game_types_data, filename=filename_game_types_RCT, auto_open=False)

            print_chart(game_types_data_print_chart, labels_array=labels_array, axis_labels=['Rounds', 'Number of Interactions'], data_folder=params.run_game_types_folder, filename='game_types_RCT_2', show_legend=True)

        # if we are counting the number of RCT game types, we plot these data also.
        if len(dbs.games_type_dict_RCT) > 0:

            # print_fine_dets = 1
            filename_game_types = '%s/game_types_gross_num_RCT_%d-%d-%d-%d-%d.html' % (params.run_game_types_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

            game_types_data = []

            if print_fine_dets:
                print('\n number of games =', len(dbs.games_type_dict_RCT), '\n')

            for game_type in dbs.games_type_dict_RCT:

                MA_time_series = generate_MA_array(dbs.games_type_dict_RCT[game_type], 10)

                if print_fine_dets:
                    print(' game ', game_type, 'sum', np.sum(dbs.games_type_dict_RCT[game_type]))

                game_types_data.append(go.Scatter(x=np.arange(rounds), y=MA_time_series, connectgaps=False, name=game_type))

            print_fine_dets = 0
            dbs.games_type_RCT = plotly.offline.plot(game_types_data, filename=filename_game_types, auto_open=False)

        if two_tribes:

            # sharks
            total_trans_and_fights_sharks = []
        
            total_trans_and_fights_sharks.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_sharks[6], connectgaps=False, name='Transactions'))
            total_trans_and_fights_sharks.append(go.Scatter(x=np.arange(rounds), y=dbs.num_fight_each_round_sharks, connectgaps=False, name='Fights'))
        
            fig_trans_and_fights_sharks = dict(data=total_trans_and_fights_sharks)
            
            if print_plotly_charts == 1:
    
                filename_trans_and_fights_sharks = '%s/trans_and_fights_sharks_%d-%d-%d-%d-%d.html' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                
                dbs.trans_and_fights_url_sharks = plotly.offline.plot(fig_trans_and_fights_sharks, filename=filename_trans_and_fights_sharks, auto_open=False)
                
                if plotly_online:
    
                    filename_trans_and_fights_sharks = '%s/trans_and_fights_sharks_%d-%d-%d-%d-%d' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)                   

                    try:
                        
                        dbs.trans_and_fights_url_sharks = py.plot(fig_trans_and_fights_sharks, filename=filename_trans_and_fights_sharks, auto_open=False, sharing=plotly_sharing)
     
                    except:
            
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.trans_and_fights_url_sharks\n')

            # jets
            total_trans_and_fights_jets = []
        
            total_trans_and_fights_jets.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_jets[6], connectgaps=False, name='Transactions'))
            total_trans_and_fights_jets.append(go.Scatter(x=np.arange(rounds), y=dbs.num_fight_each_round_jets, connectgaps=False, name='Fights'))
        
            fig_trans_and_fights_jets = dict(data=total_trans_and_fights_jets)
            
            if print_plotly_charts == 1:

                filename_trans_and_fights_jets = '%s/trans_and_fights_jets_%d-%d-%d-%d-%d.html' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                
                dbs.trans_and_fights_url_jets = plotly.offline.plot(fig_trans_and_fights_jets, filename=filename_trans_and_fights_jets, auto_open=False)
                
                if plotly_online:
    
                    filename_trans_and_fights_jets = '%s/trans_and_fights_jets_%d-%d-%d-%d-%d' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                    try:
        
                        dbs.trans_and_fights_url_jets = py.plot(fig_trans_and_fights_jets, filename=filename_trans_and_fights_jets, auto_open=False, sharing=plotly_sharing)
    
                    except:
            
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.trans_and_fights_url_jets\n')

            # inter
            total_trans_and_fights_inter = []
        
            total_trans_and_fights_inter.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_inter[6], connectgaps=False, name='Transactions'))
            total_trans_and_fights_inter.append(go.Scatter(x=np.arange(rounds), y=dbs.num_fight_each_round_inter, connectgaps=False, name='Fights'))
        
            fig_trans_and_fights_inter = dict(data=total_trans_and_fights_inter)
            
            if print_plotly_charts == 1:
    
                filename_trans_and_fights_inter = '%s/trans_and_fights_inter_%d-%d-%d-%d-%d.html' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                
                dbs.trans_and_fights_url_inter = plotly.offline.plot(fig_trans_and_fights_inter, filename=filename_trans_and_fights_inter, auto_open=False)
                
                if plotly_online:
    
                    filename_trans_and_fights_inter = '%s/trans_and_fights_inter_%d-%d-%d-%d-%d' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                    try:
        
                        dbs.trans_and_fights_url_inter = py.plot(fig_trans_and_fights_inter, filename=filename_trans_and_fights_inter, auto_open=False, sharing=plotly_sharing)
    
                    except:
            
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.trans_and_fights_url_inter\n')

        # now chart breakdown of fights by type
        fight_types = []

        # average-ify the data
        
        dbs.num_ints_each_round[1] = generate_MA_array(dbs.num_ints_each_round[1], 10)
        dbs.num_ints_each_round[2] = generate_MA_array(dbs.num_ints_each_round[2], 10)
        dbs.num_ints_each_round[4] = generate_MA_array(dbs.num_ints_each_round[4], 10)
        dbs.num_ints_each_round[6] = generate_MA_array(dbs.num_ints_each_round[6], 10)

        ints_1 = np.zeros(shape=rounds)
        ints_2 = np.zeros(shape=rounds)
        ints_4 = np.zeros(shape=rounds)
        ints_6 = np.zeros(shape=rounds)        

        for r in range(rounds):

            total_ints = dbs.num_ints_each_round[1][r] + dbs.num_ints_each_round[2][r] + dbs.num_ints_each_round[4][r] + dbs.num_ints_each_round[6][r]

            if total_ints > 0:

                ints_1[r] = dbs.num_ints_each_round[1][r] / total_ints
                ints_2[r] = dbs.num_ints_each_round[2][r] / total_ints
                ints_4[r] = dbs.num_ints_each_round[4][r] / total_ints
                ints_6[r] = dbs.num_ints_each_round[6][r] / total_ints

            else:
                
                ints_1[r] = None
                ints_2[r] = None
                ints_4[r] = None
                ints_6[r] = None

#        print('\n dbs.num_ints_each_round[1][r] =\n\n', dbs.num_ints_each_round[1][r])
#        print('\n ints_1 =\n\n', ints_1)

        fight_types.append(go.Scatter(x=np.arange(rounds), y=ints_1, connectgaps=False, name='Both Steal'))
        fight_types.append(go.Scatter(x=np.arange(rounds), y=ints_2, connectgaps=False, name='One Steals, Other Fights Back'))
        fight_types.append(go.Scatter(x=np.arange(rounds), y=ints_4, connectgaps=False, name='One Steals, Other Acquiesces'))
        fight_types.append(go.Scatter(x=np.arange(rounds), y=ints_6, connectgaps=False, name='Transactions'))

        fig_fight_types = dict(data=fight_types)

        if print_plotly_charts == 1:

            filename_fight_types = '%s/fight_types_%d-%d-%d-%d-%d.html' % (params.run_fights_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            
            dbs.fight_types_url = plotly.offline.plot(fight_types, filename=filename_fight_types, auto_open=False)
            
            if plotly_online:
                
                filename_fight_types = '%s/fight_types_%d-%d-%d-%d-%d' % (params.run_fights_charts_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                try:
    
                    dbs.fight_types_url = py.plot(fight_types, filename=filename_fight_types, auto_open=False, sharing=plotly_sharing)
        
                except:
            
                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.fight_types_url\n')

        # here we plot the number of interactions in all the 6 quadrants

        quadrants = ['1', '2F', '2A', '3F', '3A', '4']
        interaction_types_RCT_pc = [np.arange(rounds)]

        # # ensure the following entries are None if zero - avoid confusion and so charts are more accurate
        # for entry in dbs.ps_net_contr_by_scen:
        #     for day in range(rounds):
        #         if dbs.ps_net_contr_by_scen[entry][day] == 0.0:
        #             dbs.ps_net_contr_by_scen[entry][day] = None
        #
        # for entry in dbs.ps_net_contr_by_scen:
        #     for day in range(rounds):
        #         if dbs.ps_net_contr_by_scen[entry][day] == 0.0:
        #             dbs.ps_net_contr_by_scen[entry][day] = None
        #
        # for entry in dbs.pfb_net_contr_by_scen:
        #     for day in range(rounds):
        #         if dbs.pfb_net_contr_by_scen[entry][day] == 0.0:
        #             dbs.pfb_net_contr_by_scen[entry][day] = None

        for quad in quadrants:

            # print(quad, '\n dbs.quadrants_tallies_RCT[quad] \n', dbs.quadrants_tallies_RCT[quad])

            MA_data = generate_MA_array(dbs.quadrants_tallies_RCT[quad])
            interaction_types_RCT_pc.append(MA_data)

            # print('\n MA_data \n', MA_data)

        interaction_types_actual_pc = [np.arange(rounds)]

        for quad in quadrants:

            # print(quad, '\n dbs.quadrants_tallies_RCT[quad] \n', dbs.quadrants_tallies_RCT[quad])  ps_net_contr_by_scen

            MA_data = generate_MA_array(dbs.quadrants_tallies_actual[quad])
            interaction_types_actual_pc.append(MA_data)

        ps_net_contr_by_scen_list_pc = [np.arange(rounds)]

        total_net_contr_ps_dict = {'data' : np.zeros(shape=rounds, dtype=float)}

        for quad in quadrants:

            # print(quad, '\n dbs.quadrants_tallies_RCT[quad] \n', dbs.quadrants_tallies_RCT[quad])  ps_net_contr_by_scen

            MA_data = generate_MA_array(dbs.ps_net_contr_by_scen[quad])
            ps_net_contr_by_scen_list_pc.append(MA_data)

            total_net_contr_ps_dict['data'] += np.array(MA_data)

            # print('\n MA_data \n', MA_data)

        ps_net_contr_by_scen_pos_list_pc = [np.arange(rounds)]

        for quad in ['2F', '2A', '3F', '3A', '3F + 2F']:

            # print(quad, '\n dbs.quadrants_tallies_RCT[quad] \n', dbs.quadrants_tallies_RCT[quad])  ps_net_contr_by_scen

            MA_data = generate_MA_array(dbs.ps_net_contr_by_scen_pos[quad])
            ps_net_contr_by_scen_pos_list_pc.append(MA_data)

            # print('\n MA_data \n', MA_data)

        pfb_net_contr_by_scen_list_pc = [np.arange(rounds)]

        total_net_contr_pfb_dict = {'data' : np.zeros(shape=rounds, dtype=float)}

        for quad in ['2F', '2A', '3F', '3A']:           # this is for pfb influence - 1 and 4 are irrelevant

            # print(quad, '\n dbs.quadrants_tallies_RCT[quad] \n', dbs.quadrants_tallies_RCT[quad])  ps_net_contr_by_scen
            # MA_data = generate_MA_array(dbs.pfb_net_contr_by_scen[quad])

            cumul_value = dbs.pfb_net_contr_by_scen[quad][0]
            cumul_data = [cumul_value]

            for datum in dbs.pfb_net_contr_by_scen[quad][1:]:
                cumul_value += datum
                cumul_data.append(cumul_value)

            pfb_net_contr_by_scen_list_pc.append(cumul_data)

            # print('\n MA_data \n', MA_data)

            total_net_contr_pfb_dict['data'] += np.array(cumul_data)

        total_net_contr_ps_dict['name'] = 'Aggregate'
        total_net_contr_ps_dict['line_col'] = 'black'
        total_net_contr_ps_dict['line_width'] = 4

        total_net_contr_pfb_dict['name'] = 'Aggregate'
        total_net_contr_pfb_dict['line_col'] = 'black'
        total_net_contr_pfb_dict['line_width'] = 4

        if print_plotly_charts == 1:

            print_chart(interaction_types_RCT_pc, labels_array=quadrants, axis_labels=['Rounds', 'Number of Interactions'], data_folder=params.run_contributions_to_props_folder, filename='interactions_by_quads_RCT', show_legend=True)
            print_chart(interaction_types_actual_pc, labels_array=quadrants, axis_labels=['Rounds', 'Number of Interactions'], data_folder=params.run_contributions_to_props_folder, filename='interactions_by_quads_actual', show_legend=True)
            print_chart(ps_net_contr_by_scen_list_pc, labels_array=quadrants, axis_labels=['Rounds', 'Contribution'], data_folder=params.run_contributions_to_props_folder, filename='interactions_by_scen_contr_ps',show_legend=True)
            print_chart(ps_net_contr_by_scen_pos_list_pc, labels_array=['2F', '2A', '3F', '3A', '3F + 2F'], axis_labels=['Rounds', 'Contribution'], data_folder=params.run_contributions_to_props_folder, filename='interactions_by_scen_contr_ps_pos',show_legend=True)
            print_chart(pfb_net_contr_by_scen_list_pc, labels_array=['2F', '2A', '3F', '3A'], axis_labels=['Rounds', 'Contribution'], data_folder=params.run_contributions_to_props_folder, filename='interactions_by_scen_contr_pfb',show_legend=True)

            print_chart(ps_net_contr_by_scen_list_pc, special_data=total_net_contr_ps_dict, labels_array=quadrants, axis_labels=['Rounds', 'Contribution'], data_folder=params.run_contributions_to_props_folder, filename='interactions_by_scen_contr_ps_wtot',show_legend=True)
            print_chart(ps_net_contr_by_scen_pos_list_pc, special_data=total_net_contr_ps_dict, labels_array=['2F', '2A', '3F', '3A', '3F + 2F'], axis_labels=['Rounds', 'Contribution'], data_folder=params.run_contributions_to_props_folder, filename='interactions_by_scen_contr_ps_pos_wtot',show_legend=True)
            print_chart(pfb_net_contr_by_scen_list_pc, special_data=total_net_contr_pfb_dict, labels_array=['2F', '2A', '3F', '3A'], axis_labels=['Rounds', 'Contribution'], data_folder=params.run_contributions_to_props_folder, filename='interactions_by_scen_contr_pfb_wtot',show_legend=True)

            # now charts which show contributions to total
            print_contributions_to_total_chart(ps_net_contr_by_scen_list_pc, labels_array=quadrants, axis_labels=['Rounds', 'Contribution'], data_folder=params.run_contributions_to_props_folder, filename='interactions_by_scen_contr_to_tot_ps',show_legend=True)
            print_contributions_to_total_chart(pfb_net_contr_by_scen_list_pc, labels_array=['2F', '2A', '3F', '3A'], axis_labels=['Rounds', 'Contribution'], data_folder=params.run_contributions_to_props_folder, filename='interactions_by_scen_contr_to_tot_pfb',show_legend=True)



        if two_tribes:

            # sharks
            fight_types_sharks = []
    
            fight_types_sharks.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_sharks[1], connectgaps=False, name='Both Steal'))
            fight_types_sharks.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_sharks[2], connectgaps=False, name='One Steals, Other Fights Back'))
            fight_types_sharks.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_sharks[4], connectgaps=False, name='One Steals, Other Acquiesces'))
        
            fig_fight_types_sharks = dict(data=fight_types_sharks)
    
            if print_plotly_charts == 1:
    
                filename_fight_types_sharks = '%s/fight_types_sharks_%d-%d-%d-%d-%d.html' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                
                dbs.fight_types_url_sharks = plotly.offline.plot(fight_types_sharks, filename=filename_fight_types_sharks, auto_open=False)
                
                if plotly_online:
                    
                    filename_fight_types_sharks = '%s/fight_types_sharks_%d-%d-%d-%d-%d' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
    
                    try:
        
                        dbs.fight_types_url_sharks = py.plot(fight_types_sharks, filename=filename_fight_types_sharks, auto_open=False, sharing=plotly_sharing)
    
                    except:
                
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.fight_types_url_sharks\n')

            # jets
            fight_types_jets = []
    
            fight_types_jets.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_jets[1], connectgaps=False, name='Both Steal'))
            fight_types_jets.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_jets[2], connectgaps=False, name='One Steals, Other Fights Back'))
            fight_types_jets.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_jets[4], connectgaps=False, name='One Steals, Other Acquiesces'))
        
            fig_fight_types_jets = dict(data=fight_types_jets)
    
            if print_plotly_charts == 1:
    
                filename_fight_types_jets = '%s/fight_types_jets_%d-%d-%d-%d-%d.html' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                
                dbs.fight_types_url_jets= plotly.offline.plot(fight_types_jets, filename=filename_fight_types_jets, auto_open=False)
                
                if plotly_online:
                    
                    filename_fight_types_jets = '%s/fight_types_jets_%d-%d-%d-%d-%d' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
    
                    try:
        
                        dbs.fight_types_url_jets = py.plot(fight_types_jets, filename=filename_fight_types_jets, auto_open=False, sharing=plotly_sharing)
    
                    except:
                
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.fight_types_url_jets\n')

            # inter
            fight_types_inter = []
    
            fight_types_inter.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_inter[1], connectgaps=False, name='Both Steal'))
            fight_types_inter.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_inter[2], connectgaps=False, name='One Steals, Other Fights Back'))
            fight_types_inter.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_inter[4], connectgaps=False, name='One Steals, Other Acquiesces'))
        
            fig_fight_types_inter = dict(data=fight_types_inter)
    
            if print_plotly_charts == 1:
    
                filename_fight_types_inter = '%s/fight_types_inter_%d-%d-%d-%d-%d.html' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
                
                dbs.fight_types_url_inter = plotly.offline.plot(fight_types_inter, filename=filename_fight_types_inter, auto_open=False)
                
                if plotly_online:
                    
                    filename_fight_types_inter = '%s/fight_types_inter_%d-%d-%d-%d-%d' % (run_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
    
                    try:
        
                        dbs.fight_types_url_inter = py.plot(fight_types_inter, filename=filename_fight_types_inter, auto_open=False, sharing=plotly_sharing)
    
                    except:
                
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on *** dbs.fight_types_url_inter\n')

        # now we create a data file to write all sim data for when respect_property_rights == 0
    
        filepath = run_folder
        filename = "text_no_property_rights"

        print('\n---> printing text_no_property_rights')

        fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (params.run_propensities_charts_folder, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
        fileHandle.write("Data Relevant for Agents Not Respecting Property Rights\n\n\n")

        fileHandle.write("Day\tmean_ps\t\tstd\t\tmean_ps_>_50\tmean_ps_<_50\tmean_fb\t\tstd\t\tmean_fb_>_50\tmean_fb_<_50\tnum trans\tnum fights\ttype 1\t\t2 & 3\t\t4 & 5\n\n")

        for day in range(rounds):

            mean_steal = dbs.prop_steal_mean_db[day]

            if mean_steal == None:
                
                mean_steal = 'none'

            else:
                
                mean_steal = '%1.4f' % mean_steal

            std_steal = dbs.prop_steal_std_db[day]

            if std_steal == None:
                
                std_steal = 'none'

            else:
                
                std_steal = '%1.4f' % std_steal

            mean_above_50_steal = prop_steal_means_above_50[day]

            if mean_above_50_steal == None:
                
                mean_above_50_steal = 'none'

            else:
                
                mean_above_50_steal = '%1.4f' % mean_above_50_steal

            mean_below_50_steal = prop_steal_means_below_50[day]

            if mean_below_50_steal == None:
                
                mean_below_50_steal = 'none'

            else:
                
                mean_below_50_steal = '%1.4f' % mean_below_50_steal

            mean_fb = dbs.prop_fb_mean_db[day]

            if mean_fb == None:
                
                mean_fb = 'none'

            else:
                
                mean_fb = '%1.4f' % mean_fb

            std_fb = dbs.prop_fb_std_db[day]

            if std_fb == None:
                
                std_fb = 'none'

            else:
                
                std_fb = '%1.4f' % std_fb

            mean_above_50_fb = prop_fight_back_means_above_50[day]

            if mean_above_50_fb == None:
                
                mean_above_50_fb = 'none'

            else:
                
                mean_above_50_fb = '%1.4f' % mean_above_50_fb

            mean_below_50_fb = prop_fight_back_means_below_50[day]

            if mean_below_50_fb == None:
                
                mean_below_50_fb = 'none'

            else:
                
                mean_below_50_fb = '%1.4f' % mean_below_50_fb

            fileHandle.write("\n%4.0d\t%s\t\t%s\t\t%s\t\t%s\t\t%s\t\t%s\t\t%s\t\t%s\t\t%3d\t\t%3d\t\t%3d\t\t%3d\t\t%3d" % (day, mean_steal, std_steal, mean_above_50_steal, mean_below_50_steal, mean_fb, std_steal, mean_above_50_fb, mean_below_50_fb, dbs.num_ints_each_round[6][day], dbs.num_fight_each_round[day], dbs.num_ints_each_round[1][day], dbs.num_ints_each_round[2][day], dbs.num_ints_each_round[4][day]))

        fileHandle.close()

    # create a chart to show correlations between props steal
    if respect_property_rights == 0 and len(ps_corr) > 0:

        for base_round in ps_corr:

            len_chart = len(dbs.ps_corr_array)

            # print('\n dbs.ps_corr_array =', dbs.ps_corr_array)

            if len_chart > base_round:

                corr_ps_data = np.zeros(shape=len_chart, dtype=float)

                for day in range(len_chart):

                    # print('\n dbs.ps_corr_array[day] =', dbs.ps_corr_array[day])
                    # print('\n dbs.ps_corr_array[ps_corr] =', dbs.ps_corr_array[ps_corr])

                    corr_matrix = np.corrcoef(dbs.ps_corr_array[day], dbs.ps_corr_array[base_round])

                    corr_ps_data[day] = corr_matrix[0][1]

                corr_ps_chart_data = np.array([np.arange(len_chart), corr_ps_data])

                print_chart(database=corr_ps_chart_data, labels_array=[], title='', axis_labels=['Rounds', 'Correlation Coefficient'], line_width=3, colors=['blue'],
                            data_folder=run_corr_coeff_folder, filename='corr_coeff_ps_base_%d' % base_round, data_type='-', dpi='high', show_legend=False)

    # create a chart to show number of perfect specialists
    # print('\n dbs.num_perfect_specs \n\n', dbs.num_perfect_specs)

    print_chart(dbs.num_perfect_specs, ['95 pct', '99 pct', '99.9 pct'], 'Number of Specialists', ['Rounds', 'Number of Agents'], 2, ['black', 'red', 'blue'], params.run_specialisation_folder, "num_specialists", data_type='-', dpi='low', show_legend=False)

    # write successful transactions data
#    write_succ_trans_data(dbs, round, town_grid, print_dets, run_folder, daily=0, daily_db=[])

    write_for_strat_data(print_dets, print_fine_dets, dbs, fountain_population, agent_population, run_folder, rounds, two_tribes, params)

    # create a chart to show av age of the agents
    print_chart(dbs.ag_age_db, [''], 'Average Age of Agents', ['Rounds', 'Average Age'], 2, ['black'], params.run_population_folder, "agent_age", data_type='-', dpi='low')

    write_ag_age_data(dbs, run_folder, params)

    # Create a chart to show dbs.serviced_locations
    # serv_loc_db = [list(range(rounds))]
    # serv_loc_db.append(dbs.serviced_locations)
    # print_chart(serv_loc_db, [''], 'Proportion of Agent Homes within Market Catchment Area', ['Rounds', 'Ratio'], 2, ['black'], run_folder, "serviced_locs", data_type='-', dpi='low')

    # now create a chart to show how specialised agents were in their trading strategies - this will take the maximum prob in
    # each agent's trading strategy and then take an average of this across all agents

    # create chart to track the distribution of foraging strategies (we find the maximum number of times an agent forages for
    # any of the resources)

    min_max_spec = 3

#    print('min_max_spec', min_max_spec)

    for_spec_db1 = []
    for_spec_chart = []

    for_spec_chart.append(dbs.for_spec_db[0])

    for spec in np.arange(for_strat_parts + 1, dtype=int):

        for_spec_db1.append(dbs.for_spec_db[spec + 1])

    for spec in np.arange(min_max_spec + 1, for_strat_parts + 2, dtype=int):

        for_spec_chart.append(dbs.for_spec_db[spec])

    # add the mean spec data
    for_spec_means = dbs.for_spec_db[for_strat_parts + 2]

#    print('\n for_spec_db1', for_spec_db1)

    max_for_cols = []

    if print_end_of_round_charts == 1:

        print_chart(for_spec_chart, ['3', '4', '5'], 'Numbers of maximum foraging values', ['Rounds', 'Number of Agents'], 2, max_for_cols, params.run_specialisation_folder, "num_max_for", data_type='-', dpi='low', show_legend=True)

    # create chart which takes each agent's maximum foraging value and takes an average of this
    for_spec_db2 = []
    for_spec_db2.append(dbs.for_spec_db[0])
    for_spec_db2.append(dbs.for_spec_db[-1])

    if print_end_of_round_charts == 1:

        print_chart(for_spec_db2, [''], '', ['Rounds', 'Mean Max Specialisation Value'], 3, [], params.run_specialisation_folder, "num_max_for_av", data_type='-', dpi='high')       # 'Average maximum specialisation values'

    # manipulate data to generate some average & sd numbers
    av_last_50_births = np.mean(dbs.main_db[1][-50:])
    av_last_50_deaths = np.mean(dbs.main_db[2][-50:])
    av_last_50_popn = np.mean(dbs.main_db[3][-50:])

    std_last_50_births = np.std(dbs.main_db[1][-50:])
    std_last_50_deaths = np.std(dbs.main_db[2][-50:])
    std_last_50_popn = np.std(dbs.main_db[3][-50:])

    # if we're printing details, show these data:
    if print_dets == 1:

        print('final population size =', len(agent_population.pop))
        print('\nmain_db =\n', dbs.main_db)    

        print('\nav_last_50_births =', av_last_50_births, '(', std_last_50_births, ')')
        print('av_last_50_deaths =', av_last_50_deaths, '(', std_last_50_deaths, ')')
        print('av_last_50_popn =', av_last_50_popn, '(', std_last_50_popn, ')')

        for d in np.arange(num_res_founts):

            print('foutain', d, ': average level last 50 periods =', np.mean(dbs.main_db[4 + d][-50:]), '(', np.std(dbs.main_db[4 + d][-50:]), ')')

        print('\n')

    # manipulate founts_db to extract average numbers for agent's foraging strategies i.e. %age by foutain
    agent_strat_db = np.zeros(shape=(1 + num_res_founts, rounds))
    agent_strat_db[0] = np.arange(rounds)

    for g in np.arange(rounds):
        for h in np.arange(num_res_founts):

            ag_counter = 0
            for i in np.arange(for_strat_parts):

                ag_counter = ag_counter + dbs.founts_db[1 + (i * num_res_founts) + h][g]

            agent_strat_db[1 + h][g] = ag_counter / (float(dbs.main_db[3][g]) * for_strat_parts)

    if agents_trade == 1:

        # create chart which plots the % of squares with transactions in them (any number) in each round
        pct_sq_tr_db = []
        pct_sq_tr_db.append(dbs.key_trading_db[0])
        pct_sq_tr_db.append(dbs.key_trading_db[1])
    
        if print_end_of_round_charts == 1:

            print_chart(pct_sq_tr_db, labels_array=['No. of Squares'], axis_labels=['Rounds', 'Number of Squares with Transactions'], data_folder=params.run_transactions_folder, filename="num_sqrs_transactions")

#        # create chart Goods On Sale & Sold
#        trades_n_goods_db = []
#        trades_n_goods_db.append(np.arange(rounds))
#        trades_n_goods_db.append(dbs.trading_db[4])
#        trades_n_goods_db.append(dbs.trading_db[5])
#
#        print_chart(trades_n_goods_db, ['On Sale', 'Sold'], 'Goods On Sale & Sold', 'Total', 2, ['black', 'blue'], run_folder, "goods", data_type='-', dpi='low')
#
#        # create chrt showing % of goods on sale which were sold
#        trades_n_goods_db_pct = []
#        trades_n_goods_db_pct.append(np.arange(rounds))
#        trades_n_goods_db_pct.append(dbs.trading_db[6])
#
#        print_chart(trades_n_goods_db_pct, ['Percent Sold'], 'Goods Sold / On Sale', 'Percent', 2, ['black'], run_folder, "goods_pct_sold", data_type='-', dpi='low')
    
        # here we convert trading_db data in to text file
#        write_trading_array_to_text(dbs.trading_db, run_folder)

    # print a chart showing births, deaths & population
    colors = ['blue', 'red', 'black']
    line_width = 2

    labels_array = ['Births', 'Deaths', "Pop'n"]
    title = 'Births, Deaths & Population'
    axis_labels = ['Rounds', 'Total Number']

    if print_end_of_round_charts == 1:

        print_chart(dbs.main_db[:4], labels_array, title, axis_labels, line_width, colors, params.run_population_folder, "agent_population", data_type='-', dpi='low')

        # print_chart(dbs.main_db[:4], labels_array, '', 'Total Number', line_width, ['blue', 'red', 'black'], run_folder, "agent_population_paper", data_type='-', dpi='high')

        if two_tribes:

            pops_data = []
            pops_data.append(range(rounds))
            pops_data.append(dbs.pop_sharks)
            pops_data.append(dbs.pop_jets)
            
            print_chart(pops_data, ['Sharks', 'Jets'], '', ['Rounds', 'Total Number'], line_width, ['blue', 'red'], run_folder, "agent_population_paper_tribes", data_type='-', dpi='high')

        print_turnover_breakdown_charts(num_res_founts, print_dets, print_fine_dets, dbs, rounds, fountain_population, params.run_turnover_folder, gen_equ_thresh)
    
        print_turnover_charts(num_res_founts, print_dets, print_fine_dets, dbs, rounds, fountain_population, params.run_turnover_folder, gen_equ_thresh, constitutional_voting, start_const_proces, const_proc_test_period)
    
        write_turnover_acc_report(params.run_turnover_folder, rounds, dbs, gen_equ_thresh)
    
        print_prices_charts(num_res_founts, print_dets, print_fine_dets, dbs, rounds, fountain_population, params.run_prices_folder, Walrasian_Trading, two_tribes)

    # now we put the raw data in to a txt file
    write_popn_data_to_txt(dbs.main_db[:4], run_folder, num_agents, params)

    if print_end_of_round_charts == 1:

        # and create a text file showing agents' key data, including foraging strategies
        write_key_agent_data(dbs, agent_population, fountain_population, run_folder, vision_len, town_grid, rounds, params)

        # do the same with dead agents
        write_key_dead_agent_data(dbs, agent_population, fountain_population, run_folder, vision_len, town_grid, rounds, params)

    # create new database to print fountain data chart
    if two_tribes == 0:

        for i in np.arange(num_res_founts):
    
            colors = ['black', 'blue', 'red', 'green', 'aqua', 'teal', 'navy', 'fuchsia', 'purple']
            database2 = np.zeros(shape=(2, rounds))
            database2[0] = np.arange(rounds)
            database2[1] = dbs.foutain_levels[i]
    
            database2b = np.zeros(shape=(2, rounds))
            database2b[0] = np.arange(rounds)
            mov_av_days = 5
    
            database2b[1] = generate_MA_array(database2[1], mov_av_days)
    
            labels_array2 = [str(i)]
            # y_axis_label2 = 'Total Number'
            line_width = 1
    
            if trade_loc == 'fountain':
    
                title2 = 'Fountain Yields (loc [%s, %s])' % (fountain_population.pop[i].location[0], fountain_population.pop[i].location[1])
    
            else:
    
                title2 = 'Fountain Yields'
    
            Title = "fountains_yield"
    
            if print_end_of_round_charts == 1:
        
                print_chart(database2, labels_array2, title2, ['Rounds', 'Total Number'], line_width, colors, params.run_specialisation_folder, Title, data_type='-', dpi='low')
        
                # print_chart(database2b, [''], '', y_axis_label2, 2, colors, run_folder, "fountains_yield_paper", data_type='-', dpi='high')

    elif two_tribes:

        # sharks res 0
        database = np.zeros(shape=(2, rounds))
        database[0] = np.arange(rounds)
        database[1] = np.zeros(shape=rounds)

        for day in range(rounds):

            database[1][day] = dbs.init_res_levels[day][0] - dbs.res_founts_sharks[0][day]

        MA_array = generate_MA_array(database[1], 5)
        
        database[1] = MA_array

        print_chart(database, [''], '', ['Rounds', 'Total Number'], 2, ['black'], run_folder, "fountains_yield_sharks_res_0", data_type='-', dpi='high')

        # sharks res 1
        for day in range(rounds):

            database[1][day] = dbs.init_res_levels[day][1] - dbs.res_founts_sharks[1][day]

        MA_array = generate_MA_array(database[1], 5)
        
        database[1] = MA_array

        print_chart(database, [''], '', ['Rounds', 'Total Number'], 2, ['blue'], run_folder, "fountains_yield_sharks_res_1", data_type='-', dpi='high')

        # jets res 0
        for day in range(rounds):

            database[1][day] = dbs.init_res_levels[day][2] - dbs.res_founts_jets[0][day]

        MA_array = generate_MA_array(database[1], 5)
        
        database[1] = MA_array

        print_chart(database, [''], '', ['Rounds', 'Total Number'], 2, ['red'], run_folder, "fountains_yield_jets_res_0", data_type='-', dpi='high')

        # jets res 1
        for day in range(rounds):

            database[1][day] = dbs.init_res_levels[day][3] - dbs.res_founts_jets[1][day]

        MA_array = generate_MA_array(database[1], 5)
        
        database[1] = MA_array

        print_chart(database, [''], '', ['Rounds', 'Total Number'], 2, ['green'], run_folder, "fountains_yield_jets_res_1", data_type='-', dpi='high')

    # Print MRS standard deviation charts if we want
    if print_MRS_std_charts:

        for res_1 in np.arange(num_res_founts):
            for res_2 in np.arange(num_res_founts):
                if res_1 != res_2:
    
                    MRS_STD_database = [np.arange(rounds)]
    
                    for i in [0, 1]:
    
                        MRS_STD_database.append(dbs.MRS_STDs_array[res_1][res_2][i])
    
                        colors = ['black', 'blue']
                        line_width = 2
                        labels_array = ['MRS Standard Dev Before Trading', 'MRS Standard Dev After Trading']
                        title = 'Standard Deviations of MRS (Res %s vs Res %s): Before and After Trading' % (res_1, res_2)
                        y_axis_label = ['Rounds', 'Standard Deviation']
    
                    print_chart(MRS_STD_database, labels_array, title, y_axis_label, line_width, colors, run_folder, "time_series of MRS STDs - Res %s vs Res %s" % (res_1, res_2), data_type='-', dpi='low')

    # generate and print charts showing agents' threshold probabilities and observed actual transating probabilities
#    agent.thresh_probs_array[1][day] = threshold_0_to_1
#    agent.thresh_probs_array[2][day] = threshold_1_to_0
#    agent.thresh_probs_array[3][day] = agent.trade_proby
#    agent.thresh_probs_array[4][day] = agent.detect_skills_array[0][0]
#    agent.thresh_probs_array[5][day] = agent.detect_skills_array[0][1]
#    agent.thresh_probs_array[6][day] = 1 / agent.wkg_prices_memory[0][1]
#    agent.thresh_probs_array[7][day] = 1 / agent.wkg_prices_memory[1][0]

    ref_point = 0

    # we want to look at all alive and dead agents
    if print_fine_dets == 1:
        print('agent_population.pop =', agent_population.pop)
        print('agent_population.dead_agent_array =', agent_population.dead_agent_array)    

    # lump agents (alive and dead) in to a single array, which we will iterate over
    all_agents_array = []

    for agent in agent_population.pop:

        all_agents_array.append(agent)

    if res_depletion:       # only do this if we're tracking famines, otherwise it takes up too much time

        for agent in agent_population.dead_agent_array:

           all_agents_array.append(agent)

    if print_fine_dets == 1:
        print('\n all_agents_array =', all_agents_array)   

    if print_end_of_round_charts == 1:

        for agent_num in range(len(all_agents_array)):
    
    #        print('\n\n agent.thresh_probs_array:\n\n', agent.thresh_probs_array)
    
            agent = all_agents_array[agent_num]

            # print('\n agent.thresh_probs_array:', agent.thresh_probs_array)

            end_chart_date = np.min([agent.death_date, rounds])
    
    #        print('\n agent:', agent, 'birth =', agent.birth_date, 'death =', agent.death_date, 'end_chart_date =', end_chart_date)
    
            # smooth the `ctual probs (5 rounds moving average)
    
            # remove the higher threshold and prices
            if agent.thresh_probs_array[4][end_chart_date - 1] > agent.thresh_probs_array[5][end_chart_date - 1]:
    
                agent.thresh_probs_array = np.delete(agent.thresh_probs_array, [2, 6, 7], 0)    # [2, 5, 7]
    
                name_low_det = 'skill_0'
                name_low_thresh = 'threshold_0_to_1'
                name_price = 'price of resource 0'
    
                names_array = ['Probability Threshold', 'Expected Probability', 'High Detection Probability', 'Low Detection Probability']
    
            else:
    
                agent.thresh_probs_array = np.delete(agent.thresh_probs_array, [1, 6, 7], 0)    # [1, 4, 6]
    
                name_low_det = 'skill_1'
                name_low_thresh = 'threshold_1_to_0'
                name_price = 'price of resource 1'
    
                names_array = ["Prob'y Threshold", "Exp Prob'y", "Low Det. Prob'y", "High Det. Prob'y"]
    
    #        print('\n\n agent.birth_date:', agent.birth_date)
    
            # now chop in the other axis - from the day after birth to death (or end)
            if agent.birth_date == 0:
    
                agent.thresh_probs_array = agent.thresh_probs_array[:, 0:end_chart_date]
    
            else:
    
                agent.thresh_probs_array = agent.thresh_probs_array[:, agent.birth_date + 1:end_chart_date]
    
    #        print('\n\nlen(agent.thresh_probs_array[0])', len(agent.thresh_probs_array[0]))
    #        print('\n\n NEW agent.thresh_probs_array:', agent.thresh_probs_array)
    
            if len(agent.thresh_probs_array[0]) > 0:
    
                # if it's a full sim, print first 200 rounds with daily data (no moving average)
                if len(agent.thresh_probs_array[0]) > 200:

                    # print('\n printing thresh_probs_agent')
                    print_chart(agent.thresh_probs_array[:, :200], names_array, '', ['Rounds', 'Probability'], 2, ['red', 'black', 'blue', 'green'], params.run_specialisation_folder, "thresh_probs_agent_%d_200" % (agent_num), show_legend=True)
    
        #            # create two temporary arrays to store new data
        #            mov_ag_array_act = np.zeros(shape=(len(agent.thresh_probs_array[0])))
        #            mov_ag_array_thresh = np.zeros(shape=(len(agent.thresh_probs_array[0])))
            
                    # set the number of moving average days
                    mov_av_days = mov_av_days_threshold_chart
    
                    mov_ag_array_thresh = generate_MA_array(agent.thresh_probs_array[1], mov_av_days)
                    mov_ag_array_act = generate_MA_array(agent.thresh_probs_array[2], mov_av_days)
            
    #                print('\n\n mov_ag_array_thresh =', mov_ag_array_thresh)
    #                print('\n\n mov_ag_array_act =', mov_ag_array_act)
        
        #            # rest of the cells
        #            for day in range(1, len(agent.thresh_probs_array[0])):
        #    
        #                start_day = np.max([0, day - mov_av_days])
        #    
        #                mov_ag_array_thresh[day] = np.mean(agent.thresh_probs_array[1][start_day:day])    
        #                mov_ag_array_act[day] = np.mean(agent.thresh_probs_array[2][start_day:day])
            
                    # replace old data with temp data
                    agent.thresh_probs_array[1] = copy.copy(mov_ag_array_thresh)
                    agent.thresh_probs_array[2] = copy.copy(mov_ag_array_act)
    
                    if print_fine_dets == 1:
            
                        print('\n\n agent', agent_num)
                        print('\n agent.thresh_probs_array =', agent.thresh_probs_array)

                    if thresh_probs_charts_show_thresh == 0:
                        agent.thresh_probs_array = np.delete(agent.thresh_probs_array, 1, 0)
                        colors_array = ['black', 'blue', 'green']

                    else:
                        colors_array = ['red', 'black', 'blue', 'green']

                    if agent.birth_date == 0 and popn_ch == 'vary':
        
                        print_chart(agent.thresh_probs_array, names_array, '', ['Rounds', 'Probability'], 2, colors_array, params.run_specialisation_folder, "thresh_probs_agent_%d_all" % (agent_num), data_type='-', dpi='high')
        
                    else:
        
                        print_chart(agent.thresh_probs_array, names_array, '', ['Rounds', 'Probability'], 2, colors_array, params.run_specialisation_folder, "thresh_probs_agent_%d_all" % (agent_num), data_type='-', dpi='low')

#        input("Press Enter to continue...")

    # Here we question how quickly the market emerged, if there was one
    num_rounds_mov_av = 20
    for res in range(num_res_founts):

#        print('\n\n\n res =', res)

        for day in range(num_rounds_mov_av, rounds - 1):

            mov_av = np.mean(dbs.net_turnover_prop[day - num_rounds_mov_av + 1:day + 1][res])       # rounds x res

#            print('day = ', day, 'mov_av =', mov_av)

            if dbs.mkt_emerged_round[0] == 0 and mov_av > 0.9:

                dbs.mkt_emerged_round[0] = day

            if dbs.mkt_emerged_round[1] == 0 and mov_av > 0.95:

                dbs.mkt_emerged_round[1] = day

            if dbs.mkt_emerged_round[2] == 0 and mov_av > 0.99:

                dbs.mkt_emerged_round[2] = day

    # print home locations again if agent_homes='random' (will be different at the end)
    # create an array to record the locations
    if day == rounds - 1:

        homes_array = np.zeros(shape=(dimen, dimen))

        if day == rounds - 1:

            dpi = 'high'

        else:

            dpi = 'low'

        for agent in agent_population.pop:
    
            x_coord = int(agent.home[0])
            y_coord = int(agent.home[1])
    
            homes_array[x_coord][y_coord] += 1
    
#        # now illustrate homes_array via a heatmap if we're printing charts
#        if print_charts == 1 and print_end_of_round_charts == 1:
    
        create_heat_map(dimen, homes_array, params.run_population_folder, 'Greys', '', "agent_homes_end", dpi)

    # present charts for markets habituation and RL data
    if habit_val_mkts > 0.0:

        agent_num = 0
        for agent in list(agent_population.pop) + agent_population.dead_agent_array:

            # first, find dominant market in agent's memories
            highest_weight = 0
            highest_weight_loc = None

            for location in agent.locations_weights_hist_dict:

                weight = agent.locations_weights_hist_dict[location][0][-1] + agent.locations_weights_hist_dict[location][1][-1]

                if weight > highest_weight:
                    highest_weight = weight
                    highest_weight_loc = location

                # print('\n agent.home =', agent.home, 'location', location, 'weight =', weight,
                #       'o/w RL =', agent.locations_weights_hist_dict[location][0][-1], 'o/w Hab =', agent.locations_weights_hist_dict[location][1][-1])

            # print('\n highest_weight_loc=', highest_weight_loc)

            if highest_weight_loc != None:

                RL_data = agent.locations_weights_hist_dict[highest_weight_loc][0]
                Hab_data = agent.locations_weights_hist_dict[highest_weight_loc][1]

                # useful piece of data: when was the highest_weight_loc the only location ever visited?
                first_round_solo = copy.copy(rounds)

                for i in range(1, rounds):

                    # count backwards
                    i *= -1

                    sum_rest = 0

                    if sum_rest == 0:

                        for location in agent.locations_weights_hist_dict:

                            if location != highest_weight_loc:

                                sum_rest += agent.locations_weights_hist_dict[location][1][i]

                        if sum_rest == 0:
                            first_round_solo = rounds + i

                # print('\n first_round_solo =', first_round_solo)

                # change hab data to cumulative (RL is already cumulative albeit with memory decay).
                if habit_deteriorates_mkts:

                    Hab_data_history = copy.copy(Hab_data)

                    # print('\n Hab_data_history:', Hab_data_history)

                    for d in range(1, rounds):

                        # print(' Hab_data[d] =', Hab_data[d], 'Hab_data[d - 1]', Hab_data[d - 1])

                        Hab_data[d] += Hab_data[d - 1] * (1 - memory_decay_rate)

                    # print('\n resulting Hab_data:', Hab_data)

                else:

                    for d in range(1, rounds):
                        Hab_data[d] += Hab_data[d - 1]

                chart_data = [list(range(rounds)), [[RL_data, Hab_data]]]
                file_name = 'habituation_contrs_mkts_ag_%d' % agent_num

                if agent_num < len(agent_population.pop):
                    file_name += '_alive'
                else:
                    file_name += '_dead'

                file_name += '_solo_from_%d' % first_round_solo

                # print('\n chart_data =', chart_data)

                print_contributions_to_tot_2_axes(database=chart_data, axis_labels=['Rounds', 'Weight'], labels_array=['RL', 'Habituation'], line_width=3, colors=['blue', 'red'], data_folder=params.run_habituation_folder, filename=file_name, show_legend=False, font_size=40, special_data=None)

            agent_num += 1

            # pause()

    # Here we run a function which processes all the information we want to return in the run_sim() function
    sim_return_data = write_success_data(params, agent_population, dbs, print_dets, print_fine_dets, run_folder, rounds, fountain_population, for_spec_db1, for_spec_means, agent_res_init, cluster_lag, town_grid,\
                                         for_strat_parts, printed_segment_size, allow_Keynes_Inst, KO_pop, constitutional_voting, constitutional_exp, num_experiments, respect_property_rights, file_type, black_shoop_exp,
                                         fight_skill, two_tribes, OLS_include)

#    print("\n\n iterations data\n\n")
#    for day in range(rounds):
#
#        print("num_iters = ", dbs.opt_iters_record[day], "time = ", dbs.opt_time_record[day])
#
#    print("\n mean num_iters = ", np.mean(dbs.opt_iters_record), "mean time = ", np.mean(dbs.opt_time_record))

    # if we are recording times:
    if calc_timings:

        print('\n\n\n\n TIMINGS')

        total_time = dt.datetime.now() - start_time

        print('\n Total time =', total_time)

        print('\n overheads: ', dbs.timings_dict['overheads'])

        for entry in ['foraging', 'trading', 'trading_overhead', 'trading_move_overhead', 'trading_move_agent_mtt', 'trading_move_agent_eval_own_grid_sq', 'trading_move_agent_eval_exp_gains_own_square', 'trading_move_agent_agents_interact',\
                      'trading_move_agent_eval_all_grid_sqs', 'trading_move_agent_retargetting', 'trading_move_agent_bilat_eval', 'three_updates', 'comms', 'for_strats', 'new_births']:

            total_time_entry = dt.timedelta(0, 0, 0)

            for day_entry in dbs.timings_dict[entry]:
                total_time_entry += day_entry

            mean_time_delta = total_time_entry / len(dbs.timings_dict[entry])

            years, days, hours, minutes, seconds = length_of_time(mean_time_delta)

            print('\n', entry, 'mean time =', hours, 'hours', minutes, 'minutes', seconds, 'seconds')

        print('\n\n')

        for day in range(rounds):

            print(' day ', day, 'trading time =', dbs.timings_dict['trading'][day], 'comms time =', dbs.timings_dict['comms'][day], 'proportion comms / trading', dbs.timings_dict['comms'][day] / dbs.timings_dict['trading'][day])

        print('\n\n')

    # here we create two charts, one for dbs.target_locations and another for dbs.transaction_locations

    # shift the data in to arrays for inputting in to print_chart
    target_locs_array = np.array([np.arange(rounds)])
    target_locs_names = np.array([], dtype=str)

    for entry in dbs.target_locations:

        target_locs_names = np.append(target_locs_names, entry)

        # append target_locs_array
        target_locs_array = np.vstack((target_locs_array, dbs.target_locations[entry]))

    # print('\n target_locs_names =', target_locs_names)
    # print('\n target_locs_array:', target_locs_array)

    # now transaction locations
    trans_locs_array = np.array([np.arange(rounds)])
    trans_locs_names = np.array([], dtype=str)

    entry_num = 1
    for entry in dbs.transaction_locations:

        trans_locs_names = np.append(trans_locs_names, entry)

        trans_locs_array = np.vstack((trans_locs_array, np.zeros(rounds, dtype=int)))

        for d in range(rounds):
            trans_locs_array[entry_num][d] = len(dbs.transaction_locations[entry][d])

        entry_num += 1

    # print('\n len(dbs.transaction_locations)', len(dbs.transaction_locations))
    # print('\n trans_locs_names', trans_locs_names)
    # print('\n trans_locs_array\n\n', trans_locs_array)

    # print('\n trans_locs_names =', trans_locs_names)
    # print('\n trans_locs_array:', trans_locs_array)

    colors = ['black', 'blue', 'red', 'green', 'aqua', 'teal', 'navy', 'fuchsia', 'purple']

    # create chart for target locations:
    print_chart(target_locs_array, target_locs_names, 'Time Series of Target Locations (Number of Agents)', ['Rounds', 'Number of Agents'], 2, colors, params.run_target_locations_folder, "target_locs_all", data_type='-', dpi='high')

    if rounds >= 20:
        print_chart(target_locs_array[:, :20], target_locs_names, 'Time Series of Target Locations (Number of Agents) - 20 Rounds', ['Rounds', 'Number of Agents'], 2, colors, params.run_target_locations_folder, "target_locs_20", data_type='-', dpi='high')

        if rounds >= 50:
            print_chart(target_locs_array[:, :50], target_locs_names, 'Time Series of Target Locations (Number of Agents) - 50 Rounds', ['Rounds', 'Number of Agents'], 2, colors, params.run_target_locations_folder, "target_locs_50", data_type='-', dpi='high')

            if rounds >= 100:
                print_chart(target_locs_array[:, :100], target_locs_names, 'Time Series of Target Locations (Number of Agents) - 100 Rounds', ['Rounds', 'Number of Agents'], 2, colors, params.run_target_locations_folder, "target_locs_100", data_type='-', dpi='high')

    # create chart for transaction locations:
    if entry_num > 1:           # don't print if there were no transactions

        print_chart(trans_locs_array, trans_locs_names, 'Time Series of Transaction Locations (Number of Agents)', 'Number of Agents', 2, colors, params.run_target_locations_folder, "trans_locs_all", data_type='-', dpi='high')

        if rounds >= 20:
            print_chart(trans_locs_array[:, :20], trans_locs_names, 'Time Series of Transaction Locations (Number of Agents) - 20 Rounds', ['Rounds', 'Number of Agents'], 2, colors, params.run_target_locations_folder, "trans_locs_20", data_type='-', dpi='high')

            if rounds >= 50:
                print_chart(trans_locs_array[:, :50], trans_locs_names, 'Time Series of Transaction Locations (Number of Agents) - 50 Rounds', ['Rounds', 'Number of Agents'], 2, colors, params.run_target_locations_folder, "trans_locs_50", data_type='-', dpi='high')

                if rounds >= 100:
                    print_chart(trans_locs_array[:, :100], trans_locs_names, 'Time Series of Transaction Locations (Number of Agents) - 100 Rounds', ['Rounds', 'Number of Agents'], 2, colors, params.run_target_locations_folder, "trans_locs_100", data_type='-', dpi='high')

    # create chart for number of A-foragers, B-foragers, or neither

    # first add rounds to array
    dbs.num_specialists = np.insert(dbs.num_specialists, 0, np.arange(rounds, dtype=int), 0)

    spec_names = ('A', 'B', 'None')
    specs_cols = ['red', 'blue', 'black']

    print_chart(dbs.num_specialists, spec_names, 'Time Series of Specialists', ['Rounds', 'Number of Agents'], 2, specs_cols, params.run_specialisation_folder, "specs_time_ser", data_type='-', dpi='high', show_legend=False)

    dbs.num_specialists_tot = np.insert(dbs.num_specialists_tot, 0, np.arange(rounds, dtype=int), 0)

    spec_names = ('A', 'B', 'None')
    specs_cols = ['red', 'blue', 'black']

    print_chart(dbs.num_specialists_tot, spec_names, 'Time Series of Absolute Specialists', ['Rounds', 'Number of Agents'], 2, specs_cols, params.run_specialisation_folder, "specs_abs_time_ser", data_type='-', dpi='high', show_legend=True)

    # now we plot gini coefficient for resource holdings at end of rounds
    gini_MA_data = generate_MA_array(dbs.res_conc_gini, N=5)
    gini_MA_data_starts = generate_MA_array(dbs.res_conc_gini_starts, N=5)
    print_chart(database=[np.arange(rounds), gini_MA_data_starts, gini_MA_data], labels_array=['Start of Round', 'End of Round'], colors=('blueviolet', 'darkblue'), axis_labels=['Rounds', 'Gini Coefficient'], line_width=3,
                data_folder=run_folder, filename='gini_res_conc')

    # here we find the mean size of trans and fights in each day and plot
    res_transfer_data = [np.arange(rounds), [], []]       # 0 is rounds, 1 is trans, 2 is fights
    spec_data = []

    props_fight_data_2F = [np.arange(rounds), [], [], [], []]      # 0 is round, 1 is init ps, 2 is init pfb, 3 is cp ps, 4 is cp pfb
    props_res_trans_data_2F = [np.arange(rounds), [], []]

    props_fight_data_3F = [np.arange(rounds), [], [], [], []]      # 0 is round, 1 is init ps, 2 is init pfb, 3 is cp ps, 4 is cp pfb
    props_res_trans_data_3F = [np.arange(rounds), [], []]

    # we want 3 charts for contributions - one for all alive at the time, one for all alive at the end, and another for died by end
    dbs.all_agents_contrs_by_scen = {}

    dbs.all_agents_contrs_by_scen['1'] = np.zeros(shape=rounds, dtype=float)
    dbs.all_agents_contrs_by_scen['2F'] = np.zeros(shape=rounds, dtype=float)
    dbs.all_agents_contrs_by_scen['2A'] = np.zeros(shape=rounds, dtype=float)
    dbs.all_agents_contrs_by_scen['3F'] = np.zeros(shape=rounds, dtype=float)
    dbs.all_agents_contrs_by_scen['3A'] = np.zeros(shape=rounds, dtype=float)
    dbs.all_agents_contrs_by_scen['4'] = np.zeros(shape=rounds, dtype=float)

    dbs.alive_agents_contrs_by_scen = {}

    dbs.alive_agents_contrs_by_scen['1'] = np.zeros(shape=rounds, dtype=float)
    dbs.alive_agents_contrs_by_scen['2F'] = np.zeros(shape=rounds, dtype=float)
    dbs.alive_agents_contrs_by_scen['2A'] = np.zeros(shape=rounds, dtype=float)
    dbs.alive_agents_contrs_by_scen['3F'] = np.zeros(shape=rounds, dtype=float)
    dbs.alive_agents_contrs_by_scen['3A'] = np.zeros(shape=rounds, dtype=float)
    dbs.alive_agents_contrs_by_scen['4'] = np.zeros(shape=rounds, dtype=float)

    dbs.al_capones_contrs_by_scen = {}

    dbs.al_capones_contrs_by_scen['1 init'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['1 cp'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['2F init'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['2F cp'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['2A init'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['2A cp'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['3F init'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['3F cp'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['3A init'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['3A cp'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['4 init'] = np.zeros(shape=rounds, dtype=float)
    dbs.al_capones_contrs_by_scen['4 cp'] = np.zeros(shape=rounds, dtype=float)

    for day in range(rounds):

        # print('\n day =', day)

        todays_transs = dbs.transs_daily_db[day]

        # print('\n todays_transs :', todays_transs, '\n')

        trans_counter = 0
        sum_trans = 0.0

        for trans_num in todays_transs:

            trans = dbs.trans_db[trans_num]
            sum_trans += trans.tot_trans_ag_buy
            trans_counter += 1

            # print('\n day', day, 'trans_num ', trans_num, 'trans.agent_a', trans.agent_a, 'trans.agent_b', trans.agent_b)
            # print(' agent_population.dead_agent_array:', agent_population.dead_agent_array)

            for dead_agent in agent_population.dead_agent_array:

                if dead_agent.birth_date <= day <= dead_agent.death_date:

                    if str(dead_agent) == trans.agent_a:

                        dbs.al_capones_contrs_by_scen['1 init'][day] += trans.initiator_new_prop_steal - trans.initiator_start_prop_steal
                        dbs.all_agents_contrs_by_scen['1'][day] += trans.initiator_new_prop_steal - trans.initiator_start_prop_steal

                        # print(' str(dead_agent) == trans.agent_a: change in ps =', trans.initiator_new_prop_steal - trans.initiator_start_prop_steal)

                    elif str(dead_agent) == trans.agent_b:

                        dbs.al_capones_contrs_by_scen['1 cp'][day] += trans.counterpart_new_prop_steal - trans.counterpart_start_prop_steal
                        dbs.all_agents_contrs_by_scen['1'][day] += trans.counterpart_new_prop_steal - trans.counterpart_start_prop_steal

                        # print(' str(dead_agent) == trans.agent_b: change in ps =', trans.counterpart_new_prop_steal - trans.counterpart_start_prop_steal)

            for alive_agent in agent_population.pop:

                if alive_agent.birth_date <= day:

                    if str(alive_agent) == trans.agent_a:

                        dbs.alive_agents_contrs_by_scen['1'][day] += trans.initiator_new_prop_steal - trans.initiator_start_prop_steal
                        dbs.all_agents_contrs_by_scen['1'][day] += trans.initiator_new_prop_steal - trans.initiator_start_prop_steal

                        # print(' str(alive_agent) == trans.agent_a: change in ps =', trans.initiator_new_prop_steal - trans.initiator_start_prop_steal)

                    elif str(alive_agent) == trans.agent_b:

                        dbs.alive_agents_contrs_by_scen['1'][day] += trans.counterpart_new_prop_steal - trans.counterpart_start_prop_steal
                        dbs.all_agents_contrs_by_scen['1'][day] += trans.counterpart_new_prop_steal - trans.counterpart_start_prop_steal

                        # print(' str(dead_agent) == trans.agent_b: change in ps =', trans.counterpart_new_prop_steal - trans.counterpart_start_prop_steal)

        if trans_counter > 0:
            mean_trans = sum_trans / float(trans_counter)
        else:
            mean_trans = None

        res_transfer_data[1].append(mean_trans)

        # now for fights
        todays_fights = dbs.fights_daily_db[day]

        # print('\n todays_fights :', todays_fights, '\n')

        fight_vals = []           # record the values we're interested in for the day initiator_dec

        init_ps_data_2F = []
        cp_ps_data_2F = []
        init_pfb_data_2F = []
        cp_pfb_data_2F = []
        init_ps_data_3F = []
        cp_ps_data_3F = []
        init_pfb_data_3F = []
        cp_pfb_data_3F = []

        init_start_res_2F = []
        cp_start_res_2F = []
        init_start_res_3F = []
        cp_start_res_3F = []

        for fight_num in todays_fights:

            fight = dbs.fights_db[fight_num]

            if fight.initiator_dec == 'fight_back' and fight.counterpart_dec == 'steal':

                init_ps_data_2F.append(fight.initiator_start_prop_steal)
                init_pfb_data_2F.append(fight.initiator_start_prop_fight_back)
                cp_ps_data_2F.append(fight.counterpart_start_prop_steal)
                cp_pfb_data_2F.append(fight.counterpart_start_prop_fight_back)

                init_start_res_2F.append(np.sum(fight.initiator_start_basket))
                cp_start_res_2F.append(np.sum(fight.counterpart_start_basket))

            elif fight.initiator_dec == 'steal' and fight.counterpart_dec == 'fight_back':

                init_ps_data_3F.append(fight.initiator_start_prop_steal)
                init_pfb_data_3F.append(fight.initiator_start_prop_fight_back)
                cp_ps_data_3F.append(fight.counterpart_start_prop_steal)
                cp_pfb_data_3F.append(fight.counterpart_start_prop_fight_back)

                init_start_res_3F.append(np.sum(fight.initiator_start_basket))
                cp_start_res_3F.append(np.sum(fight.counterpart_start_basket))

            init_ag_receives = np.sum(fight.initiator_end_basket) - np.sum(fight.initiator_start_basket)

            if init_ag_receives > 0.0:

                fight_vals.append(init_ag_receives)

            else:       # then this will be positive or zero
                cp_ag_receives = np.sum(fight.counterpart_end_basket) - np.sum(fight.counterpart_start_basket)

                fight_vals.append(cp_ag_receives)

            # print('\n fight_num =', fight_num)
            # print(' fight.initiator_dec =', fight.initiator_dec, 'fight.counterpart_dec =', fight.counterpart_dec)

            # now we do dead agents - contributions by scenario
            for dead_agent in agent_population.dead_agent_array:

                if dead_agent.birth_date <= day <= dead_agent.death_date:

                    # if str(dead_agent) == fight.initiator:
                    #     print(' dead_agent == fight.initiator - contr = ', fight.initiator_new_prop_steal - fight.initiator_start_prop_steal)
                    #
                    # elif str(dead_agent) == fight.counterpart:
                    #     print(' dead_agent == fight.counterpart - contr = ', fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal)

                    if fight.initiator_dec == 'trade' and fight.counterpart_dec == 'steal':

                        if str(dead_agent) == fight.initiator:
                            dbs.al_capones_contrs_by_scen['2A init'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                            dbs.all_agents_contrs_by_scen['2A'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                        elif str(dead_agent) == fight.counterpart:
                            dbs.al_capones_contrs_by_scen['2A cp'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                            dbs.all_agents_contrs_by_scen['2A'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

                    elif fight.initiator_dec == 'fight_back' and fight.counterpart_dec == 'steal':

                        if str(dead_agent) == fight.initiator:
                            dbs.al_capones_contrs_by_scen['2F init'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                            dbs.all_agents_contrs_by_scen['2F'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                        elif str(dead_agent) == fight.counterpart:
                            dbs.al_capones_contrs_by_scen['2F cp'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                            dbs.all_agents_contrs_by_scen['2F'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

                    elif fight.initiator_dec == 'steal' and fight.counterpart_dec == 'trade':

                        if str(dead_agent) == fight.initiator:
                            dbs.al_capones_contrs_by_scen['3A init'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                            dbs.all_agents_contrs_by_scen['3A'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                        elif str(dead_agent) == fight.counterpart:
                            dbs.al_capones_contrs_by_scen['3A cp'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                            dbs.all_agents_contrs_by_scen['3A'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

                    elif fight.initiator_dec == 'steal' and fight.counterpart_dec == 'fight_back':

                        if str(dead_agent) == fight.initiator:
                            dbs.al_capones_contrs_by_scen['3F init'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                            dbs.all_agents_contrs_by_scen['3F'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                        elif str(dead_agent) == fight.counterpart:
                            dbs.al_capones_contrs_by_scen['3F cp'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                            dbs.all_agents_contrs_by_scen['3F'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

                    elif fight.initiator_dec == 'steal' and fight.counterpart_dec == 'steal':

                        if str(dead_agent) == fight.initiator:
                            dbs.al_capones_contrs_by_scen['4 init'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                            dbs.all_agents_contrs_by_scen['4'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                        elif str(dead_agent) == fight.counterpart:
                            dbs.al_capones_contrs_by_scen['4 cp'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                            dbs.all_agents_contrs_by_scen['4'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

            for alive_agent in agent_population.pop:

                if alive_agent.birth_date <= day:

                    # if str(alive_agent) == fight.initiator:
                    #     print(' alive_agent == fight.initiator - contr = ', fight.initiator_new_prop_steal - fight.initiator_start_prop_steal)
                    #
                    # elif str(alive_agent) == fight.counterpart:
                    #     print(' alive_agent == fight.counterpart - contr = ', fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal)

                    if fight.initiator_dec == 'trade' and fight.counterpart_dec == 'steal':

                        if str(alive_agent) == fight.initiator:
                            dbs.alive_agents_contrs_by_scen['2A'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                            dbs.all_agents_contrs_by_scen['2A'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                        elif str(alive_agent) == fight.counterpart:
                            dbs.alive_agents_contrs_by_scen['2A'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                            dbs.all_agents_contrs_by_scen['2A'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

                    elif fight.initiator_dec == 'fight_back' and fight.counterpart_dec == 'steal':

                        if str(alive_agent) == fight.initiator:
                            dbs.alive_agents_contrs_by_scen['2F'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                            dbs.all_agents_contrs_by_scen['2F'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                        elif str(alive_agent) == fight.counterpart:
                            dbs.alive_agents_contrs_by_scen['2F'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                            dbs.all_agents_contrs_by_scen['2F'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

                    elif fight.initiator_dec == 'steal' and fight.counterpart_dec == 'trade':

                        if str(alive_agent) == fight.initiator:
                            dbs.alive_agents_contrs_by_scen['3A'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                            dbs.all_agents_contrs_by_scen['3A'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                        elif str(alive_agent) == fight.counterpart:
                            dbs.alive_agents_contrs_by_scen['3A'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                            dbs.all_agents_contrs_by_scen['3A'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

                    elif fight.initiator_dec == 'steal' and fight.counterpart_dec == 'fight_back':

                        if str(alive_agent) == fight.initiator:
                            dbs.alive_agents_contrs_by_scen['3F'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                            dbs.all_agents_contrs_by_scen['3F'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                        elif str(alive_agent) == fight.counterpart:
                            dbs.alive_agents_contrs_by_scen['3F'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                            dbs.all_agents_contrs_by_scen['3F'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

                    elif fight.initiator_dec == 'steal' and fight.counterpart_dec == 'steal':

                        if str(alive_agent) == fight.initiator:
                            dbs.alive_agents_contrs_by_scen['4'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
                            dbs.all_agents_contrs_by_scen['4'][day] += fight.initiator_new_prop_steal - fight.initiator_start_prop_steal

                        elif str(alive_agent) == fight.counterpart:
                            dbs.alive_agents_contrs_by_scen['4'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal
                            dbs.all_agents_contrs_by_scen['4'][day] += fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

        # record last transfer from fight
        if len(todays_fights) > 0:

            max_fight_val = np.max(fight_vals)
            mean_fight_val = np.mean(fight_vals)

            if len(init_ps_data_2F) > 0:
                props_fight_data_2F[1].append(np.mean(init_ps_data_2F))
                props_fight_data_2F[2].append(np.mean(init_pfb_data_2F))
                props_fight_data_2F[3].append(np.mean(cp_ps_data_2F))
                props_fight_data_2F[4].append(np.mean(cp_pfb_data_2F))
                props_res_trans_data_2F[1].append(np.mean(init_start_res_2F))
                props_res_trans_data_2F[2].append(np.mean(cp_start_res_2F))
            else:
                props_fight_data_2F[1].append(None)
                props_fight_data_2F[2].append(None)
                props_fight_data_2F[3].append(None)
                props_fight_data_2F[4].append(None)
                props_res_trans_data_2F[1].append(None)
                props_res_trans_data_2F[2].append(None)

            if len(init_ps_data_3F) > 0:
                props_fight_data_3F[1].append(np.mean(init_ps_data_3F))
                props_fight_data_3F[2].append(np.mean(init_pfb_data_3F))
                props_fight_data_3F[3].append(np.mean(cp_ps_data_3F))
                props_fight_data_3F[4].append(np.mean(cp_pfb_data_3F))
                props_res_trans_data_3F[1].append(np.mean(init_start_res_3F))
                props_res_trans_data_3F[2].append(np.mean(cp_start_res_3F))
            else:
                props_fight_data_3F[1].append(None)
                props_fight_data_3F[2].append(None)
                props_fight_data_3F[3].append(None)
                props_fight_data_3F[4].append(None)
                props_res_trans_data_3F[1].append(None)
                props_res_trans_data_3F[2].append(None)

        else:
            max_fight_val = None
            mean_fight_val = None

        res_transfer_data[2].append(mean_fight_val)
        spec_data.append(max_fight_val)

    res_transfer_data[1] = generate_MA_array(res_transfer_data[1], N=5, might_contain_None=True)
    res_transfer_data[2] = generate_MA_array(res_transfer_data[2], N=5, might_contain_None=True)
    spec_data = generate_MA_array(spec_data, N=5, might_contain_None=True)

    spec_data_dict = {'data' : spec_data, 'name' : 'Fights Max', 'dash' : 'dash', 'line_col' : 'red', 'line_width' : 3}

    print_chart(res_transfer_data, labels_array=['Trans Mean', 'Fights Mean'], axis_labels=['Rounds', 'Resources Transferred'], colors=['blue', 'red'], data_folder=run_folder, filename='res_transfer_sizes', show_legend=True, special_data=spec_data_dict)

    print_chart(props_fight_data_2F, labels_array=['Init ps', 'Init pfb', 'CP ps', 'CP pfb'], axis_labels=['Rounds', 'Propensity'], data_folder=params.run_fights_charts_folder, filename='props_start_fights_2F', show_legend=True)
    print_chart(props_res_trans_data_2F, labels_array=['Init res', 'CP res'], axis_labels=['Rounds', 'Total Resources'], data_folder=params.run_fights_charts_folder, filename='fights_res_start_2F', show_legend=True)
    print_chart(props_fight_data_3F, labels_array=['Init ps', 'Init pfb', 'CP ps', 'CP pfb'], axis_labels=['Rounds', 'Propensity'], data_folder=params.run_fights_charts_folder, filename='props_start_fights_3F', show_legend=True)
    print_chart(props_res_trans_data_3F, labels_array=['Init res', 'CP res'], axis_labels=['Rounds', 'Total Resources'], data_folder=params.run_fights_charts_folder, filename='fights_res_start_3F', show_legend=True)

    # now let's do contributions by scenario for all the agents - alive or dead at the end of the sim
    all_agent_data = np.zeros(shape=(7, rounds), dtype=float)
    all_agent_data[0] = np.arange(rounds)

    labels_array = []

    counter = 1
    for entry in dbs.all_agents_contrs_by_scen:

        labels_array.append(entry)

        # # set zeros to None and use MA
        # for day in range(rounds):
        #
        #     if dbs.all_agents_contrs_by_scen[entry][day] == 0.0:
        #         dbs.all_agents_contrs_by_scen[entry][day] = None

        all_agent_data[counter] = generate_MA_array(dbs.all_agents_contrs_by_scen[entry], N=5, might_contain_None=True)
        counter += 1

    print_chart(database=all_agent_data, labels_array=labels_array, axis_labels=['Rounds', 'Contribution'], line_width=3, data_folder=params.run_contributions_to_props_folder, filename='interaction_contr_ps_all_ags', show_legend=True)

    # now let's do contributions by scenario for all the agents alive at the end
    all_alive_data = np.zeros(shape=(7, rounds), dtype=float)
    all_alive_data[0] = np.arange(rounds)

    labels_array = []

    counter = 1
    for entry in dbs.alive_agents_contrs_by_scen:
        labels_array.append(entry)

        # # set zeros to None and use MA
        # for day in range(rounds):
        #
        #     if dbs.alive_agents_contrs_by_scen[entry][day] == 0.0:
        #         dbs.alive_agents_contrs_by_scen[entry][day] = None

        all_alive_data[counter] = generate_MA_array(dbs.alive_agents_contrs_by_scen[entry], N=5, might_contain_None=True)
        counter += 1

    # print('\n all_alive_data =', all_alive_data)

    print_chart(database=all_alive_data, labels_array=labels_array, axis_labels=['Rounds', 'Contribution'], line_width=3, data_folder=params.run_contributions_to_props_folder, filename='interaction_contr_ps_alive_only', show_legend=True)

    # now let's do the al capone contributions by scenario
    al_capone_data = np.zeros(shape=(13, rounds), dtype=float)
    al_capone_data[0] = np.arange(rounds)

    labels_array = []

    counter = 1
    for entry in dbs.al_capones_contrs_by_scen:
        labels_array.append(entry)

        # # set zeros to None and use MA
        # for day in range(rounds):
        #
        #     if dbs.al_capones_contrs_by_scen[entry][day] == 0.0:
        #         dbs.al_capones_contrs_by_scen[entry][day] = None

        al_capone_data[counter] = generate_MA_array(dbs.al_capones_contrs_by_scen[entry], N=5, might_contain_None=True)
        counter += 1

    print_chart(database=al_capone_data, labels_array=labels_array, axis_labels=['Rounds', 'Contribution'], line_width=3, data_folder=params.run_contributions_to_props_folder, filename='interaction_contr_ps_dead_ags', show_legend=True)

    # now we want to consider every interaction and its impact on each scenario: but both positive and negative contribution to the scenario
    intn_full_decomp_data = np.zeros(shape=(22, rounds), dtype=float)
    intn_full_decomp_data[0] = np.arange(rounds)

    labels_array = ['trans', '2F no res +', '2F no res -', '2F res +', '2F res -', '2A no res +', '2A no res -', '2A res +', '2A res -', '3F no res +', '3F no res -', '3F res +', '3F res -', '3A no res +', '3A no res -', '3A res +', '3A res -', '4 no res +', '4 no res -', '4 res +', '4 res -']

    # note: [1] is transactions (only positive); [2] - [5] are 2F; [6] - [9] are 2A; [10] - [13] are 3F; [14] - [17] are 3A; and [18] - [21] are 4
    # in each bundle of 4: first 2 are no res transferred, second 2 are when resources were transferred; and in each pair, first is pos contribution, second negative.

    for trans in dbs.trans_db:

        tot_impact_ps = trans.initiator_new_prop_steal - trans.initiator_start_prop_steal + trans.counterpart_new_prop_steal - trans.counterpart_start_prop_steal
        intn_full_decomp_data[1][trans.day] += tot_impact_ps

    for fight in dbs.fights_db:

        # the bucket_num tells us which line the change in ps goes into. defaults to 2 and then we add to it depending on scenario, whether res's transferred, and whether + or -ve
        bucket_num = 2

        # note if we're in 2F we don't add to bucket_num; but...
        if fight.initiator_dec == 'trade' and fight.counterpart_dec == 'steal':     # then 2A
            bucket_num += 4
        elif fight.initiator_dec == 'steal' and fight.counterpart_dec == 'fight_back':     # then 3F
            bucket_num += 8
        elif fight.initiator_dec == 'steal' and fight.counterpart_dec == 'trade':     # then 3A
            bucket_num += 12
        elif fight.initiator_dec == 'steal' and fight.counterpart_dec == 'steal':  # then 4
            bucket_num += 16

        # note if there's no transfer of resources we don't add to bucket_num, but...
        if np.sum(fight.initiator_end_basket) != np.sum(fight.initiator_start_basket) or np.sum(fight.counterpart_end_basket) != np.sum(fight.counterpart_start_basket):
            bucket_num += 2

        # now we distinguish between the contributions of the two fighters - these can be positive or negative
        ch_initiator_ps = fight.initiator_new_prop_steal - fight.initiator_start_prop_steal
        ch_counterpart_ps = fight.counterpart_new_prop_steal - fight.counterpart_start_prop_steal

        if ch_initiator_ps > 0.0:

            intn_full_decomp_data[bucket_num][fight.day] += ch_initiator_ps

        elif ch_initiator_ps < 0.0:

            intn_full_decomp_data[bucket_num + 1][fight.day] += ch_initiator_ps

        if ch_counterpart_ps > 0.0:

            intn_full_decomp_data[bucket_num][fight.day] += ch_counterpart_ps

        elif ch_counterpart_ps < 0.0:

            intn_full_decomp_data[bucket_num + 1][fight.day] += ch_counterpart_ps

    print_chart(database=intn_full_decomp_data, labels_array=labels_array, axis_labels=['Rounds', 'Contribution'],
                line_width=3, data_folder=params.run_contributions_to_props_folder, filename='interaction_contr_ps_res_pos_neg', show_legend=True)

    # create a chart to show agents' total resources
    tot_resources_data = [np.arange(rounds)]
    agent_locations = []

    for agent in agent_population.pop:

        agent_tot_res = []

        for day in np.arange(rounds):

            tot_res = np.sum(agent.agent_res_array_hist[day])

            if tot_res == 0:
                tot_res = None

            agent_tot_res.append(tot_res)

        tot_resources_data.append(agent_tot_res)
        agent_locations.append(str(agent.home))

    for dead_agent in agent_population.dead_agent_array:

        agent_tot_res = []

        for day in np.arange(rounds):

            tot_res = np.sum(dead_agent.agent_res_array_hist[day])

            if tot_res == 0:
                tot_res = None

            agent_tot_res.append(tot_res)

        tot_resources_data.append(agent_tot_res)
        agent_locations.append(str(dead_agent.home))

    print_chart(tot_resources_data, labels_array=agent_locations, axis_labels=['Rounds', 'Total Resources'],
                line_width=1, data_folder=run_folder, filename='total_resources', font_size=40)

    # now for corruption incidence charts and medians
    if corruption_prop_charge:

        corruption_charts_data = [np.arange(rounds), dbs.corruption_array, dbs.non_corruption_array]

        print_chart(database=corruption_charts_data, labels_array=['Corruption', 'No Corruption'], axis_labels=['Rounds', 'Number of Interactions'], data_folder=run_folder, filename='corruption_ts', show_legend=True)

        print_chart(database=[np.arange(rounds), dbs.medians_ts], axis_labels=['Rounds', 'Median Propensity to Steal (Bounded)'], line_width=3, colors=['black'], data_folder=params.run_propensities_charts_folder, filename='ps_medians')

    # if we are running a test to evaluate the time it takes to deliberate over whether to trade or steal:
    if delib == 'both':

        print('\n dbs.total_trans_delib:', dbs.total_trans_delib)
        print('\n dbs.total_trans_habit:', dbs.total_trans_habit)

        time_delib_per_ag = []
        time_habit_per_ag = []

        for day in range(rounds):

            tot_pop = dbs.trading_db[0][day]

            if dbs.total_trans_delib[day] > 0:              # and dbs.total_time_delib[day] / float(dbs.total_trans_delib[day]) < 10
                mean_delib_time = dbs.total_time_delib[day] / float(dbs.total_trans_delib[day])             # / float(tot_pop)
            else:
                mean_delib_time = None

            time_delib_per_ag.append(mean_delib_time)

            if dbs.total_trans_habit[day] > 0:              # and dbs.total_time_habit[day] / float(dbs.total_trans_habit[day]) < 10
                mean_habit_time = dbs.total_time_habit[day] / float(dbs.total_trans_habit[day])             # / float(tot_pop)
            else:
                mean_habit_time = None

            time_habit_per_ag.append(mean_habit_time)

        time_delib_per_ag = generate_MA_array(time_delib_per_ag, N=10, might_contain_None=True, last_datum=False)
        time_habit_per_ag = generate_MA_array(time_habit_per_ag, N=10, might_contain_None=True, last_datum=False)

        # dbs.total_time_delib = np.zeros(shape=rounds, dtype=int)
        # dbs.total_trans_delib = np.zeros(shape=rounds, dtype=int)
        #
        # dbs.total_time_habit = np.zeros(shape=rounds, dtype=int)
        # dbs.total_trans_habit = np.zeros(shape=rounds, dtype=int)

        # tot_pop = dbs.trading_db[0][day]

        all_delib_habit_data = [np.arange(rounds), time_delib_per_ag, time_habit_per_ag]

        # print('\n time_delib_per_trans:', time_delib_per_trans)
        # print('\n time_habit_per_trans:', time_habit_per_trans)

        print_chart(all_delib_habit_data, labels_array=['deliberation', 'habit'], title='Deliberation versus Habit Time', axis_labels=['Rounds', 'Time (microseconds)'], line_width=3, colors=['red', 'blue'],
                    data_folder=run_folder, filename='delib_habit_times', data_type=None, dpi=None, show_legend=True, keep_name=0, special_data=None)

        # pause()

    # here we create the charts for the contribution to the agents' prop steal by habituation and reinforcement learning
    if params.habit_val_props and len(agent_population.pop) > 0:

        ag_num = 0

        all_ags = []

        # print('\n agent_population.pop', agent_population.pop)
        # print('\n type(agent_population.pop)', type(agent_population.pop))
        # print('\n agent_population.dead_agent_array', agent_population.dead_agent_array)
        # print('\n type(agent_population.dead_agent_array)', type(agent_population.dead_agent_array))

        # for ag in agent_population.pop:
        #     all_ags.append(ag)
        # for ag in agent_population.dead_agent_array:
        #     all_ags.append(ag)

        num_alive_ags = len(agent_population.pop)
        num_dead_agents = len(agent_population.dead_agent_array)

        for ag in list(agent_population.pop) + agent_population.dead_agent_array:

            # ag = agent_population.pop[0]

            # print('\n ag.ps_contr_RL_pos =\n', ag.ps_contr_RL_pos)
            # print('\n ag.ps_contr_hab_pos =\n', ag.ps_contr_hab_pos)
            # print('\n ag.ps_contr_RL_neg =\n', ag.ps_contr_RL_neg)
            # print('\n ag.ps_contr_hab_neg =\n', ag.ps_contr_hab_neg)

            start_date = ag.birth_date

            # crop the databases, if necessary, so only show rounds when alive
            if ag.death_date < rounds - 1:
                end_date = ag.death_date
            else:
                end_date = rounds - 1

            rounds_alive = end_date - start_date

            ag.ps_contr_RL_pos = ag.ps_contr_RL_pos[start_date:end_date]
            ag.ps_contr_hab_pos = ag.ps_contr_hab_pos[start_date:end_date]
            ag.ps_contr_RL_neg = ag.ps_contr_RL_neg[start_date:end_date]
            ag.ps_contr_hab_neg = ag.ps_contr_hab_neg[start_date:end_date]

            cropped_prop_steal_history = ag.prop_steal_history[start_date:end_date]

            # start to build the data file for the charts
            chart_data = [np.arange(start_date, end_date, dtype=int)]

            # for area-based time series we have to create seperate `stacks' for the data (those which should stack on top of each other)
            stacks_container = []

            print('\n ag.ps_contr_RL_pos =', ag.ps_contr_RL_pos)
            print('\n len(ag.ps_contr_RL_pos) =', len(ag.ps_contr_RL_pos))
            print('\n start_date =', start_date)
            print(' end_date =', end_date)

            # turn prop changes into cumulative changes
            for db in [ag.ps_contr_RL_pos, ag.ps_contr_hab_pos]:
                for d in range(1, rounds_alive):
                    db[d] += db[d - 1]

            stacks_container.append([ag.ps_contr_RL_pos, ag.ps_contr_hab_pos])

            for db in [ag.ps_contr_RL_neg, ag.ps_contr_hab_neg]:
                for d in range(1, rounds_alive):
                    db[d] = (db[d] * -1) + db[d - 1]

            stacks_container.append([ag.ps_contr_RL_neg, ag.ps_contr_hab_neg])

            chart_data.append(stacks_container)
            # chart_data.append(ag.ps_contr_hab_pos)
            # chart_data.append(ag.ps_contr_RL_neg)
            # chart_data.append(ag.ps_contr_hab_neg)

            # print('\n ag.ps_contr_RL_pos =\n', ag.ps_contr_RL_pos)
            # print('\n ag.ps_contr_hab_pos =\n', ag.ps_contr_hab_pos)
            # print('\n ag.ps_contr_RL_neg =\n', ag.ps_contr_RL_neg)
            # print('\n ag.ps_contr_hab_neg =\n', ag.ps_contr_hab_neg)

            file_name = 'contr_ps_RL_hab_ag_%d' % ag_num
            if ag_num < num_alive_ags:
                file_name += '_alive'
            else:
                file_name += '_dead'
            file_name += '_%s' % ag.home

            print_contributions_to_tot_2_axes(chart_data, title='', labels_array=['RL pos', 'Hab pos', 'RL neg', 'Hab neg'],
                                              axis_labels=['Rounds', 'Propensity to Steal'], colors=['blue', 'darkred', 'skyblue', 'red'], font_size=40,
                                              data_folder=params.run_habituation_folder, filename=file_name, show_legend=False,
                                              keep_name=0, special_data=cropped_prop_steal_history)

            ag_num += 1

    # pause()

    # print('\n\n pre del sizes')
    # print(' sys.getsizeof(params) =', sys.getsizeof(params))
    # print(' sys.getsizeof(agent_population) =', sys.getsizeof(agent_population))
    #
    # for agent in agent_population.pop:
    #     print(agent, ' sys.getsizeof(agent) =', sys.getsizeof(agent))
    #
    # print(' sys.getsizeof(agent_population.pop) =', sys.getsizeof(agent_population.pop))
    # print(' sys.getsizeof(town_grid) =', sys.getsizeof(town_grid))
    # print(' sys.getsizeof(dbs) =', sys.getsizeof(dbs))
    #
    # tot_size = 0
    # for fight in dbs.fights_db:
    #     tot_size += sys.getsizeof(fight)
    #
    # print(' size of all fights', tot_size)
    # print('\n len(dbs.fights_db) ', len(dbs.fights_db))
    # print('\n len(dbs.trans_db) ', len(dbs.trans_db))
    #
    # print(' sys.getsizeof(fountain_population) =', sys.getsizeof(fountain_population))
    # # print(' sys.getsizeof(params) =', sys.getsizeof(params))

    # print('\n dbs.fights_db[0]', dbs.fights_db[0])
    #
    # print('\n dbs.trans_db[0]', dbs.trans_db[0])

    fileHandle = open(dbs.agent_summary_notes_file, 'a')
    fileHandle.close()

    if allow_Keynes_Inst:

        fileHandle = open(dbs.KI_notes_file, 'a')
        fileHandle.close()

    fileHandle = open(dbs.sign_locs_notes_file, 'a')
    fileHandle.close()

    # agent_population = None
    # params = None
    # town_grid = None
    # dbs = None
    # fountain_population = None

    # print('\n deleting fights_db')
    #
    # for fight_num in range(len(dbs.fights_db)):
    #     del dbs.fights_db[0]
    #
    # print('\n deleting trans_db')
    #
    # for trans_num in range(len(dbs.trans_db)):
    #     del dbs.trans_db[0]

    # print('\n agent_population.pop =\n', agent_population.pop)
    # print('\n type(agent_population.pop)', type(agent_population.pop))
    # print('\n len(agent_population.pop) ', len(agent_population.pop))

    # print('asizeof.asizeof(agent_population)', asizeof.asizeof(agent_population)/float(1024**2), 'megabytes')
    #
    # print('\n agent data:')
    #
    # for agent in agent_population.pop:
    #     print(' agent', agent, ' data size:', asizeof.asizeof(agent)/float(1024**2), 'megabytes')



    # print('\n agent_population.pop', agent_population.pop)

    # for agent in agent_population.pop:
    #     print('\n agent =', agent)
    #     del agent_population.pop[0]
    #     print(' len(agent_population.pop)', len(agent_population.pop))
        # print(' size:', asizeof.asizeof(agent)/float(1024**2), 'megabytes')

    # agent_population.pop = list(agent_population.pop)
    #
    # for agent_num in range(len(agent_population.pop)):
    #
    #     # print('\n agent to be deleted =', agent_population.pop[0])
    #     del agent_population.pop[0]
    #     # print(' len(agent_population.pop) ', len(agent_population.pop))
    #
    # agent_population.dead_agent_array = list(agent_population.dead_agent_array)
    #
    # for agent_num in range(len(agent_population.dead_agent_array)):
    #     del agent_population.dead_agent_array[0]

    # now playing with memory usage here

    # print('asizeof.asizeof(params)', asizeof.asizeof(params)/float(1024**2), 'megabytes')
    # print('asizeof.asizeof(agent_population)', asizeof.asizeof(agent_population)/float(1024**2), 'megabytes')
    # print('asizeof.asizeof(town_grid)', asizeof.asizeof(town_grid)/float(1024**2), 'megabytes')
    # print('asizeof.asizeof(dbs)', asizeof.asizeof(dbs)/float(1024**2), 'megabytes')
    # print('asizeof.asizeof(fountain_population)', asizeof.asizeof(fountain_population)/float(1024**2), 'megabytes')
    # print('asizeof.asizeof(sim_return_data)', asizeof.asizeof(sim_return_data)/float(1024**2), 'megabytes')

    # print('\n agent data:')
    #
    # for agent in agent_population.pop:
    #     print('size:', asizeof.asizeof(agent)/float(1024**2), 'megabytes')

    # now clear data
    # del params
    # del agent_population
    # del town_grid
    # del dbs
    # del fountain_population

    # print('\n agent =', agent)
    # print(' agent size:', asizeof.asizeof(agent) / float(1024 ** 2), 'megabytes')

    # print('asizeof.asizeof(params)', asizeof.asizeof(params)/float(1024**2), 'megabytes')
    # print('asizeof.asizeof(agent_population)', asizeof.asizeof(agent_population)/float(1024**2), 'megabytes')
    # print('asizeof.asizeof(town_grid)', asizeof.asizeof(town_grid)/float(1024**2), 'megabytes')
    # print('asizeof.asizeof(dbs)', asizeof.asizeof(dbs)/float(1024**2), 'megabytes')
    # print('asizeof.asizeof(fountain_population)', asizeof.asizeof(fountain_population)/float(1024**2), 'megabytes')
    # print('asizeof.asizeof(sim_return_data)', asizeof.asizeof(sim_return_data)/float(1024**2), 'megabytes')

    # print('\n\n post del sizes')
    # print(' sys.getsizeof(params) =', sys.getsizeof(params))
    # print(' sys.getsizeof(agent_population) =', sys.getsizeof(agent_population))
    # print(' sys.getsizeof(town_grid) =', sys.getsizeof(town_grid))
    # print(' sys.getsizeof(dbs) =', sys.getsizeof(dbs))
    # print(' sys.getsizeof(fountain_population) =', sys.getsizeof(fountain_population))

    # print('\n sim_return_data:\n')
    #
    # for line in sim_return_data:
    #     print(line)

    print('\n time stamp before copy.deepcopy(sim_return_data): ', dt.datetime.now())

    sim_return_data = copy.deepcopy(sim_return_data)

    print('\n amount of data taken by sim data =', total_size(sim_return_data), 'mb')

    print('\n time stamp at end of run_sim(): ', dt.datetime.now())

    # print('\n')
    #
    # check_fights_np = np.array(dbs.check_fights)
    # check_fights_np.sort()
    #
    # check_trans_np = np.array(dbs.check_trans)
    # check_trans_np.sort()
    #
    # fight_num = 0
    #
    # for fight in dbs.fights_db:
    #     if fight_num not in check_fights_np:
    #         print('fight_num =', fight_num, 'NOT IN check_fights_np')
    #     else:
    #         print('fight_num =', fight_num, 'ok')
    #     fight_num += 1
    #
    # print('\n')
    #
    # trans_num = 0
    # for trans in dbs.trans_db:
    #     if trans_num not in check_trans_np:
    #         print('trans_num =', trans_num, 'NOT IN check_trans_np', 'trans.good_a =', trans.good_a)
    #     else:
    #         print('trans_num =', trans_num, 'ok')
    #     trans_num += 1

    return sim_return_data


def create_new_agent(params, dbs, birth_date, for_strat_parts, agent_res_init, agent_res_init_std,
                     print_dets, vision_len, dimen, print_fine_dets, rounds, trade_moves,
                     trade_when_trgt, agent_mem_length, cp_trans_weight, wait_at_tgt_moves, trade_prices, cognition_factor, trade_movemnt, starting_res,
                     start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                     prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, starting_props, instantiation, tribe, fight_skill,
                     agents_die_old_age, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, popn_ch):

    """A method for creating a new agent."""

    # create a death_date to record the date when the agent died - default is 100,000, which changes if agent dies
    death_date = 100000

    # create an array to record foraging strategy array for each agents:
    for_strat_array = np.zeros(shape=(1, for_strat_parts), dtype=int)

    # now populate the for_strat_array with the various strategies open to
    # the agents.  Note 0 means agent is at fountain 0 (and so on).
    for j in np.arange(for_strat_parts):
        for_strat_array[0][j] = np.random.randint(0, num_res_founts)

    # create array to record agents' personal resource levels:
    if trade_prices == 'fixed':

        agent_res_array = []

        for res in range(num_res_founts):
            res_value = int(np.max([1, random.normalvariate(agent_res_init, agent_res_init_std)]))

            agent_res_array.append(res_value)

        agent_res_array = np.array([agent_res_array], dtype=int)

    elif trade_prices == 'variable':

        if instantiation == 0 and popn_ch == 'vary':

            agent_res_array = starting_res

        #                if starting_res is not None:
        #
        #                    print('new agent (not at instantiation) agent_res_array =', agent_res_array)

        else:

            agent_res_array = []

            for res in range(num_res_founts):
                res_value = np.max([1, random.normalvariate(agent_res_init, agent_res_init_std)])

                agent_res_array.append(res_value)

            agent_res_array = np.array([agent_res_array], dtype=float)

    # in case prob_res_detection is outside of the range of the min and max detection probs:
    if prob_res_detection < params.min_prob_det:
        start_skill_prob = np.mean([params.min_prob_det, params.max_prob_det])

    elif prob_res_detection > params.max_prob_det:
        start_skill_prob = np.mean([params.min_prob_det, params.max_prob_det])

    else:
        start_skill_prob = prob_res_detection

    # create detection skills array:
    detect_skills_array = np.array([[start_skill_prob] * num_res_founts], dtype=float)

    # Create an array to record the history of detection skills
    detect_skills_array_hist = np.zeros(shape=(rounds, num_res_founts))

    # create basket array to record the resources collected by each agent:
    if trade_prices == 'fixed':
        basket_array = np.zeros(shape=(1, num_res_founts), dtype=int)

    if trade_prices == 'variable':
        basket_array = np.zeros(shape=(1, num_res_founts), dtype=float)

    # create a location array for each agent: this is used to track where the agent is when trying to trade
    location = [0, 0]

    # create a value for the agent's vision (the number of squares away it can see in the town_grid)
    agent_vision = vision_len

    # now create a matrix which will allow the agent to record the locations of where particular sell / buy combinations
    # were transacted
    trans_loc_mat = []
    twod_array = []
    row = []
    for k in np.arange(num_res_founts):
        row.append([])
    for l in np.arange(num_res_founts):
        twod_array.append(copy.deepcopy(row))
    for j in np.arange(rounds):
        trans_loc_mat.append(copy.deepcopy(twod_array))

    # create two arrays to record which resources each agent has on sale
    sell_array = []
    buy_array = []

    # create an array to record the agent's grid target, which it aims for in the absence of other agents
    if trade_when_trgt == 0:

        grid_trgt = np.array([1000, 1000], dtype=int)

    elif trade_when_trgt == 1:

        grid_trgt = np.array([None, None])

    # create an array to record the resources an agent wants to buy and sell
    if trade_prices == 'fixed':
        trading_basket = np.zeros(shape=(1, num_res_founts), dtype=int)

    if trade_prices == 'variable':
        trading_basket = np.zeros(shape=(1, num_res_founts), dtype=float)

    # allocate a place on the town grid to the agent as its home
    home = np.array([np.random.randint(0, dimen), np.random.randint(0, dimen)], dtype=int)

    # create an array to record the agent's neighbours (updated at the beginning of every round)
    neighs = []

    # create an array to record the number of goods an agent takes to market each round
    goods_2_mkt = np.zeros(shape=(1, rounds))

    # create a variable to record the agent's expectation of trading (given neighbours' trading)
    trade_proby = 0.0

    # create an array to record the agent's locations during the trading rounds
    trade_loc_rec = []

    # create another array to record the agent's target locations during the trade_moves
    trgt_loc_rec = []

    # create a variable to track whether the agent can trade or not e.g. when it has reached the target
    can_trade = 1

    # create an array to record each agent's transactions
    ag_trans_array = []

    # create array to record which sell_good the agent chose to aim for in selecting a target grid location
    sell_good = 0

    # create array to record which buy_good the agent chose to aim for in selecting a target grid location
    buy_good = 0

    # create an array to record the agent's memory of locations
    loc_mems_array = []
    loc_mems_array_cp = []
    #        twod_array = []
    #        row = []
    #        for k in np.arange(num_res_founts):
    #            row.append([])
    #        for l in np.arange(num_res_founts):
    #            twod_array.append(copy.deepcopy(row))
    for j in np.arange(rounds):
        loc_mems_array.append([])
        loc_mems_array_cp.append([])

    #        loc_mems_array_cp = copy.deepcopy(loc_mems_array)

    # Create a variable which records the threshold probability above which the agent will specialise in each round
    # [0] is round [1] is max detection prob, [2] is r_min, [3] is threshold prob, and [4] is actual exp prob of transacting
    thresh_probs_array = np.zeros(shape=(8, rounds))
    thresh_probs_array[0] = np.arange(rounds)

    # Create varable which acknowledges if an agent trading on the way to its target has reached the target (= 1 then)
    reached_trgt = 0

    # Create an array to record the marginal rates of substitution for each agent
    MRS_array = np.zeros(shape=(num_res_founts, num_res_founts))

    # create array to record the total resource held by an agents (agent_res_array + basket_array)
    aggr_res_array = np.zeros(shape=(1, num_res_founts), dtype=int)

    dummy_basket_array = np.zeros(shape=(num_res_founts, num_res_founts, num_res_founts))

    # Create an array to record the agent's foraging strategy history
    for_strat_hist = np.zeros(shape=(rounds, for_strat_parts), dtype=int)

    # Create arrays to record basket_arrays and basket_array_starts
    basket_array_hist = np.zeros(shape=(rounds, num_res_founts))

    basket_array_start_hist = np.zeros(shape=(rounds, num_res_founts), dtype=int)

    # Create an array to record the agent's expected supply / demand of bilateral trades at the equilibrium prices.
    # [0] is the equilibrium price, [1] is the expected supply or demand of res_1 (supply of res_1 would be a positive
    # number and demand for res_1 would be negative), [2] is the counterpart expected supply or demand of res_2 (supply
    # of res_2 would be a negative number and supply of res_2 would be negative) i.e. noth positive means supply of res_1
    # and demand for res_2.
    equil_price_SD_exps = np.zeros(shape=(rounds, num_res_founts, num_res_founts, 3))

    # Create an array to record the number of actual transaction in each round - every time the agent transacts,
    # add 1 to this total
    num_act_transs = np.zeros(shape=(rounds))

    # Create a database to record the agent's MRS history
    MRS_history = np.zeros(shape=(rounds, num_res_founts, num_res_founts))

    # create array to record agents' personal resource levels:
    if trade_prices == 'fixed':
        agent_res_array_hist = np.zeros(shape=(rounds, num_res_founts), dtype=int)

    elif trade_prices == 'variable':
        agent_res_array_hist = np.zeros(shape=(rounds, num_res_founts), dtype=float)

    optimal_transs_systemic = np.zeros(shape=(rounds, num_res_founts), dtype=float)

    optimal_transs_local = np.zeros(shape=(rounds, num_res_founts), dtype=float)

    wkg_prices_memory = np.ones(shape=(num_res_founts, num_res_founts), dtype=float)

    personal_turnover_ratio = np.zeros(shape=(rounds))

    total_actual_agent_sales = np.zeros(shape=(rounds))

    total_optimal_agent_sales = np.zeros(shape=(rounds))

    over_sell_counter = 0
    didnt_over_sell_counter = 0

    foraging_strat_data = np.zeros(shape=(rounds, (3 + num_res_founts * 2)))

    resources_to_children = np.zeros(shape=num_res_founts)

    hist_trade_loc_rec = [[] for i in range(rounds)]

    # create propensities to steal and fight back in interactions
    if instantiation and start_props == 'random':

        prop_steal = random.uniform(0.0, 1.0)
        prop_fight_back = random.uniform(0.0, 1.0)

    else:

        if starting_props == None:

            prop_steal = random.normalvariate(start_prop_steal_mean, start_prop_steal_std)

            # note we constrain these values but not at the limits of 0 and 1 - if we use either of these limits, the props will be pefectly stuck there
            # note that if we're applying gross propensities which are capped this is still ok - child can start with prop's between ceiling and floor.
            if params.limit_props:

                if prop_steal > prop_steal_ceil:
                    prop_steal = prop_steal_ceil

                if prop_steal < prop_steal_floor:
                    prop_steal = prop_steal_floor

            prop_fight_back = random.normalvariate(start_prop_fight_back_mean, start_prop_fight_back_std)

            # note we constrain these values but not at the limits of 0 and 1 - if we use either of these limits, the props will be pefectly stuck there
            # note that if we're applying gross propensities which are capped this is still ok - child can start with prop's between ceiling and floor.
            if params.limit_props:

                if prop_fight_back > prop_fight_back_ceil:
                    prop_fight_back = prop_fight_back_ceil

                if prop_fight_back < prop_fight_back_floor:
                    prop_fight_back = prop_fight_back_floor

        else:

            prop_steal = starting_props[0]
            prop_fight_back = starting_props[1]

    if fix_prop_fb is not None:
        prop_fight_back = fix_prop_fb

    if fixed_prop_steal is not None:
        prop_steal = fixed_prop_steal
        # prop_fight_back = 1.0

    if fix_ps_fb_0 == 1:
        prop_steal = 0.0
        prop_fight_back = 0.0

    # create a dictionary to record reputations of other agents
    reputations_dict = dict()

    # create array to record the fights the agent was involved in during that last round
    fights_array = []

    loc_fights_array = [[] for i in range(rounds)]

    loc_fights_array_cp = [[] for i in range(rounds)]

    prop_steal_history = np.zeros(shape=rounds, dtype=float)
    prop_fight_back_history = np.zeros(shape=rounds, dtype=float)
    fight_skill_history = np.zeros(shape=rounds, dtype=float)

    agreed_meeting_point = None
    meeting_point_cps = []

    # create agent instances:
    new_agent = Agent(params, birth_date, death_date, for_strat_array, agent_res_array, detect_skills_array, basket_array, location, agent_vision,
                      grid_trgt, trading_basket, home, neighs, goods_2_mkt, trade_proby, trans_loc_mat, trade_loc_rec, trgt_loc_rec, sell_array, buy_array,
                      can_trade, ag_trans_array, sell_good, buy_good, loc_mems_array, loc_mems_array_cp, thresh_probs_array, agent_mem_length,
                      cp_trans_weight, wait_at_tgt_moves, reached_trgt, MRS_array, aggr_res_array, dummy_basket_array, for_strat_hist,
                      equil_price_SD_exps, num_act_transs, MRS_history, agent_res_array_hist, detect_skills_array_hist, optimal_transs_systemic,
                      optimal_transs_local, wkg_prices_memory, personal_turnover_ratio, basket_array_hist, basket_array_start_hist, total_actual_agent_sales,
                      total_optimal_agent_sales, cognition_factor, over_sell_counter, didnt_over_sell_counter, trade_movemnt, foraging_strat_data,
                      resources_to_children, hist_trade_loc_rec, prop_steal, prop_fight_back, reputations_dict, fights_array, loc_fights_array,
                      loc_fights_array_cp, prop_steal_history, prop_fight_back_history, agreed_meeting_point, meeting_point_cps, tribe, fight_skill,
                      agents_die_old_age, fight_skill_history)

    dbs.str_ag_to_ag_dict[str(new_agent)] = new_agent

    return new_agent


def create_agents(params, dbs, print_dets, for_strat_parts, agent_res_init, agent_res_init_std,
                  vision_len, dimen, print_fine_dets, rounds, trade_moves, trade_when_trgt, agent_homes, agent_mem_length, homes_spacing,
                  cp_trans_weight, wait_at_tgt_moves, trade_prices, min_trans_Q, cognition_factor, trade_movemnt,
                  start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                  prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, two_tribes, black_shoop_exp, fight_skill,
                  agents_die_old_age, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, stranger_int, corruption_prop_charge, popn_ch, must_update_neighs):
    """This function generates and returns an agent population instance with 'num_agents' agents in it."""

    print_fine_dets = 1

    if print_dets == 1:
        print('\n** create_agents function starts ** \n')

    # set the birth_date of all these new agents (note this function is only used awhen the agent population is instantiated)
    birth_date = 0

    # establish an array which will contain all the new agents, which will be
    # placed in to a population class (this class is then returned):
    group = []

    starting_res = None
    starting_props = None

    # print('\n create agents:')
    threads = []
    # add agents to the group:
    for i in np.arange(num_agents):  # each agent

        instantiation = 1

        agent_tribe = 'none'

        if two_tribes == 1 and i < num_agents / 2.0:

            agent_tribe = 'sharks'

        elif two_tribes == 1 and i >= num_agents / 2.0:

            agent_tribe = 'jets'

        # def create_new_agent(params, dbs, birth_date, for_strat_parts, agent_res_init, agent_res_init_std,
        #                      print_dets, vision_len, dimen, print_fine_dets, rounds, trade_moves,
        #                      trade_when_trgt, agent_mem_length, cp_trans_weight, wait_at_tgt_moves, trade_prices, cognition_factor, trade_movemnt, starting_res,
        #                      start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
        #                      prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, starting_props, instantiation, tribe, fight_skill,
        #                      agents_die_old_age, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, popn_ch):

        # create agent instances (hone locations are random here):
        agent = create_new_agent(params, dbs, birth_date, for_strat_parts, agent_res_init, agent_res_init_std,
                                 print_dets, vision_len, dimen, print_fine_dets, rounds,
                                 trade_moves, trade_when_trgt, agent_mem_length, cp_trans_weight, wait_at_tgt_moves,
                                 trade_prices, cognition_factor, trade_movemnt, starting_res,
                                 start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                                 prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, starting_props, instantiation,
                                 agent_tribe, fight_skill, agents_die_old_age, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, popn_ch)

        group.append(agent)

    homes_array = np.zeros(shape=(dimen, dimen))

    if two_tribes == 0 and agent_homes == 'even':  # then we have to distribute the agents over the town_grid evenly.  The function
        # 'create_agents' puts them in random locations by default so here we change that.

        if dimen % math.sqrt(num_agents) == 0:  # then this is a neat case and we can space the agents evenly around the grid

            # find the gap between agents:
            neigh_gap = float(dimen) / int(math.sqrt(num_agents))
            half_gap = int(neigh_gap / 2.0)

            for i in np.arange(int(math.sqrt(num_agents))):
                for j in np.arange(int(math.sqrt(num_agents))):

                    agent = group[i * int(math.sqrt(num_agents)) + j]

                    if homes_spacing == 'square':

                        agent.home = np.array([half_gap + (i * neigh_gap), half_gap + (j * neigh_gap)], dtype=int)

                    elif homes_spacing == 'hex':

                        if i % 2 == 0:

                            agent.home = np.array([half_gap + (i * neigh_gap), half_gap + (j * neigh_gap)], dtype=int)

                        else:

                            agent.home = np.array([half_gap + (i * neigh_gap), (j * neigh_gap)], dtype=int)

                    homes_array[agent.home[0]][agent.home[1]] += 1

    if two_tribes == 1:

        sub_dimen = dimen / 2.0

        # find the gap between agents:
        neigh_gap = float(sub_dimen) / int(math.sqrt(num_agents / 2.0))
        half_gap = int(neigh_gap / 2.0)

        for h in range(2):
            for i in np.arange(int(math.sqrt(num_agents / 2.0))):
                for j in np.arange(int(math.sqrt(num_agents / 2.0))):
                    agent = group[int(h * num_agents / 2.0) + (i * int(math.sqrt(num_agents / 2.0))) + j]

                    agent.home = np.array([(h * sub_dimen) + half_gap + (i * neigh_gap), (h * sub_dimen) + half_gap + (j * neigh_gap)], dtype=int)

    # the agent group is placed in a population instance:
    agent_population = Agent_Population(group, trade_prices, min_trans_Q, homes_array, for_strat_parts, black_shoop_exp, stranger_int, corruption_prop_charge, must_update_neighs)

    if params.same_agents:

        fixed_for_strats = [[1, 0, 1, 1, 1], [1, 1, 1, 1, 1], [0, 0, 1, 0, 1], [0, 1, 0, 1, 0], [0, 1, 0, 0, 0], [1, 1, 0, 1, 1], [1, 0, 1, 1, 0], [0, 0, 0, 1, 0], [1, 0, 0, 0, 1], [1, 1, 1, 1, 1], [0, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 0, 1, 1, 0],
                      [0, 0, 0, 0, 1], [0, 1, 1, 0, 1], [1, 1, 1, 0, 1], [0, 0, 0, 1, 0], [1, 0, 0, 0, 0], [0, 1, 0, 1, 0], [0, 1, 1, 1, 0], [1, 0, 0, 0, 1], [1, 0, 0, 1, 1], [1, 0, 0, 0, 0], [0, 0, 1, 0, 1], [0, 0, 1, 1, 0]]

        counter = 0
        for agent in agent_population.pop:

            # we fix these three parameters at their mean values
            agent.agent_res_array = np.array([[params.PR_res_init, params.PR_res_init]], dtype=float)
            agent.prop_steal = params.start_prop_steal_mean

            if fix_prop_fb == 0:
                agent.prop_fight_back = 0.0
            else:
                agent.prop_fight_back = params.start_prop_fight_back_mean

            # and fix their foraging strategies
            agent.for_strat_array[0] = fixed_for_strats[counter]

            counter += 1

    if print_dets == 1:
        print('\n** create_agents function ends **\n')

    # the population instance is returned
    return agent_population


def create_fountains(agent_population, print_dets, init_res_level, rounds, dimen, trade_loc, two_tribes, initial_fount_stock_high, single_tribe):
    """This function generates and returns an instance of a population of resource foutains with num_fountains in it."""

    if print_dets == 1:
        print('\n** create_fountains function starts **\n')

    # establish an array which will contain all the new foutains, which will be
    # placed in to a popultion class (this class is then returned):
    group = np.array([])

    if two_tribes == 0:

        # add agents to the group:
        for i in np.arange(num_res_founts):  # each fountain

            if single_tribe and i == 1:

                fountain = Fountain(initial_fount_stock_high, dimen, trade_loc, rounds, tribe='none')

            else:

                fountain = Fountain(init_res_level, dimen, trade_loc, rounds, tribe='none')

            # add foutain to the group of agents:
            group = np.append(group, fountain)

    elif two_tribes == 1:

        # then we create 4 fountains - we put 0 and 1 in to pop_1, 2 and 3 in to pop_2, and all in to pop

        # note that fountain 0 has more than fountain 1 (initial_fount_stock_high)
        fountain_0 = Fountain(initial_fount_stock_high, dimen, trade_loc, rounds, tribe='sharks')

        # add foutain to the group of agents:
        group = np.append(group, fountain_0)

        fountain_1 = Fountain(init_res_level, dimen, trade_loc, rounds, tribe='sharks')

        # add fountain to the group of agents:
        group = np.append(group, fountain_1)

        # foutain 3 has more than fountain 2
        fountain_2 = Fountain(init_res_level, dimen, trade_loc, rounds, tribe='jets')

        # add foutain to the group of agents:
        group = np.append(group, fountain_2)

        fountain_3 = Fountain(initial_fount_stock_high, dimen, trade_loc, rounds, tribe='jets')

        # add foutain to the group of agents:
        group = np.append(group, fountain_3)

    fountain_pop = Resource_Fountain_Population(group, two_tribes)

    if print_dets == 1:
        print('\n** create_fountains function ends **\n')

    return fountain_pop


def agents_forage(round, for_strat_parts, print_dets, print_fine_dets, agent_population, fountain_pop, dbs, print_for, two_tribes, tribe):
    """This function manages the foraging process"""

    if print_for:
        print_dets = print_fine_dets = 1

    if print_fine_dets == 1:
        print('\n tribe =', tribe)

    #    if round % 10 == 0:
    #
    #        print_dets = print_fine_dets = 1

    # we need to create four arrays to record which agents are at each fountain in each time slot every day:
    # fount_visits_array and fount_visits_agents_metaarray are created up front and agents_at_all_founts_array and
    # agents_at_fount_array are created within iteration loops

    # this array simply records the number of agents at each fountain in each time slot:
    fount_visits_array = np.zeros(shape=(for_strat_parts, num_res_founts))

    # this array is the same but instead of the number of agents in each cell, it contains an array of the agents at each
    # fountain at each time slot
    fount_visits_agents_metaarray = []

    if print_dets == 1:
        print('\n number of agents at start =', len(agent_population.pop), '\n')

    # now count the number of agents in each fountain in each time
    # slot and update fount_visits_array:

    for l in np.arange(for_strat_parts):

        if print_fine_dets == 1:
            print('\ntime slot (l) =', l)

        # this array records all of the agents at all fountains in a single time slot
        agents_at_all_founts_array = []

        for m in np.arange(num_res_founts):

            if print_fine_dets == 1:
                print('\nfountain (m) =', m, '\n')

            # create a counter to record agent numbers
            visit_counter = 0

            # create array to record agents at single fountains in each time slot
            agents_at_fount_array = np.array([])

            for agent in agent_population.pop:
                #                    print 'agent =', agent
                #                    print 'agent_population.pop[agent] =', agent_population.pop[agent]
                if two_tribes == 0 and agent.for_strat_array[0][l] == m:  # i.e. agent is at this specific fountain at
                    # this time of the day
                    #                    visit_counter += 1
                    agents_at_fount_array = np.append(agents_at_fount_array, agent)

                elif two_tribes == 1 and agent.tribe == tribe and agent.for_strat_array[0][l] == m:

                    agents_at_fount_array = np.append(agents_at_fount_array, agent)

            # add data to founts_db to record the number of agents at each fountain in each time slot
            visit_counter = len(agents_at_fount_array)
            dbs.founts_db[(num_res_founts * l) + m + 1][round] = visit_counter

            # shuffle these agents (useful below) so in effect they arrive at a fountain in a queue:
            np.random.shuffle(agents_at_fount_array)

            if print_fine_dets == 1:
                print('\nagents_at_fount_array =', agents_at_fount_array)

            agents_at_all_founts_array.append(agents_at_fount_array)
            # problem of arrays merging!!

            fount_visits_array[l][m] = visit_counter

        if print_fine_dets == 1:
            print('\nagents_at_all_founts_array =', agents_at_all_founts_array)

        fount_visits_agents_metaarray.append(agents_at_all_founts_array)

    if print_dets == 1:
        print('\n\nfount_visits_agents_metaarray =', fount_visits_agents_metaarray, '\n\n')

    # by this point we have established which agents are at which fountain in every time slot so we can move on to
    # determine which agents harvest which resources (and put these resources in their 'basket').

    # whether an agent finds a resource during a time slot depends on two factors: (i) their detection skill
    # (given in detect_skills_array); and (ii) the amount of resources remaining at the site.  An equation is used to
    # determine whether an agent detects the resource -> q = pi * L / res_index where pi is the skill level (e.g. 0.3),
    # L is the level of resource remaining, and res_index is a parameter.  For example, if pi = 0.3, L = 65, and
    # res_index = 200 then q = 0.3 * (65 / 200) = 0.0975.  We then take a random number generated (between 0 and 1) and
    # if this is below 0.0975 then the agent detects the resource (L then declines by 1).

    # for our tracking agent, we want to record the level of resources collected before trading

    agent_population.tracking_agent.add_tracking_agent_data()

    if print_dets == 1:
        print('\nForaging now starts\n')

    # there are 'for_strat_part' time slots in the day and we need to iterate over these slots:
    for slot in np.arange(for_strat_parts):

        for fount in np.arange(num_res_founts):

            # the agents have already been randomised: at each fountain they line up in a queue so that each agent
            # will attempt to forrage in order

            # record the level of resources at this fountain
            if two_tribes == 0:

                dbs.res_level_array[slot][fount] = fountain_pop[fount].res_level

            elif two_tribes == 1:

                if tribe == 'sharks':

                    dbs.res_level_array[slot][fount] = fountain_pop[fount].res_level

                elif tribe == 'jets':

                    dbs.res_level_array[slot][2 + fount] = fountain_pop[fount].res_level

            if print_fine_dets == 1:
                print('\n\n slot', slot, 'fount', fount)

            for agent in fount_visits_agents_metaarray[slot][fount]:

                if print_fine_dets == 1:
                    print('\nagent =', agent, 'for strat', agent.for_strat_array)
                    print('agent.detect_skills_array[0][fount] =', agent.detect_skills_array[0][fount])
                    print('fountain_population.pop[fount].res_level =', fountain_pop[fount].res_level)

                if tribe == 'none' or tribe == 'sharks':

                    fount_num = fount

                elif tribe == 'jets':

                    fount_num = 2 + fount

                fountain_init_level = dbs.init_res_levels[round][fount_num]

                # this is the net detection probability (see equation in notes above)
                q = agent.detect_skills_array[0][fount] * (fountain_pop[fount].res_level / fountain_init_level)

                if print_fine_dets == 1:
                    print('q =', q)

                rand_num = random.random()

                if print_fine_dets == 1:
                    print('rand_num =', rand_num)

                if rand_num < q:  # then the agent has successfully detected the resource

                    if print_fine_dets == 1:
                        print('successful forriaging!')

                    agent.basket_array[0][fount] += 1  # add resource to agent's basket

                    fountain_pop[fount].res_level -= 1  # deduct resource from fountain

                    # for the agent we're tracking,
                    if agent == agent_population.tracking_agent:
                        agent_population.tracking_agent.pre_basket_array[0][fount] += 1

                if print_fine_dets == 1:
                    print('resultant agent.basket_array =', agent.basket_array)

            # record levels of resource foutains at the end of each time slot
            if two_tribes == 0:

                dbs.res_level_array_ends[slot][fount] = fountain_pop[fount].res_level

            elif two_tribes == 1:

                if tribe == 'sharks':

                    dbs.res_level_array_ends[slot][fount] = fountain_pop[fount].res_level

                elif tribe == 'jets':

                    dbs.res_level_array_ends[slot][2 + fount] = fountain_pop[fount].res_level

    if print_dets == 1:
        print('\nForaging has finished\n')

    # now we have to record the amount of resources foraged from each fountain (initial level minus fountain levels at the end of the foraging)
    for e in np.arange(num_res_founts):
        dbs.main_db[4 + e][round] = fountain_pop[e].res_level
        dbs.foutain_levels[e][round] = dbs.fountains_init_levels_hist[e][round] - fountain_pop[e].res_level

    if tribe == 'sharks':
        dbs.res_founts_sharks[0][round] = fountain_pop[0].res_level
        dbs.res_founts_sharks[1][round] = fountain_pop[1].res_level

    if tribe == 'jets':
        dbs.res_founts_jets[0][round] = fountain_pop[0].res_level
        dbs.res_founts_jets[1][round] = fountain_pop[1].res_level

    if print_dets == 1:
        print('\nfount_visits_array =\n', fount_visits_array, '\n')

    if print_fine_dets == 1:

        for ag in agent_population.pop:
            print('\n ag', ag, 'tribe ', ag.tribe, 'basket', ag.basket_array[0])

        pause()


def update_neighbours(town_grid, agent_population, local_net_rad, print_dets, print_fine_dets, dimen, tracking_agent, track_agent, day):

    """This function takes a population of agents and updates each agent's neighbours array.  Note for each agent, its list
    of neighbours includes itself."""

    def single_agent_neigh_update(agent):

        # wipe the agent's neighs array first
        agent.neighs = []
        for pot_neigh in agent_population.pop:

            # if print_fine_dets == 1:
            #     print('\n\n ** pot_neigh.home', pot_neigh.home)

            if agent is not pot_neigh:

                dist_bw_neighs = abs_dist_on_torus(agent.home, pot_neigh.home, town_grid.dimen)

                # if print_fine_dets == 1:
                #     print(' dist_bw_neighs', dist_bw_neighs)

                if dist_bw_neighs[0] <= local_net_rad and dist_bw_neighs[1] <= local_net_rad:

                    agent.neighs.append(pot_neigh)

                    # if print_fine_dets:
                    #     print(' pot_neigh is a neighbour')

    threads = []
    for agent in agent_population.pop:

        if track_agent and track_agent <= day and agent == agent_population.tracking_agent:
           print_fine_dets = 1

        else:
            print_fine_dets = 0

        if print_fine_dets == 1:
            print('** updating agents neighbours arrays **')
            print('\n local_net_rad', local_net_rad)
            print('\n\n agent.home', agent.home)

        t = threading.Thread(target=single_agent_neigh_update, args=[agent])
        t.start()
        threads.append(t)

        if print_fine_dets == 1:
            print('\n agent home', agent.home, ': neighbours =\n', agent.neighs)
            print('\n len(neighs) =', len(agent.neighs), '\n')
            # pause()

    for thread in threads:
        thread.join()


def agents_trading(params, KO_pop, town_grid, agent_population, print_dets, trade_moves, trade_movemnt, vision_len, day,
                   trade_loc, print_fine_dets, tracking_agent, wait_at_target_til_end, wait_at_tgt_moves, track_agent, trgt_sel,
                   dimen, trade_when_trgt, goods_signal, run_folder,
                   print_round_trans, df_daily, dbs, granular_mem, fountain_population, print_move_heat_maps, trade_prices,
                   rounds, gen_equ_thresh, gen_equ_wh_lps, SD_charts_freq, price_mean, force_prices, fixed_price,
                   keynesian_ratio, find_gen_equ_PQ, use_parallel_code, price_grid_dimen, test_par_code, print_plotly_charts,
                   print_MRS_std_charts, const_mkt_opens, ststst, respect_property_rights, adjust_props_r, fight_cost, agent_intn_beta,
                   num_rounds, len_reputations_mem, intn_error_std, agent_avoid_muggers, prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil,
                   prop_fight_back_floor, trade_at_trgt_precise, fight_balance, agree_location, use_original_model_struct, two_tribes,
                   formal_inst, prob_fine, fine, print_agents_interact, fight_skill, fix_ps_fb_0, stranger_int, two_tribes_inst,
                   strat_choice, strangers_if_unknown):

    """A function for managing the process by which agents trade.  The number of transactions is returned and changes are
    made to the agent_population instance, which contains all the agents."""

    if params.calc_timings:
        trading_start_time = dt.datetime.now()

        dbs.timings_dict['trading_move_overhead'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_mtt'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_eval_own_grid_sq'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_eval_exp_gains_own_square'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_agents_interact'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_eval_all_grid_sqs'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_retargetting'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_bilat_eval'].append(dt.timedelta(0, 0, 0))

    # print_fine_dets = 1

    marker = 0

    #    for agent in agent_population.pop:
    #        print(' agent home', agent.home, 'basket', agent.basket_array)
    #
    #    pause()

    if print_dets == 1 or (params.track_agent and params.track_agent <= day):
        print('\n--- agents now start trading ---')

    print_model_2_dets = 0

    # create a database to record the successful transactions of agents in this round.  Must be a list as np array doesn't work well
    # with variable length arrays
    daily_succ_trans = []

    # same for fights
    daily_fights = []

    # zero some arrays / values: wipe the trading_cps array for the agents
    for agent in dbs.agent_list:

        agent.previous_trgt = []
        agent.trade_loc_rec = []
        agent.trgt_loc_rec = []
        agent.can_trade = 0             # this gets set to 1 below if agent walking randomly or if agent home is its target square
        agent.reached_trgt = 0
        agent.reached_tgt_on_move = 0
        agent.last_transaction = 0
        agent.wait_at_tgt_moves_pro_rata = wait_at_tgt_moves
        agent.ignore_agents_array = []
        agent.agent_last_traded_with = None
        agent.exp_int_gains_dict = dict()
        agent.exp_int_gains_dict_strangers = dict()
        agent.last_intn = None
        agent.exp_rtns_matrix = dict()
        agent.total_res_reduced_value_start_trading = find_total_res_reduced_value(agent, print_fine_dets=0)
        agent.heads_home = 0

        agent.total_res_held_moves = []

    # now we update the gini coefficient for resource holdings at the start of the trading phase - we do the same at the end
    gini_array = np.zeros(shape=len(dbs.agent_list))

    ag_counter = 0
    for ag in dbs.agent_list:
        tot_res = np.sum(ag.basket_array)
        gini_array[ag_counter] = tot_res

        ag_counter += 1

    gini_array.sort()

    gini_day_val = gini(gini_array)

    dbs.res_conc_gini_starts[day] = gini_day_val

    # this list records if agents have reached home (they get ignored)
    dbs.agents_reached_home = []

    # update dict of whether agents know other agents
    mem_start_day = np.max([0, day - len_reputations_mem])

    for agent in agent_population.pop:

        for cp_agent in agent_population.pop:

            if agent is not cp_agent:

                if (str(cp_agent) in agent.reputations_dict and np.sum(agent.reputations_dict[str(cp_agent)][1][mem_start_day:day]) > 0.0) or str(cp_agent) in agent.last_known_rep_ps_dict:

                    agent.agent_knows_cp_dict[str(cp_agent)] = 1

                else:

                    agent.agent_knows_cp_dict[str(cp_agent)] = 0

                if (str(agent) in cp_agent.reputations_dict and np.sum(cp_agent.reputations_dict[str(agent)][1][mem_start_day:day]) > 0.0) or str(agent) in cp_agent.last_known_rep_ps_dict:

                    cp_agent.agent_knows_cp_dict[str(agent)] = 1

                else:

                    cp_agent.agent_knows_cp_dict[str(agent)] = 0

    # we blank town_grid.grid_agents - this is therecord of where agents are located
    town_grid.grid_agents = []
    row = []
    for k in np.arange(town_grid.dimen):
        row.append([])
    for l in np.arange(town_grid.dimen):
        town_grid.grid_agents.append(copy.deepcopy(row))

    # Before trading, there are two important locations for the agent: where they start from and where they head to.
    # In the code which follows, we set both

    # first, the agents are placed on the town_grid - this function updates the agents' locations arrays. The important
    # variable here is trade_loc, which if == 'home' then agents start from their home location; if == 'random' then they
    # start from a random location in each round.  This function also populates town_grid.grid_accup, which counts how many
    # agents are on each grid square
    town_grid.locate_agents(agent_population, fountain_population, dbs, print_dets, trade_loc)

    # second, the agents choose a target to head towards.  They key variable here is 'trade_movemnt': if 'random' then the
    # target location is chosen randomly; and if 'set' then we use the function 'set_targets' to create a target location for
    # the agents (there are many ways in which that could be done but it uses the agent's databases)
    if trade_movemnt == 'set':

        threads = []
        for agent in dbs.agent_list:

            # locs_array_2, roulette_wheel, gross_pos_locs_array, gross_pos_locs_weights, gross_neg_locs_array, gross_neg_locs_weights =\
            # set_agent_target(params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, respect_property_rights, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt, trade_when_trgt,
            #                  dbs, track_agent, agent, day, town_grid, trgt_sel,
            #                  trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, ststst, retarg=0, move=0, has_acted=0, print_dets=print_dets, print_fine_dets=print_fine_dets, fight_balance=fight_balance,
            #                  agree_location=agree_location,
            #                  adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta, formal_inst=formal_inst, prob_fine=prob_fine, fine=fine, fight_skill=fight_skill, fix_ps_fb_0=fix_ps_fb_0, strat_choice=strat_choice,
            #                  stranger_int=stranger_int,
            #                  two_tribes_inst=two_tribes_inst, strangers_if_unknown=strangers_if_unknown)

            t = threading.Thread(target=set_agent_target,
                             args=[params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem,
                                   intn_error_std, respect_property_rights, KO_pop, agent_population, keynesian_ratio,
                                   trade_prices, trade_movemnt, trade_when_trgt, dbs, track_agent, agent, day,
                                   town_grid, trgt_sel, trade_moves, granular_mem, fountain_population,
                                   wait_at_tgt_moves, ststst],
                             kwargs={'retarg': 0, 'move': 0, 'has_acted': 0, 'print_dets': print_dets,
                                     'print_fine_dets': print_fine_dets, 'fight_balance': fight_balance,
                                     'agree_location': agree_location, 'adjust_props_r': adjust_props_r,
                                     'agent_intn_beta': agent_intn_beta, 'formal_inst': formal_inst,
                                     'prob_fine': prob_fine, 'fine': fine, 'fight_skill': fight_skill,
                                     'fix_ps_fb_0': fix_ps_fb_0, 'strat_choice': strat_choice,
                                     'stranger_int': stranger_int, 'two_tribes_inst': two_tribes_inst,
                                     'strangers_if_unknown': strangers_if_unknown}
                             )
            t.start()
            threads.append(t)

            agent.start_trgt_loc_rec[day].append(agent.grid_trgt)

            # if the agent has no memory then agent.trade_movemnt == 'random' and we need to set agent.can_trade = 1
            if agent.trade_movemnt == 'random':
                agent.can_trade = 1

                dbs.target_locations['none'][day] += 1

            else:

                # +1 for each agent's target in dbs.target_locations[day]
                if str(agent.grid_trgt) not in dbs.target_locations:
                    dbs.target_locations[str(agent.grid_trgt)] = np.zeros(rounds, dtype=int)

                dbs.target_locations[str(agent.grid_trgt)][day] += 1

            # print(' agent.start_trgt_loc_rec', agent.start_trgt_loc_rec)

        for thread in threads:
            thread.join()

    elif trade_movemnt == 'random':

        for agent in dbs.agent_list:
            agent.grid_trgt = np.array([1000, 1000], dtype=int)
            agent.can_trade = 1

            agent.start_trgt_loc_rec[day].append(agent.grid_trgt)

    # for entry in dbs.target_locations:
    #
    #     print('\n entry is ', entry, 'array', dbs.target_locations[entry], 'total for this round', dbs.target_locations[entry][day])
    #
    # pause()

    # load agents on to town_grid.grid_agents
    for agent in dbs.agent_list:

        x_coord = agent.location[0]
        y_coord = agent.location[1]

        town_grid.grid_agents[x_coord][y_coord].append(agent)

        # if the agent happens to start on its target location then we set can_trade = 1
        if agent.home[0] == agent.grid_trgt[0] and agent.home[1] == agent.grid_trgt[1]:
            agent.can_trade = 1
            agent.reached_trgt = 1
            agent.reached_tgt_on_move = 0

    # update MRS arrays to start and then save data if required
    for agent in agent_population.pop:

        agent.update_agent_MRS_array(print_dets, print_fine_dets, agent_population)

        if print_MRS_std_charts == 1 or ((day + 1) % SD_charts_freq == 0) or (params.fixed_price_day and (params.fixed_price_day + 10) <= day):
            agent.MRS_history[day] = copy.copy(agent.MRS_array)

    # this line generates the supply & demand data for the 2d charts and it also finds the market clearing price and quantity when num_res_founts == 2
    if num_res_founts == 2:

        supply_demand_array = create_supply_demand_data(params, fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, gen_equ_thresh, dbs.agent_list, record_dbs_data=1, tribe='none')

        # if we fix prices, we create a list so we can append S&D curves at different times in order to track the evolution of the curves
        if (params.fixed_price_day and day >= params.fixed_price_day) or (params.res_depletion and day >= params.res_depletion):

            # print('\n day =', day, 'dbs.saved_SD_curves =\n\n', dbs.saved_SD_curves)

            if (params.fixed_price_day and day == params.fixed_price_day and day != 0) or (params.res_depletion and day == params.res_depletion and day != 0):

                dbs.saved_SD_curves.append(supply_demand_array)

                # print('\n (params.fixed_price_day and day == params.fixed_price_day and day != 0) or (params.res_depletion and day == params.res_depletion and day != 0) - dbs.saved_SD_curves =\n\n', dbs.saved_SD_curves)

            if (params.fixed_price_day and (params.fixed_price_day < day <= params.fixed_price_day + 100) and day % 10 == 0) or (params.res_depletion and (params.res_depletion < day <= params.res_depletion + 400) and day % 20 == 0 and day != 0):

                # print('\n (params.fixed_price_day and (params.fixed_price_day < day <= params.fixed_price_day + 100) and day % 10 == 0) or (params.res_depletion and (params.res_depletion < day <= params.res_depletion + 400) and day % 20 == 0 and day != 0)')

                if (params.fixed_price_day and (day == params.fixed_price_day + 10)) or (params.res_depletion and (day == params.res_depletion + 20)):            # applies the first time we record a second set of data

                    dbs.saved_SD_curves.append(supply_demand_array)

                    # print('\n (params.fixed_price_day and and (day == params.fixed_price_day + 10)) or (params.res_depletion and (day == params.res_depletion + 20)) - dbs.saved_SD_curves =\n\n', dbs.saved_SD_curves)

                elif (params.fixed_price_day and (params.fixed_price_day + 10 < day)) or (params.res_depletion and (params.res_depletion + 20 < day)):

                    dbs.saved_SD_curves[1] = supply_demand_array

                    # print('\n (params.fixed_price_day and (params.fixed_price_day + 10 < day)) or (params.res_depletion and (params.res_depletion + 20 < day)) - dbs.saved_SD_curves =\n\n', dbs.saved_SD_curves)

            if (params.fixed_price_day and (params.fixed_price_day + 100 < day)) or (params.res_depletion and (params.res_depletion + 400 < day)):

                # we wipe this array to signal to other function that we stop plotting the charts
                dbs.saved_SD_curves = []

                # print('\n (params.fixed_price_day and (params.fixed_price_day + 100 < day)) or (params.res_depletion and (params.res_depletion + 400 < day)) - dbs.saved_SD_curves =\n\n', dbs.saved_SD_curves)

        if two_tribes:

            sharks_pop = []
            jets_pop = []

            for agent in agent_population.pop:

                if agent.tribe == 'sharks':

                    sharks_pop.append(agent)

                elif agent.tribe == 'jets':

                    jets_pop.append(agent)

            supply_demand_array_sharks = create_supply_demand_data(params, fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, gen_equ_thresh, sharks_pop, record_dbs_data=0, tribe='sharks')

            supply_demand_array_jets = create_supply_demand_data(params, fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, gen_equ_thresh, jets_pop, record_dbs_data=0, tribe='jets')

    if num_res_founts == 3 and find_gen_equ_PQ == 1:
        find_simultaneous_equ_prices(fountain_population, agent_population, print_dets, print_fine_dets, dbs, day, gen_equ_thresh, gen_equ_wh_lps, town_grid, run_folder, use_parallel_code, price_grid_dimen, test_par_code,
                                     print_plotly_charts)

    # create a heatmap to show the position of all agents at the start of trading and at the end of each move
    if print_move_heat_maps == 1 or (params.track_agent and params.track_agent <= day):

        agent_loc_db = np.zeros(shape=(dimen, dimen))

        for remain_agent in dbs.agent_list:
            x_coord = remain_agent.location[0]
            y_coord = remain_agent.location[1]
            agent_loc_db[x_coord][y_coord] += 1

        title = 'Agent locations in round %s, before moving' % (day)
        print('\n')
        create_heat_map(town_grid.dimen, agent_loc_db, df_daily, 'Blues', title, 'num agent', dpi='low')

    # In case the parameters are accidentally set to trade_when_trgt = 1 and trade_movemnt = 'random', for simplicity we
    # set trade_when_trgt = 0
    if trade_when_trgt == 1 and trade_movemnt == 'random':
        trade_when_trgt = 0

    # create variable switch to generate and print MRS daily charts
    print_MRS_daily_charts = 0

    # Blank the array which records all MRSs over all of the moves
    if (day + 1) % SD_charts_freq == 0 or (params.fixed_price_day and ((params.fixed_price_day <= day < (params.fixed_price_day + 10)) or ((params.fixed_price_day <= day < params.fixed_price_day + 200) and day % 5 == 0))) or\
            (params.res_depletion and (params.res_depletion <= day < params.res_depletion + 200) and day % 5 == 0):

        print_MRS_daily_charts = 1

    if print_MRS_daily_charts:

        # dbs.MRS_moves_array = [[[[] for move in np.arange(trade_moves + 1)] for res_1 in np.arange(num_res_founts)] for res_2 in np.arange(num_res_founts)]

        dbs.MRS_moves_array_2 = np.zeros(shape=(len(dbs.agent_list), trade_moves + 1), dtype=float)

        # create a dictionary so we record the agents in same line in dbs.MRS_moves_array_2 - we map the agent's home (a unique identification) on to its starting position in dbs.agent_list
        MRS_array_dict = {}

        agent_num = 0
        for agent in dbs.agent_list:

            # for res_1 in np.arange(num_res_founts):
            #     for res_2 in np.arange(num_res_founts):
            #
            #         if res_1 != res_2:
            #             dbs.MRS_moves_array[res_1][res_2][0].append(agent.MRS_array[res_1][res_2])

            dbs.MRS_moves_array_2[agent_num][0] = agent.MRS_array[0][1]
            MRS_array_dict[str(agent.home)] = agent_num

            # print('\n agent_num ', agent_num, 'agent.MRS_array[0][1]', agent.MRS_array[0][1])

            agent_num += 1

    if print_fine_dets or (params.track_agent and params.track_agent <= day):
        print('\n\n////////////// Start Move Iterations ////////////')

    #    input("Press Enter to continue...")
    #    print('day =', day)

    if params.calc_timings:
        # assert isinstance(trading_start_time, object) - play with this later
        dbs.timings_dict['trading_overhead'].append(dt.datetime.now() - trading_start_time)

    # iterate over moves:
    for move in np.arange(trade_moves):

        if params.calc_timings:
            start_move_time = dt.datetime.now()

        #        print_heatmap_end_move = 0

        # it's possible that an agent's resources decline to below zero if they fight - we make it so they cannot trade
        for ag in dbs.agent_list:

            if any(res < 0.0 for res in ag.agent_res_array[0]):
                ag.can_trade = 0

        if print_fine_dets or (params.track_agent and params.track_agent <= day):
            print('\n\n\n\n************* move =', move, 'of', trade_moves, ' | round ', day)
            print('\n agents remaining on the grid:\n')

            for agent in dbs.agent_list:

                print(' agent', agent, ' | home =', agent.home, ' | location =', agent.location, ' | target loc =', agent.grid_trgt)

        if len(dbs.agent_list) < 2:

            #            if print_dets == 1:
            print('\n There are either no agents or 1 agent remains: we do not carry on with move iterations because there can be no trading')

        elif len(dbs.agent_list) >= 2:

            # randomize the agent list so no one agent has an advantage due to moving earlier or later.
            # this is important when agents don't respect property rights: when agents move in the same sequence some will chase and the others run and
            # there would be no interaction.  If we change turns in each move, we allow the possibility of a chasing agent moving twice and catching the runner.
            # I think this accords with reality: it allows people to be mugged, for example.
            random.shuffle(dbs.agent_list)

            if params.calc_timings:
                dbs.timings_dict['trading_move_overhead'][day] += dt.datetime.now() - start_move_time

            # Start iteration over agents in dbs.agent_list
            for agent in dbs.agent_list:

                #                print_fine_dets = 0 track_agent

                #                if day > 50:
                #                    print_fine_dets = 1
                #                    print_dets = 1

                if (params.track_agent and params.track_agent <= day) and agent == agent_population.tracking_agent: # and len(town_grid.grid_agents[agent.location[0]][agent.location[1]]) > 1:  # and agent.trade_movemnt == 'set':
                    print_for_tracking = 1

                else:
                    print_for_tracking = 0

                # if agent.heads_home:
                #     print_fine_dets = 1
                # else:
                #     print_fine_dets = 0

                if print_fine_dets or print_for_tracking:

                    print('\n\n****** Start new agent: agent', agent, '  |  home =', agent.home, '  |  day =', day, '  |  move =', move, ' of ', trade_moves, 'reached_tgt_on_move =', agent.reached_tgt_on_move, 'agent.grid_trgt', agent.grid_trgt, 'agent.location', agent.location)

                if print_fine_dets:

                    print('\n agent.meeting_point_cps =', agent.meeting_point_cps, '\n')
                    print('\n home location for meeting_point_cps:\n')
                    for dude in agent.meeting_point_cps:
                        print(dude.home)
                    print('\n agent.grid_trgt', agent.grid_trgt)
                    print(' wait_at_target_til_end', wait_at_target_til_end)

                    if trade_loc == 'fountain':

                        for fount in fountain_population.pop:
                            print('fount_loc = ', fount.location)

                if params.calc_timings:
                    agent_start_move = dt.datetime.now()

                agent_has_moved = 0

                # In the following case, the agent must be moving to a set target on the grid and hasn't reached it yet or it
                # has stepped off its target onto another cp_agent's square.  If this is true then we don't need to create
                # agent_crop_list, the agent simply moves to its target.
                if agent.can_trade == 0 and (params.respect_property_rights or (params.respect_property_rights == 0 and agent not in dbs.agents_reached_home)):  # and (len(town_grid.grid_agents[agent.location[0]][agent.location[1]]) == 1 or agent.heads_home)

                    if print_dets or print_for_tracking:
                        print('\n **** agent cannot trade ****')

                    # How do we decide which cell to move to?  We look at all of the cells the agent could move to
                    # and choose the one with the shortest 'as the crow flies' distance which has a cell that isn't full.
                    # This approach has multiple advantages including 'queueing' the agent up outside the target when the
                    # target is full.

                    # We want to remove the agent from its current location and then place it on the new location
                    x_coord = agent.location[0]
                    y_coord = agent.location[1]

                    if print_fine_dets == 1:
                        print('agent =', agent)
                        print('agent.location :', agent.location)
                        print('town_grid.grid_agents[x_coord][y_coord] =', town_grid.grid_agents[x_coord][y_coord])
                        print('\n where agent on grid_agents?')
                        for array in np.arange(town_grid.dimen):
                            for cell in np.arange(town_grid.dimen):
                                if agent in town_grid.grid_agents[array][cell]:
                                    print(' agent in cell', array, cell)

                    # We take the agent off its current location in this database
                    town_grid.grid_agents[x_coord][y_coord].remove(agent)

                    # This function changes the agent's location, depending on its target and how full squares are in
                    # town_grid.grid.  If the agent's grid_trgt is within reach this function also sets agent.can_trade = 1
                    # whether the agent moves on to that square or not (i.e. if the target square is full then
                    # agent.can_trade = 1.  It also sets agent.reached_tgt_on_move = move if target reached).
                    agent.choose_new_loc(town_grid, print_dets, print_fine_dets, trade_movemnt, move, day, trade_when_trgt, trade_moves, wait_at_tgt_moves, dbs, respect_property_rights, trade_at_trgt_precise)

                    # Now we place the agent on the new location
                    x_coord = agent.location[0]
                    y_coord = agent.location[1]

                    town_grid.grid_agents[x_coord][y_coord].append(agent)

                    agent_has_moved = 1

                    if print_fine_dets or print_for_tracking:

                        print('\n agent.home =', agent.home)
                        print('\n agent.trade_loc_rec =\n')
                        for mo in np.arange(len(agent.trade_loc_rec)):
                            print(agent.trade_loc_rec[mo])

                        print(agent.location, '<-- agent.location')
                        print('\n agent.trgt_loc_rec =\n')

                        for mo in np.arange(len(agent.trgt_loc_rec)):
                            print(agent.trgt_loc_rec[mo])

                        print(agent.grid_trgt, '<-- agent.grid_trgt')

                    if params.calc_timings:
                        dbs.timings_dict['trading_move_agent_mtt'][day] += dt.datetime.now() - agent_start_move

                # here an agent is heading to target but another agent is on its square - it can trade if it deems it worthwhile
                # if params.respect_property_rights == 0 and agent.can_trade == 0 and agent_has_moved == 0 and len(town_grid.grid_agents[agent.location[0]][agent.location[1]]) > 1 and agent.heads_home == 0: # and agent.heads_home == 0:
                #
                #     if print_fine_dets or print_for_tracking:
                #         print('\n agent.can_trade == 0 and agent_has_moved == 0 and len(town_grid.grid_agents[agent.location[0]][agent.location[1]]) > 1')
                #         print(' so we set agent.can_trade = 1')
                #
                #     agent.can_trade = 1

                if agent.can_trade == 1 and (params.respect_property_rights or (params.respect_property_rights == 0 and agent_has_moved == 0)): # and all(res > 0.0 for res in agent.agent_res_array[0]) - dealt with above already

                    if params.calc_timings:
                        agent_can_trade_start_time = dt.datetime.now()

                    if print_dets or print_for_tracking:
                        print('\n ---> agent.can_trade =', agent.can_trade)
                        print(' agent.location =', agent.location)
                        print(' agent.grid_trgt =', agent.grid_trgt)

                    # find out how many agents on the agent's current square:
                    agent_x_coord = agent.location[0]
                    agent_y_coord = agent.location[1]

                    num_ags_on_own_square = len(town_grid.grid_agents[agent_x_coord][agent_y_coord])

                    if print_dets or print_for_tracking:

                        print('\n town_grid.grid_agents[agent_x_coord][agent_y_coord] =\n', town_grid.grid_agents[agent_x_coord][agent_y_coord])
                        print('\n agent.trade_loc_rec:\n')

                        for mo in np.arange(len(agent.trade_loc_rec)):
                            print(' ', agent.trade_loc_rec[mo])

                        print(agent.location, '<-- agent.location')
                        print('\n num_ags_on_own_square (incl self)', num_ags_on_own_square)

                    agent_crop_list = []
                    # this variable records the mean expected return on the agent's current grid square, for when respect_property_rights == 0
                    own_loc_exp_rtn = 0
                    exp_cp_returns_array = []
                    exp_cp_returns_array_pos = []
                    cp_agent = None  # set this as default
                    agents_nearby = 0

                    if num_ags_on_own_square > 1:

                        #                        no_neighs = 0
                        #
                        #                        for i in range(-1, 2):
                        #
                        #                            for j in range(-1, 2):
                        #
                        #                                x_coord = (agent.location[0] + i) % town_grid.dimen
                        #                                y_coord = (agent.location[1] + j) % town_grid.dimen
                        #
                        #                                if i == 0 and j == 0 and len(town_grid.grid_agents[x_coord][y_coord]) > 1:
                        #
                        #                                    no_neighs = 1
                        #
                        #                                    print('\n x_coord', x_coord, 'y_coord', y_coord, 'i', i, 'j', j, ' town_grid.grid_agents[x_coord][y_coord]', town_grid.grid_agents[x_coord][y_coord])
                        #
                        #                                if (i == 0 and j == 0) == False and len(town_grid.grid_agents[x_coord][y_coord]) > 0:
                        #
                        #                                    no_neighs = 1
                        #
                        #                                    print('\n town_grid.grid_agents[x_coord][y_coord]', town_grid.grid_agents[x_coord][y_coord])
                        #
                        #                        if no_neighs == 1:
                        #
                        #                            print_fine_dets = 1
                        #
                        #                        else:
                        #
                        #                            print_fine_dets = 0

                        # if len(town_grid.grid_agents[agent_x_coord][agent_y_coord]) > 2:
                        #
                        #     print_fine_dets = 1

                        # print_fine_dets = 1

                        if print_fine_dets:
                            print('\n town_grid.grid_agents[agent_x_coord][agent_y_coord]:\n\n', town_grid.grid_agents[agent_x_coord][agent_y_coord])
                            print(' len(town_grid.grid_agents[agent_x_coord][agent_y_coord])', len(town_grid.grid_agents[agent_x_coord][agent_y_coord]))

                        # First, shuffle the agents on the current square - this is to randomize the consideration of each potential counterparty (pot_cp) on the square.  We only need to do this when
                        # we have set a limit and the number of agents (+1 for agent) exceeds this limit.
                        if params.limit_agent_interaction and len(town_grid.grid_agents[agent_x_coord][agent_y_coord]) > params.limit_agent_interaction + 1:
                            random.shuffle(town_grid.grid_agents[agent_x_coord][agent_y_coord])

                        if print_fine_dets or print_for_tracking:
                            print('\n POST-SHUFFLE: town_grid.grid_agents[agent_x_coord][agent_y_coord]:\n\n', town_grid.grid_agents[agent_x_coord][agent_y_coord])

                        agent_crop_list = []

                        # start with iter of zero - this will help iterate through agents on square
                        iter = 0
                        # one condition for ending while loop is finished_iter = 1 (last agent)
                        finished_iter = 0

                        # we create a while loop which works whether params.limit_agent_interaction is positive or None.  If positive, the while loop continues until the number of selected agents equals the limit; and
                        # if None, agents are selected based on the criteria below - there is no limit
                        while (params.limit_agent_interaction and len(agent_crop_list) < params.limit_agent_interaction and finished_iter == 0) or \
                                (params.limit_agent_interaction == None and finished_iter == 0):

                            pot_cp = town_grid.grid_agents[agent_x_coord][agent_y_coord][iter]

                            if print_fine_dets:
                                print('\n iter =', iter)
                                print(' pot_cp: ', pot_cp)

                            accept_agent = 1

                            if params.respect_property_rights and (((agent.basket_array[0][0] > 0.0 and pot_cp.basket_array[0][1] > 0.0) or (agent.basket_array[0][1] > 0.0 and pot_cp.basket_array[0][0] > 0.0)) == False):
                                accept_agent = 0

                                if print_fine_dets or print_for_tracking:
                                    print('\n agents respect property rights but they cannot trade - incompatible resource holdings')

                            elif params.respect_property_rights and (trade_movemnt != 'random' and agent.trade_movemnt != 'random' and params.trade_when_trgt and pot_cp.reached_trgt == 0):
                                accept_agent = 0

                                if print_fine_dets or print_for_tracking:
                                    print('\n agents respect property rights, they only trade after reaching target and pot_cp cannot trade yet')

                            elif pot_cp is agent:
                                accept_agent = 0

                                if print_fine_dets or print_for_tracking:
                                    print('\n pot_cp is agent')

                            elif (respect_property_rights == 1 and pot_cp.can_trade == 0) or pot_cp.can_trade == 0:
                                accept_agent = 0

                                if print_fine_dets or print_for_tracking:
                                    print('\n (respect_property_rights == 1 and pot_cp.can_trade == 0) or pot_cp.can_trade == 0')

                            elif agent.agent_last_traded_with is pot_cp and pot_cp.agent_last_traded_with is agent:
                                accept_agent = 0

                                if print_fine_dets or print_for_tracking:
                                    print('\n agent.agent_last_traded_with is pot_cp and pot_cp.agent_last_traded_with is agent')

                            elif any(res < 0.0 for res in pot_cp.agent_res_array[0]):
                                accept_agent = 0

                                if print_fine_dets or print_for_tracking:
                                    print('\n any(res < 0.0 for res in pot_cp.agent_res_array[0])')

                            elif trade_when_trgt == 0 and agent.reached_trgt == 0 and pot_cp in agent.ignore_agents_array:
                                accept_agent = 0

                                if print_fine_dets or print_for_tracking:
                                    print('\n trade_when_trgt == 0 and agent.reached_trgt == 0 and pot_cp in agent.ignore_agents_array')

                            elif two_tribes == 1 and agent_population.ignore_strangers == 1 and pot_cp.tribe != agent.tribe:
                                accept_agent = 0

                                if print_fine_dets or print_for_tracking:
                                    print('\n two_tribes == 1 and agent_population.ignore_strangers == 1 and pot_cp.tribe != agent.tribe')

                            elif agent in dbs.agents_reached_home:
                                accept_agent = 0

                                if print_fine_dets or print_for_tracking:
                                    print('\n agent went back home')

                            # if none of the above conditions are true, add pot_cp to agent_crop_list
                            if accept_agent == 1:
                                agent_crop_list.append(pot_cp)

                                if print_fine_dets or print_for_tracking:
                                    print('\n agent passed all tests - added to agent_crop_list')

                            else:

                                if print_fine_dets or print_for_tracking:
                                    print('\n agent failed at least one of the tests - ignored')

                            # add 1 to iter
                            if iter < len(town_grid.grid_agents[agent_x_coord][agent_y_coord]) - 1:
                                iter += 1

                            # unless we have come to the end of the iterations
                            else:
                                finished_iter = 1
                                if print_fine_dets:
                                    print('\n this was the last iteration')

                        if print_fine_dets or print_for_tracking:
                            print('\n END agent_crop_list:', agent_crop_list)
                            # pause()

                        # if (day + 1) % 100 == 0 and day > 550 and move == 49:
                        #     print('day', day, 'move = 49  |  agent home', agent.home, ' len(agent_crop_list) =', len(agent_crop_list))

                    if params.calc_timings:
                        dbs.timings_dict['trading_move_agent_eval_own_grid_sq'][day] += dt.datetime.now() - agent_can_trade_start_time

                    # Key point: if there are still cp_agents in agent_crop_list that means there are cp_agents on the agent's grid square
                    if len(agent_crop_list) > 0:

                        if params.calc_timings:
                            len_acl_start_time = dt.datetime.now()

                        # if the agents don't respect property rights and they can trade, they will look around for other agents they might steal from or trade with.
                        # the agent needs to look on all its squares and take a view on which to locate itself (or it can trade with an agent on its current square)
                        if respect_property_rights == 0 and use_original_model_struct == 0:

                            #                            if day >= 20 and len(agent_crop_list) > 1:
                            #
                            # print_fine_dets = 1

                            if print_fine_dets or print_for_tracking:
                                print('\n\n\n -------------->>> There are potential cps on the agents square (day', day, 'move', move, ')')
                                print('\n strangers_if_unknown =', strangers_if_unknown)

                            # this is an array to record potential counterparties
                            pot_cps = []
                            # we record the expected returns for all the agents in agent_crop_list in this array
                            exp_returns_array = []
                            # here we record only the agents with a positive return
                            exp_returns_array_pos = []
                            # same for cp returns
                            exp_cp_returns_array_pos = []

                            if print_fine_dets:
                                print('\n agent.tribe =', agent.tribe)
                                print(' len(agent_crop_list)', len(agent_crop_list))

                            # if we limit the amount of agent interaction then we will take a sample from agent_crop_list of size params.limit_agent_interaction (else this is None)
                            if params.limit_agent_interaction and params.limit_agent_interaction < len(agent_crop_list):

                                agent_crop_list = random.sample(agent_crop_list, params.limit_agent_interaction)

                            # by this stage the agent is left with one or more potential cp_agent - they will evaluate which they want to interact with and then choose cp_agent
                            for pot_cp_agent in agent_crop_list:

                                if print_fine_dets:
                                    print('\n ----> pot_cp_agent.tribe =', pot_cp_agent.tribe)

                                #                                if agent == agent_population.pop[0] or pot_cp_agent == agent_population.pop[0]:
                                #                                    print_fine_dets = 1
                                #                                    print_dets = 1
                                #                                    print_model_2_dets = 1
                                #
                                #                                else:
                                #
                                #                                    print_fine_dets = 0
                                #                                    print_dets = 0
                                #                                    print_model_2_dets = 0

                                if agent.tribe == pot_cp_agent.tribe:

                                    if print_fine_dets or print_for_tracking:

                                        print('\n agent and cp are of same tribe')
                                        print('\n agent.agent_knows_cp_dict[str(pot_cp_agent)] ', agent.agent_knows_cp_dict[str(pot_cp_agent)])
                                        print('\n pot_cp_agent.agent_knows_cp_dict[str(agent)] =', pot_cp_agent.agent_knows_cp_dict[str(agent)])

                                        # print('\n agent.trade_loc_rec =\n')
                                        # print(agent.home, '<-- agent.home')
                                        # for mo in np.arange(len(agent.trade_loc_rec)):
                                        #     print('end of move', mo, '\t', agent.trade_loc_rec[mo])
                                        #
                                        # print(agent.location, '<-- agent.location')

                                        print('\n pot_cp_agent.trade_loc_rec:\n')
                                        print(pot_cp_agent.home, '<-- pot_cp_agent.home')
                                        for mo in np.arange(len(pot_cp_agent.trade_loc_rec)):
                                            print('end of move', mo, '\t', pot_cp_agent.trade_loc_rec[mo])

                                        print(pot_cp_agent.location, '<-- pot_cp_agent.location')
                                        # pause()

                                    # in this scenario, the agents use propensities to determine ps and pfb; unless strangers_if_unknown and one or both agents doesn't know the other
                                    if strat_choice == 'propensities' and (strangers_if_unknown == 0 or (strangers_if_unknown and agent.agent_knows_cp_dict[str(pot_cp_agent)] and pot_cp_agent.agent_knows_cp_dict[str(agent)])):

                                        agent_exp_gain, cp_exp_gain = agent.find_exp_returns_intn(params, pot_cp_agent, agent_population, print_dets, price_mean, force_prices, fixed_price,
                                                                                                  day, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                                  print_fine_dets, fight_balance, adjust_props_r, agent_intn_beta, move, formal_inst,
                                                                                                  prob_fine, fine, simulated_int=0, fight_skill=fight_skill, fix_ps_fb_0=fix_ps_fb_0, stranger_int=stranger_int,
                                                                                                  strat_choice=strat_choice, strangers_if_unknown=strangers_if_unknown)

                                        agent_dec = 1
                                        cp_agent_dec = 1

                                    else:  # i.e. strat_choice == 'rational'; or strat_choice == 'propensities' and one or both agents don't know each other:

                                        use_start_basket = 0
                                        agent_dec, cp_agent_dec, agent_exp_gain, cp_exp_gain = strangers_interact(params, agent_population.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, agent_population, fountain_population,
                                                                                                                  print_dets, print_fine_dets, use_start_basket, agent, pot_cp_agent, stranger_int, formal_inst, prob_fine, fine,
                                                                                                                  two_tribes_inst, fight_cost)

                                        # print('\n agent_dec, cp_agent_dec, agent_exp_gain, cp_exp_gain:', agent_dec, cp_agent_dec, agent_exp_gain, cp_exp_gain)

                                    if agent_exp_gain != None and agent_exp_gain > agent_population.min_trans_Q and agent_dec != 'none' and cp_agent_dec != 'none':

                                        pot_cps.append(pot_cp_agent)
                                        agent.expected_gains_dict[str(pot_cp_agent)] = [agent_exp_gain, cp_exp_gain]
                                        exp_returns_array_pos.append(agent_exp_gain)
                                        exp_cp_returns_array_pos.append(cp_exp_gain)

                                    # we update these arrays regardless of whether the agent 'likes' the potential cp - they are used to retarget later if the agent does not want to interact in this time period
                                    exp_returns_array.append(agent_exp_gain)
                                    exp_cp_returns_array.append(cp_exp_gain)

                                # elif agent_population.ignore_strangers == 0 and agent.tribe != pot_cp_agent.tribe:
                                #
                                #     #                                    print_fine_dets = 1
                                #
                                #     use_start_basket = 0
                                #     agent_dec, cp_agent_dec, agent_exp_gain, cp_exp_gain = strangers_interact(params, agent_population.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, agent_population, fountain_population,
                                #                                                                               print_dets, print_fine_dets, use_start_basket, agent, pot_cp_agent, stranger_int, formal_inst, prob_fine, fine, two_tribes_inst,
                                #                                                                               fight_cost)
                                #
                                #     if print_fine_dets:
                                #         print('\n agent is of different tribe: agent_exp_gain', agent_exp_gain, 'cp_exp_gain', cp_exp_gain, 'agent_dec', agent_dec, 'cp_agent_dec', cp_agent_dec)
                                #
                                #     # we are only interested in this agent if both have dominant strategies
                                #     if agent_dec is not 'none' and cp_agent_dec is not 'none' and agent_exp_gain > agent_population.min_trans_Q:
                                #
                                #         pot_cps.append(pot_cp_agent)
                                #         agent.expected_gains_dict[str(pot_cp_agent)] = [agent_exp_gain, cp_exp_gain]
                                #         exp_returns_array_pos.append(agent_exp_gain)
                                #
                                #     # we update these arrays regardless of whether the agent 'likes' the potential cp - they are used to retarget later if the agent does not want to interact in this time period
                                #     exp_returns_array.append(agent_exp_gain)
                                #     exp_cp_returns_array.append(cp_exp_gain)

                                if print_fine_dets or print_model_2_dets or print_for_tracking:

                                    print('\n agent has considered the potential counterparty...')
                                    print('\n agent_exp_gain =', agent_exp_gain, 'cp_exp_gain', cp_exp_gain)
                                    print(' len(pot_cps) =', len(pot_cps))
                                    print(' exp_returns_array =', exp_returns_array)
                                    print(' exp_returns_array_pos =', exp_returns_array_pos)
                                    print(' exp_cp_returns_array =', exp_cp_returns_array)
                                    print(' exp_cp_returns_array_pos =', exp_cp_returns_array_pos)
                                    if str(pot_cp_agent) in agent.reputations_dict:
                                        print(' exp cp p_s =', np.sum(agent.reputations_dict[str(pot_cp_agent)][0]/float(np.sum(agent.reputations_dict[str(pot_cp_agent)][1]))))
                                        print(' exp cp p_fb =', np.sum(agent.reputations_dict[str(pot_cp_agent)][2]/float(np.sum(agent.reputations_dict[str(pot_cp_agent)][3]))))
                                    # pause()

                            if len(pot_cps) > 0:

                                max_exp_return = np.max(exp_returns_array_pos)

                            else:

                                max_exp_return = -1

                            # expected mean return on own square
                            # print('\n exp_returns_array_pos', exp_returns_array_pos)
                            # print('\n exp_returns_array', exp_returns_array)
                            if len (exp_returns_array_pos) > 0:
                                own_loc_exp_rtn = np.mean(exp_returns_array_pos)
                            else:
                                own_loc_exp_rtn = 0.0

                            if max_exp_return > 0:  # if none of the expected returns are positive then the agent won't want to interact

                                for cp_agent_index in range(len(exp_returns_array_pos)):

                                    #                                    print('\n poss cp =', pot_cps[cp_agent_index])
                                    #                                    print(' exp_return = ', exp_returns_array[cp_agent_index])
                                    #                                    print(' agent.exp_rtns_matrix[str(cp_agent)]', agent.exp_rtns_matrix[str(pot_cps[cp_agent_index])])

                                    if exp_returns_array_pos[cp_agent_index] == max_exp_return:
                                        cp_agent = pot_cps[cp_agent_index]

                            if print_fine_dets or print_model_2_dets or print_for_tracking or (cp_agent is not None and agent.expected_gains_dict[str(cp_agent)][0] != max_exp_return) or \
                                                                                              (cp_agent is not None and agent.expected_gains_dict[str(cp_agent)][0] < 0):
                                # or (max_exp_return > 0 and (agent.exp_int_gains_dict[str(cp_agent)][9] == 'trade' or agent.exp_int_gains_dict[str(cp_agent)][10] == 'trade')):

                                print('\n After potential cps have been considered:')
                                print('\n agent.home', agent.home)
                                print(' exp_returns_array', exp_returns_array)
                                print(' max_exp_return', max_exp_return)
                                print(' own_loc_exp_rtn', own_loc_exp_rtn)
                                print(' exp_cp_returns_array', exp_cp_returns_array)
                                print('\n resulting cp_agent is', cp_agent)

                                if cp_agent is not None:
                                    print('\n agent.expected_gains_dict[str(cp_agent)] =', agent.expected_gains_dict[str(cp_agent)])

                        elif respect_property_rights == 1 or use_original_model_struct == 1:

                            # select a counterparty from the list
                            cp_agent = random.choice(agent_crop_list)

                            if print_fine_dets == 1:
                                print('\n*** there is more than one agent on agent.location ***')
                                print(' agent.ignore_agents_array =', agent.ignore_agents_array)
                                print('\nlen(agent_crop_list) =', len(agent_crop_list))
                                print('cp_agent =', cp_agent)
                                print('\n**** agents at same location ****')
                                print('\nchosen agent =', cp_agent)

                        if params.calc_timings:
                            dbs.timings_dict['trading_move_agent_eval_exp_gains_own_square'][day] += dt.datetime.now() - len_acl_start_time

                        # the following method manages the agent interaction and returns an array with 4 elements:
                        # ret_array[0] is an array of agents to remove; ret_array[1] the number of transactions;
                        # ret_array[2] is an array of the resources traded in the interaction; and [3] is the
                        # transaction number(s) asigned to the transaction(s).

                        here = 0

                        if move >= const_mkt_opens and cp_agent is not None:  # here we allow for the market not opening until a certain move, which occurs when weare testing different market constitutions
                            # the 'is not None' part of this deals with the possibility that when respect_property_rights == 1 there might be no cp the agent wants to interact with (exp return < 0)

                            if params.calc_timings:
                                agents_interact_start_time = dt.datetime.now()

                            if print_for_tracking:

                                print('\n Two agents now interact: agent', agent, 'and', 'cp_agent', cp_agent)

                            # if day > 100:
                            #
                            #     print('\n agent', agent.MRS_array)
                            #     print(' agent.agent_res_array', agent.agent_res_array)
                            #     print(' agent.basket_array', agent.basket_array)
                            #     print(' agent total res', agent.basket_array + agent.agent_res_array)
                            #     print('\n cp_agent', cp_agent.MRS_array)
                            #     print(' cp_agent.agent_res_array', cp_agent.agent_res_array)
                            #     print(' cp_agent.basket_array', cp_agent.basket_array)
                            #     print(' cp_agent total res', cp_agent.basket_array + cp_agent.agent_res_array)
                            #     print('\n agent.can_trade: ', agent.can_trade)

                            remove_agents, numb_trans, res_traded, trans_numbs, fight_num = agent_population.agents_interact(params, fountain_population, agent, cp_agent, day, town_grid, move, dbs, price_mean, force_prices, fixed_price,
                                                                                                                             print_dets, respect_property_rights, adjust_props_r, fight_cost, agent_intn_beta, num_rounds, print_fine_dets,
                                                                                                                             prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, fight_balance, len_reputations_mem,
                                                                                                                             intn_error_std, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt, trade_when_trgt,
                                                                                                                             track_agent,
                                                                                                                             trgt_sel, trade_moves, granular_mem, wait_at_tgt_moves, ststst, agree_location, formal_inst, prob_fine, fine,
                                                                                                                             print_agents_interact, fight_skill, fix_ps_fb_0, two_tribes_inst, strat_choice, stranger_int, strangers_if_unknown)

                            # if numb_trans != 0 and day > 100:
                            #
                            #     print('numb_trans:', numb_trans)
                            #     print('res_traded:', res_traded)
                            #     print('trans_numbs:', trans_numbs)
                            #
                            #     pause()

                            # if print_fine_dets == 1:

                            # Add 1 to each agent's num_act_transs[day] to record actual transactions, whether or not successful
                            #                        if numb_trans > 0:
                            agent.num_act_transs[day] += 1
                            cp_agent.num_act_transs[day] += 1

                            # if the agents are trading on the way to target, they must ignore their counterpart until they get to target.
                            # they will also ignore each other if they are wondering around randomly and have traded
                            if trade_when_trgt == 0 and agent.reached_trgt == 0:
                                agent.ignore_agents_array.append(cp_agent)
                                cp_agent.ignore_agents_array.append(agent)

                            if agent.trade_movemnt == 'random' and cp_agent not in agent.ignore_agents_array:
                                agent.ignore_agents_array.append(cp_agent)

                            if cp_agent.trade_movemnt == 'random' and agent not in cp_agent.ignore_agents_array:
                                cp_agent.ignore_agents_array.append(agent)

                            # append daily_succ_trans with all trans_num
                            for trans_num in trans_numbs:
                                daily_succ_trans.append(trans_num)

                            if fight_num is not None:
                                daily_fights.append(fight_num)

                            # post-interaction, there are three scenarios: (i) no transaction; (ii) transaction with one
                            # agent removed; and (iii) transaction with both removed:
                            if numb_trans > 0:
                                # update the town_grid.all_trans_array
                                x_coord = agent.location[0]
                                y_coord = agent.location[1]
                                town_grid.all_trans_array[day][x_coord][y_coord] += numb_trans

                                # register transaction in this database too
                                dbs.transactions_record[x_coord][y_coord][day] += 1

                                # update last_transaction for both
                                agent.last_transaction = move
                                cp_agent.last_transaction = move

                            if params.calc_timings:
                                dbs.timings_dict['trading_move_agent_agents_interact'][day] += dt.datetime.now() - agents_interact_start_time

                    #                        print_fine_dets = 0
                    #                        pause()

                    # agent will look to its neighbouring squares if it can trade when not at target, there are no agents to trade with on own square and if it hasn't already reached its target; or
                    # the agent has no memory so it's moving randomly
                    # note this is only for when agents respect property rights - we create a different approach for when they don't below
                    elif (respect_property_rights == 1 and len(agent_crop_list) == 0 and ((trade_when_trgt == 0 and agent.reached_trgt == 0) or agent.trade_movemnt == 'random')) or (
                            respect_property_rights == 0 and use_original_model_struct == 1):

                        if print_dets or print_for_tracking:

                            print('\n\n *** no cp_agents on same grid square ***')
                            print('\n ** checking if any cp_agents are near to the subject agent **')

                        if print_dets:

                            print('\n agent.can_trade =', agent.can_trade)
                            print(' agent.location =', agent.location)
                            print(' agent.grid_trgt =', agent.grid_trgt)

                        # We run a function called find_nearby_agent() in order to find the agents not on same square but within sight (and the agent can trade with)
                        nearby_agents, best_cp_agent = find_nearby_agents(print_dets, print_fine_dets, dbs, town_grid, agent, goods_signal, trade_prices, agent_population, day, trade_when_trgt)

                        if print_fine_dets or print_for_tracking:
                            print('\n\n --> summary after checking if agents nearby')
                            print('\n nearby_agents =', nearby_agents)

                        if print_fine_dets:

                            print('\n agent.trade_loc_rec =\n')

                            for mo in np.arange(len(agent.trade_loc_rec)):
                                print(agent.trade_loc_rec[mo])

                            print(agent.location, '<-- agent.location')
                            print('\n agent.trgt_loc_rec =\n')

                            for mo in np.arange(len(agent.trgt_loc_rec)):
                                print(agent.trgt_loc_rec[mo])

                            print(agent.grid_trgt, '<-- agent.grid_trgt =')
                            print('\n agent.home =', agent.home)
                            print(' agent.location =', agent.location)

                        if len(nearby_agents) > 0:  # there are agents nearby... the agent moves

                            if print_fine_dets or print_for_tracking:
                                print('\n randomly chosen best_cp_agent =', best_cp_agent)
                                print('\n pre agent.location =', agent.location)
                                print(' best_cp_agent.location =', best_cp_agent.location)
                                print(' agent =', agent)

                            # we want to remove the agent from its current location and then place him on the new location
                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].remove(agent)

                            # copy the neighbour's location in to the agent's
                            agent.location = copy.copy(best_cp_agent.location)

                            # Now we place the agent on the new location
                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].append(agent)

                            if print_fine_dets or print_for_tracking:
                                print('\n post agent.location =', agent.location)

                            # if it happens to be the case the agent moves on to its target location when moving on to a cp_agent's square, we must do the following:
                            if agent.location[0] == agent.grid_trgt[0] and agent.location[1] == agent.grid_trgt[1]:
                                agent.reached_trgt = 1
                                agent.reached_tgt_on_move = move

                                # we set ignore_agents_array to blank - agent can now trade with whomever
                                agent.ignore_agents_array = []

                        elif len(nearby_agents) == 0:

                            if print_fine_dets or print_for_tracking:

                                print('\n\n *** Agent is trading on way to target but hasnt reached it yet and there was nobody to play with')
                                print('\n agent.reached_trgt =', agent.reached_trgt)

                            # we want to remove the agent from its current location and then place him on the new location
                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].remove(agent)

                            # This function changes the agent's location, depending on its target and how full squares are in
                            # town_grid.grid.  If the agent's grid_trgt is within reach this function also sets agent.can_trade = 1
                            # whether the agent moves on to that square or not (i.e. if the target square is full then
                            # agent.can_trade = 1).
                            agent.choose_new_loc(town_grid, print_dets, print_fine_dets, trade_movemnt, move, day, trade_when_trgt, trade_moves, wait_at_tgt_moves, dbs, respect_property_rights, trade_at_trgt_precise)

                            here = 0

                            # Now we place the agent on the new location
                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].append(agent)

                    # when the agents dont respect property rights and the agent doesn't want to interact with any agent on own square (or there are none)
                    if respect_property_rights == 0 and cp_agent is None:

                        if print_for_tracking:

                            print('\n There are no other agents to interact with - agent now evaluates all squares in its vicinity')

                        if params.calc_timings:
                            eval_all_grid_sqs_start = dt.datetime.now()

                        ##                        print('\n respect_property_rights == 0 and cp_agent is None, agents_nearby ', agents_nearby, 'location =', agent.location)
                        #
                        #                        if (agents_nearby == 0 or print_model_2_dets == 1) and day > 0 and agent.trade_movemnt == 'set':
                        #
                        #                            for i in range(-1, 2):
                        #                                for j in range(-1, 2):
                        #
                        #                                    x_coord = (agent.location[0] + i) % town_grid.dimen
                        #                                    y_coord = (agent.location[1] + j) % town_grid.dimen
                        #
                        #                                    if (i == 0 and j == 0) == False and len(town_grid.grid_agents[x_coord][y_coord]) > 0:
                        #
                        #                                        agents_nearby = 1
                        #
                        #                                    if i == 0 and j == 0 and len(town_grid.grid_agents[x_coord][y_coord]) > 1:
                        #
                        #                                        agents_nearby = 1

                        #                        if print_model_2_dets == 0:
                        #                            agents_nearby = 0
                        #                        else:
                        #                            agents_nearby = 1

                        exp_returns_array, max_mean_exp_return, max_grid_square, number_neighbours, neigh_exp_returns_array, head_to_target = \
                            agent.evaluate_exp_rtns_all_grid_sqs(params, town_grid, own_loc_exp_rtn, exp_cp_returns_array_pos, agent_population, print_dets, price_mean, force_prices, fixed_price, day,
                                                                 move, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std, print_fine_dets,
                                                                 agent_avoid_muggers, fight_balance, adjust_props_r, agent_intn_beta, two_tribes, formal_inst,
                                                                 prob_fine, fine, fight_skill, fix_ps_fb_0, two_tribes_inst, strat_choice, stranger_int, strangers_if_unknown,
                                                                 respect_property_rights, trade_when_trgt, track_agent)

                        if print_fine_dets or print_for_tracking:
                            print('\n\n\n Result of having evaluated local squares: \n\n agent.home', agent.home, 'day', day, 'move', move)
                            print('\n number_neighbours', number_neighbours)
                            print(' current location', agent.location)
                            print(' max_grid_square', max_grid_square)
                            print(' exp_returns_array:\n', exp_returns_array)
                            print(' max_mean_exp_return', max_mean_exp_return)
                            print(' neigh_exp_returns_array \n', neigh_exp_returns_array[0], '\n', neigh_exp_returns_array[1], '\n', neigh_exp_returns_array[2])
                            print(' head_to_target =', head_to_target)
                            print(' agent.trade_movemnt', agent.trade_movemnt)

                        # we don't want the agent to head to target if it is wandering around randomly
                        if agent.trade_movemnt != 'set':
                            head_to_target = 0

                        # if there are no agents in sight then the problem is simple: we just move the agent as in the case of respecting property rights
                        if head_to_target == 1:

                            if print_for_tracking:
                                print('\n agent chooses a new location')
                                print('\n prior location = ', agent.location)

                            if (print_fine_dets or print_model_2_dets == 1):  # and ((agent.location[0] == agent.grid_trgt[0] and agent.location[1] == agent.grid_trgt[1]) is False):

                                print('\n number_neighbours =', number_neighbours)
                                print('\n we call agent.choose_new_loc  |  agent.trade_movemnt ', agent.trade_movemnt)
                                print('\n trade_movemnt', trade_movemnt)
                                print(' trade_when_trgt', trade_when_trgt)
                                print('\n agent.trade_movemnt', agent.trade_movemnt)
                                print('\n prior location = ', agent.location)

                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].remove(agent)

                            agent.choose_new_loc(town_grid, print_dets, print_fine_dets, trade_movemnt, move, day, trade_when_trgt, trade_moves, wait_at_tgt_moves, dbs, respect_property_rights, trade_at_trgt_precise)

                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].append(agent)

                        else:

                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].remove(agent)

                            agent.location = copy.copy(max_grid_square)

                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].append(agent)

                            # it's possible that this max_grid_square is the target location
                            if agent.location[0] == agent.grid_trgt[0] and agent.location[1] == agent.grid_trgt[1]:

                                if print_fine_dets:
                                    print('\n agent hit target!')

                                agent.can_trade = 1
                                agent.reached_trgt = 1
                                agent.reached_tgt_on_move = move

                        if print_fine_dets or print_for_tracking:
                            print('\n head_to_target =', head_to_target)
                            print(' day', day, 'move', move)
                            print(' resulting agent.loction', agent.location)
                            print(' agent.grid_trgt', agent.grid_trgt)
                            # pause()

                        if params.calc_timings:
                            dbs.timings_dict['trading_move_agent_eval_all_grid_sqs'][day] += dt.datetime.now() - eval_all_grid_sqs_start

                    if print_fine_dets == 1:
                        print('\n\n trade_movemnt =', trade_movemnt, '  |  move =', move, '  |  agent.reached_tgt_on_move =', agent.reached_tgt_on_move, '  |  agent.wait_at_tgt_moves_pro_rata =', agent.wait_at_tgt_moves_pro_rata,
                              '  |  moves left until shift:', agent.reached_tgt_on_move + 1 + agent.wait_at_tgt_moves_pro_rata - move)
                        print('\n agent.can_trade: ', agent.can_trade)

                    # If the agent has been waiting at the target location for a while and we haven't designated that it must wait til the end, and it is time to move... (note we don't move the agent until the next move)
                    if (agent.grid_trgt[0] == agent.location[0] and agent.grid_trgt[1] == agent.location[1]) and \
                            wait_at_target_til_end == 0 and trade_movemnt == 'set' and move != town_grid.trade_moves - 1 and move == agent.reached_tgt_on_move + 1 + agent.wait_at_tgt_moves_pro_rata:  # and agent.last_transaction - move > 10:

                        if params.calc_timings:
                            retarget_start = dt.datetime.now()

                        # before retargeting we must pro rata the wait_at_target value:

                        agent.wait_at_tgt_moves_pro_rata = math.ceil(wait_at_tgt_moves * ((trade_moves - move) / float(trade_moves)))

                        if print_fine_dets == 1:
                            print('trade_moves', trade_moves, 'agent.wait_at_tgt_moves_pro_rata', agent.wait_at_tgt_moves_pro_rata)

                        set_agent_target(params, respect_property_rights, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt, trade_when_trgt, dbs, track_agent, agent, day,
                                         town_grid, trgt_sel, trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, retarg=1, move=move, has_acted=1,
                                         print_dets=0, print_fine_dets=0, agree_location=agree_location, adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta,
                                         formal_inst=formal_inst, prob_fine=prob_fine, fine=fine, fight_skill=fight_skill, strat_choice=strat_choice, stranger_int=stranger_int,
                                         two_tribes_inst=two_tribes_inst, strangers_if_unknown=strangers_if_unknown)

                        # can_trade is only 0 after the start of the trading phase and before the agent reaches its target (or is intercepted) so here it is set = 1
                        agent.can_trade = 1
                        agent.reached_tgt_on_move = 0

                        # agent.reached_trgt is 0 when agent is heading to target and 1 after it has reached it, unless moving randomly
                        if agent.trade_movemnt == 'set' and trade_when_trgt == 1 and (agent.grid_trgt[0] == agent.location[0] and agent.grid_trgt[1] == agent.location[1]) == False:

                            agent.reached_trgt = 0

                        else:

                            agent.reached_trgt = 1

                        # We want to remove the agent from its current location and then place it on the new location
                        x_coord = agent.location[0]
                        y_coord = agent.location[1]
                        town_grid.grid_agents[x_coord][y_coord].remove(agent)

                        # The agent moves - to get to this stage trade_movemnt == 'set' only so we don't move the
                        # agent randomly
                        agent.choose_new_loc(town_grid, print_dets, print_fine_dets, trade_movemnt, move, day, trade_when_trgt, trade_moves, wait_at_tgt_moves, dbs, respect_property_rights, trade_at_trgt_precise)

                        # Now we place the agent on the new location
                        x_coord = agent.location[0]
                        y_coord = agent.location[1]
                        town_grid.grid_agents[x_coord][y_coord].append(agent)

                        if print_fine_dets == 1:
                            print('\n post agent.location =', agent.location)

                        if params.calc_timings:
                            dbs.timings_dict['trading_move_agent_retargetting'][day] += dt.datetime.now() - retarget_start

                #                if print_fine_dets == 1:
                #
                #                    print('\n\n lok at list locs - end')
                #
                #                    for trad_agent in dbs.agent_list:
                #
                #                        print('trad_agent ', trad_agent, 'loc ', trad_agent.location)

                # we update two records of the agent in order for us to track its movement and its target over the trade moves
                agent.trade_loc_rec.append(copy.copy(agent.location))
                agent.trgt_loc_rec.append(copy.copy(agent.grid_trgt))

                if print_fine_dets:
                    print('\n end move agent.can_trade: ', agent.can_trade)

                if print_for_tracking:

                    print('\n END of agent move\n\n')
                    # pause()

                if move in params.show_res_conc_charts and day % params.heatmap_days_show == 0:
                    agent.total_res_held_moves.append(np.sum(agent.basket_array))

            if print_model_2_dets == 1:

                town_grid_count = np.zeros(shape=(town_grid.dimen, town_grid.dimen))

                for x_coord in range(town_grid.dimen):
                    for y_coord in range(town_grid.dimen):
                        town_grid_count[x_coord][y_coord] = len(town_grid.grid_agents[x_coord][y_coord])

                create_heat_map(town_grid.dimen, town_grid_count, run_folder, 'Blues', '', 'move_locs_day_%d_move_%d' % (day, move), dpi='low')

        #                if print_fine_dets == 1 or print_dets == 1 or print_model_2_dets == 1:
        #
        #                    pause()


        # this marks the end of the agent iterations over this one move i.e. we have iterated over all agents

        if print_fine_dets == 1:
            print('\n************************ End of move', move, 'of [', town_grid.trade_moves - 1, '] ************************')
            print('len(dbs.agent_list) =', len(dbs.agent_list))
            # pause()

        #        if print_fine_dets == 1:
        #            print('\npost-rem dbs.agent_list =', dbs.agent_list)
        #            print('len(dbs.agent_list) =', len(dbs.agent_list))

        # Print move-by-move heatmaps if required
        if print_move_heat_maps or (params.track_agent and params.track_agent <= day):

            grid_count = np.zeros(shape=(town_grid.dimen, town_grid.dimen))

            for x_coord in np.arange(town_grid.dimen):
                for y_coord in np.arange(town_grid.dimen):
                    grid_count[x_coord][y_coord] = len(town_grid.grid_agents[x_coord][y_coord])

            title = 'Agent locations at end of round %s, move %s' % (day, move)
            create_heat_map(town_grid.dimen, grid_count, df_daily, 'Blues', title, 'num agent', dpi='low')

            if (params.track_agent and params.track_agent <= day):

                if agent_population.tracking_agent.grid_trgt[0] is not None:
                    dist_to_target = abs_dist_on_torus(agent_population.tracking_agent.location, agent_population.tracking_agent.grid_trgt, town_grid.dimen)
                    travel_dist = np.max(dist_to_target)

                else:
                    travel_dist = 'random walk'

                print(' tracking_agent.location ', agent_population.tracking_agent.location, 'versus target ', agent_population.tracking_agent.grid_trgt, 'dist \t\t\t', travel_dist)

        # Add agents' MRS data to MRS_moves_array (so we can see MRS through all moves)
        if print_MRS_daily_charts:

            for agent in dbs.agent_list:

                # for res_1 in np.arange(num_res_founts):
                #     for res_2 in np.arange(num_res_founts):
                #
                #         if res_1 != res_2:
                #             dbs.MRS_moves_array[res_1][res_2][move + 1].append(agent.MRS_array[res_1][res_2])

                agent_num = MRS_array_dict[str(agent.home)]

                dbs.MRS_moves_array_2[agent_num][move + 1] = agent.MRS_array[0][1]

        #### This is the end of a move iteration ####

    # if we are plotting resource concentration charts:
    if len(params.show_res_conc_charts) > 0 and day % params.heatmap_days_show == 0:

        # for all days:
        rc_sub_folder = "%s/day_%d" % (dbs.rc_sub_folder, day)
        if os.path.exists(rc_sub_folder) == False:
            os.makedirs(rc_sub_folder)

        res_conc_movie_data = []
        res_conc_movie_data_labels = []
        x_axis_titles = []

        counter = 0
        for move in params.show_res_conc_charts:

            # first, create basic histograms
            histogram_conc_data = np.zeros(shape=len(dbs.agent_list), dtype=float)

            ag_num = 0
            for ag in dbs.agent_list:
                histogram_conc_data[ag_num] = ag.total_res_held_moves[counter]
                ag_num += 1

            histogram_conc_data.sort()

            res_conc_movie_data.append(histogram_conc_data)

            if counter == 0:
                res_conc_movie_data_labels.append('Start')
                x_axis_titles.append('gini = %1.3f' % gini(histogram_conc_data))
            elif counter == 1:
                res_conc_movie_data_labels.append('Middle')
                x_axis_titles.append('gini = %1.3f' % gini(histogram_conc_data))
            elif counter == 2:
                res_conc_movie_data_labels.append('End')
                x_axis_titles.append('gini = %1.3f' % gini(histogram_conc_data))

            # print('\n histogram_conc_data =', histogram_conc_data)
            # we can now create a simple 2-d histogram
            create_plotly_2d_histogram(input_data=histogram_conc_data, x_data=np.arange(len(dbs.agent_list)), folder=rc_sub_folder, filename='res_conc_move_%d' % move)

            counter += 1

        res_conc_movie_data = np.array(res_conc_movie_data)

        # now for movie chart
        create_plotly_2d_histogram(input_data=res_conc_movie_data, x_data=np.arange(len(dbs.agent_list)), folder=rc_sub_folder, filename='movie', labels=res_conc_movie_data_labels, x_axis_titles=x_axis_titles)

    # now we update the gini coefficient for resource holdings at the end of the trading phase
    gini_array = np.zeros(shape=len(dbs.agent_list))

    ag_counter = 0
    for ag in dbs.agent_list:
        tot_res = np.sum(ag.basket_array)
        gini_array[ag_counter] = tot_res

        ag_counter += 1

    gini_array.sort()

    gini_day_val = gini(gini_array)

    dbs.res_conc_gini[day] = gini_day_val

    for ag in dbs.agent_list:
        # record the agent's history of moves in this array Agent
        ag.hist_trade_loc_rec[day] = copy.copy(ag.trade_loc_rec)

    #        if (day + 1) % SD_charts_freq == 0:
    #
    #            print('agent', ag, 'agent.trade_loc_rec', ag.trade_loc_rec)

    # Update dbs.transs_daily_db with daily transaction data
    dbs.transs_daily_db[day] = daily_succ_trans
    dbs.fights_daily_db[day] = daily_fights

    # if we want to track the agent MRSs at the beginning and end of rounds, we must record the data:
    if print_MRS_std_charts == 1:

        for res_1 in np.arange(num_res_founts):

            for res_2 in np.arange(num_res_founts):

                if res_1 != res_2:

                    MRS_scatter_db_start = []
                    MRS_scatter_db_end = []

                    for agent in dbs.agent_list:
                        MRS_scatter_db_start.append(agent.MRS_history[day][res_1][res_2])
                        MRS_scatter_db_end.append(agent.MRS_array[res_1][res_2])

                    start_std = np.std(MRS_scatter_db_start)
                    end_std = np.std(MRS_scatter_db_end)

                    dbs.MRS_STDs_array[res_1][res_2][0][day] = start_std
                    dbs.MRS_STDs_array[res_1][res_2][1][day] = end_std

    # Update dbs.net_transs_db, which is used to create some charts
    dbs.update_net_transs_db(params, day, print_dets, print_fine_dets, fountain_population, agent_population, town_grid, daily_succ_trans, two_tribes, respect_property_rights)

    # If we're allowing prices to vary then we will print the supply & demand curves.  Here we combine the
    # supply_demand_data array and the average price and total quantity data.
    if SD_charts_freq > 0:

        if print_MRS_std_charts or print_MRS_daily_charts:

            create_supply_demand_charts(params, num_res_founts, supply_demand_array, fountain_population, agent_population, print_dets, print_fine_dets, params.run_periodic_day_charts_folder, day, dbs, rounds, trade_moves, SD_charts_freq, daily_succ_trans, pop='all')

            # if two_tribes:
            #     create_supply_demand_charts(params, supply_demand_array_sharks, fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, rounds, trade_moves, SD_charts_freq, daily_succ_trans, pop='sharks')
            #
            #     create_supply_demand_charts(params, supply_demand_array_jets, fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, rounds, trade_moves, SD_charts_freq, daily_succ_trans, pop='jets')

    if print_fine_dets == 1:
        print('\n\n----------> at the end of trading, trade_tally = ')
        print('\ndbs.agent_list =', dbs.agent_list)
        print('\nlen(dbs.agent_list) =', len(dbs.agent_list))

    # if we print daily data, here we print 3 text files
    if print_round_trans != 0 and (day + 1) % print_round_trans == 0:
        # write successful transactions data
        write_succ_trans_data(day, town_grid, print_dets, df_daily, daily=1, daily_db=daily_succ_trans)

    if print_dets == 1:
        print('\n***************** END OF TRADING ******************\n')


def create_supply_demand_data(params, fountain_population, agent_population, print_dets, print_fine_dets, data_folder, day, dbs, gen_equ_thresh, agent_list, record_dbs_data, tribe):
    """This function creates the data for the supply and demand charts when we have 2 resources.  This data has
    to be created at the beginning of agents_trading since we want data prior to any transactions.  But we need to overlay
    the actual trading data (average transaction price and total quantity), which can only be known after trading.  So we
    create some of the data here."""

    #    here = 0

    # if day >= 0:
    #     print_fine_dets = 1

    #    if day == 100:
    #        print_fine_dets = 1

    # We default to 20 price points (so there are 19 gaps)
    num_price_points = 20

    # Data for res_1 versus combined resources
    supply_demand_array = []
    for k in np.arange(num_res_founts):
        supply_demand_array.append([])

    price_points_array = np.zeros(shape=(num_res_founts, num_price_points))

    for agent in agent_list:

        tot_res = agent.agent_res_array + agent.basket_array

        agent.MRS_array_tot_res = generate_MRS_array(tot_res, print_fine_dets=0)

    if params.write_detailed_S_D_data and params.write_detailed_S_D_data[0] <= day < params.write_detailed_S_D_data[1]:

        text = "\nDay %d\n" % day
        with open(dbs.daily_S_D_data, 'a') as myfile:
            myfile.write(text)

        if print_fine_dets == 1:
            print('text', text)

    # First create the price points and put them in price_points_array
    # for res_1 in np.arange(num_res_founts):
    #
    #     for other_res in np.arange(num_res_founts):
    #
    #         if other_res != res_1:

    if print_fine_dets == 1:
        print('\nFind high and low prices: res_1 %d / res_2 %d' % (0, 1))

    # Find the highest and lowest possible prices - start with res 0 / res 1; and then use inversions of highest and lowest for res 1 / res 0
    highest_price = 0.0
    lowest_price = 100.0

    for agent in agent_list:

        if agent.MRS_array_tot_res[0][1] > highest_price:

            highest_price = agent.MRS_array_tot_res[0][1]

            if print_fine_dets == 1:
                print('\nagent.MRS_array_tot_res =\n', agent.MRS_array_tot_res)
                print('\nagent.MRS_array_tot_res[0][1] =', agent.MRS_array_tot_res[0][1])
                print('highest_price at this stage =', highest_price)

        if agent.MRS_array_tot_res[0][1] < lowest_price:

            lowest_price = agent.MRS_array_tot_res[0][1]

            if print_fine_dets == 1:
                print('\nagent.MRS_array_tot_res =\n', agent.MRS_array_tot_res)
                print('\nagent.MRS_array_tot_res[0][1] =', agent.MRS_array_tot_res[0][1])
                print('lowest_price at this stage =', lowest_price)

    price_points_0_1 = np.linspace(lowest_price, highest_price, num_price_points)
    price_points_array[0] = price_points_0_1

    price_points_1_0 = np.linspace(1 / float(highest_price), 1 / float(lowest_price), num_price_points)
    price_points_array[1] = price_points_1_0

    if print_fine_dets == 1:
        print('\n FINAL highest_price =', highest_price)
        print(' FINAL lowest_price =', lowest_price)
        print('\n ending price_points =', price_points_0_1)

        #        if res_1 == 0:

    # record the resource's highest price (note this is a working price but we want the highest chart price so we take the lowest working price)
    fountain_population.pop[0].highest_prices[day] = lowest_price

    if print_fine_dets == 1:
        print('\nprice_points_array =\n', price_points_array)

        # pause()

    # record each agent's supply of / demand for both resources
    if params.write_detailed_S_D_data and params.write_detailed_S_D_data[0] <= day < params.write_detailed_S_D_data[1]:

        for agent in agent_list:

            agent.supply_of_A = np.zeros(shape=num_price_points, dtype=float)
            agent.demand_for_A = np.zeros(shape=num_price_points, dtype=float)
            agent.supply_of_B = np.zeros(shape=num_price_points, dtype=float)
            agent.demand_for_B = np.zeros(shape=num_price_points, dtype=float)

    # In the 2d charts we allow the price between 2 resources to vary and we assume that the prices of all the other resource
    # combinations is equal to the expected prices contained in exp_prices_array.
    for res_1 in [0, 1]:

        if res_1 == 0:

            other_res = 1

        elif res_1 == 1:

            other_res = 0

        # unpack relevant price points
        price_points = price_points_array[res_1]

        # Create an array to record the chart data (all non-res_1 resources) & populate with price points. [0] is supply,
        # [1] is demand.
        S_D_charts_array = np.zeros(shape=(3, len(price_points)))
        S_D_charts_array[0] = price_points

        # Iterate through all the price points
        for price_index in np.arange(num_price_points):

            # create counters for total supply & demand
            total_supply = 0
            total_demand = 0

            # unpack price
            price = price_points[price_index]

            # if res_1 == 0 and other_res == 1:
            #     agent_supply_data[0].append(price)

            # # write to text file
            # text = "%5.5s\t" % price
            # with open(dbs.agent_summary_notes_file, 'a') as myfile:
            #     myfile.write(text)

            if print_fine_dets == 1:
                print('\n\n\n\n\nprice =', price, '\n')

            for agent in agent_list:  # these are the agents with resources (don't need those without)

                if agent.basket_array[0][0] > 0 or agent.basket_array[0][1] > 0:

                    agent.aggr_res_array = agent.agent_res_array + agent.basket_array

                    if print_fine_dets == 1:
                        print('\n\nagent =', agent, 'home', agent.home)

                    MRS = agent.MRS_array_tot_res[res_1][other_res]

                    if print_fine_dets == 1:
                        print('\n--> res_1 =', res_1, 'other_res =', other_res)
                        print('agent.MRS_array_tot_res:\n', agent.MRS_array_tot_res)
                        print('MRS =', MRS)
                        print('price =', price)

                    if MRS > price:  # then the agent will supply res_1

                        tot_Q = Q_at_price(res_1, other_res, price, agent.aggr_res_array)
                        agent_holding = agent.basket_array[0][res_1]

                        # For single res:
                        max_supply = np.min([agent_holding, tot_Q])

                        if print_fine_dets == 1:
                            print('\n MRS > price')
                            print(' agent.basket_array =', agent.basket_array)
                            print(' agent.aggr_res_array =', agent.aggr_res_array)
                            print(' tot_Q (would supply, without constraints) =', tot_Q)
                            print(' would buy (other res), without constraints =', tot_Q / price)
                            print(' agent_holding =', agent_holding)
                            print(' max_supply (min of agent_holding and tot_Q) =', max_supply)

                        total_supply += max_supply

                        if params.write_detailed_S_D_data and params.write_detailed_S_D_data[0] <= day < params.write_detailed_S_D_data[1]:
                            if res_1 == 0:
                                agent.supply_of_A[price_index] = max_supply
                            else:
                                agent.supply_of_B[price_index] = max_supply

                    elif MRS < price:  # then the agent will demand res_1

                        # use a substitute price
                        subst_price = 1.0 / price

                        # note we switch the resources - this gives us a preferred supply of other_res
                        tot_Q = Q_at_price(other_res, res_1, subst_price, agent.aggr_res_array)
                        agent_holding = agent.basket_array[0][other_res]

                        # For single res, the amount demanded (other_res) would be constrained by the agent's holding of res_1
                        max_supply_other_res = np.min([agent_holding, tot_Q])
                        max_demand = max_supply_other_res * price

                        total_demand += max_demand

                        if params.write_detailed_S_D_data and params.write_detailed_S_D_data[0] <= day < params.write_detailed_S_D_data[1]:
                            if res_1 == 0:
                                agent.demand_for_A[price_index] = max_demand
                            else:
                                agent.demand_for_B[price_index] = max_demand

                        if print_fine_dets == 1:
                            print('\n MRS < price so agent would buy res', res_1, 'if it had holdings of res', other_res)
                            print(' agent.basket_array =', agent.basket_array)
                            print(' agent.aggr_res_array =', agent.aggr_res_array)
                            print(' tot_Q =', tot_Q)
                            print(' price =', price)
                            print(' subst_price =', subst_price)
                            print(' agent_holding (other res) =', agent_holding)
                            print(' max_supply_other_res (min of agent_holding and tot_Q) =', max_supply_other_res)

                    elif MRS == price:

                        if print_fine_dets:
                            print('\n MRS == price so no supply or demand')

                else:

                    if print_fine_dets:
                        print('\n\n agent =', agent)
                        print('\n agent has no resources - no supply or demand')

                if print_fine_dets == 1:
                    print('\n total_supply now =', total_supply)
                    print(' total_demand now =', total_demand)

                # This is the end of the agent iterations

            # if print_fine_dets:
            #     pause()

            S_D_charts_array[1][price_index] = total_supply
            S_D_charts_array[2][price_index] = total_demand

            # if res_1 == 0 and other_res == 1:
            #     agent_supply_data[1].append(total_supply)
            #     agent_supply_data[2].append(total_supply)

        supply_demand_array[res_1] = S_D_charts_array

        # write to text file - this is the aggregate supple / demand data
        if params.write_detailed_S_D_data and params.write_detailed_S_D_data[0] <= day < params.write_detailed_S_D_data[1]:

            if res_1 == 0:
                text_res_0 = 'A'
                text_res_1 = 'B'

            else:
                text_res_0 = 'B'
                text_res_1 = 'A'

            text = "\nMRS (%s/%s)\tSupply %s\t Demand %s\n\n" % (text_res_0, text_res_1, text_res_0, text_res_0)
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

            if print_fine_dets == 1:
                print('text', text)

            for line in np.arange(1, num_price_points + 1):

                inv_line = line * -1

                text = "%5.5s\t\t%5.5s\t\t%5.5s\n" % (S_D_charts_array[0][inv_line], S_D_charts_array[1][inv_line], S_D_charts_array[2][inv_line])
                with open(dbs.daily_S_D_data, 'a') as myfile:
                    myfile.write(text)

                if print_fine_dets == 1:
                    print('text', text)

            text = "\n"
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

    # now write to file the breakdown of agent supply / demand of / for either resource
    if params.write_detailed_S_D_data and params.write_detailed_S_D_data[0] <= day < params.write_detailed_S_D_data[1]:

        text = "\nBeakdown of Supply / Demand by agent\n\n"
        with open(dbs.daily_S_D_data, 'a') as myfile:
            myfile.write(text)

        for res_1 in np.arange(2):

            if res_1 == 0:
                res_2 = 1

            elif res_1 == 1:
                res_2 = 0

            if res_1 == 0:
                text = "Resource %d / Resource %d (Supply of and Demand for [in square brackets] Resource A)\n\n" % (res_1, res_2)
            else:
                text = "Resource %d / Resource %d (Supply of and Demand for [in square brackets] Resource B)\n\n" % (res_1, res_2)

            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

            text = "Agent (home):\t"
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

            for agent in agent_list:
                text = "[%d %d]\t\t" % (agent.home[0], agent.home[1])
                with open(dbs.daily_S_D_data, 'a') as myfile:
                    myfile.write(text)

            text = "\n\n"
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

            text = "Res\t\t"
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

            for agent in agent_list:
                text = "[%5.5s %5.5s]\t" % (agent.agent_res_array[0][0], agent.agent_res_array[0][1])
                with open(dbs.daily_S_D_data, 'a') as myfile:
                    myfile.write(text)

            text = "\n"
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

            text = "Bskt\t\t"
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

            for agent in agent_list:
                text = "[%d %d]\t\t" % (agent.basket_array[0][0], agent.basket_array[0][1])
                with open(dbs.daily_S_D_data, 'a') as myfile:
                    myfile.write(text)

            text = "\n"
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

            text = "MRS\t\t"
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

            for agent in agent_list:
                text = "%5.5s\t\t" % (agent.MRS_array_tot_res[res_1][res_2])
                with open(dbs.daily_S_D_data, 'a') as myfile:
                    myfile.write(text)

            text = "\n\nPrice\n\n"
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

            for line in np.arange(1, num_price_points + 1):

                price_index = line * -1

                text = "%5.5s\t\t" % (supply_demand_array[res_1][0][price_index])
                with open(dbs.daily_S_D_data, 'a') as myfile:
                    myfile.write(text)

                for agent in agent_list:

                    if res_1 == 0:
                        sup = agent.supply_of_A[price_index]
                        dem = agent.demand_for_A[price_index]

                    text = "%4.4s   [%4.4s]\t" % (sup, dem)
                    with open(dbs.daily_S_D_data, 'a') as myfile:
                        myfile.write(text)

                text = "\n"
                with open(dbs.daily_S_D_data, 'a') as myfile:
                    myfile.write(text)

            text = "\n\n\n"
            with open(dbs.daily_S_D_data, 'a') as myfile:
                myfile.write(text)

    # Here we will find the intersection of the S&D curves when we only have 2 resources
    net_demand_array = supply_demand_array[0][1] - supply_demand_array[0][2]
    price_points = supply_demand_array[0][0]

    if print_fine_dets == 1:
        print('\n net_demand_array \n', net_demand_array)

    max_boundary_p = 0.0
    min_boundary_p = 0.0
    tot_net_demand = 10.0
    while_loop_counter = 0

    while np.abs(tot_net_demand) > gen_equ_thresh:

        for price_point_ind in range(len(price_points) - 1):

            # We find the two prices below which and above which the intersection point lies
            if net_demand_array[price_point_ind] >= 0 and net_demand_array[price_point_ind + 1] <= 0:

                min_boundary_p = price_points[price_point_ind]
                max_boundary_p = price_points[price_point_ind + 1]

                mean_price = np.mean([max_boundary_p, min_boundary_p])

                # we now test whether this mean price is close enough to market clearing

                if print_fine_dets == 1:
                    print('\n\n while loop counter =', while_loop_counter)
                    print(' max_boundary_p', max_boundary_p)
                    print(' min_boundary_p', min_boundary_p)
                    print(' mean_price', mean_price)

                tot_demand, tot_supply = find_total_S_D(agent_list, dbs, day, agent_population, mean_price, res_1=0, res_2=1, print_fine_dets=0, find_optimals=0)

                tot_net_demand = tot_demand - tot_supply

                # we need to create new set of price_points for next while loop only if the while loop's condition still holds
                if np.abs(tot_net_demand) > gen_equ_thresh:

                    price_points = np.linspace(min_boundary_p, max_boundary_p, num_price_points)

                    if print_fine_dets == 1:
                        print('\n new price_points:\n', price_points)

                    for new_price_ind in range(num_price_points):

                        new_price = price_points[new_price_ind]

                        new_supply, new_demand = find_total_S_D(agent_list, dbs, day, agent_population, new_price, res_1=0, res_2=1, print_fine_dets=0, find_optimals=0)

                        net_demand_array[new_price_ind] = new_demand - new_supply

                        if print_fine_dets == 1:
                            print('\n new_price =', new_price)
                            print(' new_supply =', new_supply)
                            print(' new_demand =', new_demand)
                            print(' new_demand - new_supply =', new_demand - new_supply)

                    if print_fine_dets == 1:
                        print('\n net_demand_array =\n', net_demand_array)

                    while_loop_counter += 1

    # we need to set agent.optimal_transs_systemic[day] when we know the market clearing level of P & Q
    tot_demand, tot_supply = find_total_S_D(agent_list, dbs, day, agent_population, mean_price, res_1=0, res_2=1, print_fine_dets=0, find_optimals=1)

    #    print('\nday', day, 'Q =', np.mean([tot_demand, tot_supply]), 'P =', mean_price)

    turnover_res_0 = np.mean([tot_demand, tot_supply])
    turnover_res_1 = turnover_res_0 / mean_price  # it's x conventional price so divide by inverse price

    if record_dbs_data:

        dbs.optimal_price_array[day][0][1] = mean_price
        dbs.optimal_price_array[day][1][0] = 1 / float(mean_price)

        dbs.optimal_bskt_turnover[day] = np.array([turnover_res_0, turnover_res_1])

        dbs.optimal_bskt_errors[day] = np.array([tot_supply - tot_demand, (tot_demand - tot_supply) / mean_price])

        dbs.optimal_bskt_iters[day] = while_loop_counter

    if params.two_tribes:

        if tribe == 'sharks':

            dbs.optimal_price_array_sharks[day][0][1] = mean_price
            dbs.optimal_price_array_sharks[day][1][0] = 1 / float(mean_price)

            dbs.optimal_bskt_turnover_sharks[day] = np.array([turnover_res_0, turnover_res_1])

        elif tribe == 'jets':

            dbs.optimal_price_array_jets[day][0][1] = mean_price
            dbs.optimal_price_array_jets[day][1][0] = 1 / float(mean_price)

            dbs.optimal_bskt_turnover_jets[day] = np.array([turnover_res_0, turnover_res_1])

    # Here we invert the prices: above, res_0 is move valued the lower the price (equivalent to an appreciation).
    # For visual comfort we will invert the prices.
    # for res_1 in np.arange(num_res_founts):
    #
    #     for price_index in np.arange(num_price_points):
    #         price = S_D_charts_array[0][price_index]
    #
    #         inv_price = 1.0 / price
    #
    #         S_D_charts_array[0][price_index] = inv_price
    #
    #     supply_demand_array[res_1] = S_D_charts_array

    if print_fine_dets == 1:
        print('\n\n supply_demand_array[0]:\n\n', supply_demand_array[0])
        print('\n\n supply_demand_array[1]:\n\n', supply_demand_array[1])

        # pause()

    return supply_demand_array


def find_total_S_D(agent_list, dbs, day, agent_population, price, res_1, res_2, print_fine_dets, find_optimals):
    #    if find_optimals == 1:
    #
    #        print_fine_dets == 1

    if print_fine_dets == 1:

        print('\n agent_list:', agent_list)

        for agent in agent_list:
            print(' agent.home', agent.home, 'tribe', agent.tribe)

    def agent_S_D(agent):

        agent.aggr_res_array = agent.agent_res_array + agent.basket_array

        # MRS = agent.MRS_array[res_1][res_2]
        MRS = agent.MRS_array_tot_res[res_1][res_2]

        if print_fine_dets == 1:
            print('\n\n ----> find_total_S_D:\n agent', agent)
            print(' agent.MRS_array:\n', agent.MRS_array)
            print(' agent.MRS_array_tot_res:\n', agent.MRS_array_tot_res)
            print(' agent.agent_res_array:', agent.agent_res_array)
            print(' agent.basket_array: ', agent.basket_array)
            print(' MRS =', MRS)
            print(' price =', price)

        if MRS > price:  # then the agent will supply res_1

            tot_Q = Q_at_price(res_1, res_2, price, agent.aggr_res_array)

            agent_holding = agent.basket_array[0][res_1]
            max_supply = np.min([agent.basket_array[0][res_1], tot_Q])

            total_supply[0] += max_supply

            if print_fine_dets == 1:
                print('\n agent supplies', max_supply)

            if find_optimals == 1:
                agent.optimal_transs_systemic[day][0] = max_supply
                # note that when we use price_MRS we must divide by the price to get the amount of res 1 units in exchange for this res 0 supply
                # and we multiply by -1 to denote it's demanded not supplied
                agent.optimal_transs_systemic[day][1] = (max_supply / price) * -1
                dbs.optimal_price_array[day][0][1] = price

        elif MRS < price:  # then the agent will demand res_1

            # use a substitute price
            subst_price = 1.0 / price

            # note we switch the resources - this gives us a preferred supply of other_res
            tot_Q = Q_at_price(res_2, res_1, subst_price, agent.aggr_res_array)

            agent_holding = agent.basket_array[0][res_2]
            max_supply_other_res = np.min([agent_holding, tot_Q])

            max_demand_res_1 = max_supply_other_res * price

            total_demand[0] += max_demand_res_1

            if find_optimals == 1:
                agent.optimal_transs_systemic[day][0] = -1 * max_demand_res_1
                agent.optimal_transs_systemic[day][1] = max_supply_other_res
                dbs.optimal_price_array[day][1][0] = 1 / float(price)

            if print_fine_dets == 1:
                print('\n agent demands (res_1)', max_demand_res_1)

    total_demand = [0.0]
    total_supply = [0.0]

    threads = []
    for agent in agent_list:

        #        if day > 100 and find_optimals == 1:
        #
        #            if agent_population.pop[0] == agent:
        #
        #                print_fine_dets = 1
        #
        #            else:
        #
        #                print_fine_dets = 0

        t = threading.Thread(target= agent_S_D, args=[agent])
        t.start()
        threads.append(t)

    for thread in threads:
        thread.join()

    # print_fine_dets = 1
    if print_fine_dets == 1:

        if print_fine_dets == 1:
            print('\n\n total_demand = ', total_demand[0])
            print(' total_supply = ', total_supply[0])
            print(' net demand = ', total_demand[0] - total_supply[0])

    return total_demand[0], total_supply[0]


def set_agent_target(params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, respect_property_rights, KO_pop,
                     agent_population, keynesian_ratio, trade_prices, trade_movemnt, trade_when_trgt, dbs, track_agent,
                     agent, day, town_grid, trgt_sel, trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, ststst, retarg,
                     move, has_acted, print_dets, print_fine_dets, fight_balance, agree_location, adjust_props_r, agent_intn_beta,
                     formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0, strat_choice, stranger_int, two_tribes_inst, strangers_if_unknown):
    """This function sets the target of a single agent."""

    if (params.track_agent and params.track_agent <= day) and agent_population.tracking_agent == agent:
        print_for_tracking = 1
    else:
        print_for_tracking = 0

    # if day > 500:
    #     print_fine_dets = 1

    # if retarg and day > 5:
    #     print_for_tracking = 1
    # else:
    #     print_for_tracking = 0

    # if (agent == agent_population.pop[0] or agent == agent_population.pop[1] or agent == agent_population.pop[2]) and params.fixed_price_day and day > 499:
    #     print_for_tracking = 1
    # else:
    #     print_for_tracking = 0

    # if len(KO_pop.pop) > 0:
    #     print_fine_dets = 1

    if print_fine_dets or print_for_tracking:
        print('\n\n ***** set_agent_target has started *****')

    if print_fine_dets or print_for_tracking:
        print(' day =', day)
        print(' agent.birth_date =', agent.birth_date)
        print(' trade_movemnt =', trade_movemnt)
        print('\n agent.location =', agent.location, '| home =', agent.home, ' | agent.grid_trgt =', agent.grid_trgt)

        print('\n town_grid.trade_moves =', town_grid.trade_moves)
        print(' move =', move)
        print('\n granular_mem =', granular_mem)
        print(' retarg =', retarg)
        print(' has_acted =', has_acted)
        print('\n agent.MRS_array =', agent.MRS_array)
        print('\n agent.agreed_meeting_point =', agent.agreed_meeting_point)
        print('\n agent.can_trade:', agent.can_trade)

    # At the beginning of each round we do two things: time decay the existing entries in the dictionary and remove those value with a v small value.  If Keynesian insts are being applied, we also do this here
    if retarg == 0:

        # we want to create a dictionary in which we save all positive entries, which will reduce time.  Note we originate it at the start of the round and it is then used for retargetting
        agent.positive_locations_dict = dict()

        if print_fine_dets or print_for_tracking:
            print('\n agent.agreed_meeting_point', agent.agreed_meeting_point)
            print('\n ****** Starting dictionary values: \n')

        # when a location's value decays to zero then we remove it - to do this we have to add these items to a list and then delete
        items_to_be_removed = []

        # first we time_decay all the values in the dictionary - note the equation used is designed to decay any entry to zero over 20 rounds
        for entry in agent.location_memories_dict:

            # NOTE that we want time decay to zero but with the equation used, positive values decay to negative and vv, so we want to limit to zero
            if agent.location_memories_dict[entry] != 0.0:

                # here we decay each value in the dictionary
                agent.location_memories_dict[entry] *= (1 - params.memory_decay_rate)

                # in this situation the time decay has moved to a very low level so we will remove it from the dictionary - the threshold will depend on the nature of the weights (params.target_location_weights)
                if (params.target_location_weights == 'crude' and -0.05 < agent.location_memories_dict[entry] < 0.05) or (params.target_location_weights == 'reduced_value' and -0.001 < agent.location_memories_dict[entry] < 0.001):
                    items_to_be_removed.append(entry)

                # to qualify for positive_locations_dict, the entry location should not be in agent.previous_trgt and the entry must be positive and not about to be removed
                if (params.target_location_weights == 'crude' and agent.location_memories_dict[entry] >= 0.05) or (params.target_location_weights == 'reduced_value' and agent.location_memories_dict[entry] >= 0.001):
                    agent.positive_locations_dict[entry] = agent.location_memories_dict[entry]

            # it's possible that agent.location_memories_dict[entry] == 0.0 (e.g., 1 trade, 1 fight)
            elif agent.location_memories_dict[entry] == 0.0:

                items_to_be_removed.append(entry)

            if print_fine_dets or print_for_tracking:
                print(' location ', entry, 'value', agent.location_memories_dict[entry])

        if print_fine_dets or print_for_tracking:
            print('\n items_to_be_removed', items_to_be_removed)

        # we remove any dictionary entries if the value is zero
        for entry in items_to_be_removed:
            del agent.location_memories_dict[entry]

        if print_fine_dets:
            print('\n agent.positive_locations_dict before habits', agent.positive_locations_dict)

        # if we're applying habit values to mkt weights and these do not deteriorate, we add the weights in agent.location_memories_habits_dict
        if params.habit_val_mkts > 0.0 and params.habit_deteriorates_mkts == 0 and len(agent.location_memories_habits_dict) > 0:

            # it's possible entries in agent.location_memories_habits_dict are not in agent.positive_locations_dict
            for entry in agent.location_memories_habits_dict:

                if entry in agent.positive_locations_dict:

                    agent.positive_locations_dict[entry] += agent.location_memories_habits_dict[entry]

                else:

                    agent.positive_locations_dict[entry] = agent.location_memories_habits_dict[entry]

        if print_fine_dets:
            print('\n agent.location_memories_habits_dict', agent.location_memories_habits_dict)
            print('\n agent.positive_locations_dict after habits', agent.positive_locations_dict)

        # if we apply Keynesian institutions, we add them here (NOTE: this code has not been tested - test when next using KIs)
        # we only proceed if len(KO_pop.pop) > 0 and if the KIs' target agents include the agent...
        if len(KO_pop.pop) > 0:

            if print_fine_dets:
                print('\n len(KO_pop.pop) > 0')

            agent_is_target = 0

            for KI in KO_pop.pop:

                if agent in KI.target_agents:
                    agent_is_target = 1

                    if print_fine_dets:
                        print('\n agent in KI.target_agents')

            if agent_is_target:

                if print_fine_dets:
                    print('\n agent_is_target')

                # start by finding aggregate weights for positive squares
                aggregate_positive_weight = 0.0

                if print_fine_dets:
                    print('\n agent.location_memories_dict', agent.location_memories_dict)

                for entry in agent.location_memories_dict:

                    if agent.location_memories_dict[entry] > 0.0:
                        aggregate_positive_weight += agent.location_memories_dict[entry]

                for KI in KO_pop.pop:

                    if print_fine_dets:
                        print('\n agent in KI.target_agents', agent in KI.target_agents)
                        print(' day == KI.day_created + 1', day == KI.day_created + 1)

                    if agent in KI.target_agents and day == KI.day_created + 1:     # KI created at end of the round so this is the first chance a KI will impact

                        str_target_loc = str(list(KI.loc))

                        if print_fine_dets:
                            print('\n str(list(KI.loc))', str(list(KI.loc)))

                        # look at the total transactions-locations weight
                        keynesian_weight = keynesian_ratio * aggregate_positive_weight

                        if print_fine_dets:
                            print('\n keynesian_weight', keynesian_weight)
                            print(' keynesian_ratio', keynesian_ratio)
                            print(' aggregate_positive_weight', aggregate_positive_weight)

                        # In the case of the agent having no locations in memory, we must force the KI weight to be non-zero:
                        if aggregate_positive_weight == 0:
                            keynesian_weight = 1

                        if str_target_loc in agent.location_memories_dict:
                            agent.location_memories_dict[str_target_loc] += keynesian_weight

                        elif str_target_loc not in agent.location_memories_dict:
                            agent.location_memories_dict[str_target_loc] = keynesian_weight

                        # we add the location to the positive_locations_dict (the entry can only be positive)
                        agent.positive_locations_dict[str_target_loc] = agent.location_memories_dict[str_target_loc]

    # if we are retargetting during a trading phase, we remove any previous targets from the agent.positive_locations_dict
    if retarg:

        if print_for_tracking:
            print('\n agent is retargeting')

        # append record
        agent.previous_trgt.append(str(list(agent.grid_trgt)))

        # work out agent.wait_at_tgt_moves_pro_rata
        # if wait_at_target_til_end == 0:
        agent.wait_at_tgt_moves_pro_rata = math.ceil(wait_at_tgt_moves * ((trade_moves - move) / float(trade_moves)))

        if print_fine_dets:
            print(' agent.wait_at_tgt_moves_pro_rata =', agent.wait_at_tgt_moves_pro_rata)

        if print_fine_dets or print_for_tracking:
            print('\n agent.previous_trgt: ', agent.previous_trgt)

            print('\n\n\n retarg: STARTING agent.positive_locations_dict:\n')
            for item in agent.positive_locations_dict:
                print(' location', item, 'value', agent.positive_locations_dict[item])

        # we remove any previous targets from agent.positive_locations_dict
        for target in agent.previous_trgt:
            if target in agent.positive_locations_dict:

                del agent.positive_locations_dict[target]

                if print_fine_dets or print_for_tracking:
                    print('\n removing ', target, 'from agent.positive_locations_dict')

    if print_fine_dets or print_for_tracking:
        print('\n\n agent.positive_locations_dict:\n')
        for item in agent.positive_locations_dict:
            print(' location', item, 'value', agent.positive_locations_dict[item])
            if len(agent.positive_locations_dict) == 0:
                print('\n no locations in agent.positive_locations_dict')
        print('\n')

    # when agents don't respect property rights but they have interacted at the end of the last round, and they both expect a positive result frmo interacting,
    # if they have no transaction locations in memory and no positive fight locations then they will agree a location to head towards
    if agent.agreed_meeting_point is not None:

        if print_fine_dets or print_for_tracking:
            print('\n\n agent.agreed_meeting_point is not None')
            print(' agent.agreed_meeting_point =', agent.agreed_meeting_point)

        agent.trade_movemnt = 'set'
        agent.grid_trgt = np.array(copy.copy(agent.agreed_meeting_point))

        # we set agent.agreed_meeting_point back to None - it has done its job; and it is not longer needed - if the agent retargets, it will not be used
        agent.agreed_meeting_point = None

        if print_fine_dets:
            print('\n resulting agent.grid_trgt ', agent.grid_trgt)
            print(' and agent.agreed_meeting_point =', agent.agreed_meeting_point)

    # here we impose a market location of ststst[3] if we want to force a steady state start:
    elif ststst[0] == 1 and 0 <= day < agent.agent_mem_length:

        agent.trade_movemnt = trade_movemnt
        agent.grid_trgt = np.array(ststst[3])

    # by this point, the entries in the agent's location_memories_dict are up to date.  We now find the total decayed value of all positive entries, which helps with the roulette wheel approach.
    # Note this code accounts for both targetting at the beginning of the round and re-targetting during the round
    elif agent.agreed_meeting_point is None:

        if print_fine_dets:
            print('\n\n agent.agreed_meeting_point is None \n')

        # if a target location is not longer within striking distance, we will remove it
        to_be_removed = []

        if len(agent.positive_locations_dict) == 0:

            agent.trade_movemnt = 'random'
            agent.grid_trgt = [None, None]
            agent.can_trade = 1
            agent.reached_trgt = 1

        # if the length of the positive_locations_dict is one then we can simply extract the one value as the agent's target and not have to run the roulette wheel process
        elif len(agent.positive_locations_dict) == 1:

            # set agent.entry_loc so we can test if within_striking_dist
            exec('agent.entry_loc = %s' % list(agent.positive_locations_dict.keys())[0])

            if print_fine_dets or print_for_tracking:
                print('\n ONLY one entry in agent.positive_locations_dict')
                print(' wait_at_target_til_end', wait_at_target_til_end)
                print(' agent.wait_at_tgt_moves_pro_rata =', agent.wait_at_tgt_moves_pro_rata)
                print(' distance is:', np.max(abs_dist_on_torus(agent.entry_loc, agent.location, town_grid.dimen)))
                print(' agent.entry_loc =', agent.entry_loc)
                print(' has_acted =', has_acted)
                print_dets = 1

            # print('\n 3 wait_at_tgt_moves', wait_at_tgt_moves)

            if within_striking_dist(wait_at_target_til_end, town_grid, agent.location, agent.wait_at_tgt_moves_pro_rata, agent.agent_vision, agent.entry_loc, move, has_acted, print_dets):

                if print_fine_dets or print_for_tracking:
                    print('\n within_striking_dist')

                agent.trade_movemnt = 'set'
                exec('agent.grid_trgt = %s' % list(agent.positive_locations_dict.keys())[0])

            else:

                to_be_removed.append(list(agent.positive_locations_dict.keys())[0])

                if print_fine_dets or print_for_tracking:
                    print(' NOT within_striking_dist')
                    print(' to_be_removed:', to_be_removed)

                # we must set trade_movemnt to random - there are no locations within striking distance
                agent.trade_movemnt = 'random'
                agent.grid_trgt = [None, None]
                agent.can_trade = 1
                agent.reached_trgt = 1

        else:

            agent.trade_movemnt = 'set'

            if trgt_sel == 'roulette':
                aggregate_wheel_weight = 0.0

            elif trgt_sel == 'WTA':
                max_dict_value = 0.0

            if print_fine_dets or print_for_tracking:
                print('\n *** finding target location now')
                print('\n trgt_sel =', trgt_sel)
                print(' retarg =', retarg)

            for entry in agent.positive_locations_dict:

                # for some reason this exec function will not run with a simple exec('entry_loc = %s' % entry), hence use of agent object
                exec('agent.entry_loc = %s' % entry)

                if print_fine_dets or print_for_tracking:
                    print('\n entry:', entry, 'value', agent.positive_locations_dict[entry])
                    print(' distance is:', np.max(abs_dist_on_torus(agent.entry_loc, agent.location, town_grid.dimen)))

                # print('\n 4 wait_at_tgt_moves', wait_at_tgt_moves)

                if within_striking_dist(wait_at_target_til_end, town_grid, agent.location, agent.wait_at_tgt_moves_pro_rata, agent.agent_vision, agent.entry_loc, move, has_acted, print_dets=0):

                    if print_fine_dets or print_for_tracking:
                        print(' within_striking_dist')

                    if trgt_sel == 'roulette':
                        aggregate_wheel_weight += agent.positive_locations_dict[entry]

                    elif trgt_sel == 'WTA' and agent.positive_locations_dict[entry] > max_dict_value:
                        max_dict_value = agent.positive_locations_dict[entry]

                else:

                    to_be_removed.append(entry)

                    if print_fine_dets or print_for_tracking:
                        print(' NOT within_striking_dist')

            # remove entries before proceeding to roulette wheel...
            for entry in to_be_removed:

                if print_fine_dets:
                    print(' removing ', entry)

                del agent.positive_locations_dict[entry]

            if trgt_sel == 'roulette' and (print_fine_dets or print_for_tracking):
                print('\n resulting aggregate_wheel_weight =', aggregate_wheel_weight)

            elif trgt_sel == 'WTA' and (print_fine_dets or print_for_tracking):
                print('\n resulting max_dict_value =', max_dict_value)

            # this condition will be true if all locations in the agent.positive_locations_dict are not within striking distance
            if (trgt_sel == 'roulette' and aggregate_wheel_weight == 0.0) or (trgt_sel == 'WTA' and max_dict_value == 0.0):

                agent.trade_movemnt = 'random'
                agent.grid_trgt = [None, None]
                agent.can_trade = 1
                agent.reached_trgt = 1

            else:

                # select value for roulette wheel
                if trgt_sel == 'roulette':
                    roulette_value = random.uniform(0, aggregate_wheel_weight)

                if print_fine_dets or print_for_tracking:
                    print('\n\n roulette_value =', roulette_value)

                start_value = 0.0
                found_loc = 0
                for entry in agent.positive_locations_dict:

                    if found_loc == 0:

                        if print_fine_dets or print_for_tracking:
                            print('\n entry', entry, 'value', agent.positive_locations_dict[entry])

                        exec('agent.entry_loc = %s' % entry)

                        # print('\n 5 wait_at_tgt_moves', wait_at_tgt_moves)

                        # if within_striking_dist(wait_at_target_til_end, town_grid, agent.location, agent.wait_at_tgt_moves_pro_rata, agent.agent_vision, agent.entry_loc, move, has_acted, print_dets=0):
                        #
                        #     if print_fine_dets or print_for_tracking:
                        #         print(' within_striking_dist')

                        if trgt_sel == 'roulette':

                            if print_fine_dets or print_for_tracking:
                                print('\n roulette wheel segment start :', start_value, ' end :', start_value + agent.positive_locations_dict[entry])

                            if start_value < roulette_value < start_value + agent.positive_locations_dict[entry]:

                                exec('agent.grid_trgt = %s' % entry)

                                found_loc = 1

                                if print_fine_dets or print_for_tracking:
                                    print('\n FOUND agent.grid_trgt =', agent.grid_trgt)

                            else:

                                start_value += agent.positive_locations_dict[entry]

                                if print_fine_dets or print_for_tracking:
                                    print('\n new start_value =', start_value)

                        elif trgt_sel == 'WTA':

                            if agent.positive_locations_dict[entry] == max_dict_value:
                                exec('agent.grid_trgt = %s' % entry)

                                found_loc = 1

                        # else:
                        #
                        #     # we don't add to to_be_removed again - this would create double counting and an error
                        #
                        #     if print_fine_dets:
                        #         print(' NOT within_striking_dist')

        # if any locations were not within striking distance, we remove them from agent.positive_locations_dict
        if print_fine_dets:
            if len(to_be_removed) > 0:
                print('\n there are items to be removed:')

        for entry in to_be_removed:

            if print_fine_dets:
                print(' removing ', entry)

            if entry in agent.positive_locations_dict:
                del agent.positive_locations_dict[entry]

        if print_fine_dets:

            print('\n Final agent.positive_locations_dict:\n')
            for item in agent.positive_locations_dict:
                print(' location', item, 'value', agent.positive_locations_dict[item])

    # we append the previous_trgt array with whatever the agent's target is, at the start of the round
    if retarg == 0:
        agent.previous_trgt.append(str(list(agent.grid_trgt)))

    if print_fine_dets or print_for_tracking:

        print(' agent.agreed_meeting_point is', agent.agreed_meeting_point)
        print(' len(agent.positive_locations_dict) =', len(agent.positive_locations_dict))
        print(' agent.positive_locations_dict', agent.positive_locations_dict)
        # print(' agent.entry_loc', agent.entry_loc)
        print(' agent.trade_movemnt', agent.trade_movemnt)

        print('\n agent.grid_trgt =', agent.grid_trgt)
        print(' agent.trade_movemnt =', agent.trade_movemnt)
        print(' retarg =', retarg)
        print('\n end of set_agent_target \n')
        pause()

    # # this is necessary if two agents are fighting
    # if retarg == 0:
    #
    #     agent.previous_trgt = copy.copy(agent.grid_trgt)

    # if print_fine_dets:   # and len(agent.positive_locations_dict) > 0:  # and agent.grid_trgt[0] == None and agent.trade_movemnt == 'set':
    #
    #     pause()

    # This function only sets an agent's target - it does not return anything


def find_nearby_agents(print_dets, print_fine_dets, dbs, town_grid, agent, goods_signal, trade_prices, agent_population, day, trade_when_trgt):

    best_cp_agent = None

    if print_fine_dets == 1:
        print('\n** starting find_nearby_agents()')

    agent_x_coord = agent.location[0]
    agent_y_coord = agent.location[1]

    if print_fine_dets == 1:
        print('\nagent_x_coord =', agent_x_coord)
        print('agent_y_coord =', agent_y_coord, '\n')
        print('agent.ignore_agents_array =', agent.ignore_agents_array, '\n')

    # create array to place nearby agents
    nearby_agents = []

    for x_shift in np.arange(-1 * agent.agent_vision, agent.agent_vision + 1):

        for y_shift in np.arange(-1 * agent.agent_vision, agent.agent_vision + 1):

            check_x_coord = (agent_x_coord + x_shift) % town_grid.dimen
            check_y_coord = (agent_y_coord + y_shift) % town_grid.dimen

            if print_fine_dets == 1:
                print('check_x_coord , check_y_coord =', check_x_coord, check_y_coord, 'num agents on grid =', len(town_grid.grid_agents[check_x_coord][check_y_coord]))

            # don't add the agents on own square, including the agent itself
            if check_x_coord != agent_x_coord or check_y_coord != agent_y_coord:

                for cp_agent in town_grid.grid_agents[check_x_coord][check_y_coord]:

                    if print_fine_dets == 1:
                        print('cp_agent =', cp_agent, '\n')

                    # if the agents are trading on the way to their target, they should ignore agents they have already traded with
                    if trade_when_trgt == 0 and cp_agent not in agent.ignore_agents_array:

                        # append nearby_agents
                        nearby_agents.append(cp_agent)

            else:       # any agent on full squares is ignored

                for cp_agent in town_grid.grid_agents[check_x_coord][check_y_coord]:

                    if print_fine_dets == 1:
                        print('\nlocation full: ignoring cp_agent =', cp_agent)

    if print_fine_dets == 1:
        print('\npre-nearby_agents =', nearby_agents)

    # now we run agent_crop_list through remove_unwanted_cp_agents, assuming there are agents in nearby_agents
    if len(nearby_agents) > 0:

        best_cp_agent = random.choice(nearby_agents)

    else:

        if print_fine_dets == 1:
            print('\nthere are no agents nearby')

    if print_fine_dets == 1:
        print('\npost-nearby_agents =', nearby_agents)

    return nearby_agents, best_cp_agent


def update_trade_probys(params, agent_population, trade_prob_mem, day, print_dets, print_fine_dets, rounds, track_agent, trade_prices, Walrasian_Trading, ststst, fight_skill, fight_skill_r, dbs):

    """This function updates each agent's trade_proby variable.  It looks at the trading data of all of an agent's neighbours
    and sets trade_proby = goods traded / goods_2_mkt over the past [trade_prob_mem] periods."""

    # if day > 0 and day % 50 == 0:
    #     print_fine_dets = 1

    def ag_trade_prob(agent):

        if agent == agent_population.change_agent:

            total_sales = agent.total_actual_agent_sales[day]
            total_desired_sales = agent.total_optimal_agent_sales[day]

            if total_sales == 0 or total_desired_sales == 0:

                turnover_ratio = 0

            else:

                turnover_ratio = total_sales / float(total_desired_sales)

            # we set trade_proby with a maximum of 1
            agent.trade_proby = np.min([1.0, turnover_ratio])

        else:

            if Walrasian_Trading == 1 or (ststst[0] == 1 and 0 <= day < 20):  # agent.agent_mem_length

                agent.trade_proby = 1.0

            else:

                # if (track_agent and track_agent <= day) and agent == agent_population.tracking_agent:
                #
                #     print_fine_dets = print_dets = 1
                #
                # else:
                #
                #     print_fine_dets = print_dets = 0

                if print_fine_dets == 1:
                    print('\n\n ---> update_trade_probys---\n')
                    print(' agent =', agent)

                if trade_prices == 'variable':  # We use personal_turnover_ratio for agent and neighs to derive proby of transacting

                    # create two variable to record actual and optimal sales, starting with the agent's own data
                    total_sales = agent.total_actual_agent_sales[day]
                    total_desired_sales = agent.total_optimal_agent_sales[day]

                    if print_fine_dets == 1:
                        print('\n agent.total_actual_agent_sales[day]', agent.total_actual_agent_sales[day])
                        print(' agent.total_optimal_agent_sales[day]', agent.total_optimal_agent_sales[day])
                        print(' agent.basket_array_start ', agent.basket_array_start[0], ' agent.agent_res_array ', agent.agent_res_array[0], '\n')

                    #            if agent.personal_turnover_ratio[day] == 0:
                    #
                    #                turnover_array.append(0.0)
                    #
                    #            elif agent.personal_turnover_ratio[day] > 0:
                    #
                    #                if agent.personal_turnover_ratio[day] < 1:
                    #                    turnover_array.append(agent.personal_turnover_ratio[day])
                    #
                    #                else:
                    #                    turnover_array.append(1.0)

                    for neigh in agent.neighs:

                        if print_fine_dets:
                            print(' neigh.home', neigh.home, 'sales', neigh.total_actual_agent_sales[day], ' vs optimal', neigh.total_optimal_agent_sales[day], ' neigh.basket_array_start ', neigh.basket_array_start[0], \
                                  ' neigh.agent_res_array ', neigh.agent_res_array[0])

                        total_sales += neigh.total_actual_agent_sales[day]
                        total_desired_sales += neigh.total_optimal_agent_sales[day]

                    #                if print_fine_dets == 1:
                    #
                    #                    print('\n neigh ', neigh)
                    #                    print(' neigh.total_actual_agent_sales[day]', neigh.total_actual_agent_sales[day])
                    #                    print(' neigh.total_optimal_agent_sales[day]', neigh.total_optimal_agent_sales[day])

                    #                if neigh.personal_turnover_ratio[day] == 0:
                    #
                    #                    turnover_array.append(0.0)
                    #
                    #                elif neigh.personal_turnover_ratio[day] > 0:      # ignore those == 0 (they did not want to trade)
                    #
                    #                    if neigh.personal_turnover_ratio[day] < 1:
                    #                        turnover_array.append(neigh.personal_turnover_ratio[day])
                    #
                    #                    else:
                    #                        turnover_array.append(1.0)
                    #
                    #            if len(turnover_array) == 0:
                    #
                    #                agent.trade_proby = 0
                    #
                    #            else:
                    #
                    #                agent.trade_proby = np.mean(turnover_array)

                    if print_fine_dets:
                        print('\n total_sales', total_sales, 'total_desired_sales', total_desired_sales)

                    if total_sales == 0 or total_desired_sales == 0:

                        self_and_neighs_turnover_ratio = 0

                    else:

                        self_and_neighs_turnover_ratio = total_sales / float(total_desired_sales)

                    # we set trade_proby with a maximum of 1
                    agent.trade_proby = np.min([1.0, self_and_neighs_turnover_ratio])

                    if print_fine_dets == 1:
                        #
                        #                print('\n\n total_sales', total_sales)
                        #                print(' total_desired_sales', total_desired_sales)
                        #                print(' self_and_neighs_turnover_ratio', self_and_neighs_turnover_ratio)

                        #                print('\n agent.personal_turnover_ratio = ', agent.personal_turnover_ratio)
                        #                print('\n turnover_array =', turnover_array)
                        print('\n agent.trade_proby =', agent.trade_proby, '\n')

                    if math.isnan(agent.trade_proby):
                        print('\n math.isnan(agent.trade_proby)', math.isnan(agent.trade_proby))
                        print('\n agent.total_actual_agent_sales[day]', agent.total_actual_agent_sales[day])
                        print(' agent.total_optimal_agent_sales[day]', agent.total_optimal_agent_sales[day])
                        pause()

        # if print_fine_dets == 1:
        #     pause()

    threads = []
    for agent in agent_population.pop:

        t = threading.Thread(target=ag_trade_prob, args=[agent])

        t.start()
        threads.append(t)

    for thread in threads:
        thread.join()

    # here we update the agents' fight skills if we allow them these skills (an experiment with 2nd model)
    if fight_skill is not None:

        #        print_fine_dets = 1

        # start by zeroing this variable
        for agent in agent_population.pop:
            agent.num_fights_today = 0

        todays_fights = dbs.fights_daily_db[day]

        total_fights = 0

        # now add one to agent.num_fights_today for all agents involved in a fight
        for fight_num in todays_fights:

            fight = dbs.fights_db[fight_num]

            for agent in agent_population.pop:

                if str(agent) == fight.initiator:
                    agent.num_fights_today += 1

                if str(agent) == fight.counterpart:
                    agent.num_fights_today += 1

            total_fights += 1

        if len(agent_population.pop) > 0:

            mean_num_fights = total_fights / float(len(agent_population.pop))

        else:

            mean_num_fights = 0

        if print_fine_dets == 1:
            print('\n total_fights =', total_fights)
            print('\n mean_num_fights =', mean_num_fights)

        #        aggr_fight_skill_ch = 0

        for agent in agent_population.pop:

            if print_fine_dets == 1:
                print('\n start fight_skill = ', agent.fight_skill)
                print(' num fights =', agent.num_fights_today)

            # agent.fight_skill = 9
            # print('\n agent.fight_skill =', agent.fight_skill)
            # print('\n params.fs_floor =', params.fs_floor)

            # deflate the existing fight_skill
            agent.fight_skill -= fight_skill_r * (agent.fight_skill - params.fs_floor)

            # print('\n resulting agent.fight_skill =', agent.fight_skill)
            # pause()

            # then add the number of fights in the last round
            agent.fight_skill += agent.num_fights_today

            if print_fine_dets == 1:
                print('\n ending fight_skill = ', agent.fight_skill)

    #            # we apply agent.num_fights_today to a logistic equation, to increase or decrease
    #            adj_param = agent.num_fights_today - mean_num_fights
    #
    #            fight_skill_change = (fight_skill_r * adj_param) * (agent.fight_skill) * (1.0 - agent.fight_skill)
    #
    #            aggr_fight_skill_ch += fight_skill_change
    #
    #            if print_fine_dets == 1:
    #
    #                print('\n agent home ', agent.home, 'pre change agent.fight_skill =', agent.fight_skill)
    #
    #            agent.fight_skill += fight_skill_change
    #
    #            # set max and min
    #            if agent.fight_skill > 0.99:
    #
    #                agent.fight_skill = 0.99
    #
    #            if agent.fight_skill < 0.01:
    #
    #                agent.fight_skill = 0.01
    #
    #            if print_fine_dets == 1:
    #
    #                print('agent.num_fights_today =', agent.num_fights_today, 'adj_param =', adj_param, 'fight_skill_r =', fight_skill_r, 'fight_skill_change =', fight_skill_change, 'new agent.fight_skill=', agent.fight_skill)
    #
    #        mean_fight_skill_ch = aggr_fight_skill_ch / float(len(agent_population.pop))
    #
    #        if print_fine_dets == 1:
    #
    #            print('\n mean_fight_skill_ch =', mean_fight_skill_ch)


def end_of_day_cons_metab(track_agent, KO_pop, agent_population, print_fine_dets, dbs, round, allow_Keynes_Inst, respect_property_rights, record_dead_agents, black_shoop_exp, agents_die_old_age):

    """This function adds personal resource arrays to basket_arrays, deducts metablism costs, and orgnises dead agents."""

    # we create a counter to count the number of agents who die at the end of the day:
    dead_agent_counter = [0]

    # measure the number of agents currently in the population:
    # start_agent_pop = len(agent_population.pop)

    # this records the number of new agents at the very end of each round
    dbs.davy_jones_locker = []

    # clear the dead agents arrays
    if record_dead_agents == 0:
        agent_population.dead_agent_array = []

    agents_died_this_round = []

    def ag_cons_metab(agent):

        if (track_agent and track_agent <= round) and agent == agent_population.tracking_agent:
            print_fine_dets = print_dets = 1

        else:
            print_fine_dets = print_dets = 0

        # add to agent's total_cons array
        agent.total_cons += agent.basket_array[0]

        # for speed we track whether each agent is alive or dead (0 = dead, 1 = alive)
        agent_alive = 1

        if print_fine_dets == 1:
            print('\n\n *** Starting end_of_day_cons_metab')
            # print('\n iter of agents (x) =', x)
            print(' len(agent_population.pop) =', len(agent_population.pop))
            print(' dead_agent_counter =', dead_agent_counter)

        for y in np.arange(num_res_founts):

            if agent_alive == 1:

                if print_fine_dets == 1:
                    print('iter over resources (y) =', y)

                # this line adds the basket to the agent's reserves
                agent.agent_res_array[0][y] += agent.basket_array[0][y]

                # this line deducts one unit from each agent's reserves (the cost of metabolism)
                agent.agent_res_array[0][y] -= 1

                # if print_fine_dets == 1:
                #     print('resource level for res', y, 'equals:', agent_population.pop[working_agent_num].agent_res_array[0][y])

                agent_died_of_old_age = 0

                if agents_die_old_age and agent.age >= agents_die_old_age:

                    agent_died_of_old_age = 1

                if agent.agent_res_array[0][y] <= 0 or agent_died_of_old_age:

                    agents_died_this_round.append(agent)
                    dead_agent = agent

                    # print('\n agent =', agent)
                    # print(' agent in agent_population.pop?', agent in agent_population.pop)
                    # print(' dead_agent', dead_agent)
                    # print(' dead_agent in agent_population.pop?', dead_agent in agent_population.pop)

                    # if we are running the black_shoop_exp and the black shoop dies, rename agent_population.black_shoop
                    if black_shoop_exp and dead_agent in agent_population.black_shoop_list:

                        print('\n black shoop died :-(')
                        #                        agent_population.black_shoop = None

                        text = '\n\nThe Black Shoop died!! :-( day %d (lifespan = %d) \n' % (round, round - dead_agent.birth_date)
                        with open(dead_agent.black_shoop_file, 'a') as myfile:
                            myfile.write(text)

                    elif agent_died_of_old_age:

                        print('\n --> day %d: agent died of old age (age = %d) \n' % (round, agent.age))

                    else:

                        print('\n --> day %d: agent just died from malnutrition!!!! NO!!!!! WILSOOOOOOOON!!!!!!' % round)
                        # print(' home ', agent_population.pop[working_agent_num].home, ' prop_steal = %5.3f' % agent_population.pop[working_agent_num].prop_steal, 'prop_fight_back = %5.3f' % agent_population.pop[working_agent_num].prop_fight_back,
                        #       ' det skills [%5.3f %5.3f]' % (agent_population.pop[working_agent_num].detect_skills_array[0][0], agent_population.pop[working_agent_num].detect_skills_array[0][1]), '\n')

                    agent_alive = 0  # agent dies if any reserves fall below zero
                    dead_agent_counter[0] += 1
                    # add agent to davy_jones_locker
                    dbs.davy_jones_locker.append(dead_agent)
                    # add agent to dead_agent_array
                    agent_population.dead_agent_array.append(dead_agent)

                    if allow_Keynes_Inst == 'total' or allow_Keynes_Inst == 'sparse':
                        KO_pop.KI_stiffs.append(dead_agent)

                    dead_agent.death_date = round

                    # Add dead agent home location to dbs.dead_ags_grid_counter
                    x_coord = dead_agent.home[0]
                    y_coord = dead_agent.home[1]

                    dbs.dead_ags_grid_counter[x_coord][y_coord] += 1

                    # and remove from population
                    # print(' agent_population.pop =', agent_population.pop)
                    agent_population.pop.remove(dead_agent)

            else:

                # if an agent dies, we must update neighbours in the next round
                agent_population.must_update_neighs = 1

                if print_fine_dets == 1:
                    print('\n ignore fountain iteration - agent is dead')
                    print(' len(agent_population.pop', len(agent_population.pop))

        if agent_alive:

            if print_fine_dets == 1:
                print('\n***POST-consumption and deduction of living cost***')
                print('agent ', agent, 'agent_res_array =', agent.agent_res_array, '\n')

        else:

            if respect_property_rights == 0:  # if the agent dies, we remove it from all agents' reputations dictionaries

                #                print('\n agent died:', dead_agent, 'res_array check', dead_agent.agent_res_array)

                for alive_agent in agent_population.pop:

                    #                    print('\n BEFORE removal: alive_agent', alive_agent, 'str(dead_agent) in alive_agent.reputations_dict', str(dead_agent) in alive_agent.reputations_dict)

                    if alive_agent is not dead_agent and str(dead_agent) in alive_agent.reputations_dict:
                        del (alive_agent.reputations_dict[str(dead_agent)])

    #                    print('\n AFTER removal: alive_agent', alive_agent, 'str(dead_agent) in alive_agent.reputations_dict', str(dead_agent) in alive_agent.reputations_dict)

        # if print_fine_dets:
        #     pause()

    # print('\n PRE agent_population.pop:', agent_population.pop)
    # print(' len(agent_population.pop) =', len(agent_population.pop))
    # print(' type(agent_population.pop) =', type(agent_population.pop))

    threads = []
    for agent in agent_population.pop:

        t = threading.Thread(target=ag_cons_metab, args=[agent])

        t.start()
        threads.append(t)

    for thread in threads:
        thread.join()

    # print('\n POST agent_population.pop:', agent_population.pop)
    # print(' len(agent_population.pop) =', len(agent_population.pop))
    # print(' type(agent_population.pop) =', type(agent_population.pop))
    #
    # print('\n agents_died_this_round =', agents_died_this_round)
    # print(' len(agents_died_this_round) =', len(agents_died_this_round))

    # record some data for printing
    for dead_agent in agents_died_this_round:

        dead_agent.agent_res_array_start_hist[round] = copy.copy(dead_agent.agent_res_array)
        dead_agent.detect_skills_array_hist[round] = copy.copy(dead_agent.detect_skills_array[0])
        dead_agent.basket_array_hist[round] = copy.copy(dead_agent.basket_array[0])
        dead_agent.basket_array_start_hist[round] = copy.copy(dead_agent.basket_array_start[0])
        dead_agent.prop_steal_history[round] = copy.copy(dead_agent.prop_steal)
        dead_agent.prop_fight_back_history[round] = copy.copy(dead_agent.prop_fight_back)

    # record number of dead agents in main_db:
    dbs.main_db[2][round] = dead_agent_counter[0]

    # if print_fine_dets:
    #     pause()


def update_foraging_skills(params, for_strat_parts, print_dets, print_fine_dets, tracking_agent, track_agent, for_skill_r, agent_population, day):

    """This function updates agents' foraging skills i.e. the probabilities of detecting the various resources at the fountains."""

    # print_dets = 1
    # print_fine_dets = 1

    if print_dets == 1:
        print('\n---------- updating forraging skills ----------\n')

    # first find a norm index - this is the number of time slots in the day / number of resource fountains i.e. for an
    # average agent this will be the number of times we would expect them to visit a resource each round.
    norm_res_for = for_strat_parts / float(num_res_founts)

    if print_fine_dets == 1:
        print('norm_res_for =', norm_res_for)

    def ag_for_skills(agent):

        if print_fine_dets == 1:
            print('\n---------- updating forraging skills ----------\n')
            print('\n foraging agent: agent.for_strat_array =', agent.for_strat_array)

        # count the number of times the agent has visited each resource:
        for fount in np.arange(num_res_founts):

            if print_fine_dets == 1:
                print('\niter fountain (fount) =', fount)

            res_counter = 0
            for slot in np.arange(for_strat_parts):

               if agent.for_strat_array[0][slot] == fount:
                   res_counter += 1

            if print_fine_dets == 1:
                print('res_counter =', res_counter)

            # we change the skill level of this agent for this resource by using a type of logistic equation
            # agent's probability skill associated with this resource:
            skill_prob = agent.detect_skills_array[0][fount]
            if print_fine_dets == 1:
                print('skill_prob =', skill_prob)

            # create a parameter to adjust the probability skill of the agent (amount of time spent forraging on this
            # resource minus the average)
            skill_adj_param = res_counter - norm_res_for

            if print_fine_dets == 1:
                print('skill_adj_param =', skill_adj_param)
                print('for_skill_r =', for_skill_r)

            # account for potential of these two being the same:
            if params.max_prob_det != params.min_prob_det:

                # here we use the logistic equation approach
                if params.for_skill_change == 'logistic':

                    new_skill_prob_change = (for_skill_r * skill_adj_param) * (skill_prob - params.min_prob_det) * (params.max_prob_det - skill_prob) / (params.max_prob_det - params.min_prob_det)

                # here we use the linear change approach
                elif params.for_skill_change == 'linear':

                    new_skill_prob_change = skill_adj_param * params.for_skill_slope

                # update the agent's skill for this resource:
                agent.detect_skills_array[0][fount] += new_skill_prob_change

                # need to bound these between 0 and 1 if linear change used
                if params.for_skill_change == 'linear':

                    if agent.detect_skills_array[0][fount] < params.min_prob_det:

                        agent.detect_skills_array[0][fount] = params.min_prob_det

                    elif agent.detect_skills_array[0][fount] > params.max_prob_det:

                        agent.detect_skills_array[0][fount] = params.max_prob_det

            if print_fine_dets == 1:
                print('params.min_prob_det =', params.min_prob_det)
                print('params.max_prob_det =', params.max_prob_det)
                print('new_skill_prob_change =', new_skill_prob_change)
                print('new prob skill = ', agent.detect_skills_array[0][fount])

    threads = []
    for agent in agent_population.pop:

        t = threading.Thread(target=ag_for_skills, args=[agent])
        t.start()
        threads.append(t)

    for thread in threads:
        thread.join()

    if print_fine_dets == 1:
        print('\n')
        pause()


def update_locations_dicts(params, town_grid, dbs, agent_population, day, wait_at_target_til_end, wait_at_tgt_moves):

    """This function takes an agent population and updates the location_memories_dict for each agent, using the day's loc_mems_array and loc_fights_array"""

    if params.track_agent:
        print_fine_dets = 1
    else:
        print_fine_dets = 0

    if print_fine_dets:
        print('\n\n *** Starting update_locations_dicts - day %d' % day)

    def ag_update_locs(agent):

        """ This function is used for multi-threading below."""

        if agent == agent_population.tracking_agent and (params.track_agent and params.track_agent <= day):
            print_fine_dets = 1
        else:
            print_fine_dets = 0

        if print_fine_dets:
            print('\n\n *** update_locations_dicts *** day', day)
            print('\n agent', agent)
            print('\n agent.location_memories_dict:\n')
            for item in agent.location_memories_dict:
                print(' ', item, '\t', agent.location_memories_dict[item])
            if len(agent.location_memories_dict) == 0:
                print(' none')
            print('\n params.target_location_weights:  ', params.target_location_weights)
            print(' params.local_fight:  ', params.local_fight)
            print('\n ----> agent.loc_mems_array[day]:', agent.loc_mems_array[day])

        # update the agents' location_memories_dict
        for trans_num in agent.loc_mems_array[day]:

            trans = dbs.trans_db[trans_num]

            if print_fine_dets:
                print('\n --> trans_num', trans_num)
                print(' trans.location', trans.location)
                print(' trans.good_a', trans.good_a)
                print(' within_striking_dist =', within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, trans.location, move=0, has_acted=0, print_dets=0))

            if trans.good_a is not None:

                # print('\n 5 wait_at_tgt_moves', wait_at_tgt_moves)
                if within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, trans.location, move=0, has_acted=0, print_dets=0):

                    if params.target_location_weights == 'reduced_value':

                        if str(agent) == trans.agent_a:
                            agent_net_benefit = trans.agent_a_reduced_value

                        else:
                            agent_net_benefit = trans.agent_b_reduced_value

                        if print_fine_dets:
                            print('\n agent_net_benefit', agent_net_benefit)

                    if print_fine_dets:
                        print('\n str(list(trans.location)) in agent.location_memories_dict?', str(list(trans.location)) in agent.location_memories_dict)

                    if str(list(trans.location)) not in agent.location_memories_dict:

                        if params.target_location_weights == 'crude':
                            agent.location_memories_dict[str(list(trans.location))] = 1.0

                        elif params.target_location_weights == 'reduced_value':
                            agent.location_memories_dict[str(list(trans.location))] = agent_net_benefit

                    else:
                        if params.target_location_weights == 'crude':
                            agent.location_memories_dict[str(list(trans.location))] += 1.0

                        elif params.target_location_weights == 'reduced_value':
                            agent.location_memories_dict[str(list(trans.location))] += agent_net_benefit

                if print_fine_dets:
                    print('\n resulting agent.location_memories_dict[str(list(trans.location))]:', agent.location_memories_dict[str(list(trans.location))])

        if print_fine_dets:
            print('\n post-transactions agent.location_memories_dict:\n')
            for item in agent.location_memories_dict:
                print(' ', item, '\t', agent.location_memories_dict[item])
            if len(agent.location_memories_dict) == 0:
                print(' none')

        # now we update the agents' location_memories_dict from the fights they were involved in

        if print_fine_dets:
            print('\n\n ----> agent.loc_fights_array[day]', agent.loc_fights_array[day])

        for fight_num in agent.loc_fights_array[day]:

            if print_fine_dets:
                print('\n\n --> fight_num', fight_num)

            fight = dbs.fights_db[fight_num]

            if print_fine_dets:
                print(' agent:', str(agent))

                if str(agent) == fight.initiator:
                    print(' other agent:', fight.counterpart)
                else:
                    print(' other agent:', fight.initiator)

                if str(agent) == fight.initiator:
                    print('\n agent change basket', fight.agent_res_gain)
                else:
                    print('\n agent change basket', fight.cp_agent_res_gain)

            if str(agent) != fight.winner:

                if print_fine_dets:
                    print('\n agent lost fight')

                if params.local_fight == 'minus_one':

                    local_list = [-1, 0, +1]

                else:

                    local_list = [0]

                if print_fine_dets:
                    print('\n local_list', local_list)

                if params.target_location_weights == 'reduced_value':

                    if str(agent) == fight.initiator:
                        agent_net_benefit = fight.initiator_reduced_value

                    else:
                        agent_net_benefit = fight.counterpart_reduced_value

                    if print_fine_dets:
                        print('\n agent_net_benefit', agent_net_benefit)

                if agent_net_benefit != 0.0:

                    for offset_x in local_list:

                        for offset_y in local_list:

                            grid_square = [(fight.location[0] + offset_x) % town_grid.dimen, (fight.location[1] + offset_y) % town_grid.dimen]

                            if print_fine_dets:
                                print('\n grid_square', grid_square)
                                print(' str(list(grid_square)) in agent.location_memories_dict', str(list(grid_square)) in agent.location_memories_dict)
                                print(' within_striking_dist =', within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, grid_square, move=0, has_acted=0, print_dets=0))

                            # print('\n 6 wait_at_tgt_moves', wait_at_tgt_moves)
                            if within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, grid_square, move=0, has_acted=0, print_dets=0):

                                if str(list(grid_square)) not in agent.location_memories_dict:

                                    if params.target_location_weights == 'crude':
                                        agent.location_memories_dict[str(list(grid_square))] = -1.0

                                    elif params.target_location_weights == 'reduced_value':
                                        agent.location_memories_dict[str(list(grid_square))] = agent_net_benefit

                                else:
                                    if params.target_location_weights == 'crude':
                                        agent.location_memories_dict[str(list(grid_square))] -= 1.0

                                    elif params.target_location_weights == 'reduced_value':
                                        agent.location_memories_dict[str(list(grid_square))] += agent_net_benefit

                    if print_fine_dets:
                        print('\n resulting agent.location_memories_dict[str(list(fight.location))]:', agent.location_memories_dict[str(list(fight.location))])

            else:       # then agent won the fight

                if print_fine_dets:
                    print('\n agent won fight')

                if params.target_location_weights == 'reduced_value':

                    if str(agent) == fight.initiator:
                        agent_net_benefit = fight.initiator_reduced_value

                    else:
                        agent_net_benefit = fight.counterpart_reduced_value

                    if print_fine_dets:
                        print('\n agent_net_benefit', agent_net_benefit)

                if agent_net_benefit != 0.0:

                    if print_fine_dets:
                        print('\n fight.location', fight.location)
                        print(' str(list(fight.location)) in agent.location_memories_dict', str(list(fight.location)) in agent.location_memories_dict)
                        print(' within_striking_dist =', within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, fight.location, move=0, has_acted=0, print_dets=0))

                    # print('\n 7 wait_at_tgt_moves', wait_at_tgt_moves)
                    if within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, fight.location, move=0, has_acted=0, print_dets=0):

                        if str(list(fight.location)) not in agent.location_memories_dict:

                            if params.target_location_weights == 'crude':
                                agent.location_memories_dict[str(list(fight.location))] = 1.0

                            elif params.target_location_weights == 'reduced_value':
                                agent.location_memories_dict[str(list(fight.location))] = agent_net_benefit

                        else:
                            if params.target_location_weights == 'crude':
                                agent.location_memories_dict[str(list(fight.location))] += 1.0

                            elif params.target_location_weights == 'reduced_value':
                                agent.location_memories_dict[str(list(fight.location))] += agent_net_benefit

                    if print_fine_dets:
                        print('\n resulting agent.location_memories_dict[str(list(fight.location))]:', agent.location_memories_dict[str(list(fight.location))])

        # Now we introduce habituation if this is being included.  We add a value of `habit_param' to the weights for any location the agents has visited
        if print_fine_dets:
            print('\n agent.grid_trgt = ', agent.grid_trgt)
            print(' params.habit_val_mkts =', params.habit_val_mkts)

        # here we apply any habituation values - we do this if these two conditions both hold
        if params.habit_val_mkts > 0.0 and agent.grid_trgt[0] is not None:

            # if we allow habits to deteriorate, we simply add the value to agent.location_memories_dict
            if params.habit_deteriorates_mkts:

                if str(list(agent.grid_trgt)) not in agent.location_memories_dict:

                    agent.location_memories_dict[str(list(agent.grid_trgt))] = params.habit_val_mkts

                else:

                    agent.location_memories_dict[str(list(agent.grid_trgt))] += params.habit_val_mkts

            # if not, we have to record the values in a seperate database
            else:

                if str(list(agent.grid_trgt)) not in agent.location_memories_habits_dict:

                    agent.location_memories_habits_dict[str(list(agent.grid_trgt))] = params.habit_val_mkts

                else:

                    agent.location_memories_habits_dict[str(list(agent.grid_trgt))] += params.habit_val_mkts

        # note that in a specific situation, we apply habituation weights to (a) transaction location(s) -
        # this is when we switch off reinforcement learning and use habituation only to decide target locations
        if params.habit_val_mkts > 0.0 and params.memory_decay_rate == 1.0 and \
                len(agent.location_memories_habits_dict) == 0 and len(agent.loc_mems_array[day]) > 0:

            # we apply the habit_val_mkts value to the locations
            for trans_num in agent.loc_mems_array[day]:

                trans = dbs.trans_db[trans_num]

                if trans.good_a is not None:

                    agent.location_memories_habits_dict[str(list(trans.location))] = params.habit_val_mkts

                    # and record in history
                    if str(list(trans.location)) not in agent.locations_weights_hist_dict:

                        agent.locations_weights_hist_dict[str(list(trans.location))] = [np.zeros(params.rounds), np.zeros(params.rounds)]

                    agent.locations_weights_hist_dict[str(list(trans.location))][1][day] += params.habit_val_mkts

        # record the weights (both via reinforcement learning and habituation) in agent.locations_weights_hist_dict
        # First, RL:
        for location in agent.location_memories_dict:

            if location not in agent.locations_weights_hist_dict:

                agent.locations_weights_hist_dict[location] = [np.zeros(params.rounds), np.zeros(params.rounds)]

            agent.locations_weights_hist_dict[location][0][day] += agent.location_memories_dict[location]

        # Next, habituation
        if str(list(agent.grid_trgt)) not in agent.locations_weights_hist_dict:

            agent.locations_weights_hist_dict[str(list(agent.grid_trgt))] = [np.zeros(params.rounds), np.zeros(params.rounds)]

        agent.locations_weights_hist_dict[str(list(agent.grid_trgt))][1][day] += params.habit_val_mkts

        if print_fine_dets:
            print('\n FINAL agent.location_memories_dict:\n')
            for item in agent.location_memories_dict:
                print(' ', item, '\t', agent.location_memories_dict[item])
            if len(agent.location_memories_dict) == 0:
                print(' none \n')
            # pause()

    threads = []
    for agent in agent_population.pop:

        t = threading.Thread(target=ag_update_locs, args=[agent])
        t.start()
        threads.append(t)

    for thread in threads:
        thread.join()

    # here we set out interaction information if we want:
    if params.track_interactions_detailed:

        pause_code = 0

        for interaction in dbs.interactions_db[day]:

            if interaction.agent == agent_population.pop[0] or interaction.cp_agent == agent_population.pop[0]:

                pause_code = 1

                print('\n\n --> day ', interaction.day, ' move ', interaction.move, ' type ', interaction.intn_type, ' location ', interaction.location)

                if interaction.agent == agent_population.pop[0]:

                    print(' pop[0] is instigating agent - home', interaction.agent.home)
                    print(' start day res ', interaction.agent_a_start_day_res, 'basket', interaction.agent_a_start_day_bskt)
                    print(' start intn res ', interaction.agent_a_start_trans_res, 'basket', interaction.agent_a_start_trans_bskt)
                    print(' counterpart home ', interaction.cp_agent.home, 'counterpart basket ', interaction.agent_b_start_trans_bskt)
                    print(' intn dec =', interaction.agent_a_dec, 'other agent =', interaction.agent_b_dec)

                    if interaction.transfer_to_agent_a[0] > 0.0 or interaction.transfer_to_agent_a[1] > 0.0:

                        print(' transfer to agent (gains) ', interaction.transfer_to_agent_a)

                    elif interaction.transfer_to_agent_a[0] < 0.0 or interaction.transfer_to_agent_a[1] < 0.0:

                        print(' transfer from agent (loses) ', interaction.transfer_to_agent_a)

                    else:

                        print(' no transfer to or from agent ', interaction.transfer_to_agent_a)

                    print('\n ag_exp_overall_rtn =', interaction.ag_exp_overall_rtn, 'cp_exp_overall_rtn =', interaction.cp_exp_overall_rtn)
                    print(' ag_exp_quad_2_rtn =', interaction.ag_exp_quad_2_rtn, ' cp_exp_quad_3_rtn =', interaction.cp_exp_quad_3_rtn)

                    print('\n agent_net_benefit =', interaction.agent_net_benefit, 'agent_net_benefit_back_prop =', interaction.agent_net_benefit_back_prop)
                    print(' (other agent_net_benefit =', interaction.cp_agent_net_benefit, 'other agent_net_benefit_back_prop =', interaction.cp_agent_net_benefit_back_prop, ')')
                    print('\n agent_net_benefit_back_prop_fb =', interaction.agent_net_benefit_back_prop_fb)
                    print(' cp_agent_net_benefit_back_prop_fb =', interaction.cp_agent_net_benefit_back_prop_fb)

                    print('\n agent_net_gain_NNs = \n', interaction.agent_net_gain_NNs)
                    print('\n cp_agent_net_gain_NNs = \n', interaction.cp_agent_net_gain_NNs)

                    print('\n ps at start of trans =', interaction.agent_a_ps_start_trans)
                    print(' ps at end of trans =', interaction.agent_a_ps_end_trans)

                    if interaction.agent_a_ps_end_trans is not None:

                        print(' change %9.8f ' % (interaction.agent_a_ps_end_trans - interaction.agent_a_ps_start_trans))

                    print(' ag_ch_prop_steal_simple = ', interaction.ag_ch_prop_steal_simple)

                    print('\n pfb at start of trans =', interaction.agent_a_pfb_start_trans)
                    print(' pfb at end of trans =', interaction.agent_a_pfb_end_trans)

                    if interaction.agent_a_pfb_end_trans is not None:

                        print(' change %9.8f ' % (interaction.agent_a_pfb_end_trans - interaction.agent_a_pfb_start_trans))

                    print(' ag_ch_prop_fb_simple =', interaction.ag_ch_prop_fb_simple)

                else:

                    print(' pop[0] is cp_agent - home', interaction.cp_agent.home)
                    print(' start day res ', interaction.agent_b_start_day_res, 'basket', interaction.agent_b_start_day_bskt)
                    print(' start intn res ', interaction.agent_b_start_trans_res, 'basket', interaction.agent_b_start_trans_bskt)
                    print(' counterpart home ', interaction.agent.home, ' counterpart basket ', interaction.agent_a_start_trans_bskt)
                    print(' intn dec =', interaction.agent_b_dec, 'other agent =', interaction.agent_a_dec)

                    if interaction.transfer_to_agent_b[0] > 0.0 or interaction.transfer_to_agent_b[1] > 0.0:

                        print(' transfer to agent (gains) ', interaction.transfer_to_agent_b)

                    elif interaction.transfer_to_agent_b[0] < 0.0 or interaction.transfer_to_agent_b[1] < 0.0:

                        print(' transfer from agent (loses) ', interaction.transfer_to_agent_b)

                    else:

                        print(' no transfer to or from agent ', interaction.transfer_to_agent_b)

                    print('\n cp_exp_overall_rtn =', interaction.cp_exp_overall_rtn, ' ag_exp_overall_rtn =', interaction.ag_exp_overall_rtn)
                    print(' cp_exp_quad_3_rtn =', interaction.cp_exp_quad_3_rtn, ' ag_exp_quad_2_rtn =', interaction.ag_exp_quad_2_rtn)

                    print('\n cp_agent_net_benefit =', interaction.cp_agent_net_benefit, 'cp_agent_net_benefit_back_prop =', interaction.cp_agent_net_benefit_back_prop)
                    print(' (other agent_net_benefit =', interaction.agent_net_benefit, ' other agent_net_benefit_back_prop =', interaction.agent_net_benefit_back_prop, ')')

                    print('\n cp_agent_net_benefit_back_prop_fb =', interaction.cp_agent_net_benefit_back_prop_fb)
                    print(' agent_net_benefit_back_prop_fb =', interaction.agent_net_benefit_back_prop_fb)

                    print('\n cp_agent_net_gain_NNs = \n', interaction.cp_agent_net_gain_NNs)
                    print('\n agent_net_gain_NNs = \n', interaction.agent_net_gain_NNs)

                    print('\n ps at start of trans =', interaction.agent_b_ps_start_trans)
                    print(' ps at end of trans =', interaction.agent_b_ps_end_trans)

                    if interaction.agent_b_ps_end_trans is not None:

                        print(' change %9.8f ' % (interaction.agent_b_ps_end_trans - interaction.agent_b_ps_start_trans))

                    print(' cp_ch_prop_steal_simple = ', interaction.cp_ch_prop_steal_simple)

                    print('\n pfb at start of trans =', interaction.agent_b_pfb_start_trans)
                    print(' pfb at end of trans =', interaction.agent_b_pfb_end_trans)

                    if interaction.agent_b_pfb_end_trans is not None:

                        print(' change %9.8f ' % (interaction.agent_b_pfb_end_trans - interaction.agent_b_pfb_start_trans))

                    print(' cp_ch_prop_fb_simple =', interaction.cp_ch_prop_fb_simple)

    if (params.track_agent and params.track_agent <= day) or print_fine_dets:
        print('\n\n')
        pause()


def agents_communicate(params, agent_population, fountain_population, dbs, agents_comm_prob, day, town_grid, print_dets, print_fine_dets, respect_property_rights, num_rounds, price_mean,
                       force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, agree_location, agent_mem_length, prop_steal_floor, fight_balance, adjust_props_r,
                       agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0, clear_of_fights_radius, rounds, stranger_int, strat_choice, two_tribes_inst,
                       strangers_if_unknown, track_agent):

    """This function organises the communication of agents, which is when the agents on the grid tell each other about
    their transaction locations.  An important parameter here is agents_comm_prob, which is the prob'y that an agent
    communicates with each other agent.  This is a 'slider': we can increase it until agents converge on a single
    market square (or not).  The prob'y corresponds to the prob'y that an agent interacts with each of the other agent i.e.
    the agent is given an opportunity to interact with every other agent."""

    # print_fine_dets = 1
    # print_dets = 1

    # if day >= 500:
    #     print_fine_dets = 1

    if print_fine_dets or (params.track_agent and params.track_agent <= day):
        print('\n\n *** Starting agents_communicate')
        print('\n agents_comm_prob', agents_comm_prob)
        print(' agree_location ', agree_location, '\n')
        # pause()

    # blank these before proceeding
    for agent in agent_population.pop:
        agent.agreed_meeting_point = None
        agent.meeting_point_cps = []

        # at this stage we also clear the agent's exp_returns_dict
        agent.exp_returns_dict = dict()
        agent.exp_int_gains_dict = dict()
        agent.exp_int_gains_dict_strangers = dict()

    # We allow the agents to interact bilaterally first - this happens regardless of agree_location (if == 'super_strong' then the above code is executed - if anthing else, i.e. strong or
    # weak) then agents are organised in this bit of code, which also allows agents to communicate transaction locations, possibly fight location, and reputation information).
    # We want to do this before the sophisticated form of organisation because the agents can communicate about reputations, which is useful for organising.

    # Start with putting the population in pairs
    agent_pairs_bucket = []
    for ag in agent_population.pop:
        for ag_2 in agent_population.pop:
            if ag != ag_2 and random.random() < agents_comm_prob:
                agent_pairs_bucket.append([ag, ag_2])

    # copy the agent population - this copy is for the iteration over all agents (for agent in...)
    # copy_population = list(copy.copy(agent_population.pop))
    # random.shuffle(copy_population)

    # this copy manages the residual populations - we remove each agent one by one
    # copy_population_2 = copy.copy(copy_population)

    #    if print_dets == 1:
    #        print('\n copy_population', copy_population)

    #    if day >= 10:
    #
    #        print_dets = print_fine_dets = 1

    # counter = 1

    # we want any pair of agents to have a probability of communicating of agents_comm_prob: we can think of this as a squre matrix with the list of agents on each axis.
    # we want to use one side of the matrix (a triangle) without the diagonal elements only.  so if we take a copy of the agent population, remove the first agent, we are left
    # with the top line of the triangular matrix to choose a cp_agent.  We then remove each agent in turn and iterate over the remaining agents.
    # for agent in copy_population:

        #        if 0 < day - agent.birth_date < 5 and day > 100:
        #
        #            print_dets = 1

        #        print('\n len(copy_population)', len(copy_population))

        # copy_population_2.remove(agent)

        # if print_fine_dets:
        #     print('\n\n\n\n\n\n\n\n -------------->agent =', agent, agent.home)

        # for cp_agent in copy_population_2:

        # if track_agent and params.track_agent <= day and (agent_population.tracking_agent == agent or cp_agent == agent_population.tracking_agent):
        #     print_dets = 1
        #     print_fine_dets = 1
        # else:
        #     print_dets = 0
        #     print_fine_dets = 0

    def pair_comms(agent_pair):

        agent, cp_agent = agent_pair

        if (params.track_agent and params.track_agent <= day) and (agent == agent_population.tracking_agent or cp_agent == agent_population.tracking_agent):

            print_for_tracking = 1

        else:
            print_for_tracking = 0

        if print_fine_dets or print_for_tracking:
            print('\n\n ------> agent =', agent, agent.home)
            print(' ----> cp_agent =', cp_agent, cp_agent.home)
            print('\n agent_population.tracking_agent.home', agent_population.tracking_agent.home)
            print(' counter = ', counter)
            print(' len(copy_population) =', len(copy_population))
            print(' len(copy_population_2) =', len(copy_population_2))

        if cp_agent == agent:
            print('\n PROMBLEM!! agent interacting with self')
            pause()

        if print_fine_dets or print_for_tracking:
            print('\n str(cp_agent) in agent.reputations_dict ', str(cp_agent) in agent.reputations_dict)
            print(' str(agent) in cp_agent.reputations_dict ', str(agent) in cp_agent.reputations_dict)

        agents_want_to_comm = 'reputations_only'

        agent_exp_gain = cp_agent_exp_gain = 0

        # rand_num = random.random()
        #
        # if print_fine_dets or print_for_tracking:
        #     print('\n rand_num =', rand_num, 'agents_comm_prob', agents_comm_prob)
        #
        # if rand_num < agents_comm_prob:  # if agree_location == 'none' then we just use the probability of interaction to determine if agents interact

        # if agent_population.pop[0] == agent or agent_population.pop[0] == cp_agent:
        #     print_for_tracking = 1
        #     print_dets = print_fine_dets = 1

        if print_for_tracking:
            print('\n agents_communicate')
            print(' agents_comm_prob', agents_comm_prob)
            print(' agree_location =', agree_location)
            # print_dets = 1

        # if the agents don't respect property rights, they will only communicate with each other if (i) they both know of each other (in each other's reputations_dict) - if cp_agent
        # is not in agent.reputations_dict then agent won't listen and won't divulge, and vv; and (ii) if both of them think the interaction would be worthwhile (if the interaction is
        # expected to be negative for one agent then they won't listen and won't divulge.
        # We test (ii) by running the method find_exp_returns_intn for both agents and then seeing if they would expect to gain from an interaction.  Note we assume both have baskets of [1, 1].
        # Also, we assume they always communicate about reputations.
        # I might want to re-think this in due course - at the moment, I assume agents are very precious about divulging transaction locations but they are more comfortable divulging information
        # about other agents.
        # we don't test if the agents are in each other's dictionaries: we ask if the agents have heard about the other's prop_steal in the length of their memories
        if agree_location != 'none':

            if print_fine_dets or print_for_tracking:
                print('\n str(agent) in cp_agent.reputations_dict  ', str(agent) in cp_agent.reputations_dict, '  str(cp_agent) in agent.reputations_dict   ', str(cp_agent) in agent.reputations_dict)

            if str(agent) in cp_agent.reputations_dict and str(cp_agent) in agent.reputations_dict:

                if strat_choice == 'propensities':

                    ag_exp_cp_prop_steal, ag_exp_cp_prop_fight_back, num_interactions = find_cp_props(params, agent, cp_agent, day, len_reputations_mem, print_fine_dets)
                    cp_exp_ag_prop_steal, cp_exp_ag_prop_fight_back, num_interactions = find_cp_props(params, cp_agent, agent, day, len_reputations_mem, print_fine_dets)

                    if print_fine_dets or print_for_tracking:
                        print('\n ag_exp_cp_prop_steal', ag_exp_cp_prop_steal, 'cp_exp_ag_prop_steal', cp_exp_ag_prop_steal)

                # both agents must be known to have transactioned over the memory length of reach other (note no fb used here)
                if respect_property_rights == 0 and (strat_choice == 'rational' or (strat_choice == 'propensities' and ag_exp_cp_prop_steal is not None and cp_exp_ag_prop_steal is not None)):

                    # print_fine_dets = print_dets = 1

                    if print_for_tracking:

                        print('\n two agents check_if_want_to_interact')

                    agent_exp_gain, cp_agent_exp_gain = check_if_want_to_interact(params, agent, cp_agent, agent_population, price_mean, force_prices, fixed_price, day,
                                                                                  dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                  fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill,
                                                                                  fix_ps_fb_0, stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                    if agent_exp_gain is not None and agent_exp_gain > 0 and cp_agent_exp_gain is not None and cp_agent_exp_gain > 0:
                        agents_want_to_comm = 'both'

        #                                if day >= 0:
        #
        #                                    print('\n\n day ', day, 'agents know about each other')
        #                                    print(' ag_exp_cp_prop_steal', ag_exp_cp_prop_steal, 'cp_exp_ag_prop_steal', cp_exp_ag_prop_steal, 'num_interactions', num_interactions, '\n')
        #                                    print(' agent_exp_gain', agent_exp_gain, 'cp_agent_exp_gain', cp_agent_exp_gain)
        #                                    print('agents_want_to_comm', agents_want_to_comm, '\n')
        #
        #                                    pause()

        two_agents_communicate(params, agent_population, town_grid, agent, cp_agent, day, print_dets, respect_property_rights, num_rounds, day, agents_want_to_comm, dbs,
                               price_mean, force_prices, fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
                               agent_exp_gain, cp_agent_exp_gain, agent_mem_length, fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                               clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst, print_fine_dets, track_agent, strangers_if_unknown)

        # if print_for_tracking:
        #
        #     pause()
        #
        # print_dets = print_fine_dets = 0

    # counter += 1

    threads = []
    counter = 0
    # print(f'\n agent comms: len(agent_pairs_bucket) = {len(agent_pairs_bucket)}')
    for agent_pair in agent_pairs_bucket:

        t = threading.Thread(target=pair_comms, args=[agent_pair])
        t.start()
        threads.append(t)

        # print(f'counter = {counter} | Active Threads: {threading.active_count()}')

        counter += 1

    # print(f'end - Active Threads: {threading.active_count()}')

    for thread in threads:
        thread.join()

    if (params.track_agent and params.track_agent <= day):

        print('\n\n ---> end of agents_communicate agent_population.tracking_agent.reputations_dict: ')

        start_day = np.max([0, day - params.agent_mem_length])

        if len(agent_population.tracking_agent.reputations_dict) == 0:

            print('\n none')

        else:

            for rep_agent in agent_population.tracking_agent.reputations_dict:

                ps = np.sum(agent_population.tracking_agent.reputations_dict[str(rep_agent)][0][start_day:day + 1]) / float(np.sum(agent_population.tracking_agent.reputations_dict[str(rep_agent)][1][start_day:day + 1]))

                if np.sum(agent_population.tracking_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]) > 0.0:

                    pfb = np.sum(agent_population.tracking_agent.reputations_dict[str(rep_agent)][2][start_day:day + 1]) / float(np.sum(agent_population.tracking_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]))

                else:

                    pfb = 0.0

                for ag in agent_population.pop:
                    if str(ag) == rep_agent:

                        print('\n rep_agent home', ag.home, 'exp prop_steal %4.2f' % ps, 'vs actual %4.2f' % ag.prop_steal, 'exp prop_fight_back %4.2f' % pfb, 'vs actual %4.2f' % ag.prop_fight_back)

                print(' ps numerator =', agent_population.tracking_agent.reputations_dict[str(rep_agent)][0][start_day:day + 1], 'ps denom =', agent_population.tracking_agent.reputations_dict[str(rep_agent)][1][start_day:day + 1])
                print(' pfb numerator =', agent_population.tracking_agent.reputations_dict[str(rep_agent)][2][start_day:day + 1], 'pfb denom =', agent_population.tracking_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1])

        print('\n End of agents_communicate \n')
        # pause()

            # set these to None - speeds code up so we don't keep finding these
    dbs.latest_trans = None
    dbs.latest_fights = None

    # if we allow the agents to organise themselves in a sophisticated way (agree_location == 'super_strong') then we run this code first
    if respect_property_rights == 0 and agree_location == 'super_strong':

        # print_fine_dets = 1

        if print_fine_dets == 1:
            print('\n\n\n\n ******* starting new group organisation process')

        # first collect all the agents who have prop_steal equal to the prop_stel_floor
        min_prop_steal_agents = []
        residual_agents = []

        for agent in agent_population.pop:

            if agent.prop_steal == prop_steal_floor:

                min_prop_steal_agents.append(agent)

            else:

                residual_agents.append(agent)

        # in this situation we ensure that every agent in min_prop_steal_agents has each other in their dictionary with no fights, i.e., exp prop_steal = 0
        # here we assume two things: first, that prop_steal_floor is always zero or very low (e.g. 0.01); and, second, that if an agent doesn't have another agent in its reputations dict,
        # it will give that agent the benefit of the doubt, and assume it is an angel
        for agent in agent_population.pop:

            for cp_agent in agent_population.pop:

                if agent is not cp_agent:

                    if cp_agent is not agent_population.change_agent and agent is not agent_population.change_agent:

                        str_agent = str(agent)
                        str_cp_agent = str(cp_agent)

                        if str_agent not in cp_agent.reputations_dict:
                            cp_agent.reputations_dict[str_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                    np.zeros(shape=(num_rounds), dtype=int)]

                            # add one interaction to this (cp_agent will then assume that in this interaction the agent did not fight)
                            cp_agent.reputations_dict[str_agent][1][day] += 1
                            cp_agent.reputations_dict[str_agent][3][day] += 1

                        if str_cp_agent not in agent.reputations_dict:
                            agent.reputations_dict[str_cp_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                    np.zeros(shape=(num_rounds), dtype=int)]

                            # add one interaction to this (agent will then assume that in this interaction the agent did not fight)
                            agent.reputations_dict[str_cp_agent][1][day] += 1
                            agent.reputations_dict[str_cp_agent][3][day] += 1

                    elif agent is agent_population.change_agent:

                        str_agent = str(agent)
                        str_cp_agent = str(cp_agent)

                        if str_agent not in cp_agent.reputations_dict:
                            cp_agent.reputations_dict[str_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                    np.zeros(shape=(num_rounds), dtype=int)]

                            # the cp_agent knows from the outset that change_agent's reputation is 0.5 steal, 0.5 fb
                            cp_agent.reputations_dict[str_agent][0][day] += 1
                            cp_agent.reputations_dict[str_agent][1][day] += 2
                            cp_agent.reputations_dict[str_agent][2][day] += 1
                            cp_agent.reputations_dict[str_agent][3][day] += 2

                        if str_cp_agent not in agent.reputations_dict:
                            agent.reputations_dict[str_cp_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                    np.zeros(shape=(num_rounds), dtype=int)]

                            # add one interaction to this (agent will then assume that in this interaction the agent did not fight)
                            agent.reputations_dict[str_cp_agent][1][day] += 1
                            agent.reputations_dict[str_cp_agent][3][day] += 1

        #        if day == 0 or day > 20:

        #        print('\n first agent reputations arrays \n')
        #
        #        for agent in agent_population.pop:
        #
        #            if agent is not agent_population.pop[0]:
        #
        #                print('\n agent.home', agent.home, 'reputations 0', agent_population.pop[0].reputations_dict[str(agent)][0][0:day + 1])
        #                print(' agent.home', agent.home, 'reputations 1', agent_population.pop[0].reputations_dict[str(agent)][1][0:day + 1])
        #                print(' agent.home', agent.home, 'reputations 2', agent_population.pop[0].reputations_dict[str(agent)][2][0:day + 1])
        #                print(' agent.home', agent.home, 'reputations 3', agent_population.pop[0].reputations_dict[str(agent)][3][0:day + 1])
        #
        #        pause()

        if print_fine_dets == 1:
            print('\n len(min_prop_steal_agents)', len(min_prop_steal_agents))
            print('\n min_prop_steal_agents:\n', min_prop_steal_agents)

            print('\n len(residual_agents)', len(residual_agents))
            print('\n residual_agents:\n', residual_agents)

        #            pause()

        # it is not enough that the agents have prop_steal = floor; they must also be comfortable with each other, so we allow the agents to opt in or out of this group
        if print_fine_dets == 1:
            print('\n now each of the new A Team decides if it wants to be in or not - reputations might differ from current reality')

        already_considered_group = copy.copy(min_prop_steal_agents)
        new_angel_group = []

        for angel_agent in min_prop_steal_agents:

            if print_fine_dets == 1:
                print('\n potential A Team member home = ', angel_agent.home)

            ag_aggr_gain = 0

            for cp_agent in min_prop_steal_agents:

                if angel_agent is not cp_agent:

                    if print_fine_dets == 1:
                        print('\n other A Team member home =', cp_agent.home)

                    angel_exp_gain, cp_agent_exp_gain = check_if_want_to_interact(params, angel_agent, cp_agent, agent_population, price_mean, force_prices, fixed_price, day,
                                                                                  dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                  fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill,
                                                                                  fix_ps_fb_0, stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                    if print_fine_dets == 1:
                        print(' angel_exp_gain =', angel_exp_gain)
                        print(' cp_agent_exp_gain =', cp_agent_exp_gain)

                    ag_aggr_gain += angel_exp_gain

            if print_fine_dets == 1:
                print('\n ag_aggr_gain =', ag_aggr_gain)

            if ag_aggr_gain >= 0:

                if print_fine_dets == 1:
                    print('\n => angel is staying - awww')

                new_angel_group.append(angel_agent)

            else:

                if print_fine_dets == 1:
                    print('\n => angel is outta there')

                # add the agent to residual agents = joins the crowd
                residual_agents.append(angel_agent)

        if print_fine_dets == 1:
            print('\n len(new_angel_group) = ', len(new_angel_group))
            print('\n new_angel_group \n', new_angel_group)
            print('\n new_angel_group becomes min_prop_steal_agents')

        #            pause()

        min_prop_steal_agents = copy.copy(new_angel_group)

        # randomise min_prop_steal_agents so there are no systematic biases in this process
        if len(min_prop_steal_agents) > 1:
            random.shuffle(min_prop_steal_agents)

        if print_fine_dets == 1:
            print('\n Now considering if any agents in residual_agents should join')

        # it's possible that agents in residual_agents would want to be in this group and this group would want the agent, i.e. the resid agent doesn't have prop steal at floor but people want it
        # if both these conditions are true then we add the agent
        if len(min_prop_steal_agents) > 0:

            for resid_agent in residual_agents:

                if resid_agent not in already_considered_group:  # if they were in the original group and left, they cannot re-join

                    if print_fine_dets == 1:
                        print('\n resid_agent.home \n', resid_agent.home)

                    # first of all, does the resid_agent want to be a part of this min_prop_steal_agents group?
                    resid_aggr_exp_gain = 0
                    lovely_aggr_exp_gain = 0

                    for lovely_agent in min_prop_steal_agents:

                        resid_exp_gain, lovely_exp_gain = check_if_want_to_interact(params, resid_agent, lovely_agent, agent_population, price_mean, force_prices, fixed_price, day,
                                                                                    dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                    fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                                                                    stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                        if print_fine_dets == 1:
                            print(' lovely_agent.home', lovely_agent.home, 'resid_exp_gain =', resid_exp_gain, 'lovely_exp_gain =', lovely_exp_gain)

                        #                        if print_fine_dets == 1:
                        #                            print(' resid_exp_gain =', resid_exp_gain)
                        #                            print(' lovely_exp_gain =', lovely_exp_gain)

                        resid_aggr_exp_gain += resid_exp_gain
                        lovely_aggr_exp_gain += lovely_exp_gain

                    if print_fine_dets == 1:
                        print('\n resid_aggr_exp_gain =', resid_aggr_exp_gain)
                        print(' lovely_aggr_exp_gain =', lovely_aggr_exp_gain)

                    if resid_aggr_exp_gain >= 0 and lovely_aggr_exp_gain >= 0:  # then the resid_agent joins the group

                        if print_fine_dets == 1:
                            print('\n resid_agent joins the A group!')

                        min_prop_steal_agents.append(resid_agent)
                        residual_agents.remove(resid_agent)

                    else:

                        if print_fine_dets == 1:
                            print('\n resid_agent did not join the A group.')

        #                    pause()

        if print_fine_dets == 1:
            print('\n len(min_prop_steal_agents)', len(min_prop_steal_agents))
            print(' min_prop_steal_agents \n', min_prop_steal_agents)

            print('\n now we consider if all of these agents want to be in the group!')

        # by this stage we will have agents in min_prop_steal_agents but we have to allow the agents in the group now to leave if they want
        newer_angel_group = []

        for angel_agent in min_prop_steal_agents:

            if print_fine_dets == 1:
                print('\n potential A Team member home = ', angel_agent.home)

            ag_aggr_gain = 0

            for cp_agent in min_prop_steal_agents:

                if angel_agent is not cp_agent:

                    if print_fine_dets == 1:
                        print('\n does this agent want to remain in the group?')

                    angel_exp_gain, cp_agent_exp_gain = check_if_want_to_interact(params, angel_agent, cp_agent, agent_population, price_mean, force_prices, fixed_price, day,
                                                                                  dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                  fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                                                                  stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                    if print_fine_dets == 1:
                        print(' angel_exp_gain =', angel_exp_gain)
                        print(' cp_agent_exp_gain =', cp_agent_exp_gain)

                    ag_aggr_gain += angel_exp_gain

            if print_fine_dets == 1:
                print('\n ag_aggr_gain =', ag_aggr_gain)

            if ag_aggr_gain >= 0:

                if print_fine_dets == 1:
                    print(' angel is staying - awww')

                newer_angel_group.append(angel_agent)

            else:

                if print_fine_dets == 1:
                    print('\n angel is outta there')

                # add the agent to residual agents = joins the crowd
                residual_agents.append(angel_agent)

            if print_fine_dets == 1:
                print('\n len(newer_angel_group) = ', len(newer_angel_group))
                print('\n newer_angel_group \n', newer_angel_group)
                print(' newer_angel_group becomes min_prop_steal_agents')

        min_prop_steal_agents = copy.copy(newer_angel_group)

        if len(min_prop_steal_agents) == 1:  # just one dude, no one else: it can't agree to meet anyone this way...

            min_prop_steal_agents[0].agreed_meeting_point = None

        elif len(min_prop_steal_agents) > 1:

            agreed_loc = find_agreed_loc(min_prop_steal_agents, dbs, town_grid, agent_mem_length, day, print_fine_dets, clear_of_fights_radius, rounds)

            if print_fine_dets == 1:
                print(' agreed_loc ', agreed_loc)

            # we should have a best_grid_loc now - all the agents in the lovelies group will go to this
            for lovely_agent in min_prop_steal_agents:
                lovely_agent.agreed_meeting_point = agreed_loc
                lovely_agent.meeting_point_cps = min_prop_steal_agents

            # we add the location and number of this first group of agents to dbs.agreed_locs[day] like so
            num_ags = len(min_prop_steal_agents)
            loc_x = agreed_loc[0]
            loc_y = agreed_loc[1]

            dbs.agreed_locs[day].append([loc_x, loc_y, num_ags])

        if print_fine_dets == 1:
            print('\n\n we have the A team organised now - we focus on the residual_agents')
            print('\n len(residual_agents) = ', len(residual_agents))

            pause()

        # the first group of the loveliest agents is now sorted - we move on to the next bunch of agents who were not in this group - residual_agents
        if len(residual_agents) > 1:

            # we sort the residual_agents array by the agents' propensity to steal, so the agents with the lowest prop_steal go first
            #            print('\n residual_agents =', residual_agents)

            residual_agents = sorted(residual_agents, key=lambda agent: agent.prop_steal)

            #            print('\n  post residual_agents =', residual_agents)
            #
            #            pause()

            copy_residual_agents = copy.copy(residual_agents)

            # we allow each agent in this group to attempt to form a group, going in turns (note the group was shuffled to make it random)
            for resid_agent in residual_agents:

                if print_fine_dets == 1:
                    print('\n ----> resid_agent.home = ', resid_agent.home)

                if resid_agent in copy_residual_agents and len(copy_residual_agents) > 1:  # for the first agent this will be true but it might not be true thereafter - if the agent has been removed then it is in a group

                    if print_fine_dets == 1:
                        print(' resid_agent in copy_residual_agents and len(copy_residual_agents) > 1')

                    new_group = [resid_agent]

                    # remove the agent so we iterate over remaining
                    copy_residual_agents.remove(resid_agent)

                    if print_fine_dets == 1:
                        print(' len(copy_residual_agents) = ', len(copy_residual_agents))
                        print(' agent iterates over all other agents in copy_residual_agents: \n')

                    for cp_agent in copy_residual_agents:

                        if print_fine_dets == 1:
                            print(' cp_agent.home = ', cp_agent.home)

                        resid_agent_exp_gain, cp_agent_exp_gain = check_if_want_to_interact(params, resid_agent, cp_agent, agent_population, price_mean, force_prices, fixed_price, day,
                                                                                            dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                            fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                                                                            stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                        if print_fine_dets == 1:
                            print('\n resid_agent_exp_gain =', resid_agent_exp_gain)
                            print(' cp_agent_exp_gain =', cp_agent_exp_gain)

                        if resid_agent_exp_gain >= 0 and cp_agent_exp_gain >= 0:

                            if print_fine_dets == 1:
                                print('\n cp_agent joins resid_agent gang')

                            new_group.append(cp_agent)

                    if print_fine_dets == 1:
                        print('\n len(new_group)', len(new_group))

                    if len(new_group) == 1:

                        if print_fine_dets == 1:
                            print(' Only 1 agent in group - dude is on his own.  Next hombre or move on')

                        new_group[0].agreed_meeting_point = None

                    elif len(new_group) > 1:

                        # new_group currently has agents who will interact with the resid_agent - now allow each to decide if it wants to be part of this group

                        if print_fine_dets == 1:
                            print('\n now each of the new gang decides if it wants to be in or not')

                        final_new_group = []

                        for ag_new_group in new_group:

                            if print_fine_dets == 1:
                                print('\n potential gang member home = ', ag_new_group.home)

                            ag_aggr_gain = 0

                            for cp_agent in new_group:

                                if ag_new_group is not cp_agent:

                                    if print_fine_dets == 1:
                                        print(' does it like this gang member?')

                                    ag_new_group_exp_gain, cp_agent_exp_gain = check_if_want_to_interact(params, ag_new_group, cp_agent, agent_population, price_mean, force_prices, fixed_price,
                                                                                                         day, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                                         fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                                                                                         stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                                    if print_fine_dets == 1:
                                        print(' ag_new_group_exp_gain =', ag_new_group_exp_gain)
                                        print(' cp_agent_exp_gain =', cp_agent_exp_gain)

                                    ag_aggr_gain += ag_new_group_exp_gain

                            if print_fine_dets == 1:
                                print('\n ag_aggr_gain =', ag_aggr_gain)

                            if ag_new_group_exp_gain >= 0:

                                if print_fine_dets == 1:
                                    print('\n dude is staying')

                                final_new_group.append(ag_new_group)

                            else:

                                if print_fine_dets == 1:
                                    print('\n dude is outta there')

                            if print_fine_dets == 1:
                                print('\n len(final_new_group) = ', len(final_new_group))

                        if print_fine_dets == 1:
                            print('\n\n final_new_group hombres now invites each of the remaining residual agents to apply to join the group, hommy \n')

                        # this group now invites each of the remaining residual agents to apply to join the group
                        for cp_agent in copy_residual_agents:

                            if cp_agent not in new_group and cp_agent not in final_new_group:  # i.e. it hasn't been considered by the final_new_group nor the resid_agent

                                if print_fine_dets == 1:
                                    print('\n ----> cp_agent.home = ', cp_agent.home)
                                    print(' cp_agent not in new_group and cp_agent not in final_new_group')

                                cp_aggr_gain = 0
                                final_new_group_aggr_gain = 0

                                for ag_final_new_group in final_new_group:

                                    if print_fine_dets == 1:
                                        print('\n ag_final_new_group.home =', ag_final_new_group.home)

                                    cp_agent_exp_gain, ag_final_new_group_exp_gain = check_if_want_to_interact(params, cp_agent, ag_final_new_group, agent_population, price_mean, force_prices, fixed_price, day, dbs,
                                                                                                               fountain_population, fight_cost, len_reputations_mem, intn_error_std, fight_balance, adjust_props_r,
                                                                                                               formal_inst, prob_fine, fine, agent_intn_beta, fight_skill, fix_ps_fb_0, stranger_int, strat_choice,
                                                                                                               two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                                    if print_fine_dets == 1:
                                        print(' cp_agent_exp_gain =', cp_agent_exp_gain)
                                        print(' ag_final_new_group_exp_gain =', ag_final_new_group_exp_gain)

                                    cp_aggr_gain += cp_agent_exp_gain
                                    final_new_group_aggr_gain += ag_final_new_group_exp_gain

                                if print_fine_dets == 1:
                                    print('\n cp_aggr_gain =', cp_aggr_gain)
                                    print(' final_new_group_aggr_gain =', final_new_group_aggr_gain)

                                if cp_aggr_gain > 0 and final_new_group_aggr_gain > 0:  # then cp_agent joins final_new_group

                                    if print_fine_dets == 1:
                                        print('\n => hombre is joining the gang!')

                                    final_new_group.append(cp_agent)

                                else:

                                    if print_fine_dets == 1:
                                        print('\n => hombre is a douche, he aint joinin')

                        # now find location for group:
                        agreed_loc = find_agreed_loc(final_new_group, dbs, town_grid, agent_mem_length, day, print_fine_dets, clear_of_fights_radius, rounds)

                        if print_fine_dets == 1:
                            print('\n len(final_new_group)', len(final_new_group))
                            print('\n final_new_group ', final_new_group)
                            print(' agreed_loc', agreed_loc)

                        for ag_final_new_group in final_new_group:

                            ag_final_new_group.agreed_meeting_point = agreed_loc
                            ag_final_new_group.meeting_point_cps = final_new_group

                            # remove the agents from residual_agents
                            if ag_final_new_group in copy_residual_agents:
                                copy_residual_agents.remove(ag_final_new_group)

                        # we add the location and number of this first group of agents to dbs.agreed_locs[day] like so
                        num_ags = len(final_new_group)
                        loc_x = agreed_loc[0]
                        loc_y = agreed_loc[1]

                        dbs.agreed_locs[day].append([loc_x, loc_y, num_ags])

        if print_fine_dets == 1:
            print('\n lets look at the population after these grouping: \n')

            for agent in agent_population.pop:
                print('agent.home', agent.home, 'agreed_meeting_point =', agent.agreed_meeting_point, '  res [%1.2f %1.2f]' % (agent.agent_res_array[0][0], agent.agent_res_array[0][1]),
                      '  basket [%1.2f %1.2f]' % (agent.basket_array_start[0][0], agent.basket_array_start[0][1]), '  prop_steal %1.3f' % agent.prop_steal, 'prop_fight_back %1.3f' % agent.prop_fight_back)

    #        if day % 10 == 0:

    #        print('\n day', day, 'agents organising to meet:\n')
    #
    #        for agent in agent_population.pop:
    #
    #            print(' agent.home', agent.home, 'agreed_meeting_point =', agent.agreed_meeting_point, '  res [%1.2f %1.2f]' % (agent.agent_res_array[0][0], agent.agent_res_array[0][1]), '  basket [%1.2f %1.2f]' % (agent.basket_array_start[0][0], agent.basket_array_start[0][1]), '  prop_steal %1.3f' % agent.prop_steal, 'prop_fight_back %1.3f' % agent.prop_fight_back)
    #
    #        print('\n first agent journey that day:', agent_population.pop[0].trade_loc_rec)
    #        print('\n first agent targets that day:', agent_population.pop[0].trgt_loc_rec)
    #
    #        print('\n second agent journey that day:', agent_population.pop[1].trade_loc_rec)
    #        print('\n second agent targets that day:', agent_population.pop[1].trgt_loc_rec)
    #
    #        print('\n change_agent journey that day:', agent_population.change_agent.trade_loc_rec)
    #        print('\n change_agent targets that day:', agent_population.change_agent.trgt_loc_rec)

    if print_fine_dets == 1:
        pause()

    # summarise any groups
    #    if day > 49:
    #
    #        print('\n\n\n groupings of buddies:')
    #
    #        for agent in agent_population.pop:
    #
    #            if len(agent.meeting_point_cps) > 0:
    #
    #                print('\n\n agent.home', agent.home, 'agent.agreed_meeting_point', agent.agreed_meeting_point, 'prop_steal', agent.prop_steal, 'prop_fight_back', agent.prop_fight_back)
    #                print(' agent.meeting_point_cps', agent.meeting_point_cps)
    #                print('\n perceived reputation by agent of each cp')
    #
    #                for cp in agent.meeting_point_cps:
    #
    #                    cp_prop_steal, cp_prop_fight_back, num_interactions = find_cp_props(agent, cp, day, len_reputations_mem, print_fine_dets=1)
    #
    #                    print('\n ', cp, ': agent exp prop_steal', cp_prop_steal, 'cv actual cp.prop_steal = ', cp.prop_steal, 'agent exp prop_fight_back', cp_prop_fight_back, 'cv actual cp.prop_fight_back = ', cp.prop_fight_back)
    #                    print('\n cp in agent.reputations_dict?', str(cp) in agent.reputations_dict)

    #    pause()
    #
    #    print_dets = 0
    #    print_fine_dets = 0

    #                if print_dets == 1 and agents_want_to_comm == 'both':
    #                    input("Press Enter to continue...")

    #    # print reputation dictionaries
    #    print('\n\n reputations dictionaries:\n')

    #    for agent in agent_population.pop:
    #
    #        print(agent, agent.reputations_dict)
    #
    #    input("Press Enter to continue...")

    if print_fine_dets == 1:
        print('\n ------> Updating prices')

    # Each agent now looks through its memory and updates its agent.wkg_prices_memory
    start_round = np.max([0, day - agent.agent_mem_length])

    if print_fine_dets == 1:
        print('\n start_round =', start_round)

    for agent in agent_population.pop:

        #        if print_fine_dets == 1 and random.random() < 0.1 and day == 199:
        #            print_dets = 1
        #            print_fine_dets = 1
        #
        #        else:
        #            print_dets = 0
        #            print_fine_dets = 0

        if print_fine_dets == 1:
            print('\n\n\n\n\n agent =', agent)

        #        for sell_res in np.arange(num_res_founts):
        #
        #            for buy_res in np.arange(num_res_founts):
        #
        #                if sell_res < buy_res:      # this ensures we only do it the necessary number of times (default: 0, 1; 0, 2; and 1, 2)

        if print_fine_dets == 1 and random.random() < 0.1:
            print('\n agent.loc_mems_array[start_round : (day + 1)] =\n')
            for day_line in agent.loc_mems_array[start_round: (day + 1)]:
                print(day_line)
            print('\n agent.loc_mems_array[day] =\n', agent.loc_mems_array[day])

        # get transactions in agent's own memories ([sell_res][buy_res])
        transs_for_prices = np.array([agent.loc_mems_array[d][i] for d in np.arange(start_round, (day + 1)) for i in np.arange(len(agent.loc_mems_array[d]))], dtype=int)

        #        # get transactions in agent's own memories ([buy_res][sell_res])
        #        transs_for_prices = np.append(transs_for_prices, np.array([agent.loc_mems_array[d][i] for d in np.arange(start_round, (day + 1)) for i in np.arange(len(agent.loc_mems_array[d])) if agent.loc_mems_array[d][i] not in transs_for_prices], dtype=int))

        # add transactions in memories from second persons ([sell_res][buy_res])
        transs_for_prices = np.append(transs_for_prices,
                                      np.array([agent.loc_mems_array_cp[d][i] for d in np.arange(start_round, (day + 1)) for i in np.arange(len(agent.loc_mems_array_cp[d])) if agent.loc_mems_array_cp[d][i] not in transs_for_prices],
                                               dtype=int))

        #        # add transactions in memories from second persons ([buy_res][sell_res])
        #        transs_for_prices = np.append(transs_for_prices, np.array([agent.loc_mems_array_cp[d][i] for d in np.arange(start_round, (day + 1)) for i in np.arange(len(agent.loc_mems_array_cp[d])) if agent.loc_mems_array_cp[d][i] not in transs_for_prices], dtype=int))

        #                if len(transs_for_prices) > 0:

        if print_fine_dets == 1:
            print('\n transs_for_prices =\n', transs_for_prices)

        # Find total value of sell_res and divide by total value of buy_res => working price
        tot_value_sell_res = 0.0
        tot_value_buy_res = 0.0

        if print_fine_dets == 1:
            print('\n working through transactions in transs_for_prices :\n')

        for trans_num in transs_for_prices:

            trans = dbs.trans_db[trans_num]

            if trans.good_a is not None:

                if print_fine_dets == 1:
                    print('\n trans_num =', trans_num)
                    print(' trans.good_a =', trans.good_a)
                    print(' trans.tot_trans_ag_sell =', trans.tot_trans_ag_sell)
                    print(' trans.good_b =', trans.good_b)
                    print(' trans.tot_trans_ag_buy =', trans.tot_trans_ag_buy)

                for sell_res in np.arange(num_res_founts):

                    for buy_res in np.arange(num_res_founts):

                        if sell_res < buy_res:  # this ensures we only do it the necessary number of times (default: 0, 1; 0, 2; and 1, 2)

                            if trans.good_a == sell_res:

                                tot_value_sell_res += trans.tot_trans_ag_sell
                                tot_value_buy_res += trans.tot_trans_ag_buy

                            elif trans.good_a == buy_res:

                                tot_value_sell_res += trans.tot_trans_ag_buy
                                tot_value_buy_res += trans.tot_trans_ag_sell

                            if print_fine_dets == 1:
                                print('\n tot_value_sell_res =', tot_value_sell_res)
                                print(' tot_value_buy_res =', tot_value_buy_res)

                            working_price = tot_value_sell_res / float(tot_value_buy_res)

                            if print_fine_dets == 1:
                                print('\n working_price =', working_price)

                            agent.wkg_prices_memory[sell_res][buy_res] = working_price
                            agent.wkg_prices_memory[buy_res][sell_res] = 1 / float(working_price)

        if print_fine_dets == 1:
            print('\n agent.wkg_prices_memory =\n', agent.wkg_prices_memory)

    if print_dets == 1 or print_fine_dets == 1:

        pause()


def two_agents_communicate(params, agent_population, town_grid, agent, cp_agent, round, print_dets, respect_property_rights, num_rounds, day, agents_want_to_comm, dbs,
                           price_mean, force_prices, fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
                           start_agent_exp_gain, start_cp_agent_exp_gain, agent_mem_length, fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine,
                           fight_skill, fix_ps_fb_0, clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst, print_fine_dets, track_agent, strangers_if_unknown):
    """This function organises the communication of two agents i.e. the exchange of information about transaction
    locations and also prices."""

    if print_fine_dets:
        print('\n\n ** Starting two_agents_communicate')

    # now we allow the agents to communicate about their own transactions in the current round
    # they do this regardless of whether they have transacted with each other

    # if day >= 500:
    #
    #     print_fine_dets = print_dets = 1

    #    else:
    #
    #        print_fine_dets = print_dets = 0
    #
    #    if agents_want_to_comm == 'both' and day > 49:
    #        print_fine_dets = print_dets = 1

    if ((params.track_agent and params.track_agent <= day) and (agent_population.tracking_agent == agent or agent_population.tracking_agent == cp_agent)) or print_fine_dets:
        print_dets = print_fine_dets = 1

        print('\n\n -> two_agents_communicate starts - day', day)
        print('\n agent.home =', agent.home, 'cp_agent.home', cp_agent.home)
        print(' agree_location', agree_location)

        print('\n start_agent_exp_gain =', start_agent_exp_gain, 'start_cp_agent_exp_gain', start_cp_agent_exp_gain)
        print('\n agents_want_to_comm: ', agents_want_to_comm)

    if print_dets == 1 and agents_want_to_comm == 'both':
        print('\n agents communicate with each other about these arrays:')
        print('\n pre-agent.loc_mems_array[round] =', agent.loc_mems_array[round])
        print(' pre-cp_agent.loc_mems_array[round] =', cp_agent.loc_mems_array[round])

        print('\n other agents transactions arrays - today prior to including any new information')
        print('\n pre-agent.loc_mems_array_cp[round] =', agent.loc_mems_array_cp[round])
        print(' pre-cp_agent.loc_mems_array_cp[round] =', cp_agent.loc_mems_array_cp[round])

    if respect_property_rights == 1 or agents_want_to_comm == 'both' or agree_location == 'none':

        num_transs_in_mem = 0
        last_round_trans_loc = None

        pass_strong_to_weak_org = 0

        locs_where_traded_before = []

        all_ags_trans_locs = []

        # if (len(agent.loc_mems_array[round]) > 0 or len(cp_agent.loc_mems_array[round]) > 0): # or ((agree_location == 'weak' or agree_location == 'strong') and (len(agent.loc_fights_array[day]) > 0 or len(cp_agent.loc_fights_array[day]) > 0)):
        #     print_fine_dets = 1

        # if print_fine_dets:
        #     print('\n\n ** Starting two_agents_communicate')

        # start with the subject agent telling the cp_agent about transactions in the previous round
        if len(agent.loc_mems_array[day]) > 0:  # then there's data, add them one at a time

            if print_fine_dets:
                print('\n agent.loc_mems_array[day]:', agent.loc_mems_array[day])
                print('\n cp_agent.location_memories_dict: \n')
                for item in cp_agent.location_memories_dict:
                    print(' ', item, '\t', cp_agent.location_memories_dict[item])
                print('\n params.target_location_weights', params.target_location_weights)

            for trans_num in agent.loc_mems_array[day]:

                trans = dbs.trans_db[trans_num]

                if print_fine_dets:
                    print('\n --> trans_num', trans_num)
                    print(' trans.location', trans.location)
                    print(' trans.good_a', trans.good_a)
                    print(' trans.agent_a_home', trans.agent_a_home)
                    print(' trans.agent_b_home', trans.agent_b_home)
                    print(' trans.tot_trans_ag_buy', trans.tot_trans_ag_buy)

                if trans.good_a is not None:

                    num_transs_in_mem += 1

                    all_ags_trans_locs.append(copy.copy(trans.location))

                    if print_fine_dets:
                        print('\n trans_num in cp_agent.loc_mems_array[day]', trans_num in cp_agent.loc_mems_array[day])

                    # we are not interested in transactions which cp_agent was involved in (double counting)
                    if trans_num not in cp_agent.loc_mems_array[day]:

                        # if str(cp_agent) is not trans.agent_a and str(cp_agent) is not trans.agent_b:

                        # if the location weights are using reduced values then we need to find these:
                        if params.target_location_weights == 'reduced_value':

                            # note that we want the agent to inform the cp_agent of its reduced value in the transaction
                            if str(agent) == trans.agent_a:
                                agent_reduced_value = trans.agent_a_reduced_value

                            elif str(agent) == trans.agent_b:
                                agent_reduced_value = trans.agent_b_reduced_value

                            if print_fine_dets:
                                print('\n agent_reduced_value', agent_reduced_value)

                        if print_fine_dets:
                            print(' str(list(trans.location)) in cp_agent.location_memories_dict', str(list(trans.location)) in cp_agent.location_memories_dict)

                        if str(list(trans.location)) not in cp_agent.location_memories_dict:

                            if params.target_location_weights == 'crude':
                                cp_agent.location_memories_dict[str(list(trans.location))] = cp_agent.cp_trans_weight

                            elif params.target_location_weights == 'reduced_value':
                                cp_agent.location_memories_dict[str(list(trans.location))] = agent_reduced_value * cp_agent.cp_trans_weight

                        else:

                            if params.target_location_weights == 'crude':
                                cp_agent.location_memories_dict[str(list(trans.location))] += cp_agent.cp_trans_weight

                            elif params.target_location_weights == 'reduced_value':
                                cp_agent.location_memories_dict[str(list(trans.location))] += agent_reduced_value * cp_agent.cp_trans_weight

                    if print_fine_dets:
                        print('\n resulting cp_agent.location_memories_dict[str(list(trans.location))] =', cp_agent.location_memories_dict[str(list(trans.location))])

                # find out if the two agents had transacted in the last round
                if str(cp_agent) is trans.agent_a or str(cp_agent) is trans.agent_b:
                    locs_where_traded_before.append(copy.copy(trans.location))

            if print_fine_dets:
                print('\n end of agent telling cp_agent: cp_agent.location_memories_dict: \n')
                for item in cp_agent.location_memories_dict:
                    print(' ', item, '\t', cp_agent.location_memories_dict[item])

        # now switch - cp_agent shows agent its transactions
        if len(cp_agent.loc_mems_array[round]) > 0:  # then there's data, add then one at a time

            if print_fine_dets:
                print('\n\n cp_agent.loc_mems_array[day]:', cp_agent.loc_mems_array[day])
                print('\n agent.location_memories_dict: \n')
                for item in agent.location_memories_dict:
                    print(' ', item, '\t', agent.location_memories_dict[item])
                print('\n params.target_location_weights', params.target_location_weights)

            for trans_num in cp_agent.loc_mems_array[round]:

                trans = dbs.trans_db[trans_num]

                if print_fine_dets:
                    print('\n --> trans_num', trans_num)
                    print(' trans.location', trans.location)
                    print(' trans.good_a', trans.good_a)

                if trans.good_a is not None:

                    num_transs_in_mem += 1

                    all_ags_trans_locs.append(copy.copy(trans.location))

                    if print_fine_dets:
                        print('\n trans_num in agent.loc_mems_array[day]', trans_num in agent.loc_mems_array[day])

                    # we are not interested in transactions which agent was involved in (double counting)
                    if trans_num not in agent.loc_mems_array[day]:

                        # if str(agent) is not trans.agent_a and str(agent) is not trans.agent_b:

                        # if the location weights are using reduced values then we need to find these:
                        if params.target_location_weights == 'reduced_value':

                            if str(cp_agent) == trans.agent_a:
                                cp_agent_reduced_value = trans.agent_a_reduced_value

                            elif str(cp_agent) == trans.agent_b:
                                cp_agent_reduced_value = trans.agent_b_reduced_value

                            if print_fine_dets:
                                print('\n cp_agent_reduced_value', cp_agent_reduced_value)

                        if print_fine_dets:
                            print('\n str(list(trans.location)) in agent.location_memories_dict', str(list(trans.location)) in agent.location_memories_dict)

                        if str(list(trans.location)) not in agent.location_memories_dict:

                            if params.target_location_weights == 'crude':
                                agent.location_memories_dict[str(list(trans.location))] = agent.cp_trans_weight

                            elif params.target_location_weights == 'reduced_value':
                                agent.location_memories_dict[str(list(trans.location))] = cp_agent_reduced_value * cp_agent.cp_trans_weight

                        else:

                            if params.target_location_weights == 'crude':
                                agent.location_memories_dict[str(list(trans.location))] += agent.cp_trans_weight

                            elif params.target_location_weights == 'reduced_value':
                                agent.location_memories_dict[str(list(trans.location))] += cp_agent_reduced_value * cp_agent.cp_trans_weight

                    if print_fine_dets:
                        print('\n resulting agent.location_memories_dict[str(list(trans.location))] =', agent.location_memories_dict[str(list(trans.location))])

                # find out if the two agents had transacted in the last round
                if str(agent) is trans.agent_a or str(agent) is trans.agent_b:
                    locs_where_traded_before.append(copy.copy(trans.location))

            if print_fine_dets:
                print('\n agent.location_memories_dict: \n')
                for item in agent.location_memories_dict:
                    print(' ', item, '\t', agent.location_memories_dict[item])

        # if print_fine_dets:
        #     pause()
        #     print_fine_dets = 0

        if print_dets == 1:
            print('\n other agents transactions arrays - today AFTER including any new information')
            print('\n post-agent.loc_mems_array_cp[round] =', agent.loc_mems_array_cp[round])
            print(' post-cp_agent.loc_mems_array_cp[round] =', cp_agent.loc_mems_array_cp[round])
            print(' num_transs_in_mem', num_transs_in_mem)

        # here the agents exchange fight location information (only relevant if respect_property_rights == 0):
        if respect_property_rights == 0 and (agree_location == 'weak' or agree_location == 'strong'):

            if len(agent.loc_fights_array[day]) > 0:

                if print_fine_dets:
                    print('\n agent.loc_fights_array[day]:', agent.loc_fights_array[day])

                    print('\n cp_agent.location_memories_dict: \n')
                    for item in cp_agent.location_memories_dict:
                        print(' ', item, '\t', cp_agent.location_memories_dict[item])
                    print('\n params.target_location_weights', params.target_location_weights)

                for fight_num in agent.loc_fights_array[day]:

                    fight = dbs.fights_db[fight_num]

                    if print_fine_dets:
                        print('\n --> fight_num', fight_num)
                        print(' fight.location', fight.location)

                        if str(agent) == fight.initiator:
                            print(' agent change basket', fight.agent_res_gain)
                        else:
                            print(' agent change basket', fight.cp_agent_res_gain)

                    if print_fine_dets:
                        print('\n fight.initiator != str(cp_agent) and fight.counterpart != str(cp_agent)', fight.initiator != str(cp_agent) and fight.counterpart != str(cp_agent))

                    if fight.initiator != str(cp_agent) and fight.counterpart != str(cp_agent):  # the cp_agent doesn't know about the fight

                        # if the location weights are using reduced values then we need to find these:
                        if params.target_location_weights == 'reduced_value':

                            if str(agent) == fight.initiator:
                                agent_reduced_value = fight.initiator_reduced_value

                            elif str(agent) == fight.counterpart:
                                agent_reduced_value = fight.counterpart_reduced_value

                            if print_fine_dets:
                                print(' agent_reduced_value', agent_reduced_value)

                            if agent_reduced_value != 0.0:

                                if params.local_fight == 'minus_one' and agent_reduced_value < 0.0:

                                    local_list = [-1, 0, +1]

                                else:

                                    local_list = [0]

                                if print_fine_dets:
                                    print('\n local_list', local_list)

                                for offset_x in local_list:

                                    for offset_y in local_list:

                                        grid_square = [(fight.location[0] + offset_x) % town_grid.dimen, (fight.location[1] + offset_y) % town_grid.dimen]

                                        if print_fine_dets:
                                            print('\n grid_square', grid_square)
                                            print('\n str(list(grid_square)) in cp_agent.location_memories_dict:  ', str(list(grid_square)) in cp_agent.location_memories_dict)

                                            if str(list(grid_square)) in cp_agent.location_memories_dict:
                                                print(' original value: ', cp_agent.location_memories_dict[str(list(grid_square))])

                                        if str(list(grid_square)) not in cp_agent.location_memories_dict:
                                            cp_agent.location_memories_dict[str(list(grid_square))] = agent_reduced_value * cp_agent.cp_trans_weight

                                        else:
                                            cp_agent.location_memories_dict[str(list(grid_square))] += agent_reduced_value * cp_agent.cp_trans_weight

                                        if print_fine_dets:
                                            print(' resulting cp_agent.location_memories_dict[str(list(grid_square))] :', cp_agent.location_memories_dict[str(list(grid_square))])

                        elif params.target_location_weights == 'crude':

                            if str(agent) == fight.winner:
                                location_value = 1.0

                                if print_fine_dets:
                                    print('\n agent won the fight: location_value =', location_value)

                            else:
                                location_value = -1.0

                                if print_fine_dets:
                                    print('\n agent lost the fight: location_value =', location_value)

                            if params.local_fight == 'minus_one' and location_value < 0.0:

                                local_list = [-1, 0, +1]

                            else:

                                local_list = [0]

                            if print_fine_dets:
                                print('\n local_list', local_list)

                            for offset_x in local_list:

                                for offset_y in local_list:

                                    grid_square = [(fight.location[0] + offset_x) % town_grid.dimen, (fight.location[1] + offset_y) % town_grid.dimen]

                                    if print_fine_dets:
                                        print('\n grid_square', grid_square)

                                    if print_fine_dets:
                                        print('\n str(list(grid_square)) in cp_agent.location_memories_dict:  ', str(list(grid_square)) in cp_agent.location_memories_dict)

                                        if str(list(grid_square)) in cp_agent.location_memories_dict:
                                            print(' original value: ', cp_agent.location_memories_dict[str(list(grid_square))])

                                    if str(list(grid_square)) not in cp_agent.location_memories_dict:
                                        cp_agent.location_memories_dict[str(list(grid_square))] = location_value * cp_agent.cp_trans_weight

                                    else:
                                        cp_agent.location_memories_dict[str(list(grid_square))] += location_value * cp_agent.cp_trans_weight

                                    if print_fine_dets:
                                        print(' resulting cp_agent.location_memories_dict[str(list(grid_square))] :', cp_agent.location_memories_dict[str(list(grid_square))])

                if print_fine_dets:
                    print('\n end of agent telling cp_agent: cp_agent.location_memories_dict: \n')
                    for item in cp_agent.location_memories_dict:
                        print(' ', item, '\t', cp_agent.location_memories_dict[item])

            if len(cp_agent.loc_fights_array[day]) > 0:

                if print_fine_dets:
                    print('\n\n\n cp_agent.loc_fights_array[day]:', cp_agent.loc_fights_array[day])

                    print('\n agent.location_memories_dict: \n')
                    for item in agent.location_memories_dict:
                        print(' ', item, '\t', agent.location_memories_dict[item])
                    print('\n params.target_location_weights', params.target_location_weights)

                for fight_num in cp_agent.loc_fights_array[day]:

                    fight = dbs.fights_db[fight_num]

                    if print_fine_dets:
                        print('\n --> fight_num', fight_num)
                        print(' fight.location', fight.location)

                        if str(cp_agent) == fight.initiator:
                            print(' cp_agent change basket', fight.agent_res_gain)
                        else:
                            print(' cp_agent change basket', fight.cp_agent_res_gain)

                        print('\n fight.initiator != str(agent) and fight.counterpart != str(agent)', fight.initiator != str(agent) and fight.counterpart != str(agent))

                    if fight.initiator != str(agent) and fight.counterpart != str(agent):  # the agent doesn't know about the fight

                        # if the location weights are using reduced values then we need to find these:
                        if params.target_location_weights == 'reduced_value':

                            if str(cp_agent) == fight.initiator:
                                cp_agent_reduced_value = fight.initiator_reduced_value

                            elif str(cp_agent) == fight.counterpart:
                                cp_agent_reduced_value = fight.counterpart_reduced_value

                            if print_fine_dets:
                                print(' cp_agent_reduced_value', cp_agent_reduced_value)

                            if cp_agent_reduced_value != 0.0:

                                if params.local_fight == 'minus_one' and cp_agent_reduced_value < 0.0:

                                    local_list = [-1, 0, +1]

                                else:

                                    local_list = [0]

                                if print_fine_dets:
                                    print('\n local_list', local_list)

                                for offset_x in local_list:

                                    for offset_y in local_list:

                                        grid_square = [(fight.location[0] + offset_x) % town_grid.dimen, (fight.location[1] + offset_y) % town_grid.dimen]

                                        if print_fine_dets:
                                            print('\n grid_square', grid_square)
                                            print('\n str(list(grid_square)) in agent.location_memories_dict', str(list(grid_square)) in agent.location_memories_dict)

                                            if str(list(grid_square)) in agent.location_memories_dict:
                                                print(' original value: ', agent.location_memories_dict[str(list(grid_square))])

                                        if str(list(grid_square)) not in agent.location_memories_dict:
                                            agent.location_memories_dict[str(list(grid_square))] = cp_agent_reduced_value * agent.cp_trans_weight

                                        else:
                                            agent.location_memories_dict[str(list(grid_square))] += cp_agent_reduced_value * agent.cp_trans_weight

                                        if print_fine_dets:
                                            print(' resulting agent.location_memories_dict[str(list(grid_square))] :', agent.location_memories_dict[str(list(grid_square))])

                        elif params.target_location_weights == 'crude':

                            if str(cp_agent) == fight.winner:
                                location_value = 1.0

                                if print_fine_dets:
                                    print('\n cp_agent won the fight: location_value =', location_value)

                            else:
                                location_value = -1.0

                                if print_fine_dets:
                                    print('\n cp_agent lost the fight: location_value =', location_value)

                            if params.local_fight == 'minus_one' and location_value < 0.0:

                                local_list = [-1, 0, +1]

                            else:

                                local_list = [0]

                            if print_fine_dets:
                                print('\n local_list', local_list)

                            for offset_x in local_list:

                                for offset_y in local_list:

                                    grid_square = [(fight.location[0] + offset_x) % town_grid.dimen, (fight.location[1] + offset_y) % town_grid.dimen]

                                    if print_fine_dets:
                                        print('\n grid_square', grid_square)
                                        print('\n str(list(grid_square)) in agent.location_memories_dict', str(list(grid_square)) in agent.location_memories_dict)

                                        if str(list(grid_square)) in agent.location_memories_dict:
                                            print(' original value: ', agent.location_memories_dict[str(list(grid_square))])

                                    if str(list(grid_square)) not in agent.location_memories_dict:
                                        agent.location_memories_dict[str(list(grid_square))] = location_value * agent.cp_trans_weight

                                    elif str(list(grid_square)) in agent.location_memories_dict:
                                        agent.location_memories_dict[str(list(grid_square))] += location_value * agent.cp_trans_weight

                                    if print_fine_dets:
                                        print(' resulting agent.location_memories_dict[str(list(grid_square))] :', agent.location_memories_dict[str(list(grid_square))])

                if print_fine_dets:
                    print('\n end of cp_agent telling agent: agent.location_memories_dict: \n')
                    for item in agent.location_memories_dict:
                        print(' ', item, '\t', agent.location_memories_dict[item])

            # if print_fine_dets:
            #     pause()
            #     print_fine_dets = 0

        if agree_location == 'strong':

            # print_fine_dets = 1

            if print_fine_dets:
                print('\n agree_location == strong')
                print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)

            # both_group = 0

            if agent.agreed_meeting_point == None and cp_agent.agreed_meeting_point == None:

                pass_strong_to_weak_org = 1

            # in the next 2 conditions, one agent copies the other
            elif agent.agreed_meeting_point != None and cp_agent.agreed_meeting_point == None:

                cp_agent.agreed_meeting_point = copy.copy(agent.agreed_meeting_point)

            elif agent.agreed_meeting_point == None and cp_agent.agreed_meeting_point != None:

                agent.agreed_meeting_point = copy.copy(cp_agent.agreed_meeting_point)

            # elif agent.agreed_meeting_point != None and cp_agent.agreed_meeting_point != None:
            #     both_group = 1

            # Note we do not include the fourth possibility whereby both agents have agreed locations already.  In this case, nothing happens - it is possible that it is the same location
            # but it might not be.

            if print_fine_dets:
                print('\n resulting:')
                print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)
                print(' pass_strong_to_weak_org', pass_strong_to_weak_org)

            # print_fine_dets = 0
            #
            # if both_group:
            #
            #     pause()

        # the essential condition here is agree_location == 'weak' but we also only want to run this code if pass_strong_to_weak_org, when agree_loc is strong and neither agent is currently in a group
        if params.respect_property_rights == 0 and ((agree_location == 'weak' and agent.agreed_meeting_point == None and cp_agent.agreed_meeting_point == None) or pass_strong_to_weak_org):

            # the approach we take is to compare the two agents' location_memories_dict's: if both have positive locations in common then we choose the location with the most
            # positive to meet in the next round.  Otherwise we choose a location with the highest value where one agent has a positive score and the other zero.  Otherwise,
            # we choose a location with a zero score which is furthest from any combined negative location.

            # print_fine_dets = 1

            if print_fine_dets:

                print('\n\n --> agents now agree a location to meet at in the next round')
                print('\n agent.location_memories_dict: \n')
                for item in agent.location_memories_dict:
                    print(' ', item, '\t', agent.location_memories_dict[item])

                print('\n\n cp_agent.location_memories_dict: \n')
                for item in cp_agent.location_memories_dict:
                    print(' ', item, '\t', cp_agent.location_memories_dict[item])

                print('\n')

            # we start by designating 2 values and 2 corresponding locations, for the double-positive locations and single-positive locations
            double_positive_score = 0.0
            double_positive_location = None

            single_positive_score = 0.0
            single_positive_location = None

            positive_and_negative_score = 0.0
            positive_and_negative_location = None

            # first we iterate over agent.location_memories_dict and update all four variables
            for entry in agent.location_memories_dict:

                if print_fine_dets:
                    print('\n agent[entry] =', agent.location_memories_dict[entry])

                    if entry in cp_agent.location_memories_dict:
                        print(' cp_agent[entry] =', cp_agent.location_memories_dict[entry])

                    else:
                        print(' cp_agent[entry] = None')

                if agent.location_memories_dict[entry] > 0.0 and entry in cp_agent.location_memories_dict and cp_agent.location_memories_dict[entry] > 0.0:

                    if agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry] > double_positive_score:

                        double_positive_score = agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry]
                        double_positive_location = copy.copy(entry)

                        if print_fine_dets:
                            print('\n agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry] > double_positive_score')
                            print(' NEW double_positive_score =', double_positive_score)
                            print(' double_positive_location', double_positive_location)

                if agent.location_memories_dict[entry] > 0.0 and (entry not in cp_agent.location_memories_dict or cp_agent.location_memories_dict[entry] == 0.0):

                    exec('town_grid.ad_hoc_location = %s' % entry)

                    # print('\n 8 wait_at_tgt_moves', wait_at_tgt_moves)
                    if within_striking_dist(params.wait_at_target_til_end, town_grid, cp_agent.home, params.wait_at_tgt_moves, cp_agent.agent_vision, town_grid.ad_hoc_location, move=0, has_acted=0, print_dets=0):

                        if agent.location_memories_dict[entry] > single_positive_score:

                            single_positive_score = agent.location_memories_dict[entry]
                            single_positive_location = copy.copy(entry)

                            if print_fine_dets:
                                print('\n agent.location_memories_dict[entry] > single_positive_score')
                                print(' NEW single_positive_score =', single_positive_score)
                                print(' single_positive_location', single_positive_location)

                if (agent.location_memories_dict[entry] > 0.0 and entry in cp_agent.location_memories_dict and cp_agent.location_memories_dict[entry] < 0.0) or \
                        (agent.location_memories_dict[entry] < 0.0 and entry in cp_agent.location_memories_dict and cp_agent.location_memories_dict[entry] > 0.0):

                    if agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry] > positive_and_negative_score:

                        positive_and_negative_score = agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry]
                        positive_and_negative_location = copy.copy(entry)

                        if print_fine_dets:
                            print('\n agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry] > positive_and_negative_score')
                            print(' NEW positive_and_negative_score =', positive_and_negative_score)
                            print(' positive_and_negative_location', positive_and_negative_location)

            if print_fine_dets:
                print('\n Now looking at cp dict \n')

            # second we iterate over cp_agent.location_memories_dict and update only single_positive_score and single_positive_location
            for entry in cp_agent.location_memories_dict:

                if print_fine_dets:
                    print('\n cp_agent[entry] =', cp_agent.location_memories_dict[entry])

                    if entry in agent.location_memories_dict:
                        print(' agent[entry] =', agent.location_memories_dict[entry])

                    else:
                        print(' agent[entry] = None')

                if cp_agent.location_memories_dict[entry] > 0.0 and (entry not in agent.location_memories_dict or agent.location_memories_dict[entry] == 0.0):

                    exec('town_grid.ad_hoc_location = %s' % entry)

                    # print('\n 9 wait_at_tgt_moves', wait_at_tgt_moves)
                    if within_striking_dist(params.wait_at_target_til_end, town_grid, agent.home, params.wait_at_tgt_moves, agent.agent_vision, town_grid.ad_hoc_location, move=0, has_acted=0, print_dets=0):

                        if cp_agent.location_memories_dict[entry] > single_positive_score:

                            single_positive_score = cp_agent.location_memories_dict[entry]
                            single_positive_location = copy.copy(entry)

                            if print_fine_dets:
                                print('\n cp_agent.location_memories_dict[entry] > single_positive_score')
                                print(' NEW single_positive_score =', single_positive_score)
                                print(' single_positive_location', single_positive_location)

            # by now we will know if any location has a positive value for both agents (and the highest combined value if there was more than 1) and what that location is.
            # we will also have the same information for any location which has a positive value for one agent and no value for (or is not known to) the other.

            if print_fine_dets:
                print('\n\n double_positive_score =', double_positive_score)
                print(' double_positive_location =', double_positive_location)

                print('\n single_positive_score =', single_positive_score)
                print(' single_positive_location =', single_positive_location)

                print('\n positive_and_negative_score =', positive_and_negative_score)
                print(' positive_and_negative_location =', positive_and_negative_location)

            if double_positive_score > 0.0:

                exec('agent.agreed_meeting_point = %s' % double_positive_location)
                cp_agent.agreed_meeting_point = copy.copy(agent.agreed_meeting_point)

                if print_fine_dets:
                    print('\n double_positive_score > 0.0')
                    print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                    print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)

            elif single_positive_score > 0.0:

                exec('agent.agreed_meeting_point = %s' % single_positive_location)
                cp_agent.agreed_meeting_point = copy.copy(agent.agreed_meeting_point)

                if print_fine_dets:
                    print('\n single_positive_score > 0.0')
                    print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                    print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)

            elif positive_and_negative_score > 0.0:

                exec('agent.agreed_meeting_point = %s' % positive_and_negative_location)
                cp_agent.agreed_meeting_point = copy.copy(agent.agreed_meeting_point)

                if print_fine_dets:
                    print('\n positive_and_negative_score > 0.0')
                    print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                    print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)

            else:

                # if the three methods above do not work then we find a location which is zero to both agents.  We do this by developing a combined dictionary,
                # and then choosing a random location which is not in this dictionary.

                # find a combined dictionary
                combined_dict = copy.copy(agent.location_memories_dict)

                for entry in cp_agent.location_memories_dict:

                    if entry in combined_dict:
                        combined_dict[entry] += cp_agent.location_memories_dict[entry]

                    else:
                        combined_dict[entry] = cp_agent.location_memories_dict[entry]

                if print_fine_dets:
                    print('\n len(agent.location_memories_dict) =', len(agent.location_memories_dict))
                    print(' len(cp_agent.location_memories_dict) =', len(cp_agent.location_memories_dict))
                    print(' len(combined_dict) =', len(combined_dict))

                # start with a random location
                random_loc = [random.randint(0, town_grid.dimen - 1), random.randint(0, town_grid.dimen - 1)]
                str_random_loc = str(random_loc)

                # print('\n 10 wait_at_tgt_moves', wait_at_tgt_moves)

                wsd_agent = within_striking_dist(params.wait_at_target_til_end, town_grid, agent.home, params.wait_at_tgt_moves, agent.agent_vision, random_loc, move=0, has_acted=0, print_dets=0)
                wsd_cp = within_striking_dist(params.wait_at_target_til_end, town_grid, cp_agent.home, params.wait_at_tgt_moves, cp_agent.agent_vision, random_loc, move=0, has_acted=0, print_dets=0)

                if print_fine_dets:
                    print('\n initial random_loc =', random_loc)
                    print(' wsd_agent', wsd_agent)
                    print(' wsd_cp', wsd_cp)

                # we don't want to be stuck in a while loop so we give it 10 opportunities to find a solution
                while_counter = 0

                while str_random_loc in combined_dict and while_counter < 10 and wsd_agent == 0 and wsd_cp == 0:

                    random_loc = [random.randint(0, town_grid.dimen - 1), random.randint(0, town_grid.dimen - 1)]
                    str_random_loc = str(random_loc)

                    # print('\n 11 wait_at_tgt_moves', wait_at_tgt_moves)

                    wsd_agent = within_striking_dist(params.wait_at_target_til_end, town_grid, agent.home, params.wait_at_tgt_moves, agent.agent_vision, random_loc, move=0, has_acted=0, print_dets=0)
                    wsd_cp = within_striking_dist(params.wait_at_target_til_end, town_grid, cp_agent.home, params.wait_at_tgt_moves, cp_agent.agent_vision, random_loc, move=0, has_acted=0, print_dets=0)

                    if print_fine_dets:
                        print('\n NEXT random_loc =', random_loc)
                        print(' wsd_agent', wsd_agent)
                        print(' wsd_cp', wsd_cp)

                    while_counter += 1

                if while_counter < 10:

                    agent.agreed_meeting_point = random_loc
                    cp_agent.agreed_meeting_point = random_loc

                else:

                    agent.agreed_meeting_point = None
                    cp_agent.agreed_meeting_point = None

                if print_fine_dets:
                    print('\n while_counter =', while_counter)
                    print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                    print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)

            # print(' day %d two agents organised to meet at %s' % (day, agent.agreed_meeting_point))

            if print_fine_dets:
                print('\n the agents have agreed a location to meet at in the next round')
                print('\n\n')
                pause()
                # print_fine_dets = 0

    # now we allow the pair to communicate about any fights / muggings they were involved in, assuming the agents don't respect property rights - this is how reputations are spread.
    # note we don't bother with this when agents respect property rights - reputations are irrelevant.
    if respect_property_rights == 0 and strat_choice == 'propensities' and params.gossip:

        # if len(agent.trades_array) > 0 or len(cp_agent.trades_array) > 0:
        #     print_fine_dets = 1

        if print_fine_dets == 1:
            print('\n\n Agents communicate about Reputations:\n')
            print(' len(agent.trades_array)', len(agent.trades_array))
            print(' len(agent.fights_array)', len(agent.fights_array))
            print(' len(cp_agent.trades_array)', len(cp_agent.trades_array))
            print(' len(cp_agent.fights_array)', len(cp_agent.fights_array))

            print('\n\n --> agent divulging:', agent)
            print('\n start cp_agent.reputations_dict:')

            start_day = np.max([0, day - params.agent_mem_length])

            if len(cp_agent.reputations_dict) == 0:

                print('\n none')

            else:

                for rep_agent in cp_agent.reputations_dict:

                    ps = np.sum(cp_agent.reputations_dict[str(rep_agent)][0][start_day:day + 1]) / float(np.sum(cp_agent.reputations_dict[str(rep_agent)][1][start_day:day + 1]))

                    if np.sum(cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]) > 0.0:

                        pfb = np.sum(cp_agent.reputations_dict[str(rep_agent)][2][start_day:day + 1]) / float(np.sum(cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]))

                    else:

                        pfb = 0.0

                    for ag in agent_population.pop:
                        if str(ag) == rep_agent:

                            print('\n rep_agent', rep_agent, 'exp prop_steal %4.2f' % ps, 'vs actual %4.2f' % ag.prop_steal, 'exp prop_fight_back %4.2f' % pfb, 'vs actual %4.2f' % ag.prop_fight_back)

                    print(' ps numerator =', cp_agent.reputations_dict[str(rep_agent)][0][start_day:day + 1], 'ps denom =', cp_agent.reputations_dict[str(rep_agent)][1][start_day:day + 1])
                    print(' pfb numerator =', cp_agent.reputations_dict[str(rep_agent)][2][start_day:day + 1], 'pfb denom =', cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1])

            print('\n agent.fights_array', agent.fights_array, '\n\n')

        for fight_record in agent.fights_array:

            # unpack
            other_agent, fought, fought_back, i_fought, i_fought_back = fight_record

            if print_fine_dets:
                print(' fight: other agent', other_agent, 'fought?', fought, 'fought_back?', fought_back, 'i_fought?', i_fought, 'i_fought_back?', i_fought_back)

            if other_agent == str(cp_agent):

                if print_fine_dets == 1:
                    print('\n other agent in fights_array is the same as the cp_agent')

            else:

                if fought == 0:

                    fought_back_tally = 1  # the other agent wanted to trade; I tried to steal; it could have fought back

                else:

                    fought_back_tally = 0  # vice versa

                if other_agent not in cp_agent.reputations_dict:
                    cp_agent.reputations_dict[other_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                cp_agent.reputations_dict[other_agent][0][day] += fought
                cp_agent.reputations_dict[other_agent][1][day] += 1
                cp_agent.reputations_dict[other_agent][2][day] += fought_back
                cp_agent.reputations_dict[other_agent][3][day] += fought_back_tally

                # if agents have informed each other about any fight
                cp_agent.need_to_update_reps[str(other_agent)] = 1

        #        if len(agent.trades_array) > 10:
        #
        #            for transaction in agent.trades_array:
        #
        #                print('\n good_a', transaction.good_a)         # Transaction
        #                print(' good_b', transaction.good_b)         # Transaction
        #                print(' agent_a_home', transaction.agent_a_home)         # Transaction
        #                print(' agent_b_home', transaction.agent_b_home)         # Transaction
        #                print(' tot_trans_ag_sell', transaction.tot_trans_ag_sell)         # Transaction
        #                print(' tot_trans_ag_sell', transaction.tot_trans_ag_buy)         # Transaction
        #
        #            pause()

        if print_fine_dets:
            print('\n\n agent.trades_array ', agent.trades_array, '\n\n')

        for transaction in agent.trades_array:

            if print_fine_dets:
                print('\n transaction', transaction, 'location', transaction.location)

            if transaction.agent_a != str(agent) and transaction.agent_a != str(cp_agent):

                if print_fine_dets:
                    print(' transaction.agent_a', transaction.agent_a)

                if transaction.agent_a not in cp_agent.reputations_dict:

                    if print_fine_dets:
                        print(' transaction.agent_a not in cp_agent.reputations_dict')

                    cp_agent.reputations_dict[transaction.agent_a] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                        np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                cp_agent.reputations_dict[transaction.agent_a][1][day] += 1

                if print_fine_dets:
                    print(' transaction.agent_a added')

                # set this so will have to update reps data
                cp_agent.need_to_update_reps[transaction.agent_a] = 1

            elif transaction.agent_b != str(agent) and transaction.agent_b != str(cp_agent):

                if print_fine_dets:
                    print(' transaction.agent_b ', transaction.agent_b)

                if transaction.agent_b not in cp_agent.reputations_dict:

                    cp_agent.reputations_dict[transaction.agent_b] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds),dtype=int),
                                                                        np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                    if print_fine_dets:
                        print(' transaction.agent_b not in cp_agent.reputations_dict')

                cp_agent.reputations_dict[transaction.agent_b][1][day] += 1

                if print_fine_dets:
                    print(' transaction.agent_b added')

                # set this so will have to update reps data
                cp_agent.need_to_update_reps[transaction.agent_b] = 1

        if print_fine_dets == 1:
            print('\n end cp_agent.reputations_dict: ')

            if len(cp_agent.reputations_dict) == 0:

                print('\n none')

            else:

                for rep_agent in cp_agent.reputations_dict:

                    ps = np.sum(cp_agent.reputations_dict[str(rep_agent)][0][start_day:day + 1]) / float(np.sum(cp_agent.reputations_dict[str(rep_agent)][1][start_day:day + 1]))

                    if np.sum(cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]) > 0.0:

                        pfb = np.sum(cp_agent.reputations_dict[str(rep_agent)][2][start_day:day + 1]) / float(np.sum(cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]))

                    else:

                        pfb = 0.0

                    for ag in agent_population.pop:
                        if str(ag) == rep_agent:

                            print('\n rep_agent', rep_agent, 'exp prop_steal %4.2f' % ps, 'vs actual %4.2f' % ag.prop_steal, 'exp prop_fight_back %4.2f' % pfb, 'vs actual %4.2f' % ag.prop_fight_back)

                    print(' ps numerator =', cp_agent.reputations_dict[str(rep_agent)][0][start_day:day + 1], 'ps denom =', cp_agent.reputations_dict[str(rep_agent)][1][start_day:day + 1])
                    print(' pfb numerator =', cp_agent.reputations_dict[str(rep_agent)][2][start_day:day + 1], 'pfb denom =', cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1])

        if print_fine_dets == 1:

            print('\n\n --> cp_agent divulging:', cp_agent)
            print('\n start agent.reputations_dict')

            if len(agent.reputations_dict) == 0:

                print('\n none')

            else:

                start_day = np.max([0, day - 10])

                for rep_agent in agent.reputations_dict:

                    ps = np.sum(agent.reputations_dict[str(rep_agent)][0][start_day:day + 1]) / float(np.sum(agent.reputations_dict[str(rep_agent)][1][start_day:day + 1]))

                    if np.sum(agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]) > 0.0:

                        pfb = np.sum(agent.reputations_dict[str(rep_agent)][2][start_day:day + 1]) / float(np.sum(agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]))

                    else:

                        pfb = 0.0

                    for ag in agent_population.pop:
                        if str(ag) == rep_agent:

                            print(' rep_agent', rep_agent, 'exp prop_steal %4.2f' % ps, 'vs actual %4.2f' % ag.prop_steal, 'exp prop_fight_back %4.2f' % pfb, 'vs actual %4.2f' % ag.prop_fight_back)

                    print(' ps numerator =', agent.reputations_dict[str(rep_agent)][0][start_day:day + 1], 'ps denom =', agent.reputations_dict[str(rep_agent)][1][start_day:day + 1])
                    print(' pfb numerator =', agent.reputations_dict[str(rep_agent)][2][start_day:day + 1], 'pfb denom =', agent.reputations_dict[str(rep_agent)][3][start_day:day + 1])

        if print_fine_dets == 1:

            print('\n cp_agent.fights_array', cp_agent.fights_array, '\n')

        for fight_record in cp_agent.fights_array:

            # unpack
            other_agent, fought, fought_back, i_fought, i_fought_back = fight_record

            if print_fine_dets:
                print(' fight: other agent', other_agent, 'fought?', fought, 'fought_back?', fought_back, 'i_fought?', i_fought, 'i_fought_back?', i_fought_back)

            if other_agent == str(agent):

                if print_fine_dets == 1:
                    print('\n other agent in fights_array is the same as the agent')

            else:

                if fought == 0:

                    fought_back_tally = 1  # the other agent wanted to trade; I tried to steal; it could have fought back

                else:

                    fought_back_tally = 0  # vice versa

                if other_agent not in agent.reputations_dict:
                    agent.reputations_dict[other_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                agent.reputations_dict[other_agent][0][day] += fought
                agent.reputations_dict[other_agent][1][day] += 1
                agent.reputations_dict[other_agent][2][day] += fought_back
                agent.reputations_dict[other_agent][3][day] += fought_back_tally

                # set this so will have to update reps data
                agent.need_to_update_reps[str(other_agent)] = 1

        if print_fine_dets:
            print('\n\n cp_agent.trades_array ', cp_agent.trades_array)

        for transaction in cp_agent.trades_array:

            if print_fine_dets:
                print('\n transaction', transaction, 'location', transaction.location)

            if transaction.agent_a != str(cp_agent) and transaction.agent_a != str(agent):        # then agent_a was the agent's counterpart

                if print_fine_dets:
                    print(' transaction.agent_a', transaction.agent_a)
                    # print(' transaction.agent_a != str(agent)')

                if transaction.agent_a not in agent.reputations_dict:

                    if print_fine_dets:
                        print(' transaction.agent_a not in agent.reputations_dict')

                    agent.reputations_dict[transaction.agent_a] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                   np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                agent.reputations_dict[transaction.agent_a][1][day] += 1

                if print_fine_dets:
                    print(' transaction.agent_a added')

                # set this so will have to update reps data
                agent.need_to_update_reps[transaction.agent_a] = 1

            elif transaction.agent_b != str(cp_agent) and transaction.agent_b != str(agent):        # then agent_b was the agent's counterpart

                if print_fine_dets:
                    print(' transaction.agent_b ', transaction.agent_b)

                if transaction.agent_b not in agent.reputations_dict:

                    if print_fine_dets:
                        print(' transaction.agent_b not in agent.reputations_dict')

                    agent.reputations_dict[transaction.agent_b] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                   np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                agent.reputations_dict[transaction.agent_b][1][day] += 1

                if print_fine_dets:
                    print(' transaction.agent_b added')

                # set this so will have to update reps data
                agent.need_to_update_reps[transaction.agent_b] = 1

        if print_fine_dets == 1:  # and len(cp_agent.fights_array) > 0:
            print('\n end agent.reputations_dict')

            if len(agent.reputations_dict) == 0:

                print('\n none')

            else:

                for rep_agent in agent.reputations_dict:

                    ps = np.sum(agent.reputations_dict[str(rep_agent)][0][start_day:day + 1]) / float(np.sum(agent.reputations_dict[str(rep_agent)][1][start_day:day + 1]))

                    if np.sum(agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]) > 0.0:

                        pfb = np.sum(agent.reputations_dict[str(rep_agent)][2][start_day:day + 1]) / float(np.sum(agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]))

                    else:

                        pfb = 0.0

                    for ag in agent_population.pop:
                        if str(ag) == rep_agent:

                            print('\n rep_agent', rep_agent, 'exp prop_steal %4.2f' % ps, 'vs actual %4.2f' % ag.prop_steal, 'exp prop_fight_back %4.2f' % pfb, 'vs actual %4.2f' % ag.prop_fight_back)

                    print(' ps numerator =', agent.reputations_dict[str(rep_agent)][0][start_day:day + 1], 'ps denom =', agent.reputations_dict[str(rep_agent)][1][start_day:day + 1])
                    print(' pfb numerator =', agent.reputations_dict[str(rep_agent)][2][start_day:day + 1], 'pfb denom =', agent.reputations_dict[str(rep_agent)][3][start_day:day + 1])

    if ((params.track_agent and params.track_agent <= day) and (agent == agent_population.tracking_agent or cp_agent == agent_population.tracking_agent) and \
            (len(agent.trades_array) > 0 or len(cp_agent.trades_array) > 0 or len(agent.fights_array) > 0 or len(cp_agent.fights_array) > 0 or agents_want_to_comm == 'both')):
        print('\n -> two_agents_communicate ends \n')
        # pause()


def find_agreed_loc(agent_group, dbs, town_grid, agent_mem_length, day, print_fine_dets, clear_of_fights_radius, total_rounds):
    """This function takes a group of agents, searches dbs.trans_db and finds the best location for all of them to meet."""

    # print_fine_dets = 1

    if print_fine_dets == 1:
        print('\n\n ** find_agreed_loc starting on day', day)

    # find combined dictionary of all agents:
    combined_dict = copy.copy(agent_group[0].location_memories_dict)

    for agent in agent_group[1:]:

        for entry in agent.location_memories_dict:

            if entry in combined_dict:
                combined_dict[entry] += agent.location_memories_dict[entry]

            else:
                combined_dict[entry] = agent.location_memories_dict[entry]

    # now check for any positive locations
    max_value = 0.0
    best_loc = None

    for entry in combined_dict:

        if combined_dict[entry] > max_value:
            max_value = combined_dict[entry]
            best_loc = copy.copy(entry)

    if max_value > 0.0:

        exec('town_grid.best_grid_loc = %s' % best_loc)

        best_grid_loc = town_grid.best_grid_loc

        if print_fine_dets:
            print('\n max_value > 0.0: ', max_value)
            print(' best_grid_loc', best_grid_loc)
            pause()

    else:

        if print_fine_dets:
            print('\n max_value == 0.0: ', max_value)

        best_grid_loc = find_location_furthest_away(town_grid, combined_dict, print_fine_dets, complete=0)

    return best_grid_loc


def check_if_want_to_interact(params, resid_agent, lovely_agent, agent_population, price_mean, force_prices, fixed_price, day, dbs, fountain_population, fight_cost, len_reputations_mem,
                              intn_error_std, fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0, stranger_int,
                              strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets):
    """This function tests if two agents want to interact or not, returning the expected gains (losses) of both agents."""

    # print_fine_dets = 1

    if (params.track_agent and params.track_agent <= day) and (resid_agent == agent_population.tracking_agent or lovely_agent == agent_population.tracking_agent):
        print_for_tracking = 1
    else:
        print_for_tracking = 0

    if print_fine_dets or print_for_tracking:
        print('\n Starting check_if_want_to_interact function')

    if print_fine_dets:
        print('\n str(lovely_agent) in resid_agent.exp_returns_dict: ', str(lovely_agent) in resid_agent.exp_returns_dict)
        print(' str(resid_agent) in lovely_agent.exp_returns_dict: ', str(resid_agent) in lovely_agent.exp_returns_dict)

    # if they are in each other's exp_returns_dict then we don't need to look further = we return the values already calculated
    if str(lovely_agent) in resid_agent.exp_returns_dict and str(resid_agent) in lovely_agent.exp_returns_dict:

        #        print('\n agents in each others exp_returns_dict: resid_agent.exp_returns_dict[str(lovely_agent)] =', resid_agent.exp_returns_dict[str(lovely_agent)],\
        #              'lovely_agent.exp_returns_dict[str(resid_agent)', lovely_agent.exp_returns_dict[str(resid_agent)])

        if print_fine_dets or print_for_tracking:
            print('\n agents know about each other: resid_agent_exp_gain =', resid_agent.exp_returns_dict[str(lovely_agent)], 'lovely_agent_exp_gain =', lovely_agent.exp_returns_dict[str(resid_agent)])

        return resid_agent.exp_returns_dict[str(lovely_agent)], lovely_agent.exp_returns_dict[str(resid_agent)]

    # if not, we calculated the expected returns, add them to the exp_returns_dict's and return the values also
    else:

        simulated_int = 1
        move = None
        #        print_fine_dets = 0
        #        print_dets = 0
        if strat_choice == 'propensities' and (strangers_if_unknown == 0 or (strangers_if_unknown and resid_agent.agent_knows_cp_dict[str(lovely_agent)] and lovely_agent.agent_knows_cp_dict[str(resid_agent)])):

            resid_agent_exp_gain, resid_agent_cp_exp_gain = resid_agent.find_exp_returns_intn(params, lovely_agent, agent_population, print_dets, price_mean, force_prices, fixed_price,
                                                                                              day, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std, print_fine_dets,
                                                                                              fight_balance, adjust_props_r, agent_intn_beta, move, formal_inst, prob_fine, fine, simulated_int,
                                                                                              fight_skill, fix_ps_fb_0, stranger_int, strat_choice, strangers_if_unknown)

            lovely_agent_exp_gain, lovely_agent_agent_exp_gain = lovely_agent.find_exp_returns_intn(params, resid_agent, agent_population, print_dets, price_mean, force_prices, fixed_price,
                                                                                                    day, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std, print_fine_dets,
                                                                                                    fight_balance, adjust_props_r, agent_intn_beta, move, formal_inst, prob_fine, fine, simulated_int,
                                                                                                    fight_skill, fix_ps_fb_0, stranger_int, strat_choice, strangers_if_unknown)

            if print_fine_dets or print_for_tracking:
                print('\n agent.basket_array_start ', resid_agent.basket_array_start, 'cp_agent.basket_array_start ', lovely_agent.basket_array_start)

        else:  # strat_choice == 'rational' or == 'propensities' but one or both agents don't know each other.
            # note we only have to run this once as both exp gains will be identical whichever agent checks - this is not true when we use propensities (because perceived props are different to actual)

            use_start_basket = simulated_int
            agent_dec, cp_agent_dec, resid_agent_exp_gain, lovely_agent_exp_gain = strangers_interact(params, agent_population.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, agent_population, fountain_population,
                                                                                                      print_dets, print_fine_dets, use_start_basket, resid_agent, lovely_agent, agent_population.stranger_int, formal_inst, prob_fine, fine,
                                                                                                      two_tribes_inst, fight_cost)

            if print_fine_dets or print_for_tracking:

                print('\n agents did NOT know about each other: ')
                print(' agent_dec =', agent_dec, 'cp_agent_dec', cp_agent_dec)
                print(' resid_agent_exp_gain =', resid_agent_exp_gain, 'lovely_agent_exp_gain =', lovely_agent_exp_gain)
                # pause()

        resid_agent.exp_returns_dict[str(lovely_agent)] = resid_agent_exp_gain
        lovely_agent.exp_returns_dict[str(resid_agent)] = lovely_agent_exp_gain

        return resid_agent_exp_gain, lovely_agent_exp_gain


def place_agent_in_best_spot(agent_population, town_grid, agent, two_tribes):
    """When the agent population is allowed to vary but agent homes are even spaced then finding a home for a new agent is tricky: how we do this is we find the spot furthest from all other agents and place the new agent there."""

    # start with finding existing homes:
    existing_homes = []

    for current_agent in agent_population.pop:

        if current_agent.home[0] is not None and current_agent.tribe == agent.tribe:
            x_coord = current_agent.home[0]
            y_coord = current_agent.home[1]

            existing_homes.append([x_coord, y_coord])

    #    print('\n existing_homes', existing_homes)

    # we measure the z_dist from all homes on every place on the grid and chose the place with the highest z_dist
    max_z_dist = 0

    # create array to collect possible locations
    poss_new_homes = []

    #    print('\n existing_homes =', existing_homes)

    if two_tribes == 0:
        x_min = 0
        x_max = town_grid.dimen

        y_min = 0
        y_max = town_grid.dimen

    if two_tribes == 1 and agent.tribe == 'sharks':
        x_min = 0
        x_max = int(town_grid.dimen / 2.0)

        y_min = 0
        y_max = int(town_grid.dimen / 2.0)

    if two_tribes == 1 and agent.tribe == 'jets':
        x_min = int(town_grid.dimen / 2.0 + 1)
        x_max = town_grid.dimen

        y_min = int(town_grid.dimen / 2.0 + 1)
        y_max = town_grid.dimen

    for x_coord in range(x_min, x_max):

        for y_coord in range(y_min, y_max):

            # larger than highest possible z_dist
            min_z_dist = (town_grid.dimen ** 2) + 1

            for existing_home in existing_homes:

                x_dist = (x_coord - existing_home[0]) % town_grid.dimen

                if x_dist > town_grid.dimen / 2.0:
                    x_dist = town_grid.dimen - x_dist

                y_dist = (y_coord - existing_home[1]) % town_grid.dimen

                if y_dist > town_grid.dimen / 2.0:
                    y_dist = town_grid.dimen - y_dist

                z_dist = ((x_dist ** 2) + (y_dist ** 2)) ** 0.5

                if z_dist < min_z_dist:
                    min_z_dist = z_dist

            if min_z_dist > max_z_dist:
                poss_new_homes = [[x_coord, y_coord]]
                max_z_dist = min_z_dist

            if min_z_dist == max_z_dist:
                poss_new_homes.append([x_coord, y_coord])

    #    print('\n poss_new_homes =', poss_new_homes)

    new_home = random.choice(poss_new_homes)

    #    print('new_home', new_home)

    new_home = np.array(new_home)

    #                print('x_coord', x_coord, 'y_coord', y_coord, 'existing_home', existing_home, 'x_dist =', x_dist,'y_dist =', y_dist, 'min_z_dist =', min_z_dist)

    #    here = 0

    #    print('\n new_home', new_home)

    #    input("Press Enter to continue")

    return new_home


def update_for_strats(params, fountain_population, for_strat_parts, agent_population, print_dets, tracking_agent, trade_prob, track_agent, print_fine_dets, trade_loc, day, dbs, trade_prices, Walrasian_Trading, two_tribes):
    """This function updates agents' foraging strategies.  This function allows each agent to adjust one of its foraging
    strategy elements, and to simulate different strategies for this element.  The agent calculates 'what if' expected
    end-of-round baskets under each strategy.  If a basket would require the agent to trade then it uses historical
    trading probabilities (the number of agents who traded / the number of agents wanting to trade) as an estimate of the
    likelihood of trading."""

    # if day >= 501:
    #     print_fine_dets = 1

    # Find mean foutain levels in each time slot

    # if day > params.stop_trading:
    #     print_fine_dets = 1

    # Start by finding mean resource levels at fountains, which form the expectations of fountain levels in different time slots
    if two_tribes == 0:

        mean_fount_levels = np.zeros(shape=(agent_population.for_strat_parts, num_res_founts))

        for time_slot in range(agent_population.for_strat_parts):

            for res in range(num_res_founts):
                # the resource levels of this fountain (fount_visd) at the random slot time (beginning & end) were:
                start_res_level = dbs.res_level_array[time_slot][res]
                end_res_level = dbs.res_level_array_ends[time_slot][res]

                # the average of these two:
                mean_res_level = np.mean([start_res_level, end_res_level])

                # record this
                mean_fount_levels[time_slot][res] = mean_res_level

        # print('\n mean_fount_levels =', mean_fount_levels)

    elif two_tribes == 1:

        mean_fount_levels_sharks = np.zeros(shape=(agent_population.for_strat_parts, num_res_founts))

        for time_slot in range(agent_population.for_strat_parts):

            for res in range(num_res_founts):
                # the resource levels of this fountain (fount_visd) at the random slot time (beginning & end) were:
                start_res_level = dbs.res_level_array[time_slot][res]
                end_res_level = dbs.res_level_array_ends[time_slot][res]

                # the average of these two:
                mean_res_level = np.mean([start_res_level, end_res_level])

                # record this
                mean_fount_levels_sharks[time_slot][res] = mean_res_level

        mean_fount_levels_jets = np.zeros(shape=(agent_population.for_strat_parts, num_res_founts))

        for time_slot in range(agent_population.for_strat_parts):

            for res in range(num_res_founts):
                # the resource levels of this fountain (fount_visd) at the random slot time (beginning & end) were:
                start_res_level = dbs.res_level_array[time_slot][2 + res]
                end_res_level = dbs.res_level_array_ends[time_slot][2 + res]

                # the average of these two:
                mean_res_level = np.mean([start_res_level, end_res_level])

                # record this
                mean_fount_levels_jets[time_slot][res] = mean_res_level

    if two_tribes == 1 and agent.tribe == 'sharks':
        mean_fount_levels = mean_fount_levels_sharks

    if two_tribes == 1 and agent.tribe == 'jets':
        mean_fount_levels = mean_fount_levels_jets

    # Now iterate over agents to determine the foraging strategy for each
    def ag_for_strats_update(agent):

        # if track_agent and agent == agent_population.tracking_agent:
        #
        #     print_fine_dets = print_dets = 1
        #
        # else:
        #
        #     print_fine_dets = print_dets = 0

        if print_fine_dets == 1:
            print('\n\n\n\n *************** running update_for_strats() ******\n')
            print(' day = ', day)
            print('\n res_level_array =\n\n', dbs.res_level_array)
            print('\n dbs.res_level_array_ends =\n\n', dbs.res_level_array_ends)
            print('\n mean_fount_levels =\n\n', mean_fount_levels)
            print('\n start agent.for_strat_array =', agent.for_strat_array)

        # choose a random time slot:
        random_slot = np.random.randint(0, agent_population.for_strat_parts)

        agent.foraging_strat_data[day][0] = random_slot

        #        # designate 'random_res' as the resource currently being forraged in this time slot
        #        random_res = agent.for_strat_array[0][random_slot]

        # identify the resource for which the agent has highest probability (denote spec_res)
        max_skill = np.max(agent.detect_skills_array)

        for prob in np.arange(len(agent.detect_skills_array[0])):

            if agent.detect_skills_array[0][prob] == max_skill:
                # we denote the specialization resource that which has the highest probability
                spec_res = prob

        # the technique I developed worked but it is unecessarily complicated - here I will focus specifically in random_slot
        # - we only need to find the expected yield for this slot (converted by trading if different to min_res)
        exp_for_yields = []
        exp_for_yields_no_noise = []

        # here I find the expected yields of the time slots for all slots other than the random_slot
        other_slot_yields = np.zeros(shape=num_res_founts)

        for time_slot in range(agent_population.for_strat_parts):

            if time_slot != random_slot:

                # this is the resource foraged for in the time slot:
                res = agent.for_strat_array[0][time_slot]

                # this is its mean level during that time slot
                mean_res_level = mean_fount_levels[time_slot][res]

                # this is the starting level of the fountain
                if two_tribes == 0:

                    initial_resource_level = dbs.init_res_levels[day][res]

                elif two_tribes == 1:

                    if agent.tribe == 'sharks':

                        initial_resource_level = dbs.init_res_levels[day][res]

                    elif agent.tribe == 'jets':

                        initial_resource_level = dbs.init_res_levels[day][2 + res]

                # and this is the resulting yield
                E_yield = agent.detect_skills_array[0][res] * (mean_res_level / float(initial_resource_level))

                other_slot_yields[res] += E_yield

                if print_fine_dets == 1:
                    print('\n ------> time_slot', time_slot, 'with res', res)
                    print(' mean_res_level', mean_res_level, 'initial_resource_level', initial_resource_level)
                    print(' agent.detect_skills_array[0][res]', agent.detect_skills_array[0][res])
                    print(' E_yield', E_yield)

        if print_fine_dets == 1:
            print('\n other_slot_yields', other_slot_yields)

        # find resource the agent is most concerned about
        agent.aggr_res_array = agent.basket_array + agent.agent_res_array

        exp_post_for_ress = agent.basket_array[0] + agent.agent_res_array[0] - np.ones(shape=num_res_founts) + other_slot_yields

        min_res_value = np.min(exp_post_for_ress)

        r_min = 0

        for res in range(num_res_founts):

            if exp_post_for_ress[res] == min_res_value:
                r_min = res

        agent.foraging_strat_data[day][1] = r_min

        # for analysis: I have a theory that agents oversell the resources they forage most for i.e. they end up deficient in the resource they had more of in their basket
        if agent.basket_array_start[0][r_min] > 0:

            if agent.basket_array_start[0][r_min] > agent.basket_array[0][r_min]:  # the agent must have sold the resource it ended up being deficient in

                agent.over_sell_counter += 1

            else:

                agent.didnt_over_sell_counter += 1

        if print_fine_dets == 1:
            print('\n start agent.for_strat_array =', agent.for_strat_array)
            print(' random_slot =', random_slot)
            print(' random_res =', agent.for_strat_array[0][random_slot])
            print('\n agent.agent_res_array =', agent.agent_res_array)
            print('\n agent.basket_array_start =', agent.basket_array_start)
            print(' agent.optimal_transs_systemic[day] =', agent.optimal_transs_systemic[day])
            print(' agent.basket_array =', agent.basket_array)
            print(' agent.aggr_res_array =', agent.aggr_res_array)
            print('\n other_slot_yields =', other_slot_yields)
            print(' exp_post_for_ress =', exp_post_for_ress)
            #            print('\n agent.over_sell_counter = %d (%2.2f)' % (agent.over_sell_counter, agent.over_sell_counter / float(day + 1)))
            #            print(' agent.didnt_over_sell_counter = %d (%2.2f)' % (agent.didnt_over_sell_counter, agent.didnt_over_sell_counter / float(day + 1)))
            print(' agent.detect_skills_array =', agent.detect_skills_array)

            print('\n r_min =', r_min)
            print(' spec_res =', spec_res)
            print('\n Iterating....')

        # the expected yield of any resource is driven by the equation p_j . (E(l) / L) . Price . prob_trans)
        for res in range(num_res_founts):

            # the average reserve level for this resource in this time slot:
            mean_res_level = mean_fount_levels[random_slot][res]

            agent.foraging_strat_data[day][2 + res] = mean_res_level

            if two_tribes == 0:

                initial_resource_level = dbs.init_res_levels[day][res]

            elif two_tribes == 1:

                if agent.tribe == 'sharks':

                    initial_resource_level = dbs.init_res_levels[day][res]

                elif agent.tribe == 'jets':

                    initial_resource_level = dbs.init_res_levels[day][2 + res]

            if print_fine_dets == 1:
                print('\n ------> res iter =', res)
                print('\n mean_res_level', mean_res_level)
                print(' mean_res_level as proportion', mean_res_level / float(initial_resource_level))
                print(' agent.detect_skills_array[0][res] =', agent.detect_skills_array[0][res])

            if res == r_min:

                E_yield = agent.detect_skills_array[0][res] * (mean_res_level / float(initial_resource_level))

                if print_fine_dets == 1:
                    print('\n res == r_min')
                    print(' agent.detect_skills_array[0][res] =', agent.detect_skills_array[0][res])
                    print('\n E_yield', E_yield)

            else:

                if Walrasian_Trading == 1:

                    mean_working_price = dbs.optimal_price_array[day][res][r_min]

                else:

                    if trade_prices == 'variable':
                        mean_working_price = agent.wkg_prices_memory[res][r_min]
                    elif trade_prices == 'fixed':
                        mean_working_price = params.fixed_price

                if print_fine_dets == 1:
                    print('\n trade_prices =', trade_prices)
                    print(' agent.wkg_prices_memory[res][r_min]', agent.wkg_prices_memory[res][r_min])
                    print(' dbs.optimal_price_array[day][res][r_min]', dbs.optimal_price_array[day][res][r_min])
                    print(' mean_working_price =', mean_working_price)

                agent.foraging_strat_data[day][2 + num_res_founts] = mean_working_price

                E_yield = agent.detect_skills_array[0][res] * (mean_res_level / float(initial_resource_level)) * (1 / float(mean_working_price)) * agent.trade_proby

                if print_fine_dets == 1:
                    print('\n res != r_min')
                    print(' price (number of units of r_min received for 1 unit of non-r_min), the inverse of mean_working_price =', 1 / mean_working_price)
                    print(' agent.trade_proby =', agent.trade_proby)
                    print('\n E_yield', E_yield)

            exp_for_yields_no_noise.append(E_yield)

            # now we adjust the expected yield by a cognition factor - agent.cognition_factor is a used as a standard deviation to vary the E_yield
            E_yield = random.normalvariate(E_yield, agent.cognition_factor)

            # make sure yield does not dip below 0 - agents wouldn't expect negative yield
            E_yield = np.max([0, E_yield])

            if print_fine_dets == 1:
                print('\n agent.cognition_factor =', agent.cognition_factor)
                print('\n adjusted E_yield =', E_yield)

            exp_for_yields.append(E_yield)

            agent.foraging_strat_data[day][3 + num_res_founts + res] = E_yield

        if print_fine_dets == 1:
            print('\n ------------- End of Iterations ---------------')
            #            print('\n exp_for_yields_no_noise = [%1.2f, %1.2f]' % (exp_for_yields_no_noise[0], exp_for_yields_no_noise[1]))
            print('\n start agent.for_strat_array =', agent.for_strat_array, 'random_slot =', random_slot, '(res', agent.for_strat_array[0][random_slot], ')')
            print(' r_min =', r_min, 'spec_res =', spec_res)
            print(' agent.trade_proby = %1.2f' % (agent.trade_proby))
            print('\n exp_for_yields = [%1.2f, %1.2f]' % (exp_for_yields[0], exp_for_yields[1]))
            print('\n agent.foraging_strat_data[day] =', agent.foraging_strat_data[day])

        max_yield = np.max(exp_for_yields)

        res_choice = 0

        choice_array = []

        for res in range(num_res_founts):

            if exp_for_yields[res] == max_yield:
                choice_array.append(res)

        res_choice = random.choice(choice_array)

        agent.for_strat_array[0][random_slot] = res_choice

        if print_fine_dets == 1:
            print('\n res_choice =', res_choice)
            print(' new agent.for_strat_array[0] =', agent.for_strat_array[0])

        # here we work out the threshold probability above which the agent would switch to not r_min.
        # For now, do this for 2 resources only.

        if num_res_founts == 2:

            # record data in agent.thresh_probs_array
            # agent.thresh_probs_array: [0] is round [1] is threshold_0_1, which is the threshold probability for the agent choosing res 0 and trading to to res 1,
            # [2] threshold_0_1 is the same as 1 but other way round, [3] is actual exp prob of transacting, [4] is detection prob for res 0, and [5] is the same for res 1

            threshold_1_to_0 = (agent.detect_skills_array[0][0] / agent.detect_skills_array[0][1]) * (mean_fount_levels[random_slot][0] / mean_fount_levels[random_slot][1]) * (1 / agent.wkg_prices_memory[0][1])
            threshold_0_to_1 = (agent.detect_skills_array[0][1] / agent.detect_skills_array[0][0]) * (mean_fount_levels[random_slot][1] / mean_fount_levels[random_slot][0]) * (1 / agent.wkg_prices_memory[1][0])

            if print_fine_dets:
                print('\n threshold_1_to_0 =', threshold_1_to_0)
                print('\n threshold_0_to_1 =', threshold_0_to_1)

            if math.isnan(threshold_1_to_0) or math.isnan(threshold_0_to_1) or math.isnan(agent.trade_proby) or math.isnan(agent.detect_skills_array[0][0]) or math.isnan(agent.detect_skills_array[0][1]) or math.isnan(
                    1 / agent.wkg_prices_memory[1][0]) or math.isnan(1 / agent.wkg_prices_memory[0][1]):

                print('\n\n agent', agent, 'r_min', r_min)
                print('\n agent.detect_skills_array[0]', agent.detect_skills_array[0][0])
                print(' agent.detect_skills_array[1]', agent.detect_skills_array[0][1])
                print('\n mean_fount_levels[random_slot][0]', mean_fount_levels[random_slot][0])
                print(' mean_fount_levels[random_slot][1]', mean_fount_levels[random_slot][1])
                print('\n chart_price_1_0', 1 / agent.wkg_prices_memory[1][0])
                print(' chart_price_0_1', 1 / agent.wkg_prices_memory[0][1])
                print('\n threshold_0_to_1', threshold_0_to_1)
                print(' threshold_1_to_0', threshold_1_to_0)
                print('\n agent.trade_proby', agent.trade_proby)

                print('\n fountain levels:\n\n')
                for time_slot in range(agent_population.for_strat_parts):

                    for res in range(num_res_founts):

                        # the resource levels of this fountain (fount_visd) at the random slot time (beginning & end) were:
                        if two_tribes == 0:
                            start_res_level = dbs.res_level_array[time_slot][res]
                            end_res_level = dbs.res_level_array_ends[time_slot][res]

                        if two_tribes == 1:

                            if agent.tribe == 'sharks':

                                start_res_level = dbs.res_level_array[time_slot][res]
                                end_res_level = dbs.res_level_array_ends[time_slot][res]

                            elif agent.tribe == 'jets':

                                start_res_level = dbs.res_level_array[time_slot][2 + res]
                                end_res_level = dbs.res_level_array_ends[time_slot][2 + res]

                        # the average of these two:
                        mean_res_level = np.mean([start_res_level, end_res_level])

                        print(' time_slot', time_slot, 'res', res, 'start_res_level', start_res_level, 'end_res_level', end_res_level, 'mean_res_level', mean_res_level)

                if math.isnan(threshold_1_to_0) or math.isnan(threshold_0_to_1):
                    threshold_1_to_0 = None
                    threshold_0_to_1 = None

            #                input("Press Enter to continue...")

            agent.thresh_probs_array[1][day] = copy.copy(threshold_0_to_1)
            agent.thresh_probs_array[2][day] = copy.copy(threshold_1_to_0)
            agent.thresh_probs_array[3][day] = copy.copy(agent.trade_proby)
            agent.thresh_probs_array[4][day] = copy.copy(agent.detect_skills_array[0][0])
            agent.thresh_probs_array[5][day] = copy.copy(agent.detect_skills_array[0][1])
            agent.thresh_probs_array[6][day] = copy.copy(1 / agent.wkg_prices_memory[0][1])
            agent.thresh_probs_array[7][day] = copy.copy(1 / agent.wkg_prices_memory[1][0])

        # if print_fine_dets:
        #     pause()

    threads = []
    # print('\n updating for_strats:')
    for agent in agent_population.pop:

        t = threading.Thread(target=ag_for_strats_update, args=[agent])
        t.start()
        # print(f' active threads: {threading.active_count()}')
        threads.append(t)

    for thread in threads:
        thread.join()


def new_births(params, agent_population, print_dets, print_fine_dets, agent_homes, init_res_level, dbs, day,
               for_strat_parts, agent_res_init, vision_len,
               dimen, rounds, trade_moves, trade_when_trgt, popn_ch, agent_mem_length, cp_trans_weight,
               wait_at_tgt_moves, trade_prices, agent_res_init_std, mating_thresh, cognition_factor,
               town_grid, run_folder, trade_movemnt, agents_comm_prob, respect_property_rights,
               start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
               children_props, child_prop_std, prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor,
               adjust_props_r, agent_intn_beta, two_tribes, black_shoop_exp, black_shoop_pop, fight_skill, agents_die_old_age,
               black_shoop_prop_start, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, start_child_births, price_mean, force_prices,
               fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
               fight_balance, formal_inst, prob_fine, fine, clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst):

    """This function organises new births in to the population."""

    here = 0

    #    if len(dbs.davy_jones_locker) > 0:
    #        print_fine_dets = 1

    # if day > 180:
    #     print_fine_dets = 1

    if print_fine_dets == 1:
        print('\n\n---- births... ----\n')
        print('mating_thresh =', mating_thresh)
        print('len(agent_population.pop) = ', len(agent_population.pop))
        print('popn_ch = ', popn_ch)

    # first decide how many new births there will be at the end of the period - we use a logistic equation.
    new_agents_res_arrays = []
    new_agent_props = []
    new_children_tribes = []
    parents_array = []

    if popn_ch == 'vary':

        # we find new_agents by using a counter in this instance
        new_agents = 0

        for agent in agent_population.pop:

            agent_min_res = np.min(agent.agent_res_array)

            if (respect_property_rights and agent_min_res > mating_thresh) or (respect_property_rights == 0 and agent_min_res > params.PR_mating_threshold and (params.start_1_rich_agent == 0 or (params.start_1_rich_agent and agent is not agent_population.wealthy_agent))):

                cp_agent = random.choice(agent_population.pop)

                cp_agent_min_res = np.min(cp_agent.agent_res_array)

                if agent is not cp_agent and ((respect_property_rights and cp_agent_min_res > mating_thresh) or (respect_property_rights == 0 and cp_agent_min_res > params.PR_mating_threshold)) and\
                        agent.tribe == cp_agent.tribe and agent.age > start_child_births and cp_agent.age > start_child_births and agent is not agent_population.change_agent and cp_agent is not agent_population.change_agent and\
                        (params.start_1_rich_agent == 0 or (params.start_1_rich_agent and cp_agent is not agent_population.wealthy_agent)):  # then the agents will mate

                    new_children_tribes.append(copy.copy(agent.tribe))

                    # if an agent is born, we must update neighbours in the next round
                    agent_population.must_update_neighs = 1

                    # if (np.sum(agent.for_strat_array) == 5 or np.sum(agent.for_strat_array) == 0) and (np.sum(cp_agent.for_strat_array) == 5 or np.sum(cp_agent.for_strat_array) == 0):
                    #     print_fine_dets = 1

                    if print_fine_dets == 1:
                        print('\n\n **** agents mated')
                        print('\n agent.agent_res_array =', agent.agent_res_array)
                        print(' cp_agent.agent_res_array =', cp_agent.agent_res_array)

                    parent_1 = agent
                    parent_2 = cp_agent

                    parents_array.append([parent_1, parent_2])

                    # we instantiate the child with resources taken from the parents, in one two ways
                    if params.child_res == 'proportional':

                        if respect_property_rights:

                            start_res_ratio = agent_res_init / (float(mating_thresh) * 2.0)

                        else:

                            start_res_ratio = agent_res_init / (float(params.PR_mating_threshold) * 2.0)

                        starting_res = (agent.agent_res_array + cp_agent.agent_res_array) * start_res_ratio

                        # deduct from parents' res arrays
                        agent.agent_res_array *= (1 - start_res_ratio)
                        cp_agent.agent_res_array *= (1 - start_res_ratio)

                        agent.resources_to_children += (agent.agent_res_array[0] * start_res_ratio)
                        parent_2.resources_to_children += (cp_agent.agent_res_array[0] * start_res_ratio)

                    elif params.child_res == 'gross':

                        agent_res_init_0 = np.max([1, random.normalvariate(params.agent_res_init, params.agent_res_init_std)])
                        agent_res_init_1 = np.max([1, random.normalvariate(params.agent_res_init, params.agent_res_init_std)])

                        starting_res = np.array([[agent_res_init_0, agent_res_init_1]])

                        # deduct from parents' res arrays
                        agent.agent_res_array -= starting_res / 2.0
                        cp_agent.agent_res_array -= starting_res / 2.0

                        agent.resources_to_children += starting_res[0] / 2.0
                        parent_2.resources_to_children += starting_res[0] / 2.0

                    if print_fine_dets == 1:
                        print('\n parent_1.resources_to_children:', parent_1.resources_to_children)
                        print('\n parent_2.resources_to_children:', parent_2.resources_to_children)

                    new_agents_res_arrays.append(starting_res)

                    agent.num_children += 1
                    cp_agent.num_children += 1

                    if children_props == 'mean_props_and_dev':

                        # find mean of parent props and then add / subtr some value depending on std-dev
                        child_prop_steal_mean = np.mean([parent_1.prop_steal, parent_2.prop_steal])
                        child_prop_steal = random.normalvariate(child_prop_steal_mean, child_prop_std)

                        child_prop_fight_back_mean = np.mean([parent_1.prop_fight_back, parent_2.prop_fight_back])
                        child_prop_fight_back = random.normalvariate(child_prop_fight_back_mean, child_prop_std)

                        # constraint to max and min values
                        # note that if we're applying gross propensities which are capped this is still ok - child can start with prop's between ceiling and floor
                        if params.limit_child_props:

                            if child_prop_steal > prop_steal_ceil:
                                child_prop_steal = prop_steal_ceil

                            if child_prop_steal < prop_steal_floor:
                                child_prop_steal = prop_steal_floor

                            if child_prop_fight_back > prop_fight_back_ceil:
                                child_prop_fight_back = prop_fight_back_ceil

                            if child_prop_fight_back < prop_fight_back_floor:
                                child_prop_fight_back = prop_fight_back_floor

                        if print_fine_dets:
                            print('\n parent_1.prop_steal', parent_1.prop_steal, 'parent_2.prop_steal', parent_2.prop_steal, 'mean', child_prop_steal_mean, 'resulting prop_steal (with var)', child_prop_steal)
                            print('\n parent_1.prop_fight_back', parent_1.prop_fight_back, 'parent_2.prop_fight_back', parent_2.prop_fight_back, 'mean', child_prop_fight_back_mean, 'resulting fight_back (with var)', child_prop_fight_back)

                        new_agent_props.append([child_prop_steal, child_prop_fight_back])

                    new_agents += 1

                    # add a child to each parent's tally
                    agent.number_of_children += 1
                    cp_agent.number_of_children += 1

                    if print_fine_dets == 1:
                        print('\n\n Agents mated!')
                        print('\n new_agents =', new_agents)
                        print('\n new agent.agent_res_array =', agent.agent_res_array)
                        print(' new cp_agent.agent_res_array =', cp_agent.agent_res_array)
                        print('\n parent_1.parents', parent_1.parents)
                        print('\n parent_2.parents', parent_2.parents)
                        print('\n ')

                    # pause()

        #                    else:
        #
        #                        print_fine_dets = 0

        if print_fine_dets == 1:
            print('\n new_agent_props', new_agent_props)

    elif popn_ch == 'fixed':  # we only replace dead agents

        new_agents = len(dbs.davy_jones_locker)

    # record new_agents in main_db:
    dbs.main_db[1][day] = new_agents

    if print_fine_dets == 1:
        print('\n new_agents =', new_agents)
        print(' new_agents_res_arrays =', new_agents_res_arrays)

    # add the new agents to a new_agent_array and also the agent_population
    new_agent_array = []
    brand_new_agents = []

    for i in np.arange(new_agents):

        if popn_ch == 'vary':

            starting_res = new_agents_res_arrays[i]

        else:

            starting_res = None

        if popn_ch == 'vary' and children_props == 'mean_props_and_dev':

            starting_props = new_agent_props[i]

        else:

            starting_props = [0.5, 0.5]

        if popn_ch == 'vary' and two_tribes == 1:

            new_child_tribe = new_children_tribes[i]

        else:

            new_child_tribe = 'none'

        if print_fine_dets == 1:
            print('\n popn_ch ', popn_ch)
            print('\n data going in to create_new_agent: starting_res', starting_res, 'starting_props', starting_props)

        instantiation = 0
        agents_die_old_age = None

        new_agent = create_new_agent(params, dbs, day, for_strat_parts, agent_res_init, agent_res_init_std, print_dets, vision_len, dimen, print_fine_dets, rounds,
                                     trade_moves, trade_when_trgt, agent_mem_length, cp_trans_weight, wait_at_tgt_moves, trade_prices, cognition_factor, trade_movemnt, starting_res,
                                     start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                                     prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, starting_props, instantiation,
                                     new_child_tribe, fight_skill, agents_die_old_age, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, popn_ch)

        new_agent.age = 0

        if print_fine_dets:

            print('\n new_agent.detect_skills_array immediately after instantiation', new_agent.detect_skills_array)
            print(' parents_array = ', parents_array)

        if popn_ch == 'vary':

            new_agent.parents = parents_array[i]

        else:

            new_agent.parents = [None, None]

        # print_fine_dets = 1

        if print_fine_dets:
            print('\n applying means of parent NNs')

        if print_fine_dets:

            print('\n new_agent.parents = ', new_agent.parents)

        # update some of the agent's history data
        new_agent.for_strat_hist[day] = copy.copy(new_agent.for_strat_array[0])
        new_agent.agent_res_array_start_hist[day] = copy.copy(new_agent.agent_res_array)
        new_agent.detect_skills_array_hist[day] = copy.copy(new_agent.detect_skills_array[0])
        new_agent.prop_steal_history[day] = copy.copy(new_agent.prop_steal)
        new_agent.prop_fight_back_history[day] = copy.copy(new_agent.prop_fight_back)

        if params.use_NNs and params.children_inherit_parents_NNs:

            mother = new_agent.parents[0]
            father = new_agent.parents[1]

            if print_fine_dets:
                print('\n mother =', new_agent.parents[0])
                print('\n father =', new_agent.parents[1])

            if params.num_NNs == 1:

                if print_fine_dets:

                    print('\n starting new_agent.NN_parameters: \n')
                    for item in new_agent.NN_parameters:
                        print('\n item', item, 'new_agent.NN_parameters[item] \n\n', new_agent.NN_parameters[item])

                for item in new_agent.NN_parameters:

                    if print_fine_dets:
                        print('\n item =', item)

                        print('\n old new_agent.NN_parameters[item] =\n\n', new_agent.NN_parameters[item])

                    line_num = 0

                    for line in new_agent.NN_parameters[item]:

                        if print_fine_dets:
                            print('\n line =', line)

                        element_num = 0

                        for element in line:

                            if print_fine_dets:
                                print('\n element', element)

                                print('\n line_num', line_num, 'element_num', element_num)
                                print(' old new_agent.NN_parameters[item][line_num][element_num] =', new_agent.NN_parameters[item][line_num][element_num])

                                print('\n mother.NN_parameters[item][line_num][element_num]', mother.NN_parameters[item][line_num][element_num])
                                print('\n father.NN_parameters[item][line_num][element_num]', father.NN_parameters[item][line_num][element_num])

                                print('\n parental mean =', np.mean([mother.NN_parameters[item][line_num][element_num], father.NN_parameters[item][line_num][element_num]]))

                            element = np.mean([mother.NN_parameters[item][line_num][element_num], father.NN_parameters[item][line_num][element_num]])

                            new_agent.NN_parameters[item][line_num][element_num] = element

                            if print_fine_dets:
                                print('\n new new_agent.NN_parameters[item][line_num][element_num] =', new_agent.NN_parameters[item][line_num][element_num])

                            element_num += 1

                        line_num += 1

                if print_fine_dets:

                    print('\n ending new_agent.NN_parameters: \n')
                    for item in new_agent.NN_parameters:
                        print('\n item', item, 'new_agent.NN_parameters[item] \n\n', new_agent.NN_parameters[item])

            elif params.num_NNs == 2:

                if print_fine_dets:
                    print('\n starting new_agent.NN_parameters_ps: \n')
                    for item in new_agent.NN_parameters_ps:
                        print('\n item', item, 'new_agent.NN_parameters_ps[item] \n\n', new_agent.NN_parameters_ps[item])

                for item in new_agent.NN_parameters_ps:

                    if print_fine_dets:
                        print('\n item =', item)

                        print('\n old new_agent.NN_parameters_ps[item] =\n\n', new_agent.NN_parameters_ps[item])

                    line_num = 0

                    for line in new_agent.NN_parameters_ps[item]:

                        if print_fine_dets:
                            print('\n line =', line)

                        element_num = 0

                        for element in line:

                            if print_fine_dets:
                                print('\n element', element)

                                print('\n line_num', line_num, 'element_num', element_num)
                                print(' old new_agent.NN_parameters_ps[item][line_num][element_num] =', new_agent.NN_parameters_ps[item][line_num][element_num])

                                print('\n mother.NN_parameters_ps[item][line_num][element_num]', mother.NN_parameters_ps[item][line_num][element_num])
                                print(' father.NN_parameters_ps[item][line_num][element_num]', father.NN_parameters_ps[item][line_num][element_num])

                                print('\n parental mean =', np.mean([mother.NN_parameters_ps[item][line_num][element_num], father.NN_parameters_ps[item][line_num][element_num]]))

                            element = np.mean([mother.NN_parameters_ps[item][line_num][element_num], father.NN_parameters_ps[item][line_num][element_num]])

                            new_agent.NN_parameters_ps[item][line_num][element_num] = element

                            if print_fine_dets:
                                print('\n new new_agent.NN_parameters_ps[item][line_num][element_num]', new_agent.NN_parameters_ps[item][line_num][element_num])

                            element_num += 1

                        line_num += 1

                if print_fine_dets:
                    print('\n ending new_agent.NN_parameters_ps: \n')
                    for item in new_agent.NN_parameters_ps:
                        print('\n item', item, 'new_agent.NN_parameters_ps[item] \n\n', new_agent.NN_parameters_ps[item])

                if print_fine_dets:
                    print('\n starting new_agent.NN_parameters_pfb: \n')
                    for item in new_agent.NN_parameters_pfb:
                        print('\n item', item, 'new_agent.NN_parameters_pfb[item] \n\n', new_agent.NN_parameters_pfb[item])

                for item in new_agent.NN_parameters_pfb:

                    if print_fine_dets:
                        print('\n item =', item)

                    line_num = 0

                    for line in new_agent.NN_parameters_pfb[item]:

                        if print_fine_dets:
                            print('\n line =', line)

                        element_num = 0

                        for element in line:

                            if print_fine_dets:
                                print('\n element', element)

                                print('\n line_num', line_num, 'element_num', element_num)
                                print(' old new_agent.NN_parameters_pfb[item][line_num][element_num] =', new_agent.NN_parameters_pfb[item][line_num][element_num])

                                print('\n mother.NN_parameters_pfb[item][line_num][element_num]', mother.NN_parameters_pfb[item][line_num][element_num])
                                print('\n father.NN_parameters_pfb[item][line_num][element_num]', father.NN_parameters_pfb[item][line_num][element_num])

                                print('\n parental mean =', np.mean([mother.NN_parameters_pfb[item][line_num][element_num], father.NN_parameters_pfb[item][line_num][element_num]]))

                            element = np.mean([mother.NN_parameters_pfb[item][line_num][element_num], father.NN_parameters_pfb[item][line_num][element_num]])

                            new_agent.NN_parameters_pfb[item][line_num][element_num] = element

                            if print_fine_dets:
                                print('\n new new_agent.NN_parameters_pfb[item][line_num][element_num]', new_agent.NN_parameters_pfb[item][line_num][element_num])

                            element_num += 1

                        line_num += 1

                if print_fine_dets:
                    print('\n ending new_agent.NN_parameters_pfb: \n')
                    for item in new_agent.NN_parameters_pfb:
                        print('\n item', item, 'new_agent.NN_parameters_pfb[item] \n\n', new_agent.NN_parameters_pfb[item])

        # pause()

        # we track these values so need to record them
        new_agent.prop_steal_record = copy.copy(new_agent.prop_steal)
        new_agent.prop_fight_back_record = copy.copy(new_agent.prop_fight_back)
        new_agent.agent_res_array_record = copy.copy(new_agent.agent_res_array)
        new_agent.detect_skills_array_record = copy.copy(new_agent.detect_skills_array)

        # print('\n new_agent.parents', new_agent.parents)
        # pause()

        # if we are conducting the black sheep experiment and this is the first child in the sim, then make it the black sheep child
        if (black_shoop_exp == 1 and len(agent_population.black_shoop_list) == 0) or (black_shoop_exp == 'all' and len(agent_population.pop) >= black_shoop_pop):
            #           print('\n pre agent_population.black_shoop', agent_population.black_shoop, 'new_agent.agent_res_array =', new_agent.agent_res_array)

            agent_population.black_shoop_list.append(new_agent)

            # create a data file to record black_shoop data
            black_shoop_file = '%s/black_shoop_file_%d.txt' % (run_folder, len(agent_population.black_shoop_list) - 1)

            with open(black_shoop_file, 'a') as myfile:
                myfile.write("This text file is for recording notes concerning a black shoop (a child which is born with prop_steal and prop_fight_back = 1)\n")

            new_agent.black_shoop_file = black_shoop_file

            # this is a switch so we don't create any more black shoops after the first
            #            agent_population.black_shoop_seen = 1

            new_agent.prop_steal = black_shoop_prop_start
            new_agent.prop_fight_back = black_shoop_prop_start

            print('\n A black shoop was born!!!! - baaaaaaaaaaaaaa!!!!!')

            text = '\n\nThe Black Shoop was born on day %d  |  home = %s\n' % (day, new_agent.home)
            with open(new_agent.black_shoop_file, 'a') as myfile:
                myfile.write(text)

        brand_new_agents.append(new_agent)

        # note that new agents will have a randomly placed home by default so we need to overwrite this if we would like
        if agent_homes == 'even':  # we need to overwrite the agent's location

            if popn_ch == 'fixed':  # then the agent just uses the dead agent's home

                dead_agent = dbs.davy_jones_locker[i]

                new_agent.home = dead_agent.home

            elif popn_ch == 'vary':  # then we need to place the agent in the largest space possible

                new_agent.home = place_agent_in_best_spot(agent_population, town_grid, new_agent, two_tribes)

        agent_population.add_agent(new_agent)
        new_agent_array.append(new_agent)

        if new_agents > 0:
            print('\n *** New agent created: day', day, ' mating_thresh', mating_thresh, 'p_s %1.4f' % new_agent.prop_steal, ' p_fb %1.4f' % new_agent.prop_fight_back, ' home ', new_agent.home,
                  'res = [%5.5s, %5.5s]' % (new_agent.agent_res_array[0][0], new_agent.agent_res_array[0][1]),\
                  'par 1 %s ps %1.4f pfb %1.4f res [%5.5s, %5.5s]' % (new_agent.parents[0].home, new_agent.parents[0].prop_steal, new_agent.parents[0].prop_fight_back, new_agent.parents[0].agent_res_array[0][0], new_agent.parents[0].agent_res_array[0][1]),\
                  'par 2 %s ps %1.4f pfb %1.4f res [%5.5s, %5.5s]' % (new_agent.parents[1].home, new_agent.parents[1].prop_steal, new_agent.parents[1].prop_fight_back, new_agent.parents[1].agent_res_array[0][0], new_agent.parents[1].agent_res_array[0][1]), '\n')

    # if our tracking agent has died this round, we replace it with one of the new births
    if agent_population.tracking_agent in dbs.davy_jones_locker and len(new_agent_array) > 0:
        agent_population.tracking_agent = random.choice(new_agent_array)

    # record population size at end of day
    dbs.main_db[3][day] = len(agent_population.pop)

    if two_tribes:

        num_sharks = 0
        num_jets = 0

        for agent in agent_population.pop:

            if agent.tribe == 'sharks':

                num_sharks += 1

            elif agent.tribe == 'jets':

                num_jets += 1

        dbs.pop_sharks[day] = num_sharks
        dbs.pop_jets[day] = num_jets

    if (new_agents > 0 and popn_ch == 'vary' and agent_homes == 'random') or day == rounds - 1:

        if day == rounds - 1:

            dpi = 'high'

        else:

            dpi = 'low'

        homes_array = np.zeros(shape=(dimen, dimen))

        for agent in agent_population.pop:
            x_coord = int(agent.home[0])
            y_coord = int(agent.home[1])

            homes_array[x_coord][y_coord] += 1

        if new_agents > 0 and popn_ch == 'vary' and agent_homes == 'random':
            title = 'After addition - day % d' % day
        elif day == rounds - 1:
            title = 'Agent homes at the end of round %d' % day

        # now illustrate homes_array via a heatmap if we're printing charts
        create_heat_map(dimen, homes_array, params.run_population_folder, 'Greys', title, "agent_homes_end", dpi)

    # We also allow the newly born agent to communicate with all the other agents, so it is aware of trading locations
    # copy the agent population
    if respect_property_rights == 1:

        # we want any pair of agents to have a probability of communicating of agents_comm_prob: we can think of this as a squre matrix with the list of agents on each axis.
        # we want to use one side of the matrix (a triangle) without the diagonal elements only.  so if we take a copy of the agent population, remove the first agent, we are left
        # with the top line of the triangular matrix to choose a cp_agent.  We then remove each agent in turn and iterate over the remaining agents.
        for agent in brand_new_agents:

            copy_population = list(copy.copy(agent_population.pop))

            #        if 0 <= day - agent.birth_date < 5 and day > 100:
            #
            #            print_dets = 1

            if len(copy_population) > 1:

                copy_population.remove(agent)

                if print_dets == 1:
                    print('\n NEW BIRTH - copying location information')
                    print('\n\n------->agent =', agent, agent.home)

                for cp_agent in copy_population:

                    if random.random() < agents_comm_prob:

                        if print_dets == 1:
                            print('\n cp_agent =', cp_agent, cp_agent.home)

                        agents_want_to_comm = 'both'
                        agent_exp_gain = 1
                        cp_agent_exp_gain = 1
                        two_agents_communicate(params, agent_population, town_grid, agent, cp_agent, day, print_dets, respect_property_rights, rounds, day, agents_want_to_comm, dbs,
                                               price_mean, force_prices, fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
                                               agent_exp_gain, cp_agent_exp_gain, agent_mem_length, fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                               clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst, print_fine_dets, params.track_agent, params.strangers_if_unknown)

                                                # params, agent_population, town_grid, agent, cp_agent, round, print_dets, respect_property_rights, num_rounds, day, agents_want_to_comm, dbs,
                                                # price_mean, force_prices, fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
                                                # start_agent_exp_gain, start_cp_agent_exp_gain, agent_mem_length, fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine,
                                                # fight_skill, fix_ps_fb_0, clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst, print_fine_dets, track_agent, strangers_if_unknown):

#                        two_agents_communicate(agent_population, town_grid, agent, cp_agent, day, print_dets, respect_property_rights, rounds, day, agents_want_to_comm, dbs,
#                                               adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta)

    # if new_agents > 0 or print_fine_dets == 1:
    #
    #     print(' new_agent.detect_skills_array at end of function new_births', new_agent.detect_skills_array)
    #     print(' new_agent.for_strat_array at end of function new_births', new_agent.for_strat_array, '\n')
    #
    #     pause()


def propose_keynesian_inst(KO_pop, dbs, agent_population, min_res_levels_db, day, agent_res_init, town_grid,
                           print_fine_dets, print_dets, data_folder, trade_moves, wait_at_tgt_moves, agent_vision, fountain_population,
                           trade_prices, granular_mem, loc_mkt, restrict_by_district):
    """This function runs an algorithm which leads to the proposition of a new market square for certain agents.  The aim
    is to attempt to create a new market in a location where agents have been persistently dying."""

    # We look in dead_agent_array to see which agents have died.  A Keynesian institution gets proposed if
    # (i) 2 or more agents have died in (a) specific location(s); (ii) there is a location which both agents can reach

    #    print_fine_dets = 1

    print('\n *** A Keynesian institution is being proposed ***')

    if print_fine_dets == 1:
        print('\n KO_pop.KI_stiffs =\n', KO_pop.KI_stiffs)
        print('len(KO_pop.KI_stiffs) =', len(KO_pop.KI_stiffs), '\n')

    dead_ags_copy = copy.copy(dbs.dead_ags_grid_counter)

    # First we want to maximize the number of agents that can reach any proposed square, which is within striking distance
    # of a location where more than one agent has died.  We look at those squares only and then find the minimum aggregated distance.

    # Find location with more than one death in dbs.dead_ags_grid_counter
    more_than_one_death_array = [[x, y] for x in np.arange(town_grid.dimen) for y in np.arange(town_grid.dimen) if dbs.dead_ags_grid_counter[x][y] > 1]

    print(' more_than_one_death_array =', more_than_one_death_array)

    if print_fine_dets == 1:
        print(' dbs.sign_mkt_locs[day] =', dbs.sign_mkt_locs[day])

    # for simplicity, we deal with only one square in each round and we choose it randomly:
    if len(more_than_one_death_array) > 1:
        more_than_one_death_array = [random.choice(more_than_one_death_array)]

    # Create an array to count the number of agents that can reach each grid square (number of agents in striking distance)
    num_agent_in_strdist = np.zeros(shape=(town_grid.dimen, town_grid.dimen), dtype=int)

    # we want to find all the current trading agents, to minimize interference
    if print_fine_dets == 1:
        print('\n dbs.trades_array_ags ', dbs.trades_array_ags)

    trading_agents = []

    for i in range(town_grid.dimen):
        for j in range(town_grid.dimen):

            if len(dbs.trades_array_ags[i][j]) > 0:

                for ag in dbs.trades_array_ags[i][j]:
                    trading_agents.append(ag)

    if print_fine_dets == 1:
        print('\n trading_agents ', trading_agents)

    # Create array to record the home locations of agents not trading
    home_locs = []

    for agent in agent_population.pop:

        if agent not in trading_agents:
            home_locs.append(agent.home)

    print(' more_than_one_death_loc =', more_than_one_death_array)

    # we populate num_agent_in_strdist with tallies for the number of dead agent locations within striking distance of each grid square
    for more_than_one_death_loc in more_than_one_death_array:

        #        print('\n more_than_one_death_loc', more_than_one_death_loc, 'from more_than_one_death_array', more_than_one_death_array)

        # if we are using districts we need to find the boundaries of the district which the double-death location falls within (x_min, x_mix, y_min, y_max)
        if restrict_by_district == 1:

            if math.floor(more_than_one_death_loc[0] / (town_grid.dimen / 2.0)) == 0:
                boundary_x_min = 0
                boundary_x_max = int(town_grid.dimen / 2.0 - 1)

            if math.floor(more_than_one_death_loc[0] / (town_grid.dimen / 2.0)) == 1:
                boundary_x_min = int(town_grid.dimen / 2.0)
                boundary_x_max = town_grid.dimen - 1

            if math.floor(more_than_one_death_loc[1] / (town_grid.dimen / 2.0)) == 0:
                boundary_y_min = 0
                boundary_y_max = int(town_grid.dimen / 2.0 - 1)

            if math.floor(more_than_one_death_loc[1] / (town_grid.dimen / 2.0)) == 1:
                boundary_y_min = int(town_grid.dimen / 2.0)
                boundary_y_max = town_grid.dimen - 1

        for x_coord in np.arange(town_grid.dimen):

            for y_coord in np.arange(town_grid.dimen):

                poss_tgt_location = [x_coord, y_coord]

                # The first condition is that the grid square must be within striking distance of any location where two or more agents have died
                # print('\n 12 wait_at_tgt_moves', wait_at_tgt_moves)
                if within_striking_dist(wait_at_target_til_end, town_grid, more_than_one_death_loc, wait_at_tgt_moves, agent_vision, poss_tgt_location, move=0, has_acted=0, print_dets=0):

                    #                    print('\n restrict_by_district', restrict_by_district)
                    #                    print(' x_coord', x_coord, 'y_coord', y_coord)
                    #                    print(' math.floor(x_coord / (town_grid.dimen / 2.0))', math.floor(x_coord / (town_grid.dimen / 2.0)))
                    #                    print(' math.floor(x_coord / (town_grid.dimen / 2.0)) == 0?', math.floor(x_coord / (town_grid.dimen / 2.0)) == 0)
                    #                    print(' math.floor(y_coord / (town_grid.dimen / 2.0))', math.floor(y_coord / (town_grid.dimen / 2.0)))

                    within_district = 0

                    # Now we ask if the grid square is within the same policy quadrant as the more_than_one_death_loc
                    if restrict_by_district == 1:

                        #                        print('\n restrict_by_district == 1', restrict_by_district == 1)

                        #                        print_fine_dets = 1

                        if print_fine_dets == 1:
                            print('\n x_coord', x_coord, 'boundary_x_min', boundary_x_min, 'boundary_x_max', boundary_x_max, 'y_coord', y_coord, 'boundary_y_min', boundary_y_min, 'boundary_y_max', boundary_y_max)

                        if boundary_x_min <= x_coord <= boundary_x_max and boundary_y_min <= y_coord <= boundary_y_max:
                            within_district = 1

                        if print_fine_dets == 1:
                            print('within_district:', within_district)

                    if (restrict_by_district == 1 and within_district == 1) or restrict_by_district == 0:

                        # now we test if the grid square is within striking distance of any existing market:
                        within_reach_of_existing_mkt = 0

                        #                        if print_fine_dets == 1:
                        #                            print('\n loc_mkt =', loc_mkt)

                        # Test each market only if loc_mkt == 'avoid_interference'
                        if loc_mkt == 'avoid_interference':

                            for market_loc in dbs.sign_mkt_locs[day]:

                                #                                if print_fine_dets == 1:
                                #                                    print('\n market_loc', market_loc)

                                # if the grid square is within striking distance of any market we will ignore it
                                # print('\n 13 wait_at_tgt_moves', wait_at_tgt_moves)
                                if within_striking_dist(wait_at_target_til_end, town_grid, market_loc, wait_at_tgt_moves, agent_vision, poss_tgt_location, move=0, has_acted=0, print_dets=0):
                                    #                                    if print_fine_dets == 1:
                                    #                                        print('within str dist of market')

                                    within_reach_of_existing_mkt = 1

                        #                        if print_fine_dets == 1:
                        #                            print('\n within_reach_of_existing_mkt ', within_reach_of_existing_mkt)

                        # we carry on if the grid square is not within reach of an existing market OR we don't care about this
                        if within_reach_of_existing_mkt == 0:

                            # now we consider all the live agents: all if we don't care about interference; or those currently not trading if we care
                            for agent in agent_population.pop:

                                if loc_mkt != 'avoid_interference' or (loc_mkt == 'avoid_interference' and agent not in trading_agents):

                                    home_loc = agent.home

                                    #                                if print_fine_dets == 1:
                                    #                                    print('home_loc =', home_loc)

                                    # If the poss_tgt_location is within striking distance of the agent location...
                                    # print('\n 14 wait_at_tgt_moves', wait_at_tgt_moves)
                                    if within_striking_dist(wait_at_target_til_end, town_grid, home_loc, wait_at_tgt_moves, agent_vision, poss_tgt_location, move=0, has_acted=0, print_dets=0):
                                        num_agent_in_strdist[x_coord][y_coord] += 1

    print(' home_locs =', home_locs, '\n')

    if print_fine_dets == 1:
        print(' len(home_locs) =', len(home_locs), '\n')
        print('\n more_than_one_death_array =\n', more_than_one_death_array)

    # we have to be careful when there are multiple existing markets which leads to an empty home_locs array - in this case, we don't do anything
    if len(home_locs) > 0:

        # Find the maximum number of agents within reach of any location in num_agent_in_strdist - we are only interested in these locations
        max_num_ags_reach = np.max(num_agent_in_strdist)

        if print_fine_dets == 1:
            print('\n max_num_ags_reach =', max_num_ags_reach)

        # Now we create a list comprehension which develops an array which contains all of the locations equal to this maximum
        top_locs_array = [[x, y] for x in np.arange(town_grid.dimen) for y in np.arange(town_grid.dimen) if num_agent_in_strdist[x][y] == max_num_ags_reach]

        if print_fine_dets == 1:
            print('\n top_locs_array =\n', top_locs_array)
            print(' len(top_locs_array) =', len(top_locs_array), '\n')

        # The number of top locations is:
        num_top_locs = len(top_locs_array)

        # We want to look at every location in top_locs_array and find the distance with the smallest total distance for the dead
        # agent locations (we are finding the best possible square for these locations).  We record that in this array:
        total_moves_to_location_array = np.zeros(shape=(town_grid.dimen, town_grid.dimen), dtype=int)

        # We write the same information in this array
        top_loc_tot_dists = np.zeros(shape=(num_top_locs), dtype=int)

        for top_loc_index in np.arange(num_top_locs):

            top_loc = top_locs_array[top_loc_index]

            if print_fine_dets == 1:
                print('\n\n\n top_loc_index =', top_loc_index)
                print(' iter top_loc =', top_loc)

            for loc in home_locs:

                if print_fine_dets == 1:
                    print('\n loc =', loc)

                x_dist = math.fabs(top_loc[0] - loc[0])

                if x_dist > town_grid.dimen / 2.0:
                    x_dist = town_grid.dimen - x_dist

                y_dist = math.fabs(top_loc[1] - loc[1])

                if y_dist > town_grid.dimen / 2.0:
                    y_dist = town_grid.dimen - y_dist

                # The number of trading moves it will take to get there:
                travel_time = int(np.max([math.ceil(x_dist / float(agent_vision)), math.ceil(y_dist / float(agent_vision))]))

                if print_fine_dets == 1:
                    print('\n x_dist', x_dist)
                    print(' y_dist', y_dist)
                    print(' travel_time', travel_time)
                    print(' trade_moves - wait_at_tgt_moves', trade_moves - wait_at_tgt_moves)

                if travel_time <= trade_moves - wait_at_tgt_moves:  # then the agent at this home can reach the location

                    top_loc_tot_dists[top_loc_index] += travel_time

                    x_coord = top_loc[0]
                    y_coord = top_loc[1]

                    total_moves_to_location_array[x_coord][y_coord] += travel_time

            if print_fine_dets == 1:
                print('\n total_travel_time for this top loc = ', top_loc_tot_dists[top_loc_index])

                # Find the least total distance:
        min_tot_travel = np.min(top_loc_tot_dists)

        if print_fine_dets == 1:
            print('\n top_loc_tot_dists =\n', top_loc_tot_dists)
            print('\n min_tot_travel =', min_tot_travel, '(mean per agent is', min_tot_travel / float(max_num_ags_reach), ')\n')

        # We create an array to record the locations where these shortest total distance are
        min_locs_array = []

        # And we also record, for LIVE agents, the total number of agents within striking distance - if we are dividing in to districts then we still do this
        # as we have already fully prioritised district agents - this process means a market located in a district might get business from outside
        live_ag_dists = []

        live_ag_grid = np.zeros(shape=(town_grid.dimen, town_grid.dimen), dtype=int)

        for top_loc_index in np.arange(num_top_locs):

            if print_fine_dets == 1:
                print('\n\n top_loc_index =', top_loc_index)
                print('\n\n top_loc_tot_dists[top_loc_index] =', top_loc_tot_dists[top_loc_index])

            # We are only interested in the shortest total distance:
            if top_loc_tot_dists[top_loc_index] == min_tot_travel:

                # if this location has the shortest total distance then we record it in min_locs_array, live_ag_grid and live_ag_dists
                top_loc = top_locs_array[top_loc_index]

                x_coord = top_loc[0]
                y_coord = top_loc[1]

                if print_fine_dets == 1:
                    print('\n top_loc =', top_loc)

                min_locs_array.append([x_coord, y_coord])

                tot_live_dist = 0

                for agent in agent_population.pop:

                    #                    print('\n loc_mkt =', loc_mkt)
                    #                    print('\n agent', agent.home, 'in dbs.trades_array_ags?', agent in trading_agents)

                    if loc_mkt != 'avoid_interference' or (loc_mkt == 'avoid_interference' and agent not in trading_agents):

                        # print('\n 15 wait_at_tgt_moves', wait_at_tgt_moves)
                        if within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent_vision, top_loc, move=0, has_acted=0, print_dets=0):
                            tot_live_dist += 1
                            live_ag_grid[x_coord][y_coord] += 1

                live_ag_dists.append(tot_live_dist)

                if print_fine_dets == 1:
                    print('\n tot_live_dist =', tot_live_dist)

        # The maximum number of live agents which can reach the best locations for the dead agent locations is:
        max_tot_live_within = np.max(live_ag_dists)

        if print_fine_dets == 1:
            print('\n min_locs_array =', min_locs_array)
            print(' len(min_locs_array) =', len(min_locs_array))
            print('\n live_ag_dists =', live_ag_dists)
            print(' len(live_ag_dists) =', len(live_ag_dists))
            print(' max_tot_live_within =', max_tot_live_within)

        # We find all these locations and choose one of them randomly
        best_dead_alive_locs = []

        for min_loc_index in np.arange(len(min_locs_array)):

            if live_ag_dists[min_loc_index] == max_tot_live_within:
                best_dead_alive_locs.append(min_locs_array[min_loc_index])

        dbs.proposed_KI_loc = random.choice(best_dead_alive_locs)

        if print_fine_dets == 1:
            print('\n dbs.proposed_KI_loc =', dbs.proposed_KI_loc)
            print('\n home_locs =', home_locs)
            print('\n dbs.sign_mkt_locs[day] =', dbs.sign_mkt_locs[day])

        # We wipe this array in order to repopulate it
        KIagents = []
        trgt_locations = []

        for loc in home_locs:

            if print_fine_dets == 1:
                print('\n loc', loc)

            # print('\n 16 wait_at_tgt_moves', wait_at_tgt_moves)
            if within_striking_dist(wait_at_target_til_end, town_grid, loc, wait_at_tgt_moves, agent_vision, dbs.proposed_KI_loc, move=0, has_acted=0,
                                    print_dets=0):  # the dead agent's location is within striking distance of the proposed_KI_loc

                if print_fine_dets == 1:
                    print('\n within str dist of dbs.proposed_KI_loc ', dbs.proposed_KI_loc)

                #                within_reach_of_existing_mkt = 0
                #
                #                # Test each market only if we're seeking to avoid interference with existing markets
                #                if loc_mkt == 'avoid_interference':
                #
                #                    for market_loc in dbs.sign_mkt_locs[day]:
                #
                #                        # if the loc is within striking distance of any market we will ignore it
                #                        if within_striking_dist(wait_at_target_til_end, town_grid, market_loc, wait_at_tgt_moves, agent_vision, loc, move=0, has_acted=0, print_dets=0):
                #
                #                            within_reach_of_existing_mkt = 1
                #
                #                # we carry on if the loc is not within reach of an existing market
                #                if within_reach_of_existing_mkt == 0:

                for agent in agent_population.pop:

                    if loc[0] == agent.home[0] and loc[1] == agent.home[1]:  # then we want this agent on our list

                        if print_fine_dets == 1:
                            print(' agent', agent, 'home', agent.home)

                        if agent not in KIagents:
                            KIagents.append(agent)
                            trgt_locations.append(list(agent.home))

        if print_fine_dets == 1:
            print('\n KIagents =', KIagents)
            print('\n trgt_locations =', trgt_locations)
            print('len(KO_pop.KI_stiffs)', len(KO_pop.KI_stiffs))
        #            print('\n pre-home_locs = ', home_locs)
        #
        #        # before moving on we need to remove trgt_locations from home_locations
        #        for loc in home_locs:
        #
        #            for trgt_loc in trgt_locations:
        #
        #                if print_fine_dets == 1:
        #                    print('\n trgt_loc =', trgt_loc)
        #
        #                if trgt_loc[0] == loc[0] and trgt_loc[1] == loc[1]:
        #
        #                    if print_fine_dets == 1:
        #                        print(' trgt_loc[0] == loc[0] and trgt_loc[1] == loc[1]')
        #
        #                    home_locs.remove(trgt_loc)
        #
        #        if print_fine_dets == 1:
        #            print('\n post-home_locs = ', home_locs)

        copy_stiffs = copy.copy(KO_pop.KI_stiffs)

        # we only want to create the KI if there are more than 1 live agents who would benefit
        if len(KIagents) > 1:

            for trgt_loc in trgt_locations:

                if print_fine_dets == 1:
                    print('\n trgt_loc =', trgt_loc, '\n')

                # set the values of dbs.dead_ags_grid_counter to zero for these locations
                dbs.dead_ags_grid_counter[trgt_loc[0]][trgt_loc[1]] = 0

                for stiff in copy_stiffs:

                    if print_fine_dets == 1:
                        print('\n stiff home =', stiff.home)
                        print(' stiff.home[0] == trgt_loc[0]', stiff.home[0] == trgt_loc[0])
                        print(' stiff.home[1] == trgt_loc[1]', stiff.home[1] == trgt_loc[1])

                    if stiff.home[0] == trgt_loc[0] and stiff.home[1] == trgt_loc[1]:

                        if print_fine_dets == 1:
                            print('\n stiff.home[0] == trgt_loc[0] and stiff.home[1] == trgt_loc[1]')
                            print('stiff in KO_pop.KI_stiffs ', stiff in KO_pop.KI_stiffs)

                        if stiff in KO_pop.KI_stiffs:
                            KO_pop.KI_stiffs.remove(stiff)

                        if print_fine_dets == 1:
                            print('AFTER : stiff in KO_pop.KI_stiffs ', stiff in KO_pop.KI_stiffs)

            #                        if stiff not in remaining_stiffs:
            #
            #                            remaining_stiffs.append(the_stiff)

            #            if print_fine_dets == 1:
            #                print('\n remaining_stiffs =', remaining_stiffs)
            #
            #            KO_pop.KI_stiffs = copy.copy(remaining_stiffs)

            if print_fine_dets == 1:

                print('\n KO_pop.KI_stiffs =', KO_pop.KI_stiffs, '\n')

                for stiff in KO_pop.KI_stiffs:
                    print(' stiff.home =', stiff.home)

            # create new sub directory to record data
            new_ko_folder = '%s/KI_day_%s' % (data_folder, day)

            ko_notes_file = '%s/00_notes_file.txt' % (new_ko_folder)

            # this line creates the directory
            os.makedirs(new_ko_folder)

            # Finally, create the Keynesian Object
            new_ko = Keynesian_Object(day, copy.copy(dbs.proposed_KI_loc), new_ko_folder, ko_notes_file, dead_ags_copy, copy.copy(dbs.dead_ags_grid_counter),
                                      copy.copy(KIagents), trgt_locations)

            KO_pop.pop.append(new_ko)

            # Append dbs.KI_notes_file
            add_text = "\n\n A Keynesian Institution was proposed on day %s at location %s" % (day, dbs.proposed_KI_loc)

            with open(dbs.KI_notes_file, 'a') as myfile:
                myfile.write(add_text)

            # Append new_ko text_file
            add_text = "This is a Notes File pertaining to a proposed Keynesian Institution.\n\nThe Institution was proposed on day %s at location %s" % (day, dbs.proposed_KI_loc)

            new_ko.write_to_notes(add_text)

            new_ko.add_initial_text(fountain_population, trade_prices, granular_mem, print_fine_dets, print_dets, dbs, town_grid, day, wait_at_tgt_moves)

            # Print the following charts
            title = 'Dead Agents Heatmap (KI proposed) - Day %s (start)' % (day)
            create_heat_map(town_grid.dimen, dead_ags_copy, new_ko.folder, 'Greens', title, 'KI_day_%s_1_dead_ags' % (day), dpi='low')

            title = 'KI proposed: Number of Agents - Day %s' % (day)
            create_heat_map(town_grid.dimen, num_agent_in_strdist, new_ko.folder, 'Greens', title, 'KI_day_%s_2_num_ags' % (day), dpi='low')

            title = 'KI proposed: Total Moves to Location - Day %s' % (day)
            create_heat_map(town_grid.dimen, total_moves_to_location_array, new_ko.folder, 'Greens', title, 'KI_day_%s_3_moves_to_locs' % (day), dpi='low')

            title = 'KI proposed: Total Moves to Location (Live and Dead Agents) - Day %s' % (day)
            create_heat_map(town_grid.dimen, live_ag_grid, new_ko.folder, 'Greens', title, 'KI_day_%s_4_moves_to_locs' % (day), dpi='low')

            title = 'Dead Agents Heatmap (KI proposed) - Day %s (end)' % (day)
            create_heat_map(town_grid.dimen, dbs.dead_ags_grid_counter, new_ko.folder, 'Greens', title, 'KI_day_%s_5_dead_ags' % (day), dpi='low')

            # fileHandle = open(dbs.KI_notes_file, 'w')
            # fileHandle.close()

    #    else:
    #
    #        # Append dbs.KI_notes_file
    #        add_text = "\n\n A Keynesian Institution was NOT proposed on day %s because there were a number of significant market locations already existing across the grid (the array home_locs was empty)" % (day)
    #
    #        with open(ko_notes_file, 'a') as myfile:
    #            myfile.write(add_text)

    if print_fine_dets == 1:
        pause()


def form_exps_rtns_props(params, agent, pot_cp, cp_agent_prop_steal, cp_agent_prop_fight_back, agent_population, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, simulated_int, adjust_props_r,
                         agent_intn_beta, fight_balance, fight_cost, formal_inst, prob_fine, fine, print_fine_dets, fight_skill, stranger_int, strat_choice, strangers_if_unknown):

    """This function takes two agents and finds their expected returns from any interaction between them.  It also finds the expected changes in prop_steal
    and prop_fight_back if they interacted."""

    # if day > 100:
    #
    #     print_fine_dets = 1

    # print_fine_dets = 1

    if (params.track_agent and params.track_agent <= day) and (agent == agent_population.tracking_agent or pot_cp == agent_population.tracking_agent):
        print_for_tracking = 1
    else:
        print_for_tracking = 0

    if print_fine_dets or print_for_tracking:
        print('\n\n *** Starting form_exps_rtns_props')

    # we are dealing with 2 scenarios - when we are simulating an interaction and when we are not
    if simulated_int:

        agent_basket_array = agent.basket_array_start
        cp_agent_basket_array = pot_cp.basket_array_start

    else:

        agent_basket_array = agent.basket_array
        cp_agent_basket_array = pot_cp.basket_array

    # update MRS arrays
    agent_aggr_resources = agent.agent_res_array + agent_basket_array
    cp_agent_aggr_resources = pot_cp.agent_res_array + cp_agent_basket_array

    agent.MRS_array = generate_MRS_array(agent_aggr_resources, print_fine_dets=0)
    pot_cp.MRS_array = generate_MRS_array(cp_agent_aggr_resources, print_fine_dets=0)

    # find lowest resource
    agent_lowest_res = 0
    if agent_aggr_resources[0][0] > agent_aggr_resources[0][1]:
        agent_lowest_res = 1

    cp_agent_lowest_res = 0
    if cp_agent_aggr_resources[0][0] > cp_agent_aggr_resources[0][1]:
        cp_agent_lowest_res = 1

    # find probabilities of winning and losing fights
    if fight_skill is not None:

        sum_skill = agent.fight_skill + pot_cp.fight_skill

        if sum_skill != 0.0:
            
            prob_agent_wins_fight = agent.fight_skill / float(sum_skill)

        else:
            
            prob_agent_wins_fight = 0.5

        prob_agent_loses_fight = 1 - prob_agent_wins_fight

        if print_fine_dets:

            print('\n agent.fight_skill ', agent.fight_skill)
            print('\n pot_cp.fight_skill ', pot_cp.fight_skill)

    elif fight_balance == '50_50':

        prob_agent_wins_fight = prob_agent_loses_fight = 0.5
        
    elif fight_balance == 'res_power':

        agent_mean_res = np.mean(agent.agent_res_array[0])
        cp_agent_mean_res = np.mean(pot_cp.agent_res_array[0])

        # this means that if agent has more resources then it will have more chance of winning the fight
        prob_agent_wins_fight = agent_mean_res / float(agent_mean_res + cp_agent_mean_res)
        prob_agent_loses_fight = 1 - prob_agent_wins_fight

        if print_fine_dets == 1:

            print('\n agent_mean_res =', agent_mean_res)
            print(' cp_agent_mean_res =', cp_agent_mean_res)
            print('\n prob_agent_wins_fight =', prob_agent_wins_fight)
            print(' prob_agent_loses_fight =', prob_agent_loses_fight)
            print('\n fight_cost =', fight_cost)

    if (print_fine_dets or print_for_tracking) and formal_inst:
        print('\n formal institution in effect: formal_inst is', formal_inst, ', prob_fine = ', prob_fine, 'fine =', fine, 'prob_fine * fine =', prob_fine * fine, 'agent_population.mean_ps', agent_population.mean_ps, 'agent_population.corruption_prop_charge',
              agent_population.corruption_prop_charge)

    if print_fine_dets or print_for_tracking:
        
        print('\n prob_agent_wins_fight =', prob_agent_wins_fight)
        print(' prob_agent_loses_fight =', prob_agent_loses_fight)
        print('\n simulated_int ', simulated_int)

        print('\n applied: agent_basket_array', agent_basket_array)
        print(' agent.agent_res_array ', agent.agent_res_array)
        print('\n applied: cp_agent_basket_array', cp_agent_basket_array)
        print(' pot_cp.agent_res_array ', pot_cp.agent_res_array)

    # Start with finding the 'building blocks' for all the values in all the interaction types

    # First find the agent's estimate of cp's basket (reduced value)
    agent_values_own_basket_reduced = 0.0
    agent_values_cp_basket_reduced = 0.0
    agent_values_fight_costs_reduced = 0.0

    cp_values_own_basket_reduced = 0.0
    cp_values_agent_basket_reduced = 0.0
    cp_values_fight_costs_reduced = 0.0

    # now we find these values by iterating over the resources like so
    for res in range(num_res_founts):

        # agent own basket
        agent_values_own_basket_reduced += agent_basket_array[0][res] * agent.MRS_array[agent_lowest_res][res]
        # agent values cp's basket
        agent_values_cp_basket_reduced += cp_agent_basket_array[0][res] * agent.MRS_array[agent_lowest_res][res]
        # fight costs
        agent_values_fight_costs_reduced += fight_cost * agent.MRS_array[agent_lowest_res][res]

        # cp own basket
        cp_values_own_basket_reduced += cp_agent_basket_array[0][res] * pot_cp.MRS_array[cp_agent_lowest_res][res]
        # cp values agent's basket
        cp_values_agent_basket_reduced += agent_basket_array[0][res] * pot_cp.MRS_array[cp_agent_lowest_res][res]
        # cp fight costs
        cp_values_fight_costs_reduced += fight_cost * pot_cp.MRS_array[cp_agent_lowest_res][res]

    # We use these values to determine the expected gain (loss) from fighting (excluding any fines or comensation)
    agent_exp_gross_gain_fight_reduced = (prob_agent_wins_fight * agent_values_cp_basket_reduced) + (prob_agent_loses_fight * (-1 * agent_values_own_basket_reduced)) + agent_values_fight_costs_reduced
    cp_exp_gross_gain_fight_reduced = (prob_agent_loses_fight * cp_values_agent_basket_reduced) + (prob_agent_wins_fight * (-1 * cp_values_own_basket_reduced)) + cp_values_fight_costs_reduced

    # If the agents are fined then we also want to find the amount each is fined (in reduced value terms
    if formal_inst:

        # start with finding net fine
        net_fine = prob_fine * fine * ((agent_population.mean_ps * agent_population.corruption_prop_charge) + (1 - agent_population.mean_ps))

        if print_fine_dets:
            print('\n net_fine =', net_fine)

        # agent's expected fine
        agent_exp_fine_reduced = 0.0
        # cp's expected fine
        cp_exp_fine_reduced = 0.0

        # iterate over resources again
        for res in range(num_res_founts):

            agent_exp_fine_reduced += net_fine * agent.MRS_array[agent_lowest_res][res]

            cp_exp_fine_reduced += net_fine * pot_cp.MRS_array[cp_agent_lowest_res][res]

        if print_fine_dets:
            print('\n agent_exp_fine_reduced =', agent_exp_fine_reduced)
            print('\n cp_exp_fine_reduced =', cp_exp_fine_reduced)

        # if comepnsation is being paid to the victim then:
        if formal_inst == 'compensate':

            # find net compensation
            net_compensation = (1 - agent_population.mean_ps) * prob_fine * -fine

            # agent's expected compensation
            agent_exp_comp_reduced = 0.0
            # cp's expected compensation
            cp_exp_comp_reduced = 0.0

            # iterate over resources again
            for res in range(num_res_founts):

                agent_exp_comp_reduced += net_compensation * agent.MRS_array[agent_lowest_res][res]

                cp_exp_comp_reduced += net_compensation * pot_cp.MRS_array[cp_agent_lowest_res][res]

            if print_fine_dets:
                print('\n net_compensation', net_compensation)
                print(' agent_exp_comp_reduced =', agent_exp_comp_reduced)
                print(' cp_exp_comp_reduced =', cp_exp_comp_reduced)

    # Now we look at all of the quadrants:

    # Quadrant 1 is transacting

    # Find out what they would trade, if at all:
    if (simulated_int and ((agent.basket_array_start[0][0] > 0.0 and pot_cp.basket_array_start[0][1] > 0.0) or (agent.basket_array_start[0][1] > 0.0 and pot_cp.basket_array_start[0][0] > 0))) or \
       (simulated_int == 0 and ((agent.basket_array[0][0] > 0.0 and pot_cp.basket_array[0][1] > 0.0) or (agent.basket_array[0][1] > 0.0 and pot_cp.basket_array[0][0] > 0))):  # then they might trade

        tot_cons_surp_array, best_trans_data = build_tot_cons_surp_array(params, agent_population.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, print_fine_dets,
                                                                         simulated_int, agent.agent_res_array, agent_basket_array, agent.basket_array_start, pot_cp.agent_res_array, pot_cp.basket_array, pot_cp.basket_array_start)

    else:  # then they won't trade

        tot_cons_surp_array, best_trans_data = ([[0.0, 0.0], [0.0, 0.0]], [None, None, None, None, None])

    # Now we need to convert this in to a reduce gain
    if print_fine_dets == 1:
        print('\n tot_cons_surp_array:\n', tot_cons_surp_array)
        print('\n best_trans_data =', best_trans_data)

    agent_sells, agent_buys, tot_trans_ag_sell, tot_trans_ag_buy, trans_agr_MRS = best_trans_data

    # if agent_sells is not None:
    #     agent_sells = int(agent_sells)
    #     agent_buys = int(agent_buys)

    # this code is only relevant when the agents are expected to trade
    if tot_trans_ag_buy is not None and tot_trans_ag_buy > 0 and tot_trans_ag_sell > 0:

        agent_exp_gain_1_reduced = (agent.MRS_array[agent_lowest_res][agent_buys] * tot_trans_ag_buy) - (agent.MRS_array[agent_lowest_res][agent_sells] * tot_trans_ag_sell)

        cp_exp_gain_1_reduced = (pot_cp.MRS_array[cp_agent_lowest_res][agent_sells] * tot_trans_ag_sell) - (pot_cp.MRS_array[cp_agent_lowest_res][agent_buys] * tot_trans_ag_buy)

    else:

        agent_exp_gain_1_reduced = 0.0
        cp_exp_gain_1_reduced = 0.0

    # Quadrant 2F - the agent wanted to trade but the cp wanted to steal.  The agent decided to fight.
    # For the agent:
    agent_exp_gain_2F_reduced = copy.copy(agent_exp_gross_gain_fight_reduced)

    if print_fine_dets:
        print('\n agent_exp_gain_2F_reduced =', agent_exp_gain_2F_reduced)

    # if there is a formal institution, the agent will not get fined but it might get compensated
    if formal_inst == 'compensate':
        agent_exp_gain_2F_reduced += agent_exp_comp_reduced

    # For the cp:
    cp_exp_gain_2F_reduced = copy.copy(cp_exp_gross_gain_fight_reduced)

    if print_fine_dets:
        print('\n cp_exp_gain_2F_reduced =', cp_exp_gain_2F_reduced)

    # if there is a formal institution, the cp will get fined
    if formal_inst:
        cp_exp_gain_2F_reduced += cp_exp_fine_reduced


    # Quadrant 2A - the agent wanted to trade but the cp wanted to steal.  The agent acquiesced.
    # For the agent:
    agent_exp_gain_2A_reduced = -1 * agent_values_own_basket_reduced

    if print_fine_dets:
        print('\n agent_exp_gain_2A_reduced =', agent_exp_gain_2A_reduced)

    # if there is a formal institution, the agent will not get fined but it might get compensated
    if formal_inst == 'compensate':
        agent_exp_gain_2A_reduced += agent_exp_comp_reduced

    # For the cp:
    cp_exp_gain_2A_reduced = copy.copy(cp_values_agent_basket_reduced)

    if print_fine_dets:
        print('\n cp_exp_gain_2A_reduced =', cp_exp_gain_2A_reduced)

    # if there is a formal institution, the cp will get fined
    if formal_inst:
        cp_exp_gain_2A_reduced += cp_exp_fine_reduced


    # Quadrant 3F - the cp wanted to trade but the agent wanted to steal.  The cp decided to fight.
    # For the agent:
    agent_exp_gain_3F_reduced = copy.copy(agent_exp_gross_gain_fight_reduced)

    if print_fine_dets:
        print('\n agent_exp_gain_3F_reduced =', agent_exp_gain_3F_reduced)

    # if there is a formal institution, the agent will get fined
    if formal_inst:
        agent_exp_gain_3F_reduced += agent_exp_fine_reduced

    # For the cp:
    cp_exp_gain_3F_reduced = copy.copy(cp_exp_gross_gain_fight_reduced)

    if print_fine_dets:
        print('\n cp_exp_gain_3F_reduced =', cp_exp_gain_3F_reduced)

    # if there is a formal institution, the cp will not get fined but it might get compensated
    if formal_inst == 'compensate':
        cp_exp_gain_3F_reduced += cp_exp_comp_reduced


    # Quadrant 3A - the cp wanted to trade but the agent wanted to steal.  The cp acquiesced.
    # For the agent:
    agent_exp_gain_3A_reduced = copy.copy(agent_values_cp_basket_reduced)

    if print_fine_dets:
        print('\n agent_exp_gain_3A_reduced =', agent_exp_gain_3A_reduced)

    # if there is a formal institution, the agent will get fined
    if formal_inst:
        agent_exp_gain_3A_reduced += agent_exp_fine_reduced

    # For the cp:
    cp_exp_gain_3A_reduced = -1 * cp_values_own_basket_reduced

    if print_fine_dets:
        print('\n cp_exp_gain_3A_reduced =', cp_exp_gain_3A_reduced)

    # if there is a formal institution, the cp will not get fined but it might get compensated
    if formal_inst == 'compensate':
        cp_exp_gain_3A_reduced += cp_exp_comp_reduced


    # Quadrant 4 - both agents attempt to steal from each other
    # For the agent:
    agent_exp_gain_4_reduced = copy.copy(agent_exp_gross_gain_fight_reduced)

    if print_fine_dets:
        print('\n agent_exp_gain_4_reduced =', agent_exp_gain_4_reduced)

    # if there is a formal institution, the agent will get fined
    if formal_inst:
        agent_exp_gain_4_reduced += agent_exp_fine_reduced

    # For the cp:
    cp_exp_gain_4_reduced = copy.copy(cp_exp_gross_gain_fight_reduced)

    if print_fine_dets:
        print('\n cp_exp_gain_4_reduced =', cp_exp_gain_4_reduced)

    # if there is a formal institution, the cp will get fined
    if formal_inst:
        cp_exp_gain_4_reduced += cp_exp_fine_reduced

    # here we add an error terms to all 12 returns:

    if print_fine_dets:

        print('\n data prior to errors added')

        print('\n agent_exp_gross_gain_fight_reduced =', agent_exp_gross_gain_fight_reduced)
        print(' cp_exp_gross_gain_fight_reduced =', cp_exp_gross_gain_fight_reduced)

        print('\n agent_exp_gain_1_reduced =', agent_exp_gain_1_reduced)
        print(' cp_exp_gain_1_reduced =', cp_exp_gain_1_reduced)

        print('\n agent_exp_gain_2F_reduced =', agent_exp_gain_2F_reduced)
        print(' cp_exp_gain_2F_reduced =', cp_exp_gain_2F_reduced)

        print('\n agent_exp_gain_2A_reduced =', agent_exp_gain_2A_reduced)
        print(' cp_exp_gain_2A_reduced =', cp_exp_gain_2A_reduced)

        print('\n agent_exp_gain_3F_reduced =', agent_exp_gain_3F_reduced)
        print(' cp_exp_gain_3F_reduced =', cp_exp_gain_3F_reduced)

        print('\n agent_exp_gain_3A_reduced =', agent_exp_gain_3A_reduced)
        print(' cp_exp_gain_3A_reduced =', cp_exp_gain_3A_reduced)

        print('\n agent_exp_gain_4_reduced =', agent_exp_gain_4_reduced)
        print(' cp_exp_gain_4_reduced =', cp_exp_gain_4_reduced)

    # print('\n outcome_error_std =', params.outcome_error_std)
    # pause()

    # returns from cp's pov (cp only):
    cp_cp_exp_gain_1_reduced = cp_exp_gain_1_reduced + random.normalvariate(0, params.outcome_error_std)
    cp_cp_exp_gain_2F_reduced = cp_exp_gain_2F_reduced + random.normalvariate(0, params.outcome_error_std)
    cp_cp_exp_gain_2A_reduced = cp_exp_gain_2A_reduced + random.normalvariate(0, params.outcome_error_std)
    cp_cp_exp_gain_3F_reduced = cp_exp_gain_3F_reduced + random.normalvariate(0, params.outcome_error_std)
    cp_cp_exp_gain_3A_reduced = cp_exp_gain_3A_reduced + random.normalvariate(0, params.outcome_error_std)
    cp_cp_exp_gain_4_reduced = cp_exp_gain_4_reduced + random.normalvariate(0, params.outcome_error_std)

    # returns from ag's pov (both it and the cp)
    agent_exp_gain_1_reduced += random.normalvariate(0, params.outcome_error_std)
    cp_exp_gain_1_reduced += random.normalvariate(0, params.outcome_error_std)
    agent_exp_gain_2F_reduced += random.normalvariate(0, params.outcome_error_std)
    cp_exp_gain_2F_reduced += random.normalvariate(0, params.outcome_error_std)
    agent_exp_gain_2A_reduced += random.normalvariate(0, params.outcome_error_std)
    cp_exp_gain_2A_reduced += random.normalvariate(0, params.outcome_error_std)
    agent_exp_gain_3F_reduced += random.normalvariate(0, params.outcome_error_std)
    cp_exp_gain_3F_reduced += random.normalvariate(0, params.outcome_error_std)
    agent_exp_gain_3A_reduced += random.normalvariate(0, params.outcome_error_std)
    cp_exp_gain_3A_reduced += random.normalvariate(0, params.outcome_error_std)
    agent_exp_gain_4_reduced += random.normalvariate(0, params.outcome_error_std)
    cp_exp_gain_4_reduced += random.normalvariate(0, params.outcome_error_std)

    if print_fine_dets:

        print('\n\n data after errors added')

        print('\n agent_exp_gain_1_reduced =', agent_exp_gain_1_reduced)
        print(' cp_exp_gain_1_reduced =', cp_exp_gain_1_reduced)

        print('\n agent_exp_gain_2F_reduced =', agent_exp_gain_2F_reduced)
        print(' cp_exp_gain_2F_reduced =', cp_exp_gain_2F_reduced)

        print('\n agent_exp_gain_2A_reduced =', agent_exp_gain_2A_reduced)
        print(' cp_exp_gain_2A_reduced =', cp_exp_gain_2A_reduced)

        print('\n agent_exp_gain_3F_reduced =', agent_exp_gain_3F_reduced)
        print(' cp_exp_gain_3F_reduced =', cp_exp_gain_3F_reduced)

        print('\n agent_exp_gain_3A_reduced =', agent_exp_gain_3A_reduced)
        print(' cp_exp_gain_3A_reduced =', cp_exp_gain_3A_reduced)

        print('\n agent_exp_gain_4_reduced =', agent_exp_gain_4_reduced)
        print(' cp_exp_gain_4_reduced =', cp_exp_gain_4_reduced)

    # Find probabilities - note if we use neural networks, we must find agent's propensities from the NNs (we already have the cp's)
    if params.use_NNs:

        if print_fine_dets or print_for_tracking:

            print('\n agent probs:')

        NN_input_matrix = np.array([[agent_exp_gain_1_reduced, cp_exp_gain_1_reduced, agent_exp_gain_2F_reduced, cp_exp_gain_2F_reduced, agent_exp_gain_2A_reduced, cp_exp_gain_2A_reduced,\
                           agent_exp_gain_3F_reduced, cp_exp_gain_3F_reduced, agent_exp_gain_3A_reduced, cp_exp_gain_3A_reduced, agent_exp_gain_4_reduced, cp_exp_gain_4_reduced, \
                           cp_agent_prop_steal, cp_agent_prop_fight_back]]).T

        if print_fine_dets or print_for_tracking:

            print('\n cp_agent_prop_steal =', cp_agent_prop_steal)
            print('\n cp_agent_prop_fight_back =', cp_agent_prop_fight_back)

            # print('\n NN_input_matrix', NN_input_matrix)

        if params.num_NNs == 1:

            agent.intn_probs, agent.caches = L_model_forward(NN_input_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

            # print('\n agent.intn_probs', agent.intn_probs)

            agent_prop_steal = agent.intn_probs[0][0]
            agent_prop_fight_back = agent.intn_probs[1][0]

        elif params.num_NNs == 2:

            if params.NN_inputs == 'game_6':

                agent.intn_probs_ps, agent.caches_ps = L_model_forward(NN_input_matrix, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                agent_prop_steal = agent.intn_probs_ps[0][0]

                agent.intn_probs_pfb, agent.caches_pfb = L_model_forward(NN_input_matrix, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                agent_prop_fight_back = agent.intn_probs_pfb[0][0]

            elif params.NN_inputs == 'mixed':

                # we have to work out pfb first
                ag_pfb_inputs = np.array(NN_input_matrix[2:6])

                if print_fine_dets:
                    print('\n NN_input_matrix \n', NN_input_matrix)
                    print('\n ag_pfb_inputs \n', ag_pfb_inputs)
                    print('\n cp_agent_prop_fight_back =', cp_agent_prop_fight_back)

                agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_pfb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                agent_prop_fight_back = agent.intn_prob_pfb[0][0]

                if print_fine_dets:
                    print('\n agent_prop_fight_back =', agent_prop_fight_back)

                ag_ps_inputs = np.zeros(shape=(10, 1))

                ag_ps_inputs[0:2] = NN_input_matrix[0:2]
                ag_ps_inputs[2] = (NN_input_matrix[2] * agent_prop_fight_back) + (NN_input_matrix[4] * (1 - agent_prop_fight_back))
                ag_ps_inputs[3] = (NN_input_matrix[3] * agent_prop_fight_back) + (NN_input_matrix[5] * (1 - agent_prop_fight_back))
                ag_ps_inputs[4] = (NN_input_matrix[6] * cp_agent_prop_fight_back) + (NN_input_matrix[8] * (1 - cp_agent_prop_fight_back))
                ag_ps_inputs[5] = (NN_input_matrix[7] * cp_agent_prop_fight_back) + (NN_input_matrix[9] * (1 - cp_agent_prop_fight_back))
                ag_ps_inputs[6:] = NN_input_matrix[10:]

                agent.intn_probs_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                agent_prop_steal = agent.intn_probs_ps[0][0]

                if print_fine_dets:
                    print('\n agent.intn_prob_pfb \n', agent.intn_prob_pfb)
                    print('\n ag_ps_inputs = \n', ag_ps_inputs)
                    print('\n agent_prop_steal =', agent_prop_steal)

                # pause()

        if print_fine_dets or print_for_tracking:

            # print('\n agent.prop_steal', agent.prop_steal)
            # print('\n agent.prop_fight_back', agent.prop_fight_back)
            # print('\n cp_agent_prop_fight_back ', cp_agent_prop_fight_back)
            print('\n stranger_int ', stranger_int, 'strat_choice', strat_choice, 'strangers_if_unknown', strangers_if_unknown, 'agent.agent_knows_cp_dict[str(pot_cp)]', agent.agent_knows_cp_dict[str(pot_cp)], 'pot_cp.agent_knows_cp_dict[str(agent)]', pot_cp.agent_knows_cp_dict[str(agent)])

    else:

        # if the props are below 0 or above 1, we limit their values to between 0 and 1
        agent_prop_steal = np.min([np.max([agent.prop_steal, 0.0]), 1.0])
        agent_prop_fight_back = np.min([np.max([agent.prop_fight_back, 0.0]), 1.0])

    prob_quad_1 = (1 - agent_prop_steal) * (1 - cp_agent_prop_steal)
    prob_quad_2F = (1 - agent_prop_steal) * agent_prop_fight_back * cp_agent_prop_steal
    prob_quad_2A = (1 - agent_prop_steal) * (1 - agent_prop_fight_back) * cp_agent_prop_steal
    prob_quad_3F = agent_prop_steal * (1 - cp_agent_prop_steal) * cp_agent_prop_fight_back
    prob_quad_3A = agent_prop_steal * (1 - cp_agent_prop_steal) * (1 - cp_agent_prop_fight_back)
    prob_quad_4 = agent_prop_steal * cp_agent_prop_steal

    # now combine all all prob weighted gains / losses
    agent_total_exp_gain = (prob_quad_1 * agent_exp_gain_1_reduced) + (prob_quad_2F * agent_exp_gain_2F_reduced) + (prob_quad_2A * agent_exp_gain_2A_reduced) +\
                           (prob_quad_3F * agent_exp_gain_3F_reduced) + (prob_quad_3A * agent_exp_gain_3A_reduced) + (prob_quad_4 * agent_exp_gain_4_reduced)

    # Note this is the cp's expected gain but FROM THE AGENT'S POINT OF VIEW, e.g., it uses the agent's expected prop fb and steal
    pot_cp_total_exp_gain = (prob_quad_1 * cp_exp_gain_1_reduced) + (prob_quad_2F * cp_exp_gain_2F_reduced) + (prob_quad_2A * cp_exp_gain_2A_reduced) +\
                            (prob_quad_3F * cp_exp_gain_3F_reduced) + (prob_quad_3A * cp_exp_gain_3A_reduced) + (prob_quad_4 * cp_exp_gain_4_reduced)

    # we also need to create the cp's expected return from its own perspective:
    # start with cp's expectation of agent's props:
    cp_exp_ag_ps, cp_exp_ag_pfb, num_ints = find_cp_props(params, pot_cp, agent, day, params.len_reputations_mem, print_fine_dets=0)

    # then we find the probs of quadrants
    prob_quad_1_cp = (1 - cp_exp_ag_ps) * (1 - pot_cp.prop_steal)
    prob_quad_2F_cp = (1 - cp_exp_ag_ps) * cp_exp_ag_pfb * pot_cp.prop_steal
    prob_quad_2A_cp = (1 - cp_exp_ag_ps) * (1 - cp_exp_ag_pfb) * pot_cp.prop_steal
    prob_quad_3F_cp = cp_exp_ag_ps * (1 - pot_cp.prop_steal) * pot_cp.prop_fight_back
    prob_quad_3A_cp = cp_exp_ag_ps * (1 - pot_cp.prop_steal) * (1 - pot_cp.prop_fight_back)
    prob_quad_4_cp = cp_exp_ag_ps * pot_cp.prop_steal

    cp_exp_cp_exp_gain = (prob_quad_1_cp * cp_cp_exp_gain_1_reduced) + (prob_quad_2F_cp * cp_cp_exp_gain_2F_reduced) + (prob_quad_2A_cp * cp_cp_exp_gain_2A_reduced) +\
                         (prob_quad_3F_cp * cp_cp_exp_gain_3F_reduced) + (prob_quad_3A_cp * cp_cp_exp_gain_3A_reduced) + (prob_quad_4_cp * cp_cp_exp_gain_4_reduced)

    # print('\n agent_total_exp_gain =', agent_total_exp_gain)
    # print('\n agent.prop_steal =', agent.prop_steal, 'vs cp_exp_ag_ps =', cp_exp_ag_ps)
    # print(' agent.prop_fight_back =', agent.prop_fight_back, 'vs cp_exp_ag_pfb =', cp_exp_ag_pfb)
    # print('\n pot_cp_total_exp_gain =', pot_cp_total_exp_gain)
    # print(' cp_exp_cp_exp_gain =', cp_exp_cp_exp_gain)
    # pause()

    # we create an array which records the 6 expected returns for 2 agents (order: 1 (trading), 2F, 2A, 3F, 3A, 4 (fight))
    exp_rtns_matrix = [[agent_exp_gain_1_reduced, cp_exp_gain_1_reduced], [agent_exp_gain_2F_reduced, cp_exp_gain_2F_reduced], [agent_exp_gain_2A_reduced, cp_exp_gain_2A_reduced],
                       [agent_exp_gain_3F_reduced, cp_exp_gain_3F_reduced], [agent_exp_gain_3A_reduced, cp_exp_gain_3A_reduced], [agent_exp_gain_4_reduced, cp_exp_gain_4_reduced]]

    # now create the 4-pyaoff matrix
    payoffs_4_scenarios = [[agent_exp_gain_1_reduced, cp_exp_gain_1_reduced], [] ,[], [agent_exp_gain_4_reduced, cp_exp_gain_4_reduced]]

    # if stranger_int == 'fb' and (strat_choice == 'rational' or (strangers_if_unknown and (agent.agent_knows_cp_dict[str(pot_cp)] == 0 or pot_cp.agent_knows_cp_dict[str(agent)] == 0))):
    #
    #     payoffs_4_scenarios[1] = [agent_exp_gain_2F_reduced, cp_exp_gain_2F_reduced]
    #
    #     payoffs_4_scenarios[2] = [agent_exp_gain_2F_reduced, cp_exp_gain_3F_reduced]
    #
    # elif stranger_int == 'acq' and (strat_choice == 'rational' or (strangers_if_unknown and (agent.agent_knows_cp_dict[str(pot_cp)] == 0 or pot_cp.agent_knows_cp_dict[str(agent)] == 0))):
    #
    #     payoffs_4_scenarios[1] = [agent_exp_gain_2A_reduced, cp_exp_gain_2A_reduced]
    #
    #     payoffs_4_scenarios[2] = [agent_exp_gain_3F_reduced, cp_exp_gain_3F_reduced]
    #
    # else:

    # these 2 elements of the array find a weighted average return given the agent's and cp's propensities to fight back
    payoffs_4_scenarios[1] = [(agent_exp_gain_2F_reduced * agent_prop_fight_back) + agent_exp_gain_2A_reduced * (1 - agent_prop_fight_back), \
                              (cp_exp_gain_2F_reduced * agent_prop_fight_back) + cp_exp_gain_2A_reduced * (1 - agent_prop_fight_back)]

    payoffs_4_scenarios[2] = [(agent_exp_gain_3F_reduced * cp_agent_prop_fight_back) + agent_exp_gain_3A_reduced * (1 - cp_agent_prop_fight_back), \
                              (cp_exp_gain_3F_reduced * cp_agent_prop_fight_back) + cp_exp_gain_3A_reduced * (1 - cp_agent_prop_fight_back)]

    if print_fine_dets or print_for_tracking:
        print('\n agent_total_exp_gain ', agent_total_exp_gain, 'pot_cp_total_exp_gain', pot_cp_total_exp_gain)

        print('\n exp_rtns_matrix', exp_rtns_matrix)

        print('\n payoffs_4_scenarios\n\n [', payoffs_4_scenarios[0], payoffs_4_scenarios[1])
        print('  ', payoffs_4_scenarios[2], payoffs_4_scenarios[3], ']')

    # now we derive the game bit strings
    if params.track_game_types:

        # generate simple des_string
        des_string = find_des_string(payoffs_4_scenarios, print_fine_dets)
        des_string += ' propensities'

        classic_game = check_vs_classic_games(payoffs_4_scenarios)

        if classic_game != 'Other':

            des_string += ' %s' % classic_game

        if print_fine_dets:
            print('\n FINAL des_string =', des_string)

        exp_rtns_matrix.append(des_string)
        exp_rtns_matrix.append(classic_game)

        # we also want to track the game as if it were using RCT
        payoffs_4_scenarios_RCT = [[agent_exp_gain_1_reduced, cp_exp_gain_1_reduced], [], [], [agent_exp_gain_4_reduced, cp_exp_gain_4_reduced]]

        # now find Quad 2 and 3 returns based on the best exp outcome for the agents
        # for Q2 it's the best outcome for 'agent'
        if agent_exp_gain_2A_reduced > agent_exp_gain_2F_reduced:
            agent_exp_gain_2_reduced = copy.copy(agent_exp_gain_2A_reduced)
            cp_exp_gain_2_reduced = copy.copy(cp_exp_gain_2A_reduced)
        elif agent_exp_gain_2A_reduced < agent_exp_gain_2F_reduced:
            agent_exp_gain_2_reduced = copy.copy(agent_exp_gain_2F_reduced)
            cp_exp_gain_2_reduced = copy.copy(cp_exp_gain_2F_reduced)
        else:
            agent_exp_gain_2_reduced = random.choice([agent_exp_gain_2A_reduced, agent_exp_gain_2F_reduced])
            cp_exp_gain_2_reduced = random.choice([cp_exp_gain_2A_reduced, cp_exp_gain_2F_reduced])

        # for Q3 it's the best outcome for the cp
        if cp_exp_gain_3A_reduced > cp_exp_gain_3F_reduced:
            cp_exp_gain_3_reduced = copy.copy(cp_exp_gain_3A_reduced)
            agent_exp_gain_3_reduced = copy.copy(agent_exp_gain_3A_reduced)
        elif cp_exp_gain_3A_reduced < cp_exp_gain_3F_reduced:
            cp_exp_gain_3_reduced = copy.copy(cp_exp_gain_3F_reduced)
            agent_exp_gain_3_reduced = copy.copy(agent_exp_gain_3F_reduced)
        else:
            cp_exp_gain_3_reduced = random.choice([cp_exp_gain_3A_reduced, cp_exp_gain_3F_reduced])
            agent_exp_gain_3_reduced = random.choice([agent_exp_gain_3A_reduced, agent_exp_gain_3F_reduced])

        payoffs_4_scenarios_RCT[1] = [agent_exp_gain_2_reduced, cp_exp_gain_2_reduced]
        payoffs_4_scenarios_RCT[2] = [agent_exp_gain_3_reduced, cp_exp_gain_3_reduced]

        des_string_RCT = find_des_string(payoffs_4_scenarios_RCT, print_fine_dets)
        des_string_RCT += ' RCT'
        classic_game_RCT = check_vs_classic_games(payoffs_4_scenarios_RCT)

        if classic_game_RCT != 'Other':

            des_string_RCT += ' %s' % classic_game_RCT

        exp_rtns_matrix.append(des_string_RCT)
        exp_rtns_matrix.append(classic_game_RCT)
        exp_rtns_matrix.append(payoffs_4_scenarios)
        exp_rtns_matrix.append(payoffs_4_scenarios_RCT)

        if print_fine_dets:
            print('\n payoffs_4_scenarios_RCT:', payoffs_4_scenarios_RCT)
            print(' FINAL des_string_RCT =', des_string_RCT)
            print(' classic_game_RCT =', classic_game_RCT)

    # some code checking:
    if params.run_code_tests and (agent_basket_array[0][0] > 0.0 and agent_basket_array[0][1] > 0.0 and agent_exp_gain_2A_reduced == 0.0 and cp_exp_gain_2A_reduced == 0.0) or \
            (cp_agent_basket_array[0][0] > 0.0 and cp_agent_basket_array[0][1] > 0.0 and agent_exp_gain_3A_reduced == 0.0 and cp_exp_gain_3A_reduced == 0.0):

        print('\n Euston we have a problem in form_exps_rtns_props...')
        print('\n exp_rtns_matrix =', exp_rtns_matrix)
        print('\n agent_lowest_res =', agent_lowest_res)
        print(' tot_trans_ag_buy', tot_trans_ag_buy)
        print(' agent_MRS_array[agent_lowest_res][agent_buys]', agent_MRS_array[agent_lowest_res][agent_buys])
        print(' tot_trans_ag_sell', tot_trans_ag_sell)
        print(' agent_MRS_array[agent_lowest_res][agent_sells]', agent_MRS_array[agent_lowest_res][agent_sells])
        print(' agent_trade_gain', agent_trade_gain)
        print('\n cp_agent_lowest_res =', cp_agent_lowest_res)
        print(' tot_trans_ag_sell', tot_trans_ag_sell)
        print(' cp_agent_MRS_array[cp_agent_lowest_res][agent_sells]', pot_cp.MRS_array[cp_agent_lowest_res][agent_sells])
        print(' tot_trans_ag_buy', tot_trans_ag_buy)
        print(' cp_agent_MRS_array[pcp_agent_lowest_res][agent_buys]', pot_cp.MRS_array[cp_agent_lowest_res][agent_buys])
        print(' pot_cp_trade_gain', pot_cp_trade_gain)

        print('\n gain_agent_low_res_6', gain_agent_low_res_6)
        print(' gain_agent_low_res_6_prob_weighted', gain_agent_low_res_6_prob_weighted)
        print('\n gain_pot_cp_low_res_6', gain_pot_cp_low_res_6)
        print(' gain_pot_cp_low_res_6_prob_weighted', gain_pot_cp_low_res_6_prob_weighted)
        print('\n\n check all probs of scenarios: total =', prob_scen_1 + prob_scen_2 + prob_scen_3 + prob_scen_4 + prob_scen_5 + prob_scen_6)

        pause()

    if params.run_code_tests and (agent_trade_gain < 0.0 or pot_cp_trade_gain < 0.0):
        
        print('\n Euston we have that problem again: agent_trade_gain < 0.0 or pot_cp_trade_gain < 0.0 see end of form_exps_rtns_props fct')
        
        print(' agent_trade_gain =', agent_trade_gain, 'pot_cp_trade_gain =', pot_cp_trade_gain)

    if print_for_tracking or print_fine_dets:
        print('\n ending form_exp_rtns_props')

    # if print_fine_dets:
    #     pause()

    return agent_total_exp_gain, pot_cp_total_exp_gain, exp_rtns_matrix, cp_exp_cp_exp_gain


def find_des_string(payoffs_4_scenarios, print_fine_dets):

    """This function finds and returns the string which describes the payoffs of a 2 x 2 game"""

    a = payoffs_4_scenarios[0][0]
    b = payoffs_4_scenarios[0][1]
    c = payoffs_4_scenarios[1][0]
    d = payoffs_4_scenarios[1][1]
    e = payoffs_4_scenarios[2][0]
    f = payoffs_4_scenarios[2][1]
    g = payoffs_4_scenarios[3][0]
    h = payoffs_4_scenarios[3][1]

    es_dict = dict()

    es_dict['a'] = a
    es_dict['c'] = c
    es_dict['e'] = e
    es_dict['g'] = g

    # for testing:
    # es_dict['a'] = 1.0
    # es_dict['c'] = 1.0
    # es_dict['e'] = 2.0
    # es_dict['g'] = 1.0

    sorted_str = ''
    sorted_array = []

    if print_fine_dets:
        print('\n es_dict.items()', es_dict.items())
        print('\n sorted(es_dict.items(), key=lambda item: (item[1], item[0])):', sorted(es_dict.items(), key=lambda item: (item[1], item[0])))

    # note that this sorted function sorts according to return first and then by alphabetical order if return the same
    for key, value in sorted(es_dict.items(), key=lambda item: (item[1], item[0])):
        sorted_str += key
        sorted_array.append(value)

    des_string = sorted_str[0]

    oops = 0

    if print_fine_dets:
        print('\n sorted_str', sorted_str)
        print(' sorted_array', sorted_array)

    for iter_num in range(len(sorted_array) - 1):

        if sorted_array[iter_num] < sorted_array[iter_num + 1]:
            des_string += ' < '

        elif sorted_array[iter_num] == sorted_array[iter_num + 1]:
            des_string += ' = '

        elif sorted_array[iter_num] > sorted_array[iter_num + 1]:
            des_string += ' > '

            oops = 1

        des_string += sorted_str[iter_num + 1]

    des_string += '  |  '

    es_dict = dict()

    es_dict['b'] = b
    es_dict['d'] = d
    es_dict['f'] = f
    es_dict['h'] = h

    sorted_str = ''
    sorted_array = []

    for key, value in sorted(es_dict.items(), key=lambda item: (item[1], item[0])):
        sorted_str += key
        sorted_array.append(value)

    des_string += sorted_str[0]

    if print_fine_dets:
        print('\n sorted_str', sorted_str)
        print(' sorted_array', sorted_array)

    for iter_num in range(len(sorted_array) - 1):

        if sorted_array[iter_num] < sorted_array[iter_num + 1]:
            des_string += ' < '

        elif sorted_array[iter_num] == sorted_array[iter_num + 1]:
            des_string += ' = '

        elif sorted_array[iter_num] > sorted_array[iter_num + 1]:
            des_string += ' > '

            oops = 1

        des_string += sorted_str[iter_num + 1]

    if print_fine_dets:
        print('\n des_string', des_string)

    if oops != 0:
        print('\n sorted_array =', sorted_array)
        print(' des_string ', des_string)
        pause()

    # probs with accuracy issues:
    if des_string == 'a < c < g < e  |  f = h < d < b':

        des_string = 'a < c < g = e  |  f = h < d < b'

    if des_string == 'c = e = g < a  |  b < f = h < d':

        des_string = 'c = e = g < a  |  b < d = f = h'

    if des_string == 'a < c < e = g  |  d = f = h < b':

        des_string = 'a < c = e = g  |  d = f = g < b'

    if des_string == 'a = g < e < a  |  b < f < h < d':

        des_string = 'a = g < e < a  |  b < f < d = h'

    return des_string


def find_cp_props(params, agent, cp, day, len_reputations_mem, print_fine_dets):

    """This function finds and returns an agent' expected prop_steal and prop_fight_back for a cp.  The default return values are None but the function
    returns real positive values if the denominator is not zero, i.e., if they could have stolen at any time or if they could have fought back."""

    # if cp not in agent.reputations_dict then we assume props of 0.5.
    # if cp is in agent.reputations_dict then...
    # there are 2 situations: 1) the agent's information about the cp is up-to-date (so we access agent.latest_cps_dict); and 2) the agent's information is
    # not up to date.  For the second scenario, we need to test the agent.reputations_dict: if there is recent data (within memory) then we use this; else,
    # we use the last known reputations data.  If all of this fails, we assume the prop data both = 0.5.

    # if day > 9:
    #     print_fine_dets = 1

    if print_fine_dets:
        print('\n ** Starting find_cp_props')

    pot_cp_prop_steal = params.assumed_props
    pot_cp_prop_fight_back = params.assumed_props

    num_interactions = 0

    if print_fine_dets:
        print('\n str(cp) in agent.reputations_dict', str(cp) in agent.reputations_dict)

    if str(cp) in agent.reputations_dict:

        if print_fine_dets and str(cp) in agent.need_to_update_reps:
            print('\n agent.need_to_update_reps[str(cp)]', agent.need_to_update_reps[str(cp)])

        if str(cp) in agent.need_to_update_reps and agent.need_to_update_reps[str(cp)] == 0:

            pot_cp_prop_steal = agent.latest_cps_dict[str(cp)][0]
            pot_cp_prop_fight_back = agent.latest_cps_dict[str(cp)][1]

            if print_fine_dets:
                print('n agent.latest_cps_dict[str(cp)]', agent.latest_cps_dict[str(cp)])

        else:

            if print_fine_dets:
                print('\n doing it long hand...')

            # for the dict look-ups below, find the day memory starts (this will be included)
            mem_start_day = np.max([0, day - len_reputations_mem])

            # this array counts the number of fights pot_cp tried to start
            num_fights_array = agent.reputations_dict[str(cp)][0]

            # this array counts the number of interactions the agent has been in
            num_interactions_array = agent.reputations_dict[str(cp)][1]

            # this arrar contains the number of times the agent fought back
            num_fight_backs_array = agent.reputations_dict[str(cp)][2]

            # this array counts the number of times the pot_cp could have fought back
            num_fight_back_interactions_array = agent.reputations_dict[str(cp)][3]

            # we want to count the number of fights the pot_cp tried to start over the memory length of the agent len_reputations_mem
            # note that we have to include any data we might have from today's interactions
            num_times_fought_slice = num_fights_array[mem_start_day:day]

            if len_reputations_mem > 0:
                num_times_fought_slice = np.append(num_times_fought_slice, num_fights_array[day])

            num_times_pot_cp_fought = np.sum(num_times_fought_slice)

            # now the number of times the agent could have fought:
            num_interactions_slice = num_interactions_array[mem_start_day:day]

            if len_reputations_mem > 0:
                num_interactions_slice = np.append(num_interactions_slice, num_interactions_array[day])

            num_interactions = np.sum(num_interactions_slice)

            if print_fine_dets == 1:
                print('\n num_times_pot_cp_fought =', num_times_pot_cp_fought)
                print(' num_interactions', num_interactions)

            if num_interactions > 0:

                pot_cp_prop_steal = num_times_pot_cp_fought / float(num_interactions)

            # Looking at fighting back:
            # we need to evaluate whether there were any times the pot_cp could have fought back over the length of memory and then use this in a condition
            num_fight_back_interactions_slice = num_fight_back_interactions_array[mem_start_day:day]

            if len_reputations_mem > 0:
                num_fight_back_interactions_slice = np.append(num_fight_back_interactions_slice, num_fight_back_interactions_array[day])

            num_fight_back_interactions = np.sum(num_fight_back_interactions_slice)

            # we want to count the number of times the pot_cp actually fought back
            num_times_pot_cp_fought_back_slice = num_fight_backs_array[mem_start_day:day]

            if len_reputations_mem > 0:
                num_times_pot_cp_fought_back_slice = np.append(num_times_pot_cp_fought_back_slice, num_fight_backs_array[day])

            num_times_pot_cp_fought_back = np.sum(num_times_pot_cp_fought_back_slice)

            if print_fine_dets == 1:
                print('\n num_times_pot_cp_fought_back =', num_times_pot_cp_fought_back)
                print(' num_fight_back_interactions', num_fight_back_interactions)

            if num_fight_back_interactions > 0:   # i.e. we have reputational information about pot_cp fighting back

                pot_cp_prop_fight_back = num_times_pot_cp_fought_back / float(num_fight_back_interactions)

            # if pot_cp_prop_steal is None (either because cp not known to agent or because nothing in memory) then we revert to the agent's last known reputation.
            # The same it true of p_fb

            if pot_cp_prop_steal is None and str(cp) in agent.last_known_rep_ps_dict:
                pot_cp_prop_steal = copy.copy(agent.last_known_rep_ps_dict[str(cp)])

            elif pot_cp_prop_steal is not None:
                agent.last_known_rep_ps_dict[str(cp)] = pot_cp_prop_steal

            if pot_cp_prop_fight_back is None and str(cp) in agent.last_known_rep_pfb_dict:
                pot_cp_prop_fight_back = copy.copy(agent.last_known_rep_pfb_dict[str(cp)])

            elif pot_cp_prop_fight_back is not None:
                agent.last_known_rep_pfb_dict[str(cp)] = pot_cp_prop_fight_back

    # bound the props
    pot_cp_prop_steal = np.min([np.max([pot_cp_prop_steal, 0.0]), 1.0])
    pot_cp_prop_fight_back = np.min([np.max([pot_cp_prop_fight_back, 0.0]), 1.0])

    if print_fine_dets:
        print('\n pot_cp_prop_steal =', pot_cp_prop_steal)
        print('\n ** Ending find_cp_props \n')
        # pause()

    return pot_cp_prop_steal, pot_cp_prop_fight_back, num_interactions


def strangers_interact(params, min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, agent_population, fountain_population, print_dets, print_fine_dets, use_start_basket, agent, cp_agent,
                       stranger_int, formal_inst, prob_fine, fine, two_tribes_inst, fight_cost, cp_dec=0):

    """This function organises the interaction of two strangers.  It generates all of the return information for each of the 6 interaction scenarios and also the strategic decisions of the agents.  The method
    also generates a strong to describe the game (assuming 4 quadrants)."""

    print_fine_dets = 0

    # if str(cp_agent) in agent.exp_int_gains_dict_strangers:
    #     print_fine_dets = 1

    # if use_start_basket == 0:
    #     print_fine_dets = 1

    # if agent is agent_population.tracking_agent:
    #     print_fine_dets = 1

    if print_fine_dets:
        print('\n\n\n *** Starting strangers_interact')
        print(' str(cp_agent) in agent.exp_int_gains_dict_strangers', str(cp_agent) in agent.exp_int_gains_dict_strangers)
        print(' use_start_basket', use_start_basket)

    # to save coding time we first check to see if the agents need to evaluate each other - they might have done so recently
    new_eval_requd = 1

    if str(cp_agent) in agent.exp_int_gains_dict_strangers and use_start_basket == 0 and cp_dec == 0:

        known_cp_int_data = agent.exp_int_gains_dict_strangers[str(cp_agent)]

        if print_fine_dets:
            print('\n agent.exp_int_gains_dict_strangers[str(cp_agent)]:', known_cp_int_data)
            print('\n agent.exp_rtns_matrix[str(cp_agent)]:', agent.exp_rtns_matrix[str(cp_agent)])

        # if this condition is true then neither the cp_agent nor the agent have interacted since the last time the agent evaluated the outcomes for cp_agent so we can use the previous evaluation payoffs_4_scenarios
        if known_cp_int_data[0] == cp_agent.last_intn and known_cp_int_data[1] == agent.last_intn:

            ag_gain, cp_gain, cp_exp_cp_gain = known_cp_int_data[2]

            des_string = known_cp_int_data[3]
            classic_game_type = known_cp_int_data[4]

            agent_dom_strat = known_cp_int_data[5]
            cp_dom_strat = known_cp_int_data[6]

            des_string_RCT = known_cp_int_data[7]
            classic_game_type_RCT = known_cp_int_data[8]

            new_eval_requd = 0

            if print_fine_dets:

                print('\n Using Old Evaluation: agent.exp_int_gains_dict_strangers[str(cp_agent)] =', agent.exp_int_gains_dict_strangers[str(cp_agent)])
                print(' new_eval_requd =', new_eval_requd)
                print('\n cp_agent.last_intn', cp_agent.last_intn)
                print(' agent.last_intn', agent.last_intn)

    if new_eval_requd == 1:

        if print_fine_dets:
            print('\n New evaluation required:')

        # if we are simulating an interaction (say, at the end of a round), we use the start basket; otherwise if we're in the trading phase we use the agent's actual basket
        if use_start_basket == 0:
    
            start_agent_tot_ress = agent.agent_res_array[0] + agent.basket_array[0]
            start_cp_agent_tot_ress = cp_agent.agent_res_array[0] + cp_agent.basket_array[0]
    
            agent_basket_used = agent.basket_array
            cp_agent_basket_used = cp_agent.basket_array
    
        elif use_start_basket == 1:
            
            start_agent_tot_ress = agent.agent_res_array[0] + agent.basket_array_start[0]
            start_cp_agent_tot_ress = cp_agent.agent_res_array[0] + cp_agent.basket_array_start[0]
    
            agent_basket_used = agent.basket_array_start
            cp_agent_basket_used = cp_agent.basket_array_start
    
        agent.MRS_array = generate_MRS_array(agent.agent_res_array + agent_basket_used, print_fine_dets=0)
        cp_agent.MRS_array = generate_MRS_array(cp_agent.agent_res_array + cp_agent_basket_used, print_fine_dets=0)
    
        agent_min_res_value = np.min(start_agent_tot_ress)
        cp_agent_min_res_value = np.min(start_cp_agent_tot_ress)

        # find which are the agents' min res's
        agent_min_res = 0
        cp_agent_min_res = 0
            
        for res in range(num_res_founts):
    
            if start_agent_tot_ress[res] == agent_min_res_value:
    
                agent_min_res = res
    
            if start_cp_agent_tot_ress[res] == cp_agent_min_res_value:
    
                cp_agent_min_res = res
    
        if print_fine_dets:
            
            print('\n agent.agent_res_array[0] ', agent.agent_res_array[0])
            print(' agent.basket_array[0] ', agent.basket_array[0])
            print(' agent.basket_array_start[0] ', agent.basket_array_start[0])        
            print(' agent_basket_used', agent_basket_used)
            print(' agent_min_res ', agent_min_res)
    
            print('\n cp_agent.agent_res_array[0] ', cp_agent.agent_res_array[0])
            print(' cp_agent.basket_array[0] ', cp_agent.basket_array[0])
            print(' cp_agent.basket_array_start[0] ', cp_agent.basket_array_start[0])        
            print(' cp_agent_basket_used', cp_agent_basket_used)
            print(' cp_agent_min_res ', cp_agent_min_res)
            
            print('\n stranger_int =', stranger_int)
            
            print('\n fight_cost =', fight_cost)

        ##### we look at 4 scenarios to derive an appreciation of outcomes for the agents in each quadrant of a game: 1 trade / trade, 2 steal / trade, 3 trade / steal, and 4 steal / steal
        ##### we start by finding the outcomes for quadrants 1 and 4 as these will be the same irrespective of stranger_int
    
        # scenario 1 is the same regardless of self.stranger_int - both trade
        # start with finding whether and how much both would trade, and the price

        if (use_start_basket and ((agent.basket_array_start[0][0] > 0.0 and cp_agent.basket_array_start[0][1] > 0.0) or (agent.basket_array_start[0][1] > 0.0 and cp_agent.basket_array_start[0][0] > 0))) or\
            (use_start_basket == 0 and ((agent.basket_array[0][0] > 0.0 and cp_agent.basket_array[0][1] > 0.0) or (agent.basket_array[0][1] > 0.0 and cp_agent.basket_array[0][0] > 0))): # then they might trade

            tot_cons_surp_array, best_trans_data = build_tot_cons_surp_array(params, min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, print_fine_dets, use_start_basket,
                                                                             agent.agent_res_array, agent.basket_array, agent.basket_array_start, cp_agent.agent_res_array, cp_agent.basket_array, cp_agent.basket_array_start)

        else: # then they won't trade
            
            tot_cons_surp_array, best_trans_data = ([[0.0, 0.0], [0.0, 0.0]], [0.0, 0.0, 0.0, 0.0, 0.0])

        # find the maximum change in consumer surplus
        max_cons_surp_ch = np.max(tot_cons_surp_array)
    
        if print_fine_dets == 1:
            print('\n tot_cons_surp_array:\n', tot_cons_surp_array)
            print('\n max_cons_surp_ch', max_cons_surp_ch)
            print('\n best_trans_data =', best_trans_data)
    
        # We only carry on if max_cons_surp_ch is positive.  It can't be negative but all cells might be zero in which
        # case there's no advantage to both agents in transacting
        if max_cons_surp_ch > 0:
    
            agent_sells, agent_buys, tot_trans_ag_sell, tot_trans_ag_buy, trans_agr_MRS = best_trans_data
    
            # we find the reduced gain for the agents:
            exp_gain_agent_1 = tot_trans_ag_buy * agent.MRS_array[agent_min_res][agent_buys] - tot_trans_ag_sell * agent.MRS_array[agent_min_res][agent_sells]
            exp_cp_gain_1 = tot_trans_ag_sell * cp_agent.MRS_array[cp_agent_min_res][agent_sells] - tot_trans_ag_buy * cp_agent.MRS_array[cp_agent_min_res][agent_buys]
    
            if print_fine_dets == 1:
                print('\n exp_gain_agent_1:', exp_gain_agent_1)
                print(' exp_cp_gain_1', exp_cp_gain_1)
    
        else:
    
            exp_gain_agent_1 = 0
            exp_cp_gain_1 = 0
            
            if print_fine_dets == 1:
                print('\n they would not trade')
                print(' exp_gain_agent_1:', exp_gain_agent_1)
                print(' exp_cp_gain_1', exp_cp_gain_1)

        # now let us find the expected benfits of a fight for both agents (and expected fines)
        ag_gain_both_fight_ex_fine = 0.0
        cp_gain_both_fight_ex_fine = 0.0

        # when we are applying formal rules we also need to account for expected fines
        if formal_inst or two_tribes_inst:
            ag_exp_fine = 0.0
            cp_exp_fine = 0.0

        # when we apply compensation:
        if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
            ag_exp_comp = 0.0
            cp_exp_comp = 0.0

        # agent wins
        for res in range(num_res_founts):

            ag_gain_both_fight_ex_fine += cp_agent_basket_used[0][res] * agent.MRS_array[agent_min_res][res]
            ag_gain_both_fight_ex_fine += fight_cost * agent.MRS_array[agent_min_res][res]

            cp_gain_both_fight_ex_fine -= cp_agent_basket_used[0][res] * cp_agent.MRS_array[cp_agent_min_res][res]
            cp_gain_both_fight_ex_fine += fight_cost * cp_agent.MRS_array[cp_agent_min_res][res]

            if formal_inst or two_tribes_inst:
                ag_exp_fine += prob_fine * fine * agent.MRS_array[agent_min_res][res]

            if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
                ag_exp_comp -= prob_fine * fine * agent.MRS_array[agent_min_res][res]

        # cp wins
        for res in range(num_res_founts):

            ag_gain_both_fight_ex_fine -= agent_basket_used[0][res] * agent.MRS_array[agent_min_res][res]
            ag_gain_both_fight_ex_fine += fight_cost * agent.MRS_array[agent_min_res][res]

            cp_gain_both_fight_ex_fine += agent_basket_used[0][res] * cp_agent.MRS_array[cp_agent_min_res][res]
            cp_gain_both_fight_ex_fine += fight_cost * cp_agent.MRS_array[cp_agent_min_res][res]

            if formal_inst or two_tribes_inst:
                cp_exp_fine += prob_fine * fine * cp_agent.MRS_array[cp_agent_min_res][res]

            if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
                cp_exp_comp -= prob_fine * fine * cp_agent.MRS_array[cp_agent_min_res][res]

        if print_fine_dets:

            print('\n agent:')
            for res in range(num_res_founts):

                print('\n res', res, 'agent wins - red value benefit', cp_agent_basket_used[0][res] * agent.MRS_array[agent_min_res][res], '\tfight cost red value ', fight_cost * agent.MRS_array[agent_min_res][res])
                print(' res', res, 'cp wins - red value benefit', -1 * agent_basket_used[0][res] * agent.MRS_array[agent_min_res][res], '\tfight cost red value ', fight_cost * agent.MRS_array[agent_min_res][res])

            print('\n cp:')
            for res in range(num_res_founts):

                print('\n res', res, 'agent wins - red value benefit', -1 * cp_agent_basket_used[0][res] * cp_agent.MRS_array[cp_agent_min_res][res], '\tfight cost red value ', fight_cost * cp_agent.MRS_array[cp_agent_min_res][res])
                print(' res', res, 'cp wins - red value benefit', agent_basket_used[0][res] * cp_agent.MRS_array[cp_agent_min_res][res], '\tfight cost red value ', fight_cost * cp_agent.MRS_array[cp_agent_min_res][res])

        # divide these by 2 - each of the two scenrios (win and lose) have a 50/50 chance
        ag_gain_both_fight_ex_fine *= 0.5
        cp_gain_both_fight_ex_fine *= 0.5

        if print_fine_dets == 1:  # usefuldata for checking

            print('\n agent: expected gross gain from fighting (given 50 50) =', ag_gain_both_fight_ex_fine)
            if formal_inst or two_tribes_inst:
                print(' agent: expected fine =', ag_exp_fine)
            if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
                print(' agent: expected comp =', ag_exp_comp)

            print('\n cp: expected gross gain from fighting (given 50 50) =', cp_gain_both_fight_ex_fine)
            if formal_inst or two_tribes_inst:
                print(' cp: expected fine =', cp_exp_fine)
            if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
                print(' cp: expected comp =', cp_exp_comp)

        # we can derive the values for scenario 4 in all possible outcomes - they both try to steal.  their expected gains (losses) are determined by their expected gains less any fine
        exp_gain_agent_4 = copy.copy(ag_gain_both_fight_ex_fine)
        exp_cp_gain_4 = copy.copy(cp_gain_both_fight_ex_fine)

        if formal_inst or two_tribes_inst:
            exp_gain_agent_4 += ag_exp_fine
            exp_cp_gain_4 += cp_exp_fine

        if print_fine_dets == 1:
            print('\n\n exp_gain_agent_4', exp_gain_agent_4, '\t reality check: should be approx ', ((np.sum(cp_agent_basket_used) - np.sum(agent_basket_used)) / 2.0) + (fight_cost * 2))
            print(' exp_cp_gain_4', exp_cp_gain_4, '\t\t reality check: should be approx ', ((np.sum(agent_basket_used) - np.sum(cp_agent_basket_used)) / 2.0) + (fight_cost * 2))
            # pause()

        # ---> now we have expected returns from trading and fighting as well as exp value of fines and compensation and also: exp_gain_agent_1, exp_cp_gain_1, exp_gain_agent_4, exp_cp_gain_4

        # now we find the expected outcomes for scenarios 2 & 3 which depend on the assumption of whether the agents acquiesce or fight back in the face of attempted theft, or whether they are fully rational
        # if stranger_int == 'acq' or stranger_int == 'full':       # then if one trades and the other fights, the trader acquiesces
        #
        #     if print_fine_dets == 1:
        #         print('\n\n stranger_int == acq or stranger_int == full')

        # scenario 2 - agent wants to trade and cp_agent wants to steal.  agent acquiesces, cp_agent gets all
        exp_gain_agent_2_acq = 0.0
        exp_cp_gain_2_acq = 0.0

        for res in range(num_res_founts):

            exp_gain_agent_2_acq -= agent_basket_used[0][res] * agent.MRS_array[agent_min_res][res]
            exp_cp_gain_2_acq += agent_basket_used[0][res] * cp_agent.MRS_array[cp_agent_min_res][res]

        if print_fine_dets == 1:
            print('\n gross exp_gain_agent_2_acq:', exp_gain_agent_2_acq)
            print(' gross exp_cp_gain_2_acq', exp_cp_gain_2_acq)

        # reduce gain for cp if fined
        if formal_inst or two_tribes_inst:
            exp_cp_gain_2_acq += cp_exp_fine

            if print_fine_dets == 1:
                print('\n NET of fine exp_cp_gain_2_acq:', exp_cp_gain_2_acq)

        # we add compensation if
        if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
            exp_gain_agent_2_acq += ag_exp_comp

            if print_fine_dets == 1:
                print('\n ag compensated by ', ag_exp_comp)
                print(' exp_gain_agent_2_acq final: ', exp_gain_agent_2_acq)

        # scenario 3 - agent wants to steal and cp_agent wants to trade.  cp acquiesces, agent gets all
        exp_gain_agent_3_acq = 0.0
        exp_cp_gain_3_acq = 0.0

        for res in range(num_res_founts):

            exp_gain_agent_3_acq += cp_agent_basket_used[0][res] * agent.MRS_array[agent_min_res][res]
            exp_cp_gain_3_acq -= cp_agent_basket_used[0][res] * cp_agent.MRS_array[cp_agent_min_res][res]

        if print_fine_dets == 1:
            print('\n exp_gain_agent_3_acq:', exp_gain_agent_3_acq)
            print(' exp_cp_gain_3_acq', exp_cp_gain_3_acq)

        # the agent might get fined:
        if formal_inst or two_tribes_inst:
            exp_gain_agent_3_acq += ag_exp_fine

            if print_fine_dets == 1:
                print('\n ag_exp_fine =', ag_exp_fine)
                print(' NET of fine exp_gain_agent_3_acq:', exp_gain_agent_3_acq)

        # we add compensation to the agent if
        if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
            exp_cp_gain_3_acq += cp_exp_comp

            if print_fine_dets:
                print('\n cp compensated by ', cp_exp_comp)
                print(' exp_cp_gain_3_acq final', exp_cp_gain_3_acq)

        # pause()

        # here the assumption is that attempted theft leads to the agents fighting back
        # if stranger_int == 'fb' or stranger_int == 'full':
        #
        #     if print_fine_dets == 1:
        #         print('\n\n stranger_int == fb or stranger_int == full')

        # scenario 2 - agent fights back (no fine), cp steals (fine)
        exp_gain_agent_2_fb = copy.copy(ag_gain_both_fight_ex_fine)
        exp_cp_gain_2_fb = copy.copy(cp_gain_both_fight_ex_fine)

        if print_fine_dets == 1:
            print('\n exp_gain_agent_2_fb (gross gain no fine)', exp_gain_agent_2_fb)
            print(' exp_cp_gain_2_fb (gross gain with fine)', exp_cp_gain_2_fb)

        if formal_inst or two_tribes_inst:
            exp_cp_gain_2_fb += cp_exp_fine

            if print_fine_dets == 1:
                print('\n cp_agent fined by', cp_exp_fine, 'so exp_cp_gain_2_fb =', exp_cp_gain_2_fb)

        if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
            exp_gain_agent_2_fb += ag_exp_comp

            if print_fine_dets == 1:
                print('\n ag compensated by', ag_exp_comp, 'so exp_gain_agent_2_fb =', exp_gain_agent_2_fb)

        # scenario 3 - agent steals (exp fine), cp fights back (no fine)
        exp_gain_agent_3_fb = copy.copy(ag_gain_both_fight_ex_fine)
        exp_cp_gain_3_fb = copy.copy(cp_gain_both_fight_ex_fine)

        if print_fine_dets == 1:
            print('\n exp_gain_agent_3_fb (gross gain less fine)', exp_gain_agent_3_fb)
            print(' exp_cp_gain_3_fb (gross gain no fine)', exp_cp_gain_3_fb)

        if formal_inst or two_tribes_inst:
            exp_gain_agent_3_fb += ag_exp_fine

            if print_fine_dets == 1:
                print(' agent fined by', ag_exp_fine, 'so exp_gain_agent_3_fb =', exp_gain_agent_3_fb)

        if formal_inst == 'compensate' or two_tribes_inst == 'compensate':

            exp_cp_gain_3_fb += cp_exp_comp

            if print_fine_dets == 1:
                print(' cp compensated by', cp_exp_comp, 'so exp_cp_gain_3_fb =', exp_cp_gain_3_fb)

        # we now have values for scenarios 2 and 3 given either acq or fb or full, and the values for 1 and 4 so we can now move forward to find the agents' strategic choices

        # let's add an error term if appropriate:
        if print_fine_dets:

            print('\n\n outcomes prior to adding any error terms:')

            print('\n exp_gain_agent_1 a', exp_gain_agent_1)
            if stranger_int == 'fb' or stranger_int == 'full':
                print(' exp_gain_agent_2_fb', exp_gain_agent_2_fb)
            if stranger_int == 'acq' or stranger_int == 'full':
                print(' exp_gain_agent_2_acq', exp_gain_agent_2_acq)
            if stranger_int == 'fb' or stranger_int == 'full':
                print(' exp_gain_agent_3_fb', exp_gain_agent_3_fb)
            if stranger_int == 'acq' or stranger_int == 'full':
                print(' exp_gain_agent_3_acq', exp_gain_agent_3_acq)
            print(' exp_gain_agent_4 g', exp_gain_agent_4)

            print('\n exp_cp_gain_1 b', exp_cp_gain_1)
            if stranger_int == 'fb' or stranger_int == 'full':
                print(' exp_cp_gain_2_fb', exp_cp_gain_2_fb)
            if stranger_int == 'acq' or stranger_int == 'full':
                print(' exp_cp_gain_2_acq', exp_cp_gain_2_acq)
            if stranger_int == 'fb' or stranger_int == 'full':
                print(' exp_cp_gain_3_fb', exp_cp_gain_3_fb)
            if stranger_int == 'acq' or stranger_int == 'full':
                print(' exp_cp_gain_3_acq', exp_cp_gain_3_acq)
            print(' exp_cp_gain_4 h', exp_cp_gain_4)

        if params.outcome_error_std:        # i.e. only do this if this term is not zero

            exp_gain_agent_1 += random.normalvariate(0, params.outcome_error_std)
            exp_cp_gain_1 += random.normalvariate(0, params.outcome_error_std)
            if stranger_int == 'fb' or stranger_int == 'full':
                exp_gain_agent_2_fb += random.normalvariate(0, params.outcome_error_std)
                exp_cp_gain_2_fb += random.normalvariate(0, params.outcome_error_std)
            if stranger_int == 'acq' or stranger_int == 'full':
                exp_gain_agent_2_acq += random.normalvariate(0, params.outcome_error_std)
                exp_cp_gain_2_acq += random.normalvariate(0, params.outcome_error_std)
            if stranger_int == 'fb' or stranger_int == 'full':
                exp_gain_agent_3_fb += random.normalvariate(0, params.outcome_error_std)
                exp_cp_gain_3_fb += random.normalvariate(0, params.outcome_error_std)
            if stranger_int == 'acq' or stranger_int == 'full':
                exp_gain_agent_3_acq += random.normalvariate(0, params.outcome_error_std)
                exp_cp_gain_3_acq += random.normalvariate(0, params.outcome_error_std)
            exp_gain_agent_4 += random.normalvariate(0, params.outcome_error_std)
            exp_cp_gain_4 += random.normalvariate(0, params.outcome_error_std)

        # after error term:
        if print_fine_dets:

            print('\n\n outcomes AFTER to adding any error terms:')

            print('\n exp_gain_agent_1 a', exp_gain_agent_1)
            if stranger_int == 'fb' or stranger_int == 'full':
                print(' exp_gain_agent_2_fb', exp_gain_agent_2_fb)
            if stranger_int == 'acq' or stranger_int == 'full':
                print(' exp_gain_agent_2_acq', exp_gain_agent_2_acq)
            if stranger_int == 'fb' or stranger_int == 'full':
                print(' exp_gain_agent_3_fb', exp_gain_agent_3_fb)
            if stranger_int == 'acq' or stranger_int == 'full':
                print(' exp_gain_agent_3_acq', exp_gain_agent_3_acq)
            print(' exp_gain_agent_4 g', exp_gain_agent_4)

            print('\n exp_cp_gain_1 b', exp_cp_gain_1)
            if stranger_int == 'fb' or stranger_int == 'full':
                print(' exp_cp_gain_2_fb', exp_cp_gain_2_fb)
            if stranger_int == 'acq' or stranger_int == 'full':
                print(' exp_cp_gain_2_acq', exp_cp_gain_2_acq)
            if stranger_int == 'fb' or stranger_int == 'full':
                print(' exp_cp_gain_3_fb', exp_cp_gain_3_fb)
            if stranger_int == 'acq' or stranger_int == 'full':
                print(' exp_cp_gain_3_acq', exp_cp_gain_3_acq)
            print(' exp_cp_gain_4 h', exp_cp_gain_4)

        # now determine exp_gain_agent_2, exp_cp_gain_2, exp_gain_agent_3, exp_cp_gain_3
        if stranger_int == 'acq':

            exp_gain_agent_2 = copy.copy(exp_gain_agent_2_acq)
            exp_cp_gain_2 = copy.copy(exp_cp_gain_2_acq)

            exp_gain_agent_3 = copy.copy(exp_gain_agent_3_acq)
            exp_cp_gain_3 = copy.copy(exp_cp_gain_3_acq)

            ag_Q2_dec = 'acq'

        elif stranger_int == 'fb':

            exp_gain_agent_2 = copy.copy(exp_gain_agent_2_fb)
            exp_cp_gain_2 = copy.copy(exp_cp_gain_2_fb)

            exp_gain_agent_3 = copy.copy(exp_gain_agent_3_fb)
            exp_cp_gain_3 = copy.copy(exp_cp_gain_3_fb)

            ag_Q2_dec = 'fb'

        elif stranger_int == 'full' or (stranger_int == None and cp_dec == 1):

            # we have exp_gain_agent_2_fb and exp_gain_agent_2_acq so we can find exp_gain_agent_2 and exp_cp_gain_2
            if print_fine_dets:
                print('\n exp_gain_agent_2_fb =', exp_gain_agent_2_fb, 'exp_gain_agent_2_acq', exp_gain_agent_2_acq)

            if exp_gain_agent_2_fb > exp_gain_agent_2_acq:

                exp_gain_agent_2 = copy.copy(exp_gain_agent_2_fb)
                exp_cp_gain_2 = copy.copy(exp_cp_gain_2_fb)
                ag_Q2_dec = 'fb'

                if print_fine_dets:
                    print('\n agent fights back')

            elif exp_gain_agent_2_fb < exp_gain_agent_2_acq:

                exp_gain_agent_2 = copy.copy(exp_gain_agent_2_acq)
                exp_cp_gain_2 = copy.copy(exp_cp_gain_2_acq)
                ag_Q2_dec = 'acq'

                if print_fine_dets:
                    print('\n agent acquiesces')

            else:

                exp_gain_agent_2 = random.choice([exp_gain_agent_2_acq, exp_gain_agent_2_fb])
                exp_cp_gain_2 = random.choice([exp_cp_gain_2_acq, exp_cp_gain_2_fb])

                if exp_gain_agent_2 == exp_gain_agent_2_acq:
                    ag_Q2_dec = 'acq'
                else:
                    ag_Q2_dec = 'fb'

            # compare exp_cp_gain_3_fb with exp_cp_gain_3_acq:
            if print_fine_dets:
                print('\n exp_cp_gain_3_fb =', exp_cp_gain_3_fb, 'exp_cp_gain_3_acq', exp_cp_gain_3_acq)

            if exp_cp_gain_3_fb > exp_cp_gain_3_acq:

                exp_gain_agent_3 = copy.copy(exp_gain_agent_3_fb)
                exp_cp_gain_3 = copy.copy(exp_cp_gain_3_fb)
                cp_Q3_dec = 'fb'

                if print_fine_dets:
                    print('\n cp fights back')

            elif exp_cp_gain_3_fb < exp_cp_gain_3_acq:

                exp_gain_agent_3 = copy.copy(exp_gain_agent_3_acq)
                exp_cp_gain_3 = copy.copy(exp_cp_gain_3_acq)
                cp_Q3_dec = 'acq'

                if print_fine_dets:
                    print('\n cp acquiesces')

            else:

                exp_gain_agent_3 = random.choice([exp_gain_agent_3_acq, exp_gain_agent_3_fb])
                exp_cp_gain_3 = random.choice([exp_cp_gain_3_acq, exp_cp_gain_3_fb])

                if exp_cp_gain_3 == exp_cp_gain_3_acq:
                    cp_Q3_dec = 'acq'
                else:
                    cp_Q3_dec = 'fb'

        # now we can work out if the agents have dominant strategies - these will be used if the agents end up actually interacting
        agent_dom_strat = 'none'
        cp_dom_strat = 'none'
        
        matrix_4_quads = [[exp_gain_agent_1, exp_cp_gain_1], [exp_gain_agent_2, exp_cp_gain_2], [exp_gain_agent_3, exp_cp_gain_3], [exp_gain_agent_4, exp_cp_gain_4]]

        if print_fine_dets:
            print('\n matrix_4_quads:\n', matrix_4_quads[0], matrix_4_quads[1], '\n', matrix_4_quads[2], matrix_4_quads[3])

        # We have two passes - the first looks to see if the agents have dominant straties not conditional on the other ag's strategy
        # for the agent:
        if (exp_gain_agent_1 > exp_gain_agent_3 and exp_gain_agent_2 >= exp_gain_agent_4) or (exp_gain_agent_1 >= exp_gain_agent_3 and exp_gain_agent_2 > exp_gain_agent_4):
            
            agent_dom_strat = 'trade'
    
        elif (exp_gain_agent_1 < exp_gain_agent_3 and exp_gain_agent_2 <= exp_gain_agent_4) or (exp_gain_agent_1 <= exp_gain_agent_3 and exp_gain_agent_2 < exp_gain_agent_4):
        
            agent_dom_strat = 'steal'

        # for the cp_agent
        if (exp_cp_gain_1 > exp_cp_gain_2 and exp_cp_gain_3 >= exp_cp_gain_4) or (exp_cp_gain_1 >= exp_cp_gain_2 and exp_cp_gain_3 > exp_cp_gain_4):
            
            cp_dom_strat = 'trade'
    
        elif (exp_cp_gain_1 < exp_cp_gain_2 and exp_cp_gain_3 <= exp_cp_gain_4) or (exp_cp_gain_1 <= exp_cp_gain_2 and exp_cp_gain_3 < exp_cp_gain_4):
        
            cp_dom_strat = 'steal'
    
        if print_fine_dets == 1:
            
            print('\n initial strats: agent =', agent_dom_strat, 'cp =', cp_dom_strat)
    
        # second pass - if one has a dominant strategy and the other does, the other might have a dominant strategy conditional on its cp
        # if one agent has a dominant strategy and the other does not, it's likely the other will have a dominant strategy given its cp's dominant strategy
        if agent_dom_strat == 'none' and cp_dom_strat == 'trade':
            
            if exp_gain_agent_1 > exp_gain_agent_3:
                
                agent_dom_strat = 'trade'
    
            if exp_gain_agent_1 < exp_gain_agent_3:
                
                agent_dom_strat = 'steal' 
        
        if agent_dom_strat == 'none' and cp_dom_strat == 'steal':
            
            if exp_gain_agent_2 > exp_gain_agent_4:
                
                agent_dom_strat = 'trade'
    
            if exp_gain_agent_2 < exp_gain_agent_4:
                
                agent_dom_strat = 'steal' 
    
        if cp_dom_strat == 'none' and agent_dom_strat == 'trade':
            
            if exp_cp_gain_1 > exp_cp_gain_2:
                
                cp_dom_strat = 'trade'
    
            if exp_cp_gain_1 < exp_cp_gain_2:
                
                cp_dom_strat = 'steal' 
        
        if cp_dom_strat == 'none' and agent_dom_strat == 'steal':
            
            if exp_cp_gain_3 > exp_cp_gain_4:
                
                cp_dom_strat = 'trade'
    
            if exp_cp_gain_3 < exp_cp_gain_4:
                
                cp_dom_strat = 'steal' 

        if print_fine_dets == 1:

            print('\n resulting dominant strategies:')
            print('\n agent_dom_strat:', agent_dom_strat)
            print(' cp_dom_strat', cp_dom_strat)
    
    #        pause()

        # now we know the agents' strategies we can determine the gains / losses
        if agent_dom_strat == 'trade' and cp_dom_strat == 'trade':

            # here the agent has resources to trade and expects to gain from trade and an exchange is possible given resources in baskets
            if exp_gain_agent_1 > 0.0 and np.max(agent.basket_array) > 0.0 and ((agent.basket_array[0][0] > 0.0 and cp_agent.basket_array[0][1] > 0.0) or (agent.basket_array[0][1] > 0.0 and cp_agent.basket_array[0][0] > 0.0)):

                ag_gain = exp_gain_agent_1
                cp_gain = exp_cp_gain_1
            
            # if they prefer to trade but they won't as there's no benefit then they should ignore each other
            else:
                
                agent_dom_strat = 'none'
                cp_dom_strat = 'none'
            
                ag_gain = 0
                cp_gain = 0

                if print_fine_dets:
                    print('\n hold on - dominant strats are for trade but the agent believes there is no gain in trading so we set strats to none')

        elif agent_dom_strat == 'trade' and cp_dom_strat == 'steal':

            ag_gain = exp_gain_agent_2
            cp_gain = exp_cp_gain_2
    
            if stranger_int == 'fb' or (stranger_int == 'full' and ag_Q2_dec == 'fb'):

                agent_dom_strat = 'fight_back'
    
        elif agent_dom_strat == 'steal' and cp_dom_strat == 'trade':

            ag_gain = exp_gain_agent_3
            cp_gain = exp_cp_gain_3
    
            if stranger_int == 'fb' or (stranger_int == 'full' and cp_Q3_dec == 'fb'):
            
                cp_dom_strat = 'fight_back'

        elif agent_dom_strat == 'steal' and cp_dom_strat == 'steal':
            
            ag_gain = exp_gain_agent_4
            cp_gain = exp_cp_gain_4

        # for all other strategies
        else:
            
            ag_gain = None
            cp_gain = None   

        # if we are tracking game types here we find the string which describes the game type, and we also find whether the game is one of the 'classics':

        # call function to generate des_string
        des_string = find_des_string(matrix_4_quads, print_fine_dets)

        # for when 'rational' and fb - need to know how many a & b == 0 or > 0
        if params.strat_choice == 'rational' and stranger_int == 'fb':

            if des_string == 'c = e = g < a  |  d = f = h < b':

                if a == 0.0:

                    des_string += '  |  a = 0'

                else:

                    des_string += '  |  a > 0'

                if b == 0.0:

                    des_string += ' b = 0'

                else:

                    des_string += ' b > 0'

        # we also update agent.exp_rtns_matrix[str(cp_agent)]
        classic_game_type = check_vs_classic_games(matrix_4_quads)

        if classic_game_type != 'Other':

            des_string += ' %s' % classic_game_type

        if print_fine_dets:
            print('\n FINAL des_string =', des_string)
            print(' classic_game_type =', classic_game_type)

        # find RCT des string and classic game
        matrix_4_quads_RCT = [[exp_gain_agent_1, exp_cp_gain_1], [], [], [exp_gain_agent_4, exp_cp_gain_4]]

        # find quads 2 and 3 returns
        if exp_gain_agent_2_fb > exp_gain_agent_2_acq:

            exp_gain_agent_2_RCT = copy.copy(exp_gain_agent_2_fb)
            exp_cp_gain_2_RCT = copy.copy(exp_cp_gain_2_fb)

        elif exp_gain_agent_2_fb < exp_gain_agent_2_acq:

            exp_gain_agent_2_RCT = copy.copy(exp_gain_agent_2_acq)
            exp_cp_gain_2_RCT = copy.copy(exp_cp_gain_2_acq)

        else:

            exp_gain_agent_2_RCT = random.choice([exp_gain_agent_2_acq, exp_gain_agent_2_fb])
            exp_cp_gain_2_RCT = random.choice([exp_cp_gain_2_acq, exp_cp_gain_2_fb])

        # compare exp_cp_gain_3_fb with exp_cp_gain_3_acq:
        if exp_cp_gain_3_fb > exp_cp_gain_3_acq:

            exp_gain_agent_3_RCT = copy.copy(exp_gain_agent_3_fb)
            exp_cp_gain_3_RCT = copy.copy(exp_cp_gain_3_fb)

            if print_fine_dets:
                print('\n cp fights back')

        elif exp_cp_gain_3_fb < exp_cp_gain_3_acq:

            exp_gain_agent_3_RCT = copy.copy(exp_gain_agent_3_acq)
            exp_cp_gain_3_RCT = copy.copy(exp_cp_gain_3_acq)

            if print_fine_dets:
                print('\n cp acquiesces')

        else:

            exp_gain_agent_3_RCT = random.choice([exp_gain_agent_3_acq, exp_gain_agent_3_fb])
            exp_cp_gain_3_RCT = random.choice([exp_cp_gain_3_acq, exp_cp_gain_3_fb])

        matrix_4_quads_RCT[1] = [exp_gain_agent_2_RCT, exp_cp_gain_2_RCT]
        matrix_4_quads_RCT[2] = [exp_gain_agent_3_RCT, exp_cp_gain_3_RCT]

        des_string_RCT = find_des_string(matrix_4_quads_RCT, print_fine_dets)
        des_string_RCT += ' RCT'

        classic_game_type_RCT = check_vs_classic_games(matrix_4_quads_RCT)

        if classic_game_type_RCT != 'Other':
            des_string_RCT += ' %s' % classic_game_type_RCT

        if print_fine_dets:
            print('\n FINAL des_string_RCT =', des_string_RCT)
            print(' classic_game_type_RCT =', classic_game_type_RCT)

        # now we update two dictionaries (agent.exp_rtns_matrix and agent.exp_int_gains_dict_strangers) so we can unpack this data later if the agents interact OR if they consider interacting again idc
        if use_start_basket == 0:

            if stranger_int == 'acq':

                agent.exp_rtns_matrix[str(cp_agent)] = [[exp_gain_agent_1, exp_cp_gain_1], [None, None], [exp_gain_agent_2, exp_cp_gain_2], [None, None], [exp_gain_agent_3, exp_cp_gain_3], [exp_gain_agent_4, exp_cp_gain_4], des_string,
                                                        classic_game_type, des_string_RCT, classic_game_type_RCT, matrix_4_quads, matrix_4_quads_RCT, agent_dom_strat, cp_dom_strat, ag_gain, cp_gain, ag_Q2_dec]

            elif stranger_int == 'fb':

                agent.exp_rtns_matrix[str(cp_agent)] = [[exp_gain_agent_1, exp_cp_gain_1], [exp_gain_agent_2, exp_cp_gain_2], [None, None], [exp_gain_agent_3, exp_cp_gain_3], [None, None], [exp_gain_agent_4, exp_cp_gain_4], des_string,
                                                        classic_game_type, des_string_RCT, classic_game_type_RCT, matrix_4_quads, matrix_4_quads_RCT, agent_dom_strat, cp_dom_strat, ag_gain, cp_gain, ag_Q2_dec]

            elif stranger_int == 'full' or (stranger_int == None and cp_dec == 1):

                agent.exp_rtns_matrix[str(cp_agent)] = [[exp_gain_agent_1, exp_cp_gain_1], [exp_gain_agent_2_fb, exp_cp_gain_2_fb], [exp_gain_agent_2_acq, exp_cp_gain_2_acq],
                                                        [exp_gain_agent_3_fb, exp_cp_gain_3_fb], [exp_gain_agent_3_acq, exp_cp_gain_3_acq], [exp_gain_agent_4, exp_cp_gain_4],
                                                        des_string, classic_game_type, des_string_RCT, classic_game_type_RCT, matrix_4_quads, matrix_4_quads_RCT, agent_dom_strat, cp_dom_strat, ag_gain, cp_gain, ag_Q2_dec]

            agent.exp_int_gains_dict_strangers[str(cp_agent)] = [cp_agent.last_intn, agent.last_intn, [ag_gain, cp_gain, cp_gain], des_string, classic_game_type, agent_dom_strat, cp_dom_strat, des_string_RCT, classic_game_type_RCT]
            # agent.exp_int_gains_dict_strangers[str(cp_agent)] = [cp_agent.last_intn, agent.last_intn, des_string, classic_game_type, des_string_RCT, classic_game_type_RCT]

            if print_fine_dets == 1:
                print('\n matrix_4_quads :\n', matrix_4_quads[0], matrix_4_quads[1], '\n', matrix_4_quads[2], matrix_4_quads[3])
                print('\n agent.exp_int_gains_dict_strangers[str(cp_agent)] =', agent.exp_int_gains_dict_strangers[str(cp_agent)])
                print('\n agent.exp_rtns_matrix[str(cp_agent)] =', agent.exp_rtns_matrix[str(cp_agent)])
                # pause()

        elif use_start_basket:

            agent.exp_int_gains_dict_strangers[str(cp_agent)] = [[ag_gain, cp_gain], des_string, classic_game_type, agent_dom_strat, cp_dom_strat]

        # agent.MRS_array = generate_MRS_array(agent.agent_res_array + agent.basket_array, print_fine_dets=0)
        # cp_agent.MRS_array = generate_MRS_array(cp_agent.agent_res_array + cp_agent.basket_array, print_fine_dets=0)

        if print_fine_dets == 1:
            print('\n matrix_4_quads :\n', matrix_4_quads[0], matrix_4_quads[1], '\n', matrix_4_quads[2], matrix_4_quads[3])
            print('\n agent.exp_int_gains_dict_strangers[str(cp_agent)] =', agent.exp_int_gains_dict_strangers[str(cp_agent)])
    #                pause()

    # agent.exp_int_gains_dict_strangers[str(cp_agent)].append(des_string_RCT)
    # agent.exp_int_gains_dict_strangers[str(cp_agent)].append(classic_game_type_RCT)

    # add considered game type to these dictionaries if not simulated and if this is not a cp considering interaction in agents_interact
    if params.track_game_types and use_start_basket == 0 and cp_dec == 0:

        if des_string not in dbs.games_type_considered_dict:

            dbs.games_type_considered_dict[des_string] = np.zeros(shape=dbs.num_rounds, dtype=int)
    
        dbs.games_type_considered_dict[des_string][day] += 1

        if classic_game_type not in dbs.classic_games_considered:

            dbs.classic_games_considered[classic_game_type] = np.zeros(shape=dbs.num_rounds, dtype=int)
    
        dbs.classic_games_considered[classic_game_type][day] += 1

        if des_string_RCT not in dbs.games_type_considered_dict_RCT:
            dbs.games_type_considered_dict_RCT[des_string_RCT] = np.zeros(shape=dbs.num_rounds, dtype=int)

        dbs.games_type_considered_dict_RCT[des_string_RCT][day] += 1

        if classic_game_type_RCT not in dbs.classic_games_considered_RCT:
            dbs.classic_games_considered_RCT[classic_game_type_RCT] = np.zeros(shape=dbs.num_rounds, dtype=int)

        dbs.classic_games_considered_RCT[classic_game_type_RCT][day] += 1

    # code test
    if params.run_code_tests and (ag_gain == None or cp_gain == None): # or agent_dom_strat == 'trade' or cp_dom_strat == 'trade':
        
        print('\n oops - strangers_interact: ag_gain == None or cp_gain == None')
        print('\n agent.exp_int_gains_dict_strangers[str(cp_agent)] =', agent.exp_int_gains_dict_strangers[str(cp_agent)])
        
        if new_eval_requd and use_start_basket == 0:

            print('\n matrix_4_quads :\n', matrix_4_quads[0], matrix_4_quads[1], '\n', matrix_4_quads[2], matrix_4_quads[3])
            print('\n agent.exp_rtns_matrix[str(cp_agent)] =', agent.exp_rtns_matrix[str(cp_agent)])

        print('\n agent.agent_res_array[0] ', agent.agent_res_array[0])
        print(' agent.basket_array[0] ', agent.basket_array[0])
        print(' agent.basket_array_start[0] ', agent.basket_array_start[0])        
        print(' agent_basket_used', agent_basket_used)
        print(' agent_min_res ', agent_min_res)

        print('\n cp_agent.agent_res_array[0] ', cp_agent.agent_res_array[0])
        print(' cp_agent.basket_array[0] ', cp_agent.basket_array[0])
        print(' cp_agent.basket_array_start[0] ', cp_agent.basket_array_start[0])        
        print(' cp_agent_basket_used', cp_agent_basket_used)
        print(' cp_agent_min_res ', cp_agent_min_res)
        
        print('\n stranger_int =', stranger_int)
        print('\n use_start_basket', use_start_basket)

        pause()

    if print_fine_dets:
        # print('\n agent.exp_rtns_matrix[str(cp_agent)] =', agent.exp_rtns_matrix[str(cp_agent)])
        print(' returned data: agent_dom_strat', agent_dom_strat, 'cp_dom_strat', cp_dom_strat, 'ag_gain', ag_gain, 'cp_gain', cp_gain)
        print('\n *** Ending strangers_interact')
        # pause()

    return agent_dom_strat, cp_dom_strat, ag_gain, cp_gain


def build_tot_cons_surp_array(params, min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, print_fine_dets, use_start_basket,
                              agent_res_array, agent_basket_array, agent_basket_array_start, cp_agent_res_array, cp_agent_basket_array, cp_agent_basket_array_start):

    """This function builds the total consumer surplus array, which measures the change in the consumer surplus if the agents
    transacted.  It returns the array, which is num_res_founts X num_res_founts."""

    print_fine_dets = 0

    if print_fine_dets == 1:
        print('\n\n *** starting build_tot_cons_surp_array ***')
        print('\n build... use_start_basket =', use_start_basket)
#        print('\nagent.basket_array =', agent.basket_array)
#        print('agent.aggr_res_array =', agent.aggr_res_array)
#        print('\nagent.MRS_array =\n', agent.MRS_array)
#        print('\ncp_agent.basket_array =', cp_agent.basket_array)
#        print('cp_agent.aggr_res_array =', cp_agent.aggr_res_array)
#        print('\ncp_agent.MRS_array =\n', cp_agent.MRS_array)

    # Create an array to record the potential transactions between the agents (agent sells x cp_agent buys).
    # We do this for every sell / buy combination
    tot_cons_surp_array = np.zeros(shape=(num_res_founts, num_res_founts))

    highest_surpl_so_far = 0.0
    record_trans_data = []
    for agent_sell_res in np.arange(num_res_founts):

        for cp_agent_sell_res in np.arange(num_res_founts):

            if agent_sell_res != cp_agent_sell_res:     # only carry on when resources are not the same

                ch_cons_surpl, ag_sells, ag_buys, trans_agr_MRS = process_transaction_PQ(params, print_fine_dets, agent_sell_res, cp_agent_sell_res, min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, use_start_basket,
                                                                                         agent_res_array, agent_basket_array, agent_basket_array_start, cp_agent_res_array, cp_agent_basket_array, cp_agent_basket_array_start)

                if ch_cons_surpl > highest_surpl_so_far:

                    highest_surpl_so_far = ch_cons_surpl
                    record_trans_data = [[agent_sell_res, cp_agent_sell_res, ag_sells, ag_buys, trans_agr_MRS]]

                elif ch_cons_surpl > highest_surpl_so_far and ch_cons_surpl != 0.0:

                    record_trans_data.append([agent_sell_res, cp_agent_sell_res, ag_sells, ag_buys, trans_agr_MRS])

                tot_cons_surp_array[agent_sell_res][cp_agent_sell_res] = ch_cons_surpl

    if len(record_trans_data) > 0:

        best_trans_data = random.choice(record_trans_data)

    else:

        best_trans_data = [None, None, None, None, None]

    if print_fine_dets == 1:
        print('\n tot_cons_surp_array:\n', tot_cons_surp_array)
#        print('\nrecord_trans_data =\n', record_trans_data)
#        print('\nbest_trans_data:\n', best_trans_data)
        print('\n*** ENDING build_tot_cons_surp_array ***')

    return tot_cons_surp_array, best_trans_data


def process_transaction_PQ(params, print_fine_dets, agent_sell_res, cp_agent_sell_res, min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, use_start_basket,
                           agent_res_array, agent_basket_array, agent_basket_array_start, cp_agent_res_array, cp_agent_basket_array, cp_agent_basket_array_start):

#    print_fine_dets = 1 agent, cp_agent,

    if print_fine_dets == 1:
        print('\n\n -> agent_sell_res', agent_sell_res, 'cp_agent_sell_res', cp_agent_sell_res)
        print('\n agent.agent_res_array', agent_res_array)
        print(' agent.basket_array =', agent_basket_array)
        print(' agent_basket_array_start =', agent_basket_array_start)
        print('\n cp_agent.agent_res_array', cp_agent_res_array)
        print(' cp_agent_basket_array =', cp_agent_basket_array)
        print(' cp_agent_basket_array_start =', cp_agent_basket_array_start)

    # update MRS arrays
    if use_start_basket == 0:
        
        agent_aggr_res_array = agent_res_array + agent_basket_array

    elif use_start_basket == 1:
        
        agent_aggr_res_array = agent_res_array + agent_basket_array_start
        
    agent_MRS_array = generate_MRS_array(agent_aggr_res_array, print_fine_dets)

    if use_start_basket == 0:

        cp_agent_aggr_res_array = cp_agent_res_array + cp_agent_basket_array

    elif use_start_basket == 1:

        cp_agent_aggr_res_array = cp_agent_res_array + cp_agent_basket_array_start

    cp_agent_MRS_array = generate_MRS_array(cp_agent_aggr_res_array, print_fine_dets)

    if print_fine_dets == 1:

        print(' use_start_basket =', use_start_basket)
        print(' agent_aggr_res_array =', agent_aggr_res_array)
        print(' cp_agent_aggr_res_array =', cp_agent_aggr_res_array)

    # find relevant MRS
    agent_MRS = agent_MRS_array[agent_sell_res][cp_agent_sell_res]
    cp_agent_MRS = cp_agent_MRS_array[agent_sell_res][cp_agent_sell_res]

    # There are two approaches we take to deriving the mean: geometric and arithmetic

    if price_mean == 'geometric':

        # Working out price using geometric mean (taken from Epstein & Axtell)
        it_trans_agr_MRS = np.sqrt(agent_MRS_array[agent_sell_res][cp_agent_sell_res] * cp_agent_MRS_array[agent_sell_res][cp_agent_sell_res])

    elif price_mean == 'arithmetic':

        it_trans_agr_MRS = np.mean([agent_MRS_array[agent_sell_res][cp_agent_sell_res], cp_agent_MRS_array[agent_sell_res][cp_agent_sell_res]])

    # In this option we force the prices to be the optimal prices, to see what happens (note the prices are recorded as chart prices, so here we invert them)
    if force_prices == 'optimal':

        it_trans_agr_MRS = float(dbs.optimal_price_array[day][agent_sell_res][cp_agent_sell_res])

    if force_prices == 'fixed' and params.fixed_price_day <= day:

        if agent_sell_res == 0:

            it_trans_agr_MRS = fixed_price

        else:

            it_trans_agr_MRS = 1 / float(fixed_price)

    if force_prices == 'power':

        it_trans_agr_MRS = (dbs.optimal_price_array[day][agent_sell_res][cp_agent_sell_res] + fountain_population.pop[agent_sell_res].highest_prices[day]) / 2.0

    # Alternative mean is arithmetic
#    it_trans_price = np.mean([agent.MRS_array[agent_sell_res][cp_agent_sell_res], cp_agent.MRS_array[agent_sell_res][cp_agent_sell_res]])

    # If the price > 1 then the trade is in favour of the cp: think of it as the agent having too much of the good it
    # wants to sell relative to the cp. This also means the units of the good being sold exceed the units of the good
    # being received by the agent.  So if the agent sells x then it receives x / p.  Or, if it buys y then it sells
    # p * y.

    # Find the quantities the agents would sell if there were no basket constraints.  This would make the MRS = price by
    # allowing any adjustment required of the agent's resources:

    try:
        a = 1 / float(it_trans_agr_MRS)
    except ZeroDivisionError:
        print('\n problem: it_trans_agr_MRS =', it_trans_agr_MRS)
        print('\n agent_MRS_array\n\n', agent_MRS_array, '\n cp_agent_MRS_array\n\n', cp_agent_MRS_array)
        print('\n agent_res_array', agent_res_array, ' agent_basket_array', agent_basket_array)
        print('\n cp_agent_res_array', cp_agent_res_array, ' cp_agent_basket_array', cp_agent_basket_array)
        it_trans_agr_MRS = 1.0
        # pause()

    ag_MRS_equ_price_Q = Q_at_price(agent_sell_res, cp_agent_sell_res, it_trans_agr_MRS, agent_aggr_res_array)
    cp_MRS_equ_price_Q = Q_at_price(cp_agent_sell_res, agent_sell_res, 1 / float(it_trans_agr_MRS), cp_agent_aggr_res_array)

#    # check MRSs with these unconstrained desired sell / buy amounts
#    check_MRS_agent = (agent_aggr_res_array[0][agent_sell_res] + agent.basket_array[0][agent_sell_res] - ag_MRS_equ_price_Q) / float(agent.agent_res_array[0][cp_agent_sell_res] + agent.basket_array[0][cp_agent_sell_res] + (ag_MRS_equ_price_Q / float(it_trans_agr_MRS)))
#    check_MRS_cp_agent = (cp_agent.agent_res_array[0][agent_sell_res] + cp_agent.basket_array[0][agent_sell_res] + (cp_MRS_equ_price_Q * it_trans_agr_MRS)) / float(cp_agent.agent_res_array[0][cp_agent_sell_res] + cp_agent.basket_array[0][cp_agent_sell_res] - cp_MRS_equ_price_Q)
#
#    if print_fine_dets == 1:
#
#        print('\n Here we check the unconstrained preferred sale and purchases against the expected MRSs if these were achieved:')
#        print('\n check_MRS_agent =', check_MRS_agent, 'which should equal it_trans_agr_MRS =', it_trans_agr_MRS, 'difference = %1.8f' % (check_MRS_agent - it_trans_agr_MRS))
#        print('\n check_MRS_cp_agent =', check_MRS_cp_agent, 'which should equal it_trans_agr_MRS =', it_trans_agr_MRS, 'difference = %1.8f' % (check_MRS_cp_agent - it_trans_agr_MRS))
#
#        print('\n decompose cp numbers:\n\n num: cp_agent.agent_res_array[0][agent_sell_res]', cp_agent.agent_res_array[0][agent_sell_res], '+ cp_agent.basket_array[0][agent_sell_res]', cp_agent.basket_array[0][agent_sell_res], '+ cp_MRS_equ_price_Q * it_trans_agr_MRS:', cp_MRS_equ_price_Q, '*', it_trans_agr_MRS)
#        print('\n denom: agent.agent_res_array[0][cp_agent_sell_res]', agent.agent_res_array[0][cp_agent_sell_res], 'agent.basket_array[0][cp_agent_sell_res]', agent.basket_array[0][cp_agent_sell_res], '- cp_MRS_equ_price_Q', cp_MRS_equ_price_Q)

    # We use these to find the minimum amount of the goods each would sell - the lowest is the constraint (I have given the constraint a floor of zero)
    if use_start_basket == 0:

        ag_constr = np.min([agent_basket_array[0][agent_sell_res], ag_MRS_equ_price_Q])
        cp_constr = np.min([cp_agent_basket_array[0][cp_agent_sell_res], cp_MRS_equ_price_Q])

    elif use_start_basket == 1:

        ag_constr = np.min([agent_basket_array_start[0][agent_sell_res], ag_MRS_equ_price_Q])
        cp_constr = np.min([cp_agent_basket_array_start[0][cp_agent_sell_res], cp_MRS_equ_price_Q])

    ag_constr = np.max([ag_constr, 0])
    cp_constr = np.max([cp_constr, 0])

    if print_fine_dets == 1:
        print('\n agent_MRS =', agent_MRS)
        print(' cp_agent_MRS =', cp_agent_MRS)
        print('\n it_trans_agr_MRS =', it_trans_agr_MRS)
        print(' 1 / it_trans_agr_MRS =', 1 / float(it_trans_agr_MRS))
        print('\n ag_MRS_equ_price_Q =', ag_MRS_equ_price_Q)
        print(' cp_MRS_equ_price_Q =', cp_MRS_equ_price_Q)
        print('\n ag_constr =', ag_constr)
        print(' cp_constr =', cp_constr)
        print(' min_trans_Q =', min_trans_Q)
        print('\n ag_constr <= cp_constr * it_trans_agr_MRS =', ag_constr <= cp_constr * it_trans_agr_MRS)

    # We only acknowledge the transaction if they both want to sell (above the min threshold)
    if ag_constr > min_trans_Q and cp_constr > min_trans_Q:

        # There are two situations: first, when the ag's constraint is binding, and the second where the cp's constraint is
        # binding.  In the first, the agent will sell its constraint (in units of sell_res) and receive constraint / price
        # (in units of buy_res): this is when the amount it would receive is less than or = to the cp's constraint i.e.
        # ag_constr / float(it_trans_agr_MRS) <= cp_constr:
        if ag_constr / float(it_trans_agr_MRS) <= cp_constr:     # then the ag's constraint is most binding

            ag_sells = ag_constr
            ag_buys = ag_constr / float(it_trans_agr_MRS)

        elif ag_constr / float(it_trans_agr_MRS) > cp_constr:    # then the cp's constraint is most binding

            ag_sells = cp_constr * it_trans_agr_MRS
            ag_buys = cp_constr

        # the change in the consumer surplus in units of the resource being sold by the agent is: new_ag_MRS
        ch_cons_surpl = (agent_MRS - cp_agent_MRS) * ag_sells

        new_Q_ag_numer = agent_aggr_res_array[0][agent_sell_res] - ag_sells
        new_Q_ag_denom = agent_aggr_res_array[0][cp_agent_sell_res] + ag_buys

        new_Q_cp_numer = cp_agent_aggr_res_array[0][cp_agent_sell_res] - ag_buys
        new_Q_cp_denom = cp_agent_aggr_res_array[0][agent_sell_res] + ag_sells

        new_ag_MRS = new_Q_ag_numer / float(new_Q_ag_denom)
        new_cp_MRS = new_Q_cp_numer / float(new_Q_cp_denom)

        if print_fine_dets == 1:
#                print '\nQ_change =', Q_change
            print('\n ag_sells =', ag_sells)
            print(' ag_buys =', ag_buys)
            print('\n ch_cons_surpl =', ch_cons_surpl)
#            print('\n new_Q_ag_numer =', new_Q_ag_numer)
#            print(' new_Q_ag_denom =', new_Q_ag_denom)
#            print('\n new_Q_cp_numer =', new_Q_cp_numer)
#            print(' new_Q_cp_denom =', new_Q_cp_denom)
            print('\n new_ag_MRS =', new_ag_MRS)
            print(' new_cp_MRS =', new_cp_MRS)

#            pause()

        return ch_cons_surpl, ag_sells, ag_buys, it_trans_agr_MRS

    else:

        if print_fine_dets == 1:
            print('\n One or both the agents didnt want to sell (negative constraint and / or none to sell)')

#            pause()

        return 0.0, 0.0, 0.0, 0.0       # agent_trade_gain


def Q_at_price(sell_res, buy_res, price, agent_aggr_res_array):

    """This function assesses the amount an agent would sell of a resource (sell_res) in exchange for another resource
    (buy_res).  Note that if the resulting value is negative it means the agent will demand this Q of sell_res at the given
    price."""

    total_Q = (agent_aggr_res_array[0][sell_res] - (price * agent_aggr_res_array[0][buy_res])) / 2.0

    return total_Q


def generate_MRS_array(res_array, print_fine_dets):
    """This function takes an agent's resource array and returns its counterpart MRS array"""

    if print_fine_dets:
        print('\n\n Starting generate_MRS_array')

    MRS_array = np.ones(shape=(num_res_founts, num_res_founts))

    for numerat in np.arange(num_res_founts):

        for denom in np.arange(num_res_founts):

            if numerat != denom:

                # Update the agent's MRS_array

                # in the extreme case of agents being endowed with 0 resources:
                if res_array[0][denom] == 0:
                    res_array[0][denom] = 1

                MRS = res_array[0][numerat] / float(res_array[0][denom])
                MRS_array[numerat][denom] = MRS

                if print_fine_dets:
                    print('\n numerat =', numerat)
                    print(' denom =', denom)
                    print(' MRS =', MRS)

                if print_fine_dets:
                    print('\n res_array[0][numerat]', res_array[0][numerat])
                    print(' res_array[0][denom] =', res_array[0][denom])

    if print_fine_dets:
        print('\n Ending generate_MRS_array \n')

    return MRS_array


def add_game_to_game_dict(params, agent_population, fountain_population, agent, cp_agent, payoffs_6_scenarios, payoffs_6_scenarios_cp, dbs, day, strat_choice, stranger_int, strangers_if_unknown,
                          agent_dec, cp_agent_dec, ag_rat_dec, cp_rat_dec, print_fine_dets):

    """This function takes a 6-scenario payoff matrix, converts it to 4-scenario payoff and then adds the game to various games dictionaries."""

    # if day > 100:
    #     print_fine_dets = 1

    # print_fine_dets = 1

    if print_fine_dets:
        print('\n\n\n ----> starting add_game_to_game_dict')
        print('\n payoffs_6_scenarios =', payoffs_6_scenarios)
        print(' payoffs_6_scenarios_cp =', payoffs_6_scenarios_cp)
        print(' agent.prop_fight_back', agent.prop_fight_back)
        print(' cp_agent.prop_fight_back', cp_agent.prop_fight_back)
        print(' stranger_int', stranger_int)
        print(' strat_choice', strat_choice)
        print(' strangers_if_unknown', strangers_if_unknown)
        print(' agent_dec', agent_dec)
        print(' cp_agent_dec', cp_agent_dec)
        print(' agent.agent_knows_cp_dict[str(cp_agent)]', agent.agent_knows_cp_dict[str(cp_agent)])
        print(' cp_agent.agent_knows_cp_dict[str(agent)]', cp_agent.agent_knows_cp_dict[str(agent)])

    # now create two different 4-payoff matrices - one using [1] and [2] depending on strat_choice and stranger_int; the second pure RCT
    if print_fine_dets:
        print('\n payoffs_6_scenarios[10] =', payoffs_6_scenarios[10])
        print(' payoffs_6_scenarios_cp[10] =', payoffs_6_scenarios_cp[10])

    payoffs_4_scenarios = payoffs_6_scenarios[10]
    payoffs_4_scenarios_cp = payoffs_6_scenarios_cp[10]

    payoffs_4_scenarios_RCT = payoffs_6_scenarios[11]
    payoffs_4_scenarios_RCT_cp = payoffs_6_scenarios_cp[11]

    # for i in range(4):
    #
    #     payoffs_4_scenarios[i][0] = payoffs_6_scenarios[10][i][0]
    #     payoffs_4_scenarios[i][1] = payoffs_6_scenarios_cp[10][i][0]
    #
    #     payoffs_4_scenarios_RCT[i][0] = payoffs_6_scenarios[11][i][0]
    #     payoffs_4_scenarios_RCT[i][1] = payoffs_6_scenarios_cp[11][i][0]

    ag_dec_in_pr = payoffs_6_scenarios[-1]            # this will == 'acq' or 'fb'
    cp_dec_in_pr = payoffs_6_scenarios_cp[-1]            # this will == 'acq' or 'fb'

    if print_fine_dets:
        print('\n ag_dec_in_pr =', ag_dec_in_pr)
        print(' cp_dec_in_pr =', cp_dec_in_pr)

    des_string_mapping_dict = {'a':'b', 'c':'d', 'e':'f', 'g':'h'}

    # we have 2 des_strings, which correspond to how each of the agents perceive the interaction
    des_string = payoffs_6_scenarios[6]
    des_string_cp = payoffs_6_scenarios_cp[6]

    # des_string += des_string_mapping_dict[payoffs_6_scenarios_cp[6][0]] + ' ' + payoffs_6_scenarios_cp[6][2] + ' '
    # des_string += des_string_mapping_dict[payoffs_6_scenarios_cp[6][4]] + ' ' + payoffs_6_scenarios_cp[6][6] + ' '
    # des_string += des_string_mapping_dict[payoffs_6_scenarios_cp[6][8]] + ' ' + payoffs_6_scenarios_cp[6][10] + ' '
    # des_string += des_string_mapping_dict[payoffs_6_scenarios_cp[6][12]]

    # print('\n ** payoffs_6_scenarios:\n', payoffs_6_scenarios)

    if print_fine_dets:
        print('\n des_string =', des_string)
        print(' des_string_cp =', des_string_cp)

    # for quadrant data below we need ag_fb_or_acq and cp_fb_or_acq:
    if strat_choice == 'rational' and stranger_int != 'full':

        if stranger_int == 'fb':
            ag_fb_or_acq = 'fb'
            cp_fb_or_acq = 'fb'

        if stranger_int == 'acq':
            ag_fb_or_acq = 'acq'
            cp_fb_or_acq = 'acq'

    elif strat_choice == 'propensities' or (strat_choice == 'rational' and stranger_int == 'full'):

        ag_fb_or_acq = ag_dec_in_pr
        cp_fb_or_acq = cp_dec_in_pr

    a = payoffs_4_scenarios[0][0]
    b = payoffs_4_scenarios[0][1]
    c = payoffs_4_scenarios[1][0]
    d = payoffs_4_scenarios[1][1]
    e = payoffs_4_scenarios[2][0]
    f = payoffs_4_scenarios[2][1]
    g = payoffs_4_scenarios[3][0]
    h = payoffs_4_scenarios[3][1]

    a_cp = payoffs_4_scenarios_cp[0][0]
    b_cp = payoffs_4_scenarios_cp[0][1]
    c_cp = payoffs_4_scenarios_cp[1][0]
    d_cp = payoffs_4_scenarios_cp[1][1]
    e_cp = payoffs_4_scenarios_cp[2][0]
    f_cp = payoffs_4_scenarios_cp[2][1]
    g_cp = payoffs_4_scenarios_cp[3][0]
    h_cp = payoffs_4_scenarios_cp[3][1]

    if print_fine_dets == 1:
        print('\n payoffs_4_scenarios\n\n [', payoffs_4_scenarios[0], payoffs_4_scenarios[1])
        print('  ', payoffs_4_scenarios[2], payoffs_4_scenarios[3], ']')

        print('\n payoffs_4_scenarios_cp\n\n [', payoffs_4_scenarios_cp[0], payoffs_4_scenarios_cp[1])
        print('  ', payoffs_4_scenarios_cp[2], payoffs_4_scenarios_cp[3], ']')

        # print('\n a =', a)
        # print(' c =', c)
        # print(' e =', e)
        # print(' g =', g)
        #
        # print('\n b =', b)
        # print(' d =', d)
        # print(' f =', f)
        # print(' h =', h)

    # for when 'rational' and fb and des_string == 'c = e = g < a  |  d = f = h < b', need to know how many a & b == 0 or > 0 so we decompose this game type into detailed types
    if strat_choice == 'rational' and stranger_int == 'fb':

        if des_string == 'c = e = g < a  |  d = f = h < b':

            if a == 0.0:

                des_string += '  |  a = 0'

            else:

                des_string += '  |  a > 0'

            if b == 0.0:

                des_string += ' b = 0'

            else:

                des_string += ' b > 0'

        if des_string_cp == 'c = e = g < a  |  d = f = h < b':

            if a_cp == 0.0:

                des_string_cp += '  |  a = 0'

            else:

                des_string_cp += '  |  a > 0'

            if b_cp == 0.0:

                des_string_cp += ' b = 0'

            else:

                des_string_cp += ' b > 0'

    # now add this interaction (from both agents' pov) to dbs.games_type_dict (and create a dictionary entry if it's not there already)
    if des_string not in dbs.games_type_dict:
        dbs.games_type_dict[des_string] = np.zeros(shape=dbs.num_rounds, dtype=int)
    dbs.games_type_dict[des_string][day] += 1

    if des_string_cp not in dbs.games_type_dict:
        dbs.games_type_dict[des_string_cp] = np.zeros(shape=dbs.num_rounds, dtype=int)
    dbs.games_type_dict[des_string_cp][day] += 1

    ### so by this stage we have added the game type to dbs.games_type_dict ###

    # from here we add to games_type_dict_2 and games_type_dict_3 - we are looking for scenarios which help us understand the evolution of agents' interactions throughout the sim cp_ps, cp_pfb
    if strat_choice == 'propensities':

        # we run through this code twice - one for each agent
        for ag in [agent, cp_agent]:

            if ag == agent:
                cp = cp_agent

            else:
                cp = agent

                # change payoffs_4_scenarios and a - h for the second iteration (and change back later)
                payoffs_4_scenarios = payoffs_6_scenarios_cp[10]

                a = payoffs_4_scenarios[0][0]
                b = payoffs_4_scenarios[0][1]
                c = payoffs_4_scenarios[1][0]
                d = payoffs_4_scenarios[1][1]
                e = payoffs_4_scenarios[2][0]
                f = payoffs_4_scenarios[2][1]
                g = payoffs_4_scenarios[3][0]
                h = payoffs_4_scenarios[3][1]

            ag_ps = np.min([np.max([ag.prop_steal, 0.0]), 1.0])
            ag_pfb = np.min([np.max([ag.prop_fight_back, 0.0]), 1.0])

            # we find cp props - this function includes limiting them to between 0 and 1
            cp_ps, cp_pfb, num_ints = find_cp_props(params, ag, cp, day, params.len_reputations_mem, print_fine_dets=0)

            prob_scen_1 = (1 - ag_ps) * (1 - cp_ps)
            prob_scen_2 = (1 - ag_ps) * cp_ps
            prob_scen_3 = ag_ps * (1 - cp_ps)
            prob_scen_4 = ag_ps * cp_ps

            agent_prob_weighted_gain = prob_scen_1 * payoffs_4_scenarios[0][0] + prob_scen_2 * payoffs_4_scenarios[1][0] + prob_scen_3 * payoffs_4_scenarios[2][0] + prob_scen_4 * payoffs_4_scenarios[3][0]
            cp_agent_prob_weighted_gain = prob_scen_1 * payoffs_4_scenarios[0][1] + prob_scen_2 * payoffs_4_scenarios[1][1] + prob_scen_3 * payoffs_4_scenarios[2][1] + prob_scen_4 * payoffs_4_scenarios[3][1]

            # we start off assuming this but scenario_name will be over-riden under certain circumstances
            if ag == agent:
                scenario_name = des_string
            else:
                scenario_name = des_string_cp

            one_or_both_agents_has_res = 1

            if ag.basket_array[0][0] == ag.basket_array[0][1] == cp.basket_array[0][0] == cp.basket_array[0][1] == 0.0:

                one_or_both_agents_has_res = 0

                scenario_name = strat_choice + ': Neither agent has resources'

            if one_or_both_agents_has_res and (a < c < g < e or a < c < g == e or a < c == g < e or a < c == g == e or (a == c < g < e and f < h < d == b) or (a == c < g < e and f == h < d == b)):

                scenario_name = strat_choice

                if ag.basket_array[0][0] == 0.0 and ag.basket_array[0][1] == 0.0:

                    scenario_name += ': Agent with no res '

                elif ag.basket_array[0][0] > 0.0 or ag.basket_array[0][1] > 0.0:

                    scenario_name += ': Agent with res '

                if payoffs_4_scenarios[0][0] == 0.0:

                    scenario_name += 'expects to mug, no trading'

                else:

                    if prob_scen_1 > 0.5:

                        scenario_name += 'expects to trade but mugging an option'

                    else:

                        scenario_name += 'expects to mug but trading an option'

            if one_or_both_agents_has_res and (
                    (c < a < g < e and f < h < b < d) or (c < a < g < e and f < h < d < b) or (c < a < g < e and f < b == h < d) or (c < a < g < e and b == f == h < d) or (c < a < g == e and f == h < b < d) or (c < a < g == e and f == h < d < b) or \
                    (c < a < g == e and b < f == h < d) or (c < a < g < e and f < b == h < d)):

                scenario_name = strat_choice

                if ag.basket_array[0][0] == 0.0 and ag.basket_array[0][1] == 0.0:  # this is v unlikely in this familly

                    scenario_name += ': Agent with no res '

                elif ag.basket_array[0][0] > 0.0 or ag.basket_array[0][1] > 0.0:

                    scenario_name += ': Agent with res '

                if payoffs_4_scenarios[0][0] == 0.0:

                    scenario_name += 'expects to mug, no trading'

                else:

                    if prob_scen_1 > 0.5:

                        scenario_name += 'expects to trade but mugging an option'

                    else:

                        scenario_name += 'expects to mug but trading an option'

            if one_or_both_agents_has_res and (
                    (c < g < a < e and f < h < d < b) or (c < g < a < e and f < h < b < d) or (c < g < a < e and f < b < h < d) or (c < g < a < e and b < f < h < d) or (c == g < a < e and f < h == d < b) or (c == g < a < e and f < b < d == h) or \
                    (c == g < a < e and b < f < d == h) or (c < g < a < e and f < h == b < d)):

                scenario_name = strat_choice
                scenario_name += ': Risky Gamble: balance of probs, exp cp to acquiesce'

            if one_or_both_agents_has_res and ((c < g < e < a and b < f < h < d) or (c < g < e < a and f < b < h < d) or (c < g < e < a and f < h < b < d) or (c < g < e < a and f < h < d < b) or\
                                               (c < g == e < a and b < f == h < d) or (c < g == e < a and f == h < b < d) or (c < g == e < a and f == h < d < b) or (c == g < e < a and b < f < d == h) or\
                                               (c == g < e < a and f < b < d == h) or (c == g < e < a and f < d == h < b) or (c == g == e < a and b < d == f == h) or (c == g == e < a and d == f == h < b)):

                scenario_name = strat_choice
                scenario_name += ': Agent expects to trade'

            if agent_prob_weighted_gain <= 0.0:  # then the agent has made a mistake - they should not be interacting with the cp

                scenario_name += ' (mistake!)'

            if print_fine_dets:
                if ag == agent:
                    print('\n agent scenario_name =', scenario_name)
                else:
                    print(' cp scenario_name =', scenario_name)

            # mnow add the scenario_name to games_type_dict_2 and games_type_dict_3
            if scenario_name not in dbs.games_type_dict_2:
                dbs.games_type_dict_2[scenario_name] = np.zeros(shape=dbs.num_rounds, dtype=float)
            dbs.games_type_dict_2[scenario_name][day] += agent_prob_weighted_gain

            if scenario_name not in dbs.games_type_dict_3:
                dbs.games_type_dict_3[scenario_name] = np.zeros(shape=dbs.num_rounds, dtype=float)
            dbs.games_type_dict_3[scenario_name][day] += 1

        # revert back to these at end of iterations over 2 agents
        payoffs_4_scenarios = payoffs_6_scenarios[10]

        a = payoffs_4_scenarios[0][0]
        b = payoffs_4_scenarios[0][1]
        c = payoffs_4_scenarios[1][0]
        d = payoffs_4_scenarios[1][1]
        e = payoffs_4_scenarios[2][0]
        f = payoffs_4_scenarios[2][1]
        g = payoffs_4_scenarios[3][0]
        h = payoffs_4_scenarios[3][1]

    if strat_choice == 'rational':  # then the choice is already determined - we simply express the strat choice

        scenario_name = 'ag: '
        scenario_name += agent_dec
        scenario_name += '  |  cp: '
        scenario_name += cp_agent_dec


        scenario_name_cp = 'cp: '
        scenario_name_cp += cp_agent_dec
        scenario_name_cp += '  |  ag: '
        scenario_name_cp += agent_dec

        # now add the scenario_name to games_type_dict_2 and games_type_dict_3 - first for agent
        if scenario_name not in dbs.games_type_dict_2:
            dbs.games_type_dict_2[scenario_name] = np.zeros(shape=dbs.num_rounds, dtype=float)
        dbs.games_type_dict_2[scenario_name][day] += agent.exp_int_gains_dict_strangers[str(cp_agent)][2][0]

        if scenario_name not in dbs.games_type_dict_3:
            dbs.games_type_dict_3[scenario_name] = np.zeros(shape=dbs.num_rounds, dtype=float)
        dbs.games_type_dict_3[scenario_name][day] += 1

        # now for cp
        if cp_agent.exp_int_gains_dict_strangers[str(agent)][2][0] is not None:         # if cp_agent can't make a rational decision then it won't have an expected return so we can't apply this to dict
            if scenario_name_cp not in dbs.games_type_dict_2:
                dbs.games_type_dict_2[scenario_name_cp] = np.zeros(shape=dbs.num_rounds, dtype=float)
            dbs.games_type_dict_2[scenario_name_cp][day] += cp_agent.exp_int_gains_dict_strangers[str(agent)][2][0]

        if scenario_name_cp not in dbs.games_type_dict_3:
            dbs.games_type_dict_3[scenario_name_cp] = np.zeros(shape=dbs.num_rounds, dtype=float)
        dbs.games_type_dict_3[scenario_name_cp][day] += 1

        if print_fine_dets:

            print('\n rational... scenario_name', scenario_name)
            print(' rational... scenario_name_cp', scenario_name_cp)
            print('\n resulting scenario_names for dict_2 and dict_3 = ', scenario_name, ' --- and --- ', scenario_name_cp)
            print('\n agent.exp_int_gains_dict_strangers[str(cp_agent)][2][0] =', agent.exp_int_gains_dict_strangers[str(cp_agent)][2][0])
            print(' cp_agent.exp_int_gains_dict_strangers[str(agent)][2][0] =', cp_agent.exp_int_gains_dict_strangers[str(agent)][2][0])

    # now create string which represents outcome
    rat_choice_string = 'ag: '
    rat_choice_string += ag_rat_dec
    rat_choice_string += ' '
    rat_choice_string += ' / cp: '
    rat_choice_string += cp_rat_dec

    rat_choice_string_cp = 'cp: '
    rat_choice_string_cp += cp_rat_dec
    rat_choice_string_cp += ' '
    rat_choice_string_cp += ' / ag: '
    rat_choice_string_cp += ag_rat_dec

    if ag_rat_dec == 'none' or cp_rat_dec == 'none':

        rat_choice_string += ' (RE)'
        rat_choice_string_cp += ' (RE)'
        dbs.num_RE_games += 2

    else:

        rat_choice_string += ' (not RE)'
        rat_choice_string_cp += ' (not RE)'
        dbs.num_known_outcome_games += 2

    # add to games_RCT_dict
    # note we do this for both agent and cp_agent so the number of interactions is the same in all 'seen' dictionaries
    if rat_choice_string not in dbs.games_RCT_dict:
        dbs.games_RCT_dict[rat_choice_string] = np.zeros(shape=dbs.num_rounds, dtype=int)
    dbs.games_RCT_dict[rat_choice_string][day] += 1

    if rat_choice_string_cp not in dbs.games_RCT_dict:
        dbs.games_RCT_dict[rat_choice_string_cp] = np.zeros(shape=dbs.num_rounds, dtype=int)
    dbs.games_RCT_dict[rat_choice_string_cp][day] += 1

    if print_fine_dets:
        print('\n rat_choice_string =', rat_choice_string)
        print(' rat_choice_string_cp =', rat_choice_string_cp)

    # add to games_type_dict_RCT
    # note we do this for both agent and cp_agent so the number of interactions is the same in all 'seen' dictionaries
    game_type_RCT = payoffs_6_scenarios[8]
    game_type_RCT_cp = payoffs_6_scenarios_cp[8]

    if game_type_RCT not in dbs.games_type_dict_RCT:
        dbs.games_type_dict_RCT[game_type_RCT] = np.zeros(shape=dbs.num_rounds, dtype=int)
    dbs.games_type_dict_RCT[game_type_RCT][day] += 1

    if game_type_RCT_cp not in dbs.games_type_dict_RCT:
        dbs.games_type_dict_RCT[game_type_RCT_cp] = np.zeros(shape=dbs.num_rounds, dtype=int)
    dbs.games_type_dict_RCT[game_type_RCT_cp][day] += 1

    # now add to other dictionaries
    # first the quadrants assuming RCT
    if ag_rat_dec == 'trade' and cp_rat_dec == 'trade':

        dbs.quadrants_tallies_RCT['1'][day] += 1

        # print('1')

    elif ag_rat_dec == 'trade' and cp_rat_dec == 'steal' and ag_fb_or_acq == 'fb':

        dbs.quadrants_tallies_RCT['2F'][day] += 1

        # print('2F')

    elif ag_rat_dec == 'trade' and cp_rat_dec == 'steal' and ag_fb_or_acq == 'acq':

        dbs.quadrants_tallies_RCT['2A'][day] += 1

        # print('2A')

    elif ag_rat_dec == 'steal' and cp_rat_dec == 'trade' and cp_fb_or_acq == 'fb':

        dbs.quadrants_tallies_RCT['3F'][day] += 1

        # print('3F')

    elif ag_rat_dec == 'steal' and cp_rat_dec == 'trade' and cp_fb_or_acq == 'acq':

        dbs.quadrants_tallies_RCT['3A'][day] += 1

        # print('3A')

    elif ag_rat_dec == 'steal' and cp_rat_dec == 'steal':

        dbs.quadrants_tallies_RCT['4'][day] += 1

        # print('4')

    if print_fine_dets:
        print('\n for RCT quadrants:\n\n ag_rat_dec =', ag_rat_dec)
        print(' cp_rat_dec =', cp_rat_dec)

    # add to classic games dictionary
    classic_game_type = payoffs_6_scenarios[7]
    classic_game_type_cp = payoffs_6_scenarios_cp[7]

    if print_fine_dets:
        print('\n classic_game_type =', classic_game_type)
        print(' classic_game_type_cp =', classic_game_type_cp)

    if classic_game_type not in dbs.classic_games_seen:
        dbs.classic_games_seen[classic_game_type] = np.zeros(shape=dbs.num_rounds, dtype=int)
    dbs.classic_games_seen[classic_game_type][day] += 1

    if classic_game_type_cp not in dbs.classic_games_seen:
        dbs.classic_games_seen[classic_game_type_cp] = np.zeros(shape=dbs.num_rounds, dtype=int)
    dbs.classic_games_seen[classic_game_type_cp][day] += 1

    # now RCT game type
    classic_game_type_RCT = payoffs_6_scenarios[9]
    classic_game_type_RCT_cp = payoffs_6_scenarios_cp[9]

    if classic_game_type_RCT not in dbs.classic_games_seen_RCT:
        dbs.classic_games_seen_RCT[classic_game_type_RCT] = np.zeros(shape=dbs.num_rounds, dtype=int)
    dbs.classic_games_seen_RCT[classic_game_type_RCT][day] += 1

    if classic_game_type_RCT_cp not in dbs.classic_games_seen_RCT:
        dbs.classic_games_seen_RCT[classic_game_type_RCT_cp] = np.zeros(shape=dbs.num_rounds, dtype=int)
    dbs.classic_games_seen_RCT[classic_game_type_RCT_cp][day] += 1

    # classic_games_seen_RCT

    if print_fine_dets:
        print('\n ----> ENDING add_game_to_game_dict \n\n\n')

        pause()

def check_vs_classic_games(payoffs):

    a = payoffs[0][0]
    b = payoffs[0][1]
    c = payoffs[1][0]
    d = payoffs[1][1]
    e = payoffs[2][0]
    f = payoffs[2][1]
    g = payoffs[3][0]
    h = payoffs[3][1]

    list_of_strats = []
    form = 'Other'

    # aggr_payoffs = [a + b, c + d, e + f, g + h]

    if a < e and g < c and b < d and h < f:  # note this is a broad category (one of two types of coord game)
        form = 'Coordination Game: Hawk-Dove'  # note the classic game here usually includes a == b and g == h but I ignore that
        list_of_strats.append(form)

    # this is the second type of coordination game, with several sub-types
    if e < a and c < g and d < b and f < h:

        form = 'Coordination Game (Other)'

        counter = 0

        if a == g and b == h:                           # this is unlikely to transpire but it might e.g., if outcomes are zeros - the agents are indifferent to the trade / trade and steal / steal outcomes
            form = 'Coordination Game: Pure'
            list_of_strats.append(form)

            counter += 1

        if a > g and b > h:
            form = 'Coordination Game: Assurance'
            list_of_strats.append(form)

            counter += 1

            if (e > g and d > h) or (e < g and d < h):         # this gives us the correct payoff rankings in this type of game
                form = 'Coordination Game: Stag Hunt'
                list_of_strats.append(form)

                counter += 1

        if a > b and g < h and h > d and b > f and a > c and e < g:                             # these inequalities distinguish this coord game from others
            form = 'Coordination Game: Battle of the Sexes'
            list_of_strats.append(form)

            counter += 1

        if a == -1 * b and c == -1 * d and e == -1 * f and f == -1 * h:     # I cannot imagine this would come up... but this game is a coordination game where one agent's loss is the others' gain
            form = 'Matching Pennies'
            list_of_strats.append(form)

        if counter == 0:
            list_of_strats.append(form)

    # now we look at when the agents both have strongly dominant strategies - there are 4 combinations
    if (a < e and c < g and b < d and f < h) or (a < e and c < g and d < b and h < f) or (e < a and g < c and b < d and f < h) or (e < a and g < c and d < b and h < f):

        form = 'Strong Dominance'
        list_of_strats.append(form)

        # there is a sub-set of these which is characterised in this way
        if ((a < e and c < g and b < d and f < h) and (e > g and d > h)) or ((e < a and g < c and d < b and h < f) and (a < c and b < f)):

            form = 'Strong Deadlock'
            list_of_strats.append(form)

            if c < g < a < e and f < h < b < d:
                form = 'Prisoners Dilemma'
                list_of_strats.append(form)

        # if a < e and c < g and b < d and f < h and np.max(aggr_payoffs) == aggr_payoffs[3]:
        #     form = 'Strong Deadlock'
        #     list_of_strats.append(form)
        #
        # if a < e and c < g and d < b and h < f and np.max(aggr_payoffs) == aggr_payoffs[2]:
        #     form = 'Strong Deadlock'
        #     list_of_strats.append(form)
        #
        # if e < a and g < c and b < d and f < h and np.max(aggr_payoffs) == aggr_payoffs[1]:
        #     form = 'Strong Deadlock'
        #     list_of_strats.append(form)
        #
        # if e < a and g < c and d < b and h < f and np.max(aggr_payoffs) == aggr_payoffs[0]:
        #     form = 'Strong Deadlock'
        #     list_of_strats.append(form)

    # and now for agents with weakly dominant strategies
    # i has weakly dominant strategy (pref eg)
    if (a < e and c == g) or (a == e and c < g):

        # j can have weakly or strongly dominant strategy
        if (b < d and f < h) or (b < d and f == h) or (b == d and f < h):
            form = 'Weak Dominance'
            list_of_strats.append(form)

        if (d < b and h < f) or (d < b and h == f) or (d == b and h < f):
            form = 'Weak Dominance'
            list_of_strats.append(form)

    # i has weakly dominant strategy (pref ac)
    if (e < a and g == c) or (e == a and g < c):

        if (b < d and f < h) or (b < d and f == h) or (b == d and f < h):
            form = 'Weak Dominance'
            list_of_strats.append(form)

        if (d < b and h < f) or (d < b and h == f) or (d == b and h < f):
            form = 'Weak Dominance'
            list_of_strats.append(form)

    if form != 'Weak Dominance':        # there might be double counting so we only need to apply the following code if we don't already have 'Weak Dominance'

        # j has weakly dominant strategy (pref dh)
        if (b < d and f == h) or (b == d and f < h):

            # i can have weakly or strongly dominant strategy
            if (a < e and c < g) or (a < e and c == g) or (a == e and c < g):
                form = 'Weak Dominance'
                list_of_strats.append(form)

            if (e < a and g < c) or (e < a and g == c) or (e == a and g < c):
                form = 'Weak Dominance'
                list_of_strats.append(form)

        # j has weakly dominant strategy (pref bf)
        if (b > d and f == h) or (b == d and f > h):

            if (a < e and c < g) or (a < e and c == g) or (a == e and c < g):
                form = 'Weak Dominance'
                list_of_strats.append(form)

            if (e < a and g < c) or (e < a and g == c) or (e == a and g < c):
                form = 'Weak Dominance'
                list_of_strats.append(form)

    # if c < g < a < e and h < f < b < d:
    #     form = 'Dominant / Subordinate Pigs'
    #     list_of_strats.append(form)

    # if len(list_of_strats) > 1:
    #     print('\n payoffs ', payoffs)
    #     print('\n list_of_strats =', list_of_strats)
        # pause()

    # account for the fact it's possible for both of these to co-exist (note stag-hunt is considered a sub-game of assurance):
    if len(list_of_strats) == 2 and 'Coordination Game: Assurance' in list_of_strats and 'Coordination Game: Battle of the Sexes' in list_of_strats:
        form = 'Coordination Game: Assurance & Battle of the Sexes'

    # account for the fact that some games can be both stag hunt and BoS:
    if len(list_of_strats) == 3 and 'Coordination Game: Assurance' in list_of_strats and 'Coordination Game: Stag Hunt' in list_of_strats and 'Coordination Game: Battle of the Sexes' in list_of_strats:
        form = 'Coordination Game: Stag Hunt & Battle of the Sexes'

    # if len(list_of_strats) > 1 and (len(list_of_strats) == 3 and 'Prisoners Dilemma' in list_of_strats and 'Strong Dominance' in list_of_strats and 'Strong Deadlock' in list_of_strats) is False\
    #         and (len(list_of_strats) == 2 and 'Strong Dominance' in list_of_strats and 'Strong Deadlock' in list_of_strats) is False\
    #         and (len(list_of_strats) == 2 and 'Coordination Game: Assurance' in list_of_strats and 'Coordination Game: Stag Hunt' in list_of_strats) is False\
    #         and (len(list_of_strats) == 2 and 'Coordination Game: Assurance' in list_of_strats and 'Coordination Game: Battle of the Sexes' in list_of_strats) is False\
    #         and (len(list_of_strats) == 3 and 'Coordination Game: Assurance' in list_of_strats and 'Coordination Game: Stag Hunt' in list_of_strats and 'Coordination Game: Battle of the Sexes' in list_of_strats) is False:
    #     print('\n payoffs:\n', payoffs[0], payoffs[1])
    #     print(' ', payoffs[2], payoffs[3])
    #     print('\n des_string: ', find_des_string(payoffs, print_fine_dets=0))
    #     print('\n list_of_strats =', list_of_strats)
    #     print('\n form =', form)
    #     pause()

    return form


def agents_trading_Walras_Style(params, KO_pop, town_grid, agent_population, print_dets, trade_moves, trade_movemnt, vision_len, day,
                               trade_loc, print_fine_dets, tracking_agent, wait_at_target_til_end, wait_at_tgt_moves, track_agent, trgt_sel,
                               dimen, trade_when_trgt, goods_signal, run_folder,
                               print_round_trans, df_daily, dbs, granular_mem, fountain_population, print_move_heat_maps, trade_prices,
                               rounds, gen_equ_thresh, gen_equ_wh_lps, SD_charts_freq, price_mean, force_prices, fixed_price,
                               keynesian_ratio, find_gen_equ_PQ, use_parallel_code, price_grid_dimen, test_par_code, print_plotly_charts,
                               print_MRS_std_charts, const_mkt_opens):

    # update MRS arrays to start and then save data if required
    for agent in agent_population.pop:

        agent.update_agent_MRS_array(print_dets, print_fine_dets, agent_population)

    # this line generates the supply & demand data for the 2d charts and it also finds the market clearing price and quantity when num_res_founts == 2
    if num_res_founts == 2:

        # create_supply_demand_data(fountain_population, agent_population, print_dets, print_fine_dets, data_folder, day, dbs, gen_equ_thresh, agent_list, record_dbs_data, tribe)

        supply_demand_array = create_supply_demand_data(params, fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, gen_equ_thresh, dbs.agent_list, record_dbs_data=1, tribe='none')

    for agent in agent_population.pop:

#        print('\nagent:', agent, 'home', agent.home, 'res_array =', agent.agent_res_array[0], 'basket:', agent.basket_array, 'optimal trans', agent.optimal_transs_systemic[day])

        for res in range(num_res_founts):

            agent.basket_array[0][res] -= agent.optimal_transs_systemic[day][res]

            if agent.basket_array[0][res] < 0:

                print('PROMBLEM in agents_trading_Walras_Style: agent.basket_array[0][res] < 0')

                pause()

#        print('resulting basket =', agent.basket_array)

#    input("Press Enter to continue...")


def find_total_res_reduced_value(agent, print_fine_dets):

    """This function finds the reduced value of an agent's resources holdings (personal resources and basket) and returns the total reduced value."""

    agent_tot_ress = agent.agent_res_array + agent.basket_array

    agent_lowest_res = 0

    if agent_tot_ress[0][0] > agent_tot_ress[0][1]:
        agent_lowest_res = 1

    if print_fine_dets:
        print('\n agent.agent_res_array', agent.agent_res_array)
        print(' agent.basket_array', agent.basket_array)
        print('\n agent_tot_ress', agent_tot_ress)

    agent_MRS_array = generate_MRS_array(agent_tot_ress, print_fine_dets=0)

    if print_fine_dets:
        print('\n agent_MRS_array:\n', agent_MRS_array)

    total_res_reduced_val = 0

    for res in range(num_res_founts):

        # if print_fine_dets == 1 or print_model_2_dets == 1:
        if print_fine_dets:
            print('\n res ', res)

        if res == agent_lowest_res:

            total_res_reduced_val += agent_tot_ress[0][res]

        else:

            total_res_reduced_val += agent_MRS_array[agent_lowest_res][res] * agent_tot_ress[0][res]

    if print_fine_dets:
        print('\n end total_res_reduced_val =', total_res_reduced_val)

    return total_res_reduced_val


def test_NN_coefficients(params, day, agent_population, fountain_population, dbs, use_start_basket, print_dets, print_fine_dets):

    """This function runs a set of tests for the agents' NNs: it tests the impact of an agent's personal resources and basket items, a hypothetical cp's personal resources and basket,
    and also the expected ps and pfb of the hypothetical cp."""

    print_fine_dets = 0

    all_res_agent_array_ps = []
    all_res_agent_array_pfb = []

    # agent's res 0
    for res_level in [75, 80, 85, 90, 95, 100, 105, 110, 115]:

        if print_fine_dets:
            print('\n\n ---> res_level', res_level, '\n')

        res_array_0 = np.array([[res_level, 105]])
        bskt_array_0 = np.array([[2, 2]])

        res_array_1 = np.array([[105, 95]])
        bskt_array_1 = np.array([[2, 2]])

        cp_ps = 0.5
        cp_pfb = 0.5

        all_agent_array_ps = []
        all_agent_array_pfb = []

        for agent in agent_population.pop:

            # print('\n agent.home', agent.home, '\n')

            flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets)

            if params.num_NNs == 1:

                agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_probs[0][0]
                pfb = agent.intn_probs[1][0]

            elif params.num_NNs == 2:

                if params.NN_inputs == 'game_6':

                    ag_ps_inputs = flatten_rtns_matrix
                    ag_fb_inputs = flatten_rtns_matrix

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]
                    pfb = agent.intn_prob_pfb[0][0]

                elif params.NN_inputs == 'mixed':

                    ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    pfb = agent.intn_prob_pfb[0][0]

                    ag_ps_inputs = np.zeros(shape=(10, 1))

                    ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                    ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                    ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                    ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                    ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                    ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]

                    if print_fine_dets:
                        print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                        print('\n ag_fb_inputs \n', ag_fb_inputs)
                        print('\n pfb \n', pfb)
                        print('\n ag_ps_inputs \n', ag_ps_inputs)
                        print('\n ps \n', ps)

            all_agent_array_ps.append(ps)
            all_agent_array_pfb.append(pfb)

            if print_fine_dets:
                print(' agent.home =', agent.home, ' ps =', ps, 'pfb =', pfb)

        all_res_agent_array_ps.append(all_agent_array_ps)
        all_res_agent_array_pfb.append(all_agent_array_pfb)

    dbs.NN_tests_ps_ag_res_0.append(all_res_agent_array_ps)
    dbs.NN_tests_pfb_ag_res_0.append(all_res_agent_array_pfb)

    # pause()

    if print_fine_dets:
        print('\n dbs.NN_tests_ps_ag_res_0 :\n', dbs.NN_tests_ps_ag_res_0)

    all_res_agent_array_ps = []
    all_res_agent_array_pfb = []

    # agent's res 1
    for res_level in [85, 90, 95, 100, 105, 110, 115, 120, 125]:

        if print_fine_dets:
            print('\n\n ---> res_level', res_level, '\n')

        res_array_0 = np.array([[95, res_level]])
        bskt_array_0 = np.array([[2, 2]])

        res_array_1 = np.array([[105, 95]])
        bskt_array_1 = np.array([[2, 2]])

        cp_ps = 0.5
        cp_pfb = 0.5

        all_agent_array_ps = []
        all_agent_array_pfb = []

        for agent in agent_population.pop:

            # print('\n agent.home', agent.home, '\n')

            flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets)

            if params.num_NNs == 1:

                agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_probs[0][0]
                pfb = agent.intn_probs[1][0]

            elif params.num_NNs == 2:

                if params.NN_inputs == 'game_6':

                    ag_ps_inputs = flatten_rtns_matrix
                    ag_fb_inputs = flatten_rtns_matrix

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]
                    pfb = agent.intn_prob_pfb[0][0]

                elif params.NN_inputs == 'mixed':

                    ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    pfb = agent.intn_prob_pfb[0][0]

                    ag_ps_inputs = np.zeros(shape=(10, 1))

                    ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                    ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                    ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                    ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                    ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                    ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]

                    if print_fine_dets:
                        print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                        print('\n ag_fb_inputs \n', ag_fb_inputs)
                        print('\n pfb \n', pfb)
                        print('\n ag_ps_inputs \n', ag_ps_inputs)
                        print('\n ps \n', ps)

            all_agent_array_ps.append(ps)
            all_agent_array_pfb.append(pfb)

            if print_fine_dets:
                print(' agent.home =', agent.home, ' ps =', ps, 'pfb =', pfb)

        all_res_agent_array_ps.append(all_agent_array_ps)
        all_res_agent_array_pfb.append(all_agent_array_pfb)

    dbs.NN_tests_ps_ag_res_1.append(all_res_agent_array_ps)
    dbs.NN_tests_pfb_ag_res_1.append(all_res_agent_array_pfb)

    if print_fine_dets:
        print('\n dbs.NN_tests_ps_ag_res_1 :\n', dbs.NN_tests_ps_ag_res_1)

    all_res_agent_array_ps = []
    all_res_agent_array_pfb = []

    # cp's res 0
    for res_level in [85, 90, 95, 100, 105, 110, 115, 120, 125]:

        if print_fine_dets:
            print('\n\n ---> res_level', res_level, '\n')

        res_array_0 = np.array([[95, 105]])
        bskt_array_0 = np.array([[2, 2]])

        res_array_1 = np.array([[res_level, 95]])
        bskt_array_1 = np.array([[2, 2]])

        cp_ps = 0.5
        cp_pfb = 0.5

        all_agent_array_ps = []
        all_agent_array_pfb = []

        for agent in agent_population.pop:

            # print('\n agent.home', agent.home, '\n')

            flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets)

            if params.num_NNs == 1:

                agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_probs[0][0]
                pfb = agent.intn_probs[1][0]

            elif params.num_NNs == 2:

                if params.NN_inputs == 'game_6':

                    ag_ps_inputs = flatten_rtns_matrix
                    ag_fb_inputs = flatten_rtns_matrix

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]
                    pfb = agent.intn_prob_pfb[0][0]

                elif params.NN_inputs == 'mixed':

                    ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    pfb = agent.intn_prob_pfb[0][0]

                    ag_ps_inputs = np.zeros(shape=(10, 1))

                    ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                    ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                    ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                    ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                    ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                    ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]

                    if print_fine_dets:
                        print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                        print('\n ag_fb_inputs \n', ag_fb_inputs)
                        print('\n pfb \n', pfb)
                        print('\n ag_ps_inputs \n', ag_ps_inputs)
                        print('\n ps \n', ps)

            all_agent_array_ps.append(ps)
            all_agent_array_pfb.append(pfb)

            if print_fine_dets:
                print(' agent.home =', agent.home, ' ps =', ps, 'pfb =', pfb)

        all_res_agent_array_ps.append(all_agent_array_ps)
        all_res_agent_array_pfb.append(all_agent_array_pfb)

    dbs.NN_tests_ps_cp_res_0.append(all_res_agent_array_ps)
    dbs.NN_tests_pfb_cp_res_0.append(all_res_agent_array_pfb)

    if print_fine_dets:
        print('\n dbs.NN_tests_ps_cp_res_0 :\n', dbs.NN_tests_ps_cp_res_0)

    all_res_agent_array_ps = []
    all_res_agent_array_pfb = []

    # agent's res 0
    for res_level in [75, 80, 85, 90, 95, 100, 105, 110, 115]:

        if print_fine_dets:
            print('\n\n ---> res_level', res_level, '\n')

        res_array_0 = np.array([[95, 105]])
        bskt_array_0 = np.array([[2, 2]])

        res_array_1 = np.array([[105, res_level]])
        bskt_array_1 = np.array([[2, 2]])

        cp_ps = 0.5
        cp_pfb = 0.5

        all_agent_array_ps = []
        all_agent_array_pfb = []

        for agent in agent_population.pop:

            # print('\n agent.home', agent.home, '\n')

            flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets)

            if params.num_NNs == 1:

                agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_probs[0][0]
                pfb = agent.intn_probs[1][0]

            elif params.num_NNs == 2:

                if params.NN_inputs == 'game_6':

                    ag_ps_inputs = flatten_rtns_matrix
                    ag_fb_inputs = flatten_rtns_matrix

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]
                    pfb = agent.intn_prob_pfb[0][0]

                elif params.NN_inputs == 'mixed':

                    ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    pfb = agent.intn_prob_pfb[0][0]

                    ag_ps_inputs = np.zeros(shape=(10, 1))

                    ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                    ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                    ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                    ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                    ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                    ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]

                    if print_fine_dets:
                        print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                        print('\n ag_fb_inputs \n', ag_fb_inputs)
                        print('\n pfb \n', pfb)
                        print('\n ag_ps_inputs \n', ag_ps_inputs)
                        print('\n ps \n', ps)

            all_agent_array_ps.append(ps)
            all_agent_array_pfb.append(pfb)

            if print_fine_dets:
                print(' agent.home =', agent.home, ' ps =', ps, 'pfb =', pfb)

        all_res_agent_array_ps.append(all_agent_array_ps)
        all_res_agent_array_pfb.append(all_agent_array_pfb)

    dbs.NN_tests_ps_cp_res_1.append(all_res_agent_array_ps)
    dbs.NN_tests_pfb_cp_res_1.append(all_res_agent_array_pfb)

    if print_fine_dets:
        print('\n dbs.NN_tests_ps_cp_res_1 :\n', dbs.NN_tests_ps_cp_res_1)

    all_res_agent_array_ps = []
    all_res_agent_array_pfb = []

    # agent's bsk 0
    for res_level in [0, 2, 4, 6, 8, 10, 50, 100]:

        if print_fine_dets:
            print('\n\n ---> res_level', res_level, '\n')

        res_array_0 = np.array([[95, 105]])
        bskt_array_0 = np.array([[res_level, 2]])

        res_array_1 = np.array([[105, 95]])
        bskt_array_1 = np.array([[2, 2]])

        cp_ps = 0.5
        cp_pfb = 0.5

        all_agent_array_ps = []
        all_agent_array_pfb = []

        for agent in agent_population.pop:

            # print('\n agent.home', agent.home, '\n')

            flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets)

            if params.num_NNs == 1:

                agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_probs[0][0]
                pfb = agent.intn_probs[1][0]

            elif params.num_NNs == 2:

                if params.NN_inputs == 'game_6':

                    ag_ps_inputs = flatten_rtns_matrix
                    ag_fb_inputs = flatten_rtns_matrix

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]
                    pfb = agent.intn_prob_pfb[0][0]

                elif params.NN_inputs == 'mixed':

                    ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    pfb = agent.intn_prob_pfb[0][0]

                    ag_ps_inputs = np.zeros(shape=(10, 1))

                    ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                    ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                    ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                    ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                    ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                    ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]

                    if print_fine_dets:
                        print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                        print('\n ag_fb_inputs \n', ag_fb_inputs)
                        print('\n pfb \n', pfb)
                        print('\n ag_ps_inputs \n', ag_ps_inputs)
                        print('\n ps \n', ps)

            all_agent_array_ps.append(ps)
            all_agent_array_pfb.append(pfb)

            if print_fine_dets:
                print(' agent.home =', agent.home, ' ps =', ps, 'pfb =', pfb)

        all_res_agent_array_ps.append(all_agent_array_ps)
        all_res_agent_array_pfb.append(all_agent_array_pfb)

    dbs.NN_tests_ps_ag_bsk_0.append(all_res_agent_array_ps)
    dbs.NN_tests_pfb_ag_bsk_0.append(all_res_agent_array_pfb)

    if print_fine_dets:
        print('\n dbs.NN_tests_ps_ag_bsk_0 :\n', dbs.NN_tests_ps_ag_bsk_0)

    all_res_agent_array_ps = []
    all_res_agent_array_pfb = []

    # agent's bsk 1
    for res_level in [0, 2, 4, 6, 8, 10, 50, 100]:

        if print_fine_dets:
            print('\n\n ---> res_level', res_level, '\n')

        res_array_0 = np.array([[95, 105]])
        bskt_array_0 = np.array([[2, res_level]])

        res_array_1 = np.array([[105, 95]])
        bskt_array_1 = np.array([[2, 2]])

        cp_ps = 0.5
        cp_pfb = 0.5

        all_agent_array_ps = []
        all_agent_array_pfb = []

        for agent in agent_population.pop:

            # print('\n agent.home', agent.home, '\n')

            flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets)

            if params.num_NNs == 1:

                agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_probs[0][0]
                pfb = agent.intn_probs[1][0]

            elif params.num_NNs == 2:

                if params.NN_inputs == 'game_6':

                    ag_ps_inputs = flatten_rtns_matrix
                    ag_fb_inputs = flatten_rtns_matrix

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]
                    pfb = agent.intn_prob_pfb[0][0]

                elif params.NN_inputs == 'mixed':

                    ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    pfb = agent.intn_prob_pfb[0][0]

                    ag_ps_inputs = np.zeros(shape=(10, 1))

                    ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                    ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                    ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                    ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                    ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                    ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]

                    if print_fine_dets:
                        print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                        print('\n ag_fb_inputs \n', ag_fb_inputs)
                        print('\n pfb \n', pfb)
                        print('\n ag_ps_inputs \n', ag_ps_inputs)
                        print('\n ps \n', ps)

            all_agent_array_ps.append(ps)
            all_agent_array_pfb.append(pfb)

            if print_fine_dets:
                print(' agent.home =', agent.home, ' ps =', ps, 'pfb =', pfb)

        all_res_agent_array_ps.append(all_agent_array_ps)
        all_res_agent_array_pfb.append(all_agent_array_pfb)

    dbs.NN_tests_ps_ag_bsk_1.append(all_res_agent_array_ps)
    dbs.NN_tests_pfb_ag_bsk_1.append(all_res_agent_array_pfb)

    if print_fine_dets:
        print('\n dbs.NN_tests_ps_ag_bsk_1 :\n', dbs.NN_tests_ps_ag_bsk_1)

    all_res_agent_array_ps = []
    all_res_agent_array_pfb = []

    # cp's bsk 0
    for res_level in [0, 2, 4, 6, 8, 10, 50, 100]:

        if print_fine_dets:
            print('\n\n ---> res_level', res_level, '\n')

        res_array_0 = np.array([[95, 105]])
        bskt_array_0 = np.array([[2, 2]])

        res_array_1 = np.array([[105, 95]])
        bskt_array_1 = np.array([[res_level, 2]])

        cp_ps = 0.5
        cp_pfb = 0.5

        all_agent_array_ps = []
        all_agent_array_pfb = []

        for agent in agent_population.pop:

            # print('\n agent.home', agent.home, '\n')

            flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets)

            if params.num_NNs == 1:

                agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_probs[0][0]
                pfb = agent.intn_probs[1][0]

            elif params.num_NNs == 2:

                if params.NN_inputs == 'game_6':

                    ag_ps_inputs = flatten_rtns_matrix
                    ag_fb_inputs = flatten_rtns_matrix

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]
                    pfb = agent.intn_prob_pfb[0][0]

                elif params.NN_inputs == 'mixed':

                    ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    pfb = agent.intn_prob_pfb[0][0]

                    ag_ps_inputs = np.zeros(shape=(10, 1))

                    ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                    ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                    ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                    ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                    ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                    ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]

                    if print_fine_dets:
                        print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                        print('\n ag_fb_inputs \n', ag_fb_inputs)
                        print('\n pfb \n', pfb)
                        print('\n ag_ps_inputs \n', ag_ps_inputs)
                        print('\n ps \n', ps)

            all_agent_array_ps.append(ps)
            all_agent_array_pfb.append(pfb)

            if print_fine_dets:
                print(' agent.home =', agent.home, ' ps =', ps, 'pfb =', pfb)

        all_res_agent_array_ps.append(all_agent_array_ps)
        all_res_agent_array_pfb.append(all_agent_array_pfb)

    dbs.NN_tests_ps_cp_bsk_0.append(all_res_agent_array_ps)
    dbs.NN_tests_pfb_cp_bsk_0.append(all_res_agent_array_pfb)

    if print_fine_dets:
        print('\n dbs.NN_tests_ps_cp_bsk_0 :\n', dbs.NN_tests_ps_cp_bsk_0)

    all_res_agent_array_ps = []
    all_res_agent_array_pfb = []

    # cp's bsk 1
    for res_level in [0, 2, 4, 6, 8, 10, 50, 100]:

        if print_fine_dets:
            print('\n\n ---> res_level', res_level, '\n')

        res_array_0 = np.array([[95, 105]])
        bskt_array_0 = np.array([[2, 2]])

        res_array_1 = np.array([[105, 95]])
        bskt_array_1 = np.array([[2, res_level]])

        cp_ps = 0.5
        cp_pfb = 0.5

        all_agent_array_ps = []
        all_agent_array_pfb = []

        for agent in agent_population.pop:

            # print('\n agent.home', agent.home, '\n')

            flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets)

            if params.num_NNs == 1:

                agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_probs[0][0]
                pfb = agent.intn_probs[1][0]

            elif params.num_NNs == 2:

                if params.NN_inputs == 'game_6':

                    ag_ps_inputs = flatten_rtns_matrix
                    ag_fb_inputs = flatten_rtns_matrix

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]
                    pfb = agent.intn_prob_pfb[0][0]

                elif params.NN_inputs == 'mixed':

                    ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    pfb = agent.intn_prob_pfb[0][0]

                    ag_ps_inputs = np.zeros(shape=(10, 1))

                    ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                    ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                    ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                    ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                    ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                    ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]

                    if print_fine_dets:
                        print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                        print('\n ag_fb_inputs \n', ag_fb_inputs)
                        print('\n pfb \n', pfb)
                        print('\n ag_ps_inputs \n', ag_ps_inputs)
                        print('\n ps \n', ps)

            all_agent_array_ps.append(ps)
            all_agent_array_pfb.append(pfb)

            if print_fine_dets:
                print(' agent.home =', agent.home, ' ps =', ps, 'pfb =', pfb)

        all_res_agent_array_ps.append(all_agent_array_ps)
        all_res_agent_array_pfb.append(all_agent_array_pfb)

    dbs.NN_tests_ps_cp_bsk_1.append(all_res_agent_array_ps)
    dbs.NN_tests_pfb_cp_bsk_1.append(all_res_agent_array_pfb)

    if print_fine_dets:
        print('\n dbs.NN_tests_ps_cp_bsk_1 :\n', dbs.NN_tests_ps_cp_bsk_1)

    all_res_agent_array_ps = []
    all_res_agent_array_pfb = []

    # cp's ps
    for ps in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:

        if print_fine_dets:
            print('\n\n ---> ps', ps, '\n')

        res_array_0 = np.array([[95, 105]])
        bskt_array_0 = np.array([[2, 2]])

        res_array_1 = np.array([[105, 95]])
        bskt_array_1 = np.array([[2, 2]])

        cp_ps = ps
        cp_pfb = 0.5

        all_agent_array_ps = []
        all_agent_array_pfb = []

        for agent in agent_population.pop:

            # print('\n agent.home', agent.home, '\n')

            flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets)

            if params.num_NNs == 1:

                agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_probs[0][0]
                pfb = agent.intn_probs[1][0]

            elif params.num_NNs == 2:

                if params.NN_inputs == 'game_6':

                    ag_ps_inputs = flatten_rtns_matrix
                    ag_fb_inputs = flatten_rtns_matrix

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]
                    pfb = agent.intn_prob_pfb[0][0]

                elif params.NN_inputs == 'mixed':

                    ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    pfb = agent.intn_prob_pfb[0][0]

                    ag_ps_inputs = np.zeros(shape=(10, 1))

                    ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                    ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                    ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                    ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                    ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                    ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]

                    if print_fine_dets:
                        print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                        print('\n ag_fb_inputs \n', ag_fb_inputs)
                        print('\n pfb \n', pfb)
                        print('\n ag_ps_inputs \n', ag_ps_inputs)
                        print('\n ps \n', ps)

            all_agent_array_ps.append(ps)
            all_agent_array_pfb.append(pfb)

            if print_fine_dets:
                print(' agent.home =', agent.home, ' ps =', ps, 'pfb =', pfb)

        all_res_agent_array_ps.append(all_agent_array_ps)
        all_res_agent_array_pfb.append(all_agent_array_pfb)

    dbs.NN_tests_ps_cp_ps.append(all_res_agent_array_ps)
    dbs.NN_tests_pfb_cp_ps.append(all_res_agent_array_pfb)

    if print_fine_dets:
        print('\n dbs.NN_tests_ps_cp_ps :\n', dbs.NN_tests_ps_cp_ps)
        print('\n dbs.NN_tests_pfb_cp_ps :\n', dbs.NN_tests_pfb_cp_ps)

    all_res_agent_array_ps = []
    all_res_agent_array_pfb = []

    # cp's ps
    for pfb in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:

        if print_fine_dets:
            print('\n\n ---> pfb', pfb, '\n')

        res_array_0 = np.array([[95, 105]])
        bskt_array_0 = np.array([[2, 2]])

        res_array_1 = np.array([[105, 95]])
        bskt_array_1 = np.array([[2, 2]])

        cp_ps = 0.5
        cp_pfb = pfb

        all_agent_array_ps = []
        all_agent_array_pfb = []

        for agent in agent_population.pop:

            # print('\n agent.home', agent.home, '\n')

            flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets)

            if params.num_NNs == 1:

                agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_probs[0][0]
                pfb = agent.intn_probs[1][0]

            elif params.num_NNs == 2:

                if params.NN_inputs == 'game_6':

                    ag_ps_inputs = flatten_rtns_matrix
                    ag_fb_inputs = flatten_rtns_matrix

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]
                    pfb = agent.intn_prob_pfb[0][0]

                elif params.NN_inputs == 'mixed':

                    ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                    agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    pfb = agent.intn_prob_pfb[0][0]

                    ag_ps_inputs = np.zeros(shape=(10, 1))

                    ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                    ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                    ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                    ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                    ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                    ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                    agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    ps = agent.intn_prob_ps[0][0]

                    if print_fine_dets:
                        print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                        print('\n ag_fb_inputs \n', ag_fb_inputs)
                        print('\n pfb \n', pfb)
                        print('\n ag_ps_inputs \n', ag_ps_inputs)
                        print('\n ps \n', ps)

            all_agent_array_ps.append(ps)
            all_agent_array_pfb.append(pfb)

            if print_fine_dets:
                print(' agent.home =', agent.home, ' ps =', ps, 'pfb =', pfb)

        all_res_agent_array_ps.append(all_agent_array_ps)
        all_res_agent_array_pfb.append(all_agent_array_pfb)

    dbs.NN_tests_ps_cp_pfb.append(all_res_agent_array_ps)
    dbs.NN_tests_pfb_cp_pfb.append(all_res_agent_array_pfb)

    if print_fine_dets:
        print('\n dbs.NN_tests_ps_cp_pfb :\n', dbs.NN_tests_ps_cp_pfb)
        print('\n dbs.NN_tests_pfb_cp_pfb :\n', dbs.NN_tests_pfb_cp_pfb)

    # now for last layer's intercept terms and coefficienct
    res_array_0 = np.array([[95, 105]])
    bskt_array_0 = np.array([[2, 2]])

    res_array_1 = np.array([[105, 95]])
    bskt_array_1 = np.array([[2, 2]])

    # res_array_0 = np.array([[95, 105]])
    # bskt_array_0 = np.array([[1, 1]])
    #
    # res_array_1 = np.array([[105, 95]])
    # bskt_array_1 = np.array([[1, 1]])

    cp_ps = 0.5
    cp_pfb = 0.5

    flatten_rtns_matrix = generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets=0)

    final_layer_agent_data_ps = []
    final_layer_agent_data_pfb = []

    # print('\n flatten_rtns_matrix = \n', flatten_rtns_matrix)
    # pause()

    for agent in agent_population.pop:

        if params.num_NNs == 1:

            agent_NN_params_W1_zero = copy.copy(agent.NN_parameters)

            agent_NN_params_W1_zero['W1'] = np.zeros(shape=(params.NN_dimensions[0], params.NN_dimensions[1]))

            agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

            agent_intn_probs_W1_zero, agent_caches_W1_zero = L_model_forward(flatten_rtns_matrix, agent_NN_params_W1_zero, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

            # we use cache data to derive the following, which corresponds to the last layer in the NN
            A_prev = agent.caches[-1][0][0]
            W = agent.caches[-1][0][1]
    
            # A_prev = agent.caches[2][0][0]
            # W = agent.caches[2][0][1]
    
            A_prev_dot_W = np.dot(W, A_prev)
    
            b = agent.caches[-1][-2][-1]
    
            Z = agent.caches[-1][-1]
    
            # print('\n original Z = \n', Z)
    
            Z_W1_zero = agent_caches_W1_zero[-1][-1]
    
            # print('\n Z_W1_zero = \n', Z_W1_zero)
    
            activation_data = sigmoid(agent.caches[-1][-1], params.sigmoid_coefficient)
    
            A_ps = activation_data[0][0][0]
            A_pfb = activation_data[0][1][0]

            # print('\n\n\n A_prev', A_prev)
            # print('\n W', W)
            # print('\n A_prev_dot_W', A_prev_dot_W)
            # print('\n b', b)
            # print('\n Z', Z)
            # print('\n A_ps', A_ps)
            # print('\n A_pfb', A_pfb)
    
            final_layer_agent_data_ps.append([A_prev_dot_W[0][0], b[0][0], Z[0][0], Z_W1_zero[0][0], A_ps])
            final_layer_agent_data_pfb.append([A_prev_dot_W[1][0], b[1][0], Z[1][0], Z_W1_zero[1][0], A_pfb])

        elif params.num_NNs == 2:

            if params.NN_inputs == 'game_6':

                ag_ps_inputs = flatten_rtns_matrix
                ag_fb_inputs = flatten_rtns_matrix

                agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                ps = agent.intn_prob_ps[0][0]
                pfb = agent.intn_prob_pfb[0][0]

                # print('\n agent.NN_parameters_ps[W1].shape =', agent.NN_parameters_ps['W1'].shape)

                agent_NN_params_ps_W1_zero = copy.copy(agent.NN_parameters_ps)

                agent_NN_params_ps_W1_zero['W1'] = np.zeros(shape=(agent.NN_parameters_ps['W1'].shape[0], agent.NN_parameters_ps['W1'].shape[1]))

                agent_NN_params_pfb_W1_zero = copy.copy(agent.NN_parameters_pfb)

                agent_NN_params_pfb_W1_zero['W1'] = np.zeros(shape=(agent.NN_parameters_pfb['W1'].shape[0], agent.NN_parameters_pfb['W1'].shape[1]))

                # print('\n agent_NN_params_ps_W1_zero[W1].shape =', agent_NN_params_ps_W1_zero['W1'].shape)

                agent_intn_prob_ps_W1_zero, agent_caches_ps_W1_zero = L_model_forward(ag_ps_inputs, agent_NN_params_ps_W1_zero, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                agent_intn_prob_pfb_W1_zero, agent_caches_pfb_W1_zero = L_model_forward(ag_fb_inputs, agent_NN_params_pfb_W1_zero, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

            elif params.NN_inputs == 'mixed':

                ag_fb_inputs = np.array(flatten_rtns_matrix[2:6])

                agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_fb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                pfb = agent.intn_prob_pfb[0][0]

                ag_ps_inputs = np.zeros(shape=(10, 1))

                ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                ag_ps_inputs[2] = (flatten_rtns_matrix[2] * pfb) + (flatten_rtns_matrix[4] * (1 - pfb))
                ag_ps_inputs[3] = (flatten_rtns_matrix[3] * pfb) + (flatten_rtns_matrix[5] * (1 - pfb))
                ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                if print_fine_dets:
                    print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                    print('\n ag_fb_inputs \n', ag_fb_inputs)
                    print('\n pfb \n', pfb)
                    print('\n ag_ps_inputs \n', ag_ps_inputs)
                    print('\n ps \n', ps)

                agent_NN_params_ps_W1_zero = copy.copy(agent.NN_parameters_ps)

                agent_NN_params_ps_W1_zero['W1'] = np.zeros(shape=(params.NN_dimensions_ps[0], params.NN_dimensions_ps[1]))

                agent_NN_params_pfb_W1_zero = copy.copy(agent.NN_parameters_pfb)

                agent_NN_params_pfb_W1_zero['W1'] = np.zeros(shape=(params.NN_dimensions_pfb[0], params.NN_dimensions_pfb[1]))

                agent_intn_prob_pfb_W1_zero, agent_caches_pfb_W1_zero = L_model_forward(ag_fb_inputs, agent_NN_params_pfb_W1_zero, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                pfb_W1_zero = agent_intn_prob_pfb_W1_zero[0][0]

                ag_ps_inputs_W1_0 = np.zeros(shape=(10, 1))

                ag_ps_inputs_W1_0[0:2] = flatten_rtns_matrix[0:2]
                ag_ps_inputs_W1_0[2] = (flatten_rtns_matrix[2] * pfb_W1_zero) + (flatten_rtns_matrix[4] * (1 - pfb_W1_zero))
                ag_ps_inputs_W1_0[3] = (flatten_rtns_matrix[3] * pfb_W1_zero) + (flatten_rtns_matrix[5] * (1 - pfb_W1_zero))
                ag_ps_inputs_W1_0[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                ag_ps_inputs_W1_0[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                ag_ps_inputs_W1_0[6:] = flatten_rtns_matrix[10:]

                if print_fine_dets:

                    print("\n agent_NN_params_pfb_W1_zero['W1'] \n", agent_NN_params_pfb_W1_zero['W1'])
                    print("\n agent_NN_params_ps_W1_zero['W1'] \n", agent_NN_params_ps_W1_zero['W1'])
                    print('\n pfb_W1_zero =', pfb_W1_zero)
                    print('\n ag_ps_inputs_W1_0 =', ag_ps_inputs_W1_0)

                agent_intn_prob_ps_W1_zero, agent_caches_ps_W1_zero = L_model_forward(ag_ps_inputs_W1_0, agent_NN_params_ps_W1_zero, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

            # we use cache data to derive the following, which corresponds to the last layer in the NNs
            A_prev_ps = agent.caches_ps[-1][0][0]
            A_prev_pfb = agent.caches_pfb[-1][0][0]

            W_ps = agent.caches_ps[-1][0][1]
            W_pfb = agent.caches_pfb[-1][0][1]

            A_prev_dot_W_ps = np.dot(W_ps, A_prev_ps)
            A_prev_dot_W_pfb = np.dot(W_pfb, A_prev_pfb)

            b_ps = agent.caches_ps[-1][-2][-1]
            b_pfb = agent.caches_pfb[-1][-2][-1]

            Z_ps = agent.caches_ps[-1][-1]
            Z_pfb = agent.caches_pfb[-1][-1]

            Z_W1_zero_ps = agent_caches_ps_W1_zero[-1][-1]
            Z_W1_zero_pfb = agent_caches_pfb_W1_zero[-1][-1]

            activation_data_ps = sigmoid(agent.caches_ps[-1][-1], params.sigmoid_coefficient)
            activation_data_pfb = sigmoid(agent.caches_pfb[-1][-1], params.sigmoid_coefficient)

            A_ps = activation_data_ps[0][0][0]
            A_pfb = activation_data_pfb[0][0][0]

            final_layer_agent_data_ps.append([A_prev_dot_W_ps[0][0], b_ps[0][0], Z_ps[0][0], Z_W1_zero_ps[0][0], A_ps])
            final_layer_agent_data_pfb.append([A_prev_dot_W_pfb[0][0], b_pfb[0][0], Z_pfb[0][0], Z_W1_zero_pfb[0][0], A_pfb])

            if print_fine_dets:
                print('\n final_layer_agent_data_ps  ', final_layer_agent_data_ps)
                print('\n final_layer_agent_data_pfb  ', final_layer_agent_data_pfb)

            # pause()

    if print_fine_dets:
        print('\n final_layer_agent_data_ps :\n', final_layer_agent_data_ps)
        print('\n final_layer_agent_data_pfb :\n', final_layer_agent_data_pfb)

    dbs.final_layer_ps_breakdown.append(final_layer_agent_data_ps)
    dbs.final_layer_pfb_breakdown.append(final_layer_agent_data_pfb)

    # pause()


def generate_NN_inputs(params, day, dbs, fountain_population, res_array_0, bskt_array_0, res_array_1, bskt_array_1, cp_ps, cp_pfb, use_start_basket, print_dets, print_fine_dets):

    if print_fine_dets:
        print('\n res_array_0 =', res_array_0)
        print(' bskt_array_0 =', bskt_array_0)

        print('\n res_array_1 =', res_array_1)
        print(' bskt_array_1 =', bskt_array_1)

    min_res_0 = 0

    if res_array_0[0][1] + bskt_array_0[0][1] < res_array_0[0][0] + bskt_array_0[0][0]:
        min_res_0 = 1

    min_res_1 = 0

    if res_array_1[0][1] + bskt_array_1[0][1] < res_array_1[0][0] + bskt_array_1[0][0]:
        min_res_1 = 1

    if print_fine_dets:
        print('\n min_res_0 =', min_res_0)
        print(' min_res_1 =', min_res_1)

    agent_MRS_0 = generate_MRS_array(res_array_0 + bskt_array_0, print_fine_dets)
    agent_MRS_1 = generate_MRS_array(res_array_1 + bskt_array_1, print_fine_dets)

    if print_fine_dets:
        print(' agent_MRS_0 =', agent_MRS_0)
        print('\n agent_MRS_1 =', agent_MRS_1)

    use_start_basket = 0
    tot_cons_surp_array, best_trans_data = build_tot_cons_surp_array(params, params.min_trans_Q, params.price_mean, params.force_prices, params.fixed_price, day, dbs, fountain_population, print_dets, print_fine_dets, use_start_basket,
                                                                     res_array_0, bskt_array_0, bskt_array_0, res_array_1, bskt_array_1, bskt_array_1)

    ag_sells_res, agent_buys_res, ag_sells_Q, ag_buys_Q, price = best_trans_data

    if print_fine_dets:
        print('\n tot_cons_surp_array', tot_cons_surp_array)
        print('\n best_trans_data', best_trans_data)

        print('\n ag_sells_res =', ag_sells_res)
        print(' agent_buys_res =', agent_buys_res)
        print(' ag_sells_Q =', ag_sells_Q)
        print(' ag_buys_Q =', ag_buys_Q)

    if ag_sells_res is not None:

        trade_benefit_0 = (ag_buys_Q * agent_MRS_0[min_res_0][agent_buys_res]) - (ag_sells_Q * agent_MRS_0[min_res_0][ag_sells_res])
        trade_benefit_1 = (ag_sells_Q * agent_MRS_1[min_res_1][ag_sells_res]) - (ag_buys_Q * agent_MRS_1[min_res_1][agent_buys_res])

    else:

        trade_benefit_0 = 0
        trade_benefit_1 = 0

    if print_fine_dets:
        print('\n ag_buys_Q =', ag_buys_Q)
        print(' agent_MRS_0[min_res_0][agent_buys_res] = ', agent_MRS_0[min_res_0][agent_buys_res])
        print(' ag_sells_Q =', ag_sells_Q)
        print(' agent_MRS_0[min_res_0][ag_sells_res] =', agent_MRS_0[min_res_0][ag_sells_res])

        print('\n ag_sells_Q =', ag_sells_Q)
        print(' agent_MRS_1[min_res_1][ag_sells_res] = ', agent_MRS_1[min_res_1][ag_sells_res])
        print(' ag_buys_Q =', ag_buys_Q)
        print(' agent_MRS_1[min_res_1][agent_buys_res] =', agent_MRS_1[min_res_1][agent_buys_res])

        print('\n trade_benefit_0 =', trade_benefit_0)
        print(' trade_benefit_1 =', trade_benefit_1)

    # if fight:
    fight_gain_0 = 0.5 * (bskt_array_1[0][0] * agent_MRS_0[min_res_0][0] + bskt_array_1[0][1] * agent_MRS_0[min_res_0][1] + params.fight_cost * agent_MRS_0[min_res_0][0] + params.fight_cost * agent_MRS_0[min_res_0][1]) + \
                   0.5 * (-1 * bskt_array_0[0][0] * agent_MRS_0[min_res_0][0] - bskt_array_0[0][1] * agent_MRS_0[min_res_0][1] + params.fight_cost * agent_MRS_0[min_res_0][0] + params.fight_cost * agent_MRS_0[min_res_0][1])

    fight_gain_1 = 0.5 * (bskt_array_0[0][0] * agent_MRS_1[min_res_1][0] + bskt_array_0[0][1] * agent_MRS_1[min_res_1][1] + params.fight_cost * agent_MRS_1[min_res_1][0] + params.fight_cost * agent_MRS_1[min_res_1][1]) + \
                   0.5 * (-1 * bskt_array_1[0][0] * agent_MRS_1[min_res_1][0] - bskt_array_1[0][1] * agent_MRS_1[min_res_1][1] + params.fight_cost * agent_MRS_1[min_res_1][0] + params.fight_cost * agent_MRS_1[min_res_1][1])

    if print_fine_dets:
        print('\n fight_gain_0 =', fight_gain_0)
        print(' fight_gain_1 =', fight_gain_1)

    acq_gain_0_2A = (-1 * bskt_array_0[0][0] * agent_MRS_0[min_res_0][0]) + (-1 * bskt_array_0[0][1] * agent_MRS_0[min_res_0][1])
    acq_gain_1_2A = (bskt_array_0[0][0] * agent_MRS_1[min_res_1][0]) + (bskt_array_0[0][1] * agent_MRS_1[min_res_1][1])

    acq_gain_0_3A = (bskt_array_1[0][0] * agent_MRS_0[min_res_0][0]) + (bskt_array_1[0][1] * agent_MRS_0[min_res_0][1])
    acq_gain_1_3A = (-1 * bskt_array_1[0][0] * agent_MRS_1[min_res_1][0]) + (-1 * bskt_array_1[0][1] * agent_MRS_1[min_res_1][1])

    if print_fine_dets:
        print('\n acq_gain_0_2A =', acq_gain_0_2A)
        print(' acq_gain_1_2A =', acq_gain_1_2A)

        print('\n acq_gain_0_3A =', acq_gain_0_3A)
        print(' acq_gain_1_3A =', acq_gain_1_3A)

    flatten_rtns_matrix_list = [trade_benefit_0, trade_benefit_1, fight_gain_0, fight_gain_1, acq_gain_0_2A, acq_gain_1_2A, fight_gain_0, fight_gain_1, acq_gain_0_3A, acq_gain_1_3A, fight_gain_0, fight_gain_1, cp_ps, cp_pfb]

    # if print_fine_dets:
    if print_fine_dets:
        print('\n flatten_rtns_matrix_list =', flatten_rtns_matrix_list)

    flatten_rtns_matrix = np.array([flatten_rtns_matrix_list]).T

    if print_fine_dets:
        print('\n flatten_rtns_matrix =', flatten_rtns_matrix)

    return flatten_rtns_matrix


def write_trading_array_to_text(trading_db, data_folder):
    print('---> writing data to file: trading_array_data')

    filepath = data_folder
    filename = "trading_array_data"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
    fileHandle.write("Summary Trading Data\n\n")
    #    fileHandle.write("Mean\t\tSTD\t\tMin\tMax\tthreshold (mean + 5 x std)\tlocations above threshold\n")

    for i in range(len(trading_db)):
        if i == 0:

            outString = '\nPopulation\n'
            fileHandle.write(outString)

        elif i == 1:

            outString = '\nNumber of agents trying to trade\n'
            fileHandle.write(outString)

        elif i == 2:

            outString = '\nNumber of agents remaining on grid atfer trading\n'
            fileHandle.write(outString)

        elif i == 3:

            outString = '\nProportion of agents wanting to trade left on grid\n'
            fileHandle.write(outString)

        elif i == 4:

            outString = '\nTotal goods on sale\n'
            fileHandle.write(outString)

        elif i == 5:

            outString = '\nNumber of goods sold\n'
            fileHandle.write(outString)

        elif i == 6:

            outString = '\nProportion of goods on sale which are sold\n'
            fileHandle.write(outString)

        for l in np.arange(len(trading_db[i])):  # len varies
            outString = str(trading_db[i][l]) + " "
            fileHandle.write(outString)

    fileHandle.close()


def write_popn_data_to_txt(database, data_folder, start_pop, params):

    print('---> writing population data to data file: population_raw_data')

    filepath = params.run_population_folder
    filename = "population_raw_data"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
    fileHandle.write("Summary Population Data\n\n")
    fileHandle.write("Starting population = %d\n\n" % (start_pop))
    fileHandle.write("Round\tBirths\tDeaths\tPopulation")

    for i in range(len(database[0])):

        outString = "\n"
        fileHandle.write(outString)

        for l in np.arange(len(database)):     # len varies

            outString = str(database[l][i]) + "\t"
            fileHandle.write(outString)

    fileHandle.close()


def write_text_file_readme(data_folder, param_dict, scenario, readme_notes):

    # print('---> creating readme file')

    param_key_list = sorted(param_dict, key=str.lower)

    filepath = data_folder
    filename = "0_00aa_read_me_file"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
    fileHandle.write("Parameters\n")

    fileHandle.write("\nScenario: %s  |  readme_notes: %s\n" % (scenario, readme_notes))

    for entry in param_key_list:

        fileHandle.write("\n%s = %s" % (entry, param_dict[entry]))

    fileHandle.close()


def write_daily_market_report(data_folder, dbs, fountain_population, day, start_round, end_round, print_fine_dets):
    #    print_fine_dets = 0

    filename = "daily_mkt_data"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d-%d-%d.txt' % (data_folder, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day,
                                                          dt.datetime.now().hour, dt.datetime.now().minute, dt.datetime.now().second, dt.datetime.now().microsecond / 100000), 'w')

    fileHandle.write("Daily Market Data\n\nThis file contains information about all of the market locations between days %d and %d.\n" % (start_round, end_round))

    #    # Unpack the day's transactions:
    #    days_transs = dbs.transs_daily_db[day]

    # Create an array to record which agents are at which market
    sign_mkt_locs_period = copy.copy(dbs.sign_mkt_locs[start_round])

    if print_fine_dets == 1:
        print('\n beginning sign_mkt_locs_period =', sign_mkt_locs_period)

    for d in np.arange(start_round + 1, end_round + 1):

        if print_fine_dets == 1:
            print('\n d =', d)

        for pot_mkt_loc in dbs.sign_mkt_locs[d]:

            if print_fine_dets == 1:
                print('\n pot_mkt_loc =', pot_mkt_loc)

            include_loc = 1

            for known_loc in sign_mkt_locs_period:

                if include_loc == 1:

                    if pot_mkt_loc[0] == known_loc[0] and pot_mkt_loc[1] == known_loc[1]:
                        include_loc = 0

            if include_loc == 1:

                if print_fine_dets == 1:
                    print('\n include_loc = 1')

                sign_mkt_locs_period.append(pot_mkt_loc)

    if print_fine_dets == 1:
        print('\n sign_mkt_locs_period =', sign_mkt_locs_period)

    agent_in_markets = [[] for i in range(len(sign_mkt_locs_period))]

    for d in np.arange(start_round, end_round + 1):

        if print_fine_dets == 1:
            print('\nd =', d)

        for trans_num in dbs.transs_daily_db[d]:

            trans = dbs.trans_db[trans_num]

            if print_fine_dets == 1:
                print('trans_num =', trans_num, 'location =', trans.location)

            for market_index in np.arange(len(sign_mkt_locs_period)):

                market_x = sign_mkt_locs_period[market_index][0]
                market_y = sign_mkt_locs_period[market_index][1]

                #            print '\nmarket_x =', market_x
                #            print 'trans.location =', trans.location

                if trans.location[0] == market_x and trans.location[1] == market_y:  # then we have matched a transaction to a market

                    # We add the two agents to the list of agents associated with that market
                    if trans.agent_a not in agent_in_markets[market_index]:
                        agent_in_markets[market_index].append(trans.agent_a)

                    if trans.agent_b not in agent_in_markets[market_index]:
                        agent_in_markets[market_index].append(trans.agent_b)

    if print_fine_dets == 1:
        print('\n agent_in_markets =', agent_in_markets)

    # By this point, agent_in_markets has all the agents that transacted at each market

    for market_index in np.arange(len(sign_mkt_locs_period)):

        market = sign_mkt_locs_period[market_index]

        fileHandle.write("\n\n\n\nMarket Location: %s" % (market))

        for agent in agent_in_markets[market_index]:

            total_for_start = np.zeros(shape=(num_res_founts), dtype=float)
            total_for_end = np.zeros(shape=(num_res_founts), dtype=float)

            for d in np.arange(start_round, end_round + 1):

                if print_fine_dets == 1:
                    print('\n agent.basket_array_start_hist[d] =\n', agent.basket_array_start_hist[d])
                    print('\n agent.basket_array_hist[d] =\n', agent.basket_array_hist[d])

                for res in np.arange(num_res_founts):
                    total_for_start[res] += agent.basket_array_start_hist[d][res]
                    total_for_end[res] += agent.basket_array_hist[d][res]

            total_for_start = total_for_start / float(end_round - start_round)
            total_for_end = total_for_end / float(end_round - start_round)

            if print_fine_dets == 1:
                print('\n total_for_start =', total_for_start)
                print('\n total_for_end =', total_for_end)

            sale_array = total_for_start - total_for_end

            fileHandle.write(
                "\n\nagent %s:\n\nhome is %s  |  Foraging Strat (last period) = %s  |  resources (last period) = %s  |  av. start_basket = %s  |  sale (purchase) = %s  |  birth = %s  |  \n\ntarget locations hist (last period) = %s\n\nlocations visited (last period) = %s\n" % (
                agent, agent.home, agent.for_strat_array, agent.agent_res_array, total_for_start, sale_array, agent.birth_date, agent.trgt_loc_rec, agent.trade_loc_rec))


def write_success_data(params, agent_population, dbs, print_dets, print_fine_dets, data_folder, rounds, fountain_population, for_spec_db1, for_spec_means, agent_res_init, cluster_lag, town_grid, \
                       for_strat_parts, printed_segment_size, allow_Keynes_Inst, KO_pop, constitutional_voting, constitutional_exp, num_experiments, respect_property_rights, file_type, black_shoop_exp,
                       fight_skill, two_tribes, OLS_include):

    """This data writes data to a file which is the main output data for each simulation."""

    print('---> writing data to file: Success Data')

    filepath = data_folder
    filename = "text_success_data"

    if file_type == 'html':

        fileHandle = open('%s/%s %d-%d-%d-%d-%d.html' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')

    else:

        fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')

    if file_type == 'html':
        #        fileHandle.write("<html>\n<head></head>\n<body><p>Hello World!</p></body>\n\n")
        fileHandle.write("<html>")

    if file_type == 'html':
        fileHandle.write("<h1>")
    fileHandle.write("Success Data For a Single Run\n\n\n")
    if file_type == 'html':
        fileHandle.write("</h1><body>")
        fileHandle.write("<p></p><p></p>")

    #        fileHandle.write("<style> p {margin : 0}")

    #    print("\n rounds =", rounds)
    #    print("\n type(rounds) =", type(rounds))

    ten_pct_rounds_array = np.arange(0, rounds, int(printed_segment_size), dtype=int)
    num_iters = len(ten_pct_rounds_array)
    ten_pct_gap = int(printed_segment_size)

    # print('\n ten_pct_rounds_array', ten_pct_rounds_array)
    # print(' num_iters', num_iters)
    # print(' ten_pct_gap', ten_pct_gap)
    # print('\n printed_segment_size', printed_segment_size)

    # Find Population Data
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("Population Data\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    population_data = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = ten_pct_rounds_array[iter] + ten_pct_gap
        mean_numb_agents = np.mean(dbs.main_db[3][start_round:end_round])
        std_numb_agents = np.std(dbs.main_db[3][start_round:end_round])

        if two_tribes:
            mean_numb_sharks = np.mean(dbs.pop_sharks[start_round:end_round])
            std_numb_sharks = np.std(dbs.pop_sharks[start_round:end_round])
            mean_numb_jets = np.mean(dbs.pop_jets[start_round:end_round])
            std_numb_jets = np.std(dbs.pop_jets[start_round:end_round])

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")

        if two_tribes == 0:

            fileHandle.write("\nRounds %d to %d: mean num = %2.4f (%2.4f)" % (start_round, end_round - 1, mean_numb_agents, std_numb_agents))

        elif two_tribes:

            fileHandle.write("\nRounds %d to %d: mean num ags = %2.4f (%2.4f)  |  mean num sharks =  %2.4f (%2.4f)  |  mean num jets =  %2.4f (%2.4f)" % (
            start_round, end_round - 1, mean_numb_agents, std_numb_agents, mean_numb_sharks, std_numb_sharks, mean_numb_jets, std_numb_jets))

        if file_type == 'html':
            fileHandle.write("</p>")

        if two_tribes == 0:

            population_data.append(mean_numb_agents)

        elif two_tribes:

            population_data.append([mean_numb_agents, mean_numb_sharks, mean_numb_jets])

    # Find resources foraged in the last 10% of rounds (for each resource fountain and mean) and their stds

    print('---> Success Data: Foraging Data started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\nForaging Data (total foraged from fountains in each round) - average per agent")
    if file_type == 'html':
        fileHandle.write("</h2>")

    end_foraging_data = []

    if print_fine_dets == 1:
        print('\n dbs.init_res_levels =', dbs.init_res_levels)  # note when two_tribes == 1 then this has 4 cells, not num_res_founts

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = ten_pct_rounds_array[iter] + ten_pct_gap
        mean_numb_agents = np.mean(dbs.main_db[3][start_round:end_round])

        if file_type == 'html':
            fileHandle.write("<h3>")
        fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
        if file_type == 'html':
            fileHandle.write("</h3>")

        for_data = []

        for i in np.arange(num_res_founts):

            # print_fine_dets = 1

            if print_fine_dets == 1:
                print('\n start_round =', start_round)
                print(' end_round =', end_round)
                print('\n res =', i)
                print('\n [dbs.init_res_levels[d][i] for d in np.arange(start_round, end_round)] =', [dbs.init_res_levels[d][i] for d in np.arange(start_round, end_round)])
                print('\n np.mean(dbs.main_db[4 + i][start_round:end_round]) =', np.mean(dbs.main_db[4 + i][start_round:end_round]))

            if two_tribes == 0:

                initial_res_level = np.mean([dbs.init_res_levels[d][i] for d in np.arange(start_round, end_round)])

                if mean_numb_agents > 0:
                    mean_foraged = (initial_res_level - np.mean(dbs.main_db[4 + i][start_round:end_round])) / float(mean_numb_agents)
                    std_foraged = (np.std(dbs.main_db[4 + i][start_round:end_round])) / float(mean_numb_agents)

                elif mean_numb_agents == 0:
                    mean_foraged = 0
                    std_foraged = 0

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nResource %s Mean = %3.4f (%3.2f)" % (i, mean_foraged, std_foraged))
                if file_type == 'html':
                    fileHandle.write("</p>")

                for_data.append([i, mean_foraged, std_foraged])

            elif two_tribes:

                mean_numb_sharks = np.mean(dbs.pop_sharks[start_round:end_round])
                mean_numb_jets = np.mean(dbs.pop_jets[start_round:end_round])

                print('\n start_round =', start_round)
                print('\n end_round =', end_round)
                print('\n ten_pct_rounds_array =', ten_pct_rounds_array)
                print(' ten_pct_gap =', ten_pct_gap)
                print('\n printed_segment_size =', printed_segment_size)

                # do sharks' fountains first
                initial_res_level_sharks = np.mean([dbs.init_res_levels[d][i] for d in np.arange(start_round, end_round)])

                if mean_numb_sharks > 0:

                    mean_foraged_sharks = (initial_res_level_sharks - np.mean(dbs.res_founts_sharks[i][start_round:end_round])) / float(mean_numb_sharks)
                    std_foraged_sharks = np.std(dbs.res_founts_sharks[i][start_round:end_round]) / float(mean_numb_sharks)

                elif mean_numb_sharks == 0:

                    mean_foraged_sharks = 0
                    std_foraged_sharks = 0

                # now do jets
                initial_res_level_jets = np.mean([dbs.init_res_levels[d][2 + i] for d in np.arange(start_round, end_round)])

                if mean_numb_jets > 0:

                    mean_foraged_jets = (initial_res_level_jets - np.mean(dbs.res_founts_jets[i][start_round:end_round])) / float(mean_numb_jets)
                    std_foraged_jets = np.std(dbs.res_founts_jets[i][start_round:end_round]) / float(mean_numb_jets)

                elif mean_numb_jets == 0:

                    mean_foraged_jets = 0
                    std_foraged_jets = 0

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nResource %s Sharks Mean = %3.4f (%3.2f)  |  Jets Mean = %3.4f (%3.2f)" % (i, mean_foraged_sharks, std_foraged_sharks, mean_foraged_jets, std_foraged_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")

                for_data.append([i, mean_foraged_sharks, std_foraged_sharks, mean_foraged_jets, std_foraged_jets])

        end_foraging_data.append(for_data)

    if print_fine_dets == 1:
        print('\nend_foraging_data =\n', end_foraging_data)

    # Find degree of specialisation

    print('---> Success Data: Specialisation Data 1 started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nSpecialisation Data (numbers of agents in specialisation buckets)")
    if file_type == 'html':
        fileHandle.write("</h2>")

    spec_degr_data = []
    mean_spec_array = []

    #    print('\n for_spec_db1 :\n\n', for_spec_db1)

    # find minimum value of max foraging value
    min_max_spec = int(for_strat_parts / float(num_res_founts))

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = ten_pct_rounds_array[iter] + ten_pct_gap
        mean_numb_agents = np.mean(dbs.main_db[3][start_round:end_round])

        if file_type == 'html':
            fileHandle.write("<h3>")
        fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
        if file_type == 'html':
            fileHandle.write("</h3>")

        ten_pct_data = []

        #        mean_spec_values = []

        for spec_degr in np.arange(for_strat_parts + 1):

            if mean_numb_agents >= 1:

                mean_specd = np.mean(for_spec_db1[spec_degr][start_round:end_round])
                std_specd = np.std(for_spec_db1[spec_degr][start_round:end_round])

            elif mean_numb_agents < 1:

                mean_specd = 0
                std_specd = 0

            if min_max_spec <= spec_degr <= for_strat_parts:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nSpecialisation degree %d Mean = %3.4f (%3.2f)" % (spec_degr, mean_specd, std_specd))
                if file_type == 'html':
                    fileHandle.write("</p>")

            ten_pct_data.append([spec_degr, mean_specd, std_specd])

        if mean_numb_agents >= 1:

            mean_mean_spec_value = np.mean(for_spec_means[start_round:end_round])
            std_mean_spec_value = np.std(for_spec_means[start_round:end_round])

        elif mean_numb_agents < 1:

            mean_mean_spec_value = None
            std_mean_spec_value = None

        #        print('start', start_round, 'end', end_round, '\n for_spec_means[start_round:end_round]:\n\n', for_spec_means[start_round:end_round])
        #        print('mean_mean_spec_value =', mean_mean_spec_value, 'std_mean_spec_value =', std_mean_spec_value)

        if file_type == 'html':
            fileHandle.write("<p> </p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\n\nOverall weighted mean specialisation value (mean of daily means) = %s" % (mean_mean_spec_value))
        if file_type == 'html':
            fileHandle.write("</p>")

        spec_degr_data.append(ten_pct_data)
        mean_spec_array.append([mean_mean_spec_value, std_mean_spec_value])

    if print_fine_dets == 1:
        print('\nspec_degr_data =\n', spec_degr_data)
        print('\nmean_spec_array =\n', mean_spec_array)

    # find the number of agents who specialised (skill prob > 0.99)

    print('---> Success Data: Specialisation Data 2 started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nSpecialisation Data (numbers of agents in with one detection probability > 0.99)\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    num_spec_agents_array = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        av_num = np.mean(dbs.num_perfect_specs[2][start_round:end_round])
        std_num = np.std(dbs.num_perfect_specs[2][start_round:end_round])

        num_spec_agents_array.append([av_num, std_num])

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nRounds %d to %d - Average Num of Specialists: %3.4f (%3.2f)" % (start_round, end_round - 1, av_num, std_num))
        if file_type == 'html':
            fileHandle.write("</p>")

    # Find mean maximum probabilities of detection

    print('---> Success Data: Detection Probabilities Data started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nDetection Probabilities Data (mean maximum probabilities of detection) at end of rounds\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    max_probs_data = []

    for iter in range(num_iters):

        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap - 1)

        max_probs_array = dbs.copy_ags_max_det_probs[end_round]

        #        print(end_round, 'dbs.copy_ags_max_det_probs[end_round] =', dbs.copy_ags_max_det_probs[end_round])

        #        dbs.copy_ags_res_arrays[round] = agents_res_array

        #        for agent in dbs.live_agents[end_round]:
        #
        #            max_probs_array.append(np.max(agent.detect_skills_array_hist[end_round]))
        #
        #            if print_fine_dets == 1:
        #                print('\nend_round =', end_round)
        #                print('agent.detect_skills_array_hist[end_round] =', agent.detect_skills_array_hist[end_round])

        if len(max_probs_array) > 0:

            mean_max_probs = np.mean(max_probs_array)
            std_max_probs = np.std(max_probs_array)

        elif len(max_probs_array) == 0:

            mean_max_probs = None
            std_max_probs = None

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nEnd of Round %d Mean = %s (%s)" % (end_round, mean_max_probs, std_max_probs))
        if file_type == 'html':
            fileHandle.write("</p>")

        max_probs_data.append([mean_max_probs, std_max_probs])

    if print_fine_dets == 1:
        print('\nmax_probs_data =\n', max_probs_data)

    # Generate Resource Stocks Data

    print('---> Success Data: Agent Personal Resource Levels Data started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nAgent Personal Resource Levels Data at end of rounds\n\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    if file_type == 'html':
        fileHandle.write("<p>")
    fileHandle.write("Resource starting value = %s" % (agent_res_init))
    if file_type == 'html':
        fileHandle.write("</p>")

    res_array_data = []

    for iter in range(num_iters):

        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap - 1)

        min_ress_array = []
        mean_ress_array = []
        max_ress_array = []

        #        print(end_round, 'dbs.copy_ags_res_arrays[end_round] =', dbs.copy_ags_res_arrays[end_round])

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'></p>")

        for agent_line in dbs.copy_ags_res_arrays[end_round]:  # dbs.live_agents[end_round]:

            min_res = np.min(agent_line)
            mean_res = np.mean(agent_line)
            max_res = np.max(agent_line)

            min_ress_array.append(min_res)
            mean_ress_array.append(mean_res)
            max_ress_array.append(max_res)

        if len(min_ress_array) > 0:

            mean_min_res = np.mean(min_ress_array)
            std_min_res = np.std(min_ress_array)

            mean_mean_res = np.mean(mean_ress_array)
            std_mean_res = np.std(mean_ress_array)

            mean_max_res = np.mean(max_ress_array)
            std_max_res = np.std(max_ress_array)

        elif len(min_ress_array) == 0:

            mean_min_res = std_min_res = mean_max_res = std_max_res = mean_mean_res = std_mean_res = 0

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\n\nEnd of Round %d Mean Min Resource = %3.4f (%3.2f)" % (end_round, mean_min_res, std_min_res))
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nEnd of Round %d Mean Max Resource = %3.4f (%3.2f)" % (end_round, mean_max_res, std_max_res))
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nEnd of Round %d Mean Mean Resource = %3.4f (%3.2f)" % (end_round, mean_mean_res, std_mean_res))
        if file_type == 'html':
            fileHandle.write("</p><p></p>")

        res_array_data.append([[mean_min_res, std_min_res], [mean_max_res, std_max_res], [mean_mean_res, std_mean_res]])

    if print_fine_dets == 1:
        print('\nres_array_data =\n', res_array_data)

    # Generate Turnover data

    print('---> Success Data: Turnover Data started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nTurnover Data (volume of transactions of each resource)")
    if file_type == 'html':
        fileHandle.write("</h2>")

    actual_turnover_array = []
    optimal_turnover_array = []
    ratio_turnover_array = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        act_to_array = []
        opt_to_array = []
        rat_to_array = []

        if file_type == 'html':
            fileHandle.write("<h3>")
        fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
        if file_type == 'html':
            fileHandle.write("</h3>")

        for res in np.arange(num_res_founts):

            gross_to_array = [dbs.net_net_transs_db[x][res] for x in np.arange(start_round, end_round)]

            mean_to = np.mean(gross_to_array)
            std_to = np.std(gross_to_array)

            optimal_to_array = [dbs.optimal_bskt_turnover[x][res] for x in np.arange(start_round, end_round)]

            mean_opt_to = np.mean(optimal_to_array)
            std_opt_to = np.std(optimal_to_array)

            #            turnover_ratio_array = [dbs.net_net_transs_db[x][res] / float(dbs.optimal_bskt_turnover[x][res]) for x in np.arange(start_round, end_round)]
            #
            #            mean_turn_rat = np.mean(turnover_ratio_array)
            #            std_opt_turn_rat = np.std(turnover_ratio_array)

            if mean_opt_to > 0:
                mean_to_ratio = mean_to / float(mean_opt_to)
            else:
                mean_to_ratio = 0

            if std_opt_to > 0:
                std_to_ratio = std_to / float(std_opt_to)
            else:
                std_to_ratio = 0

            if two_tribes == 0:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n\nResource %s - Actual Turnover: %3.4f (%3.2f)" % (res, mean_to, std_to))
                if file_type == 'html':
                    fileHandle.write("</p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nResource %s - Optimal Turnover: %3.4f (%3.2f)" % (res, mean_opt_to, std_opt_to))
                if file_type == 'html':
                    fileHandle.write("</p>")
                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nPercent: %3.4f (%3.3f)" % (mean_to_ratio * 100, std_to_ratio * 100))
                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'><p></p>")

                act_to_array.append([mean_to, std_to])
                opt_to_array.append([mean_opt_to, std_opt_to])
                rat_to_array.append([mean_to_ratio, std_to_ratio])

            elif two_tribes:

                gross_to_array_sharks = [dbs.net_net_transs_db_sharks[x][res] for x in np.arange(start_round, end_round)]

                mean_to_sharks = np.mean(gross_to_array_sharks)
                std_to_sharks = np.std(gross_to_array_sharks)

                optimal_to_array_sharks = [dbs.optimal_bskt_turnover_sharks[x][res] for x in np.arange(start_round, end_round)]

                mean_opt_to_sharks = np.mean(optimal_to_array_sharks)
                std_opt_to_sharks = np.std(optimal_to_array_sharks)

                if mean_opt_to_sharks > 0:
                    mean_to_ratio_sharks = mean_to_sharks / float(mean_opt_to_sharks)
                else:
                    mean_to_ratio_sharks = 0

                if std_opt_to_sharks > 0:
                    std_to_ratio_sharks = std_to_sharks / float(std_opt_to_sharks)
                else:
                    std_to_ratio_sharks = 0

                gross_to_array_jets = [dbs.net_net_transs_db_jets[x][res] for x in np.arange(start_round, end_round)]

                mean_to_jets = np.mean(gross_to_array_jets)
                std_to_jets = np.std(gross_to_array_jets)

                optimal_to_array_jets = [dbs.optimal_bskt_turnover_jets[x][res] for x in np.arange(start_round, end_round)]

                mean_opt_to_jets = np.mean(optimal_to_array_jets)
                std_opt_to_jets = np.std(optimal_to_array_jets)

                if mean_opt_to_jets > 0:
                    mean_to_ratio_jets = mean_to_jets / float(mean_opt_to_jets)
                else:
                    mean_to_ratio_jets = 0

                if std_opt_to_jets > 0:
                    std_to_ratio_jets = std_to_jets / float(std_opt_to_jets)
                else:
                    std_to_ratio_jets = 0

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n\nResource %s - Actual Turnover: Total %3.4f (%3.2f)  |  Sharks %3.4f (%3.2f)  |  Jets %3.4f (%3.2f)" % (res, mean_to, std_to, mean_to_sharks, std_to_sharks, mean_to_jets, std_to_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nResource %s - Optimal Turnover: Total %3.4f (%3.2f)  |  Sharks %3.4f (%3.2f)  |  Jets %3.4f (%3.2f)" % (res, mean_opt_to, std_opt_to, mean_opt_to_sharks, std_opt_to_sharks, mean_opt_to_jets, std_opt_to_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")
                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nPercent: Total %3.4f (%3.3f)  |  Sharks %3.4f (%3.2f)  |  Jets %3.4f (%3.2f)" % (
                mean_to_ratio * 100, std_to_ratio * 100, mean_to_ratio_sharks * 100, std_to_ratio_sharks * 100, mean_to_ratio_jets * 100, std_to_ratio_jets * 100))
                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'><p></p>")

                act_to_array.append([mean_to, std_to, mean_to_sharks, std_to_sharks, mean_to_jets, std_to_jets])
                opt_to_array.append([mean_opt_to, std_opt_to, mean_opt_to_sharks, std_opt_to_sharks, mean_opt_to_jets, std_opt_to_jets])
                rat_to_array.append([mean_to_ratio, std_to_ratio, mean_to_ratio_sharks, std_to_ratio_sharks, mean_to_ratio_jets, std_to_ratio_jets])

        actual_turnover_array.append(act_to_array)
        optimal_turnover_array.append(opt_to_array)
        ratio_turnover_array.append(rat_to_array)

    if print_fine_dets == 1:
        print('\nactual_turnover_array =\n', actual_turnover_array)
        print('\noptimal_turnover_array =\n', optimal_turnover_array)

    # Generate Average Age data

    print('---> Success Data: Average Age Data started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nAverage Age Data\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    all_age_arry = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        if np.any(dbs.ag_age_db[1][start_round:end_round] == 0) == False:

            av_age = np.mean(dbs.ag_age_db[1][start_round:end_round])
            std_age = np.std(dbs.ag_age_db[1][start_round:end_round])

        elif np.any(dbs.ag_age_db[1][start_round:end_round] == 0):

            av_age = None
            std_age = None

        all_age_arry.append([av_age, std_age])

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nRounds %d to %d - Average Age: %s (%s)" % (start_round, end_round - 1, av_age, std_age))
        if file_type == 'html':
            fileHandle.write("</p>")

    if print_fine_dets == 1:
        print('\nall_age_arry = \n', all_age_arry)
    #
    #    # Generate Clustering Coefficient Data
    #    fileHandle.write("\n\n\n\nCustering Coefficient Data\n")
    #
    #    cc_array = []
    #
    #    for iter in range(num_iters):
    #
    #        start_round = ten_pct_rounds_array[iter]
    #        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)
    #
    #        if start_round > cluster_lag - 1:
    #
    #            # Note here, dbs.clustering_db[1] starts at round cluster_lag - 1 (default = 4)
    #            av_cc = np.mean(dbs.clustering_db[1][start_round:end_round])
    #            std_cc = np.std(dbs.clustering_db[1][start_round:end_round])
    #
    #            cc_array.append([start_round, end_round - 1, av_cc, std_cc])
    #
    #            fileHandle.write("\nRounds %d to %d - Clustering Coefficient = %3.4f (%3.2f)" % (start_round, end_round - 1, av_cc, std_cc))
    #
    #    if print_fine_dets == 1:
    #        print('\ncc_array = \n', cc_array)

    # Generate data showing the number of squares with transactions

    print('---> Success Data: Number of Squares with Transactions Data started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nNumber of Squares with Transactions Data\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    num_sq_array = []
    trading_prop_array = []
    trading_gini_array = []

    #    # generate and process the gini coefficient data
    #
    #    # create array to save daily gini coefficients
    #    ginis = np.zeros(shape=(rounds), dtype=float)
    #
    #    for day in range(rounds):
    #
    #        gini_coeff_daily = gini(town_grid.all_trans_array[day])
    #
    #        ginis[day] = gini_coeff_daily
    #
    #        print('day = ', day, '- gini_coeff_daily =', gini_coeff_daily)
    #
    #    print('\n ginis:\n\n', ginis)

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        # this array record the transactions in each square if there was a transaction
        ginis = []

        # We want to find a weighted average number of squares where there were transactions
        tot_sqs = 0

        trading_prop_one_sq = []

        segment_grid = np.zeros(shape=(town_grid.dimen, town_grid.dimen))

        for xdi in np.arange(town_grid.dimen):
            for ydi in np.arange(town_grid.dimen):

                # We only want to know if there has been any transaction on each grid square
                if np.sum(dbs.transactions_record[xdi][ydi][start_round:end_round]) > 0:
                    tot_sqs += 1

                # add volumes up for each grid square in each day, for whole segment
                for day in range(start_round, end_round):
                    segment_grid[xdi][ydi] += town_grid.all_trans_array[day][xdi][ydi]

                if segment_grid[xdi][ydi] > 0.0:
                    ginis.append(segment_grid[xdi][ydi])

        if len(ginis) > 0:

            segment_gini = gini(np.array(ginis))

        else:

            segment_gini = 0.0

        trading_gini_array.append(segment_gini)

        #        print('\n\n iter = ', iter, ' ginis =\n\n', ginis, '\n segment_gini coefficient=', segment_gini)

        #        trading_gini_array.append(mean_ginis)

        #        print('\n iter ', iter, 'segment grid:\n')
        #
        #        for row in segment_grid:
        #
        #            print(row)

        total_volume = np.sum(segment_grid)

        max_volume = np.max(segment_grid)

        if total_volume > 0:

            one_squ_ratio = max_volume / float(total_volume)

        else:

            one_squ_ratio = 0.0

        trading_prop_one_sq.append(one_squ_ratio)

        #        print('\n total_volume =', total_volume)
        #        print(' max_volume =', max_volume)
        #        print(' one_squ_ratio =', one_squ_ratio)

        num_sq_array.append(tot_sqs)

        trading_prop_array.append(one_squ_ratio)

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write(
            "\nRounds %d to %d - Number of Squares with transactions = %d  |  Proportion of Transaction Volumes on One Square = %1.4f  |  gini coeff (segment) = %1.4f" % (start_round, end_round - 1, tot_sqs, one_squ_ratio, segment_gini))
        if file_type == 'html':
            fileHandle.write("</p>")

    #    print('num_sq_array =', num_sq_array)

    if print_fine_dets == 1:
        print('\nnum_sq_array =\n', num_sq_array)

    # If a market emerged, by what round did it?  Here we look at dbs.mkt_emerged_round, which has 3 elements: [0] = 90% 10 day moving average turnover ratio, [1] = 95%, [3] = 99%

    print('---> Success Data: When Did the Market Emerge started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nWhen Did the Market Emerge?\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    #    print('\n dbs.mkt_emerged_round =', dbs.mkt_emerged_round)

    if dbs.mkt_emerged_round[0] > 0:

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\n10-round Moving Average of Turnover Ratio exceeded 90pct (for any resource) in Round %d\n" % (dbs.mkt_emerged_round[0]))
        if file_type == 'html':
            fileHandle.write("</p>")

        if dbs.mkt_emerged_round[1] > 0:

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("10-round Moving Average of Turnover Ratio exceeded 95pct (for any resource) in Round %d\n" % (dbs.mkt_emerged_round[1]))
            if file_type == 'html':
                fileHandle.write("</p>")

            if dbs.mkt_emerged_round[2] > 0:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("10-round Moving Average of Turnover Ratio exceeded 99pct (for any resource) in Round %d\n" % (dbs.mkt_emerged_round[2]))
                if file_type == 'html':
                    fileHandle.write("</p>")

            else:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n10-round Moving Average of Turnover Ratio never exceeded 99pct (for any resource)")
                if file_type == 'html':
                    fileHandle.write("</p>")

        else:

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n10-round Moving Average of Turnover Ratio never exceeded 95pct (for any resource)")
            if file_type == 'html':
                fileHandle.write("</p>")

    else:

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\n10-round Moving Average of Turnover Ratio never exceeded 90pct (for any resource)")
        if file_type == 'html':
            fileHandle.write("</p>")

    # Generate data showing the difference between mean actual transactions and optimal price, for each resource pair

    print('---> Success Data: Pricing Data started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nPricing Data\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    act_prices_data = []
    act_std_prices_data = []
    opt_prices_data = []
    diff_prices_data = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        if file_type == 'html':
            fileHandle.write("<h3>")
        fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
        if file_type == 'html':
            fileHandle.write("</h3>")

        if two_tribes == 0:

            act_prices_iter = [[[None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            act_std_prices_iter = [[[None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            opt_prices_iter = [[[None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            diff_prices_iter = [[[None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]

        elif two_tribes:

            act_prices_iter = [[[None, None, None, None, None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            act_std_prices_iter = [[[None, None, None, None, None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            opt_prices_iter = [[[None, None, None, None, None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            diff_prices_iter = [[[None, None, None, None, None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]

        for res_1 in np.arange(num_res_founts):
            for res_2 in np.arange(num_res_founts):

                if res_1 != res_2:

                    if print_fine_dets == 1:
                        print('\ndbs.mean_price_history[res_1][res_2] =\n', dbs.mean_price_history[res_1][res_2])
                        print('start_round =', start_round)
                        print('end_round =', end_round)
                        print('np.array(dbs.mean_price_history[res_1][res_2][start_round:end_round] =', np.array(dbs.mean_price_history[res_1][res_2][start_round:end_round]))
                        print('1 / =', 1.0 / np.array(dbs.mean_price_history[res_1][res_2][start_round:end_round]))
                        print('list...', list(1.0 / np.array(dbs.mean_price_history[res_1][res_2][start_round:end_round])))
                        print('\n[dbs.optimal_price_array[i][res_1][res_2] for i in np.arange(start_round:end_round)] =\n', [dbs.optimal_price_array[i][res_1][res_2] for i in np.arange(start_round, end_round)])

                    # Unpack the relevant price data, which is in working price form
                    act_chart_prices_array = np.array(dbs.mean_price_history[res_1][res_2][start_round:end_round])
                    act_chart_prs_stds_array = np.array(dbs.price_history_std[res_1][res_2][start_round:end_round])

                    if two_tribes:
                        act_chart_prices_array_sharks = np.array(dbs.mean_price_history_sharks[res_1][res_2][start_round:end_round])
                        act_chart_prs_stds_array_sharks = np.array(dbs.price_history_std_sharks[res_1][res_2][start_round:end_round])

                        act_chart_prices_array_jets = np.array(dbs.mean_price_history_jets[res_1][res_2][start_round:end_round])
                        act_chart_prs_stds_array_jets = np.array(dbs.price_history_std_jets[res_1][res_2][start_round:end_round])

                    # These are recorded as working prices at this stage, so inversion necessary
                    opt_prices_array = [1 / dbs.optimal_price_array[i][res_1][res_2] for i in np.arange(start_round, end_round)]

                    if two_tribes:
                        opt_prices_array_sharks = [1 / dbs.optimal_price_array_sharks[i][res_1][res_2] for i in np.arange(start_round, end_round)]
                        opt_prices_array_jets = [1 / dbs.optimal_price_array_jets[i][res_1][res_2] for i in np.arange(start_round, end_round)]

                    # We have to crop this data to remove the days when there were no transactions i.e. dbs.mean_price_history[res_1][res_2][day] == None

                    # Create databases to capture the cropped data
                    cropped_chart_prices_array = []
                    cropped_chart_prices_std_array = []
                    cropped_opt_prices_array = []

                    if two_tribes:
                        cropped_chart_prices_array_sharks = []
                        cropped_chart_prices_std_array_sharks = []
                        cropped_opt_prices_array_sharks = []

                        cropped_chart_prices_array_jets = []
                        cropped_chart_prices_std_array_jets = []
                        cropped_opt_prices_array_jets = []

                    price_day = 0

                    # If there were no transactions in a particular day, we must ignore price data - we search through
                    # dbs.mean_price_history[res_1][res_2] and ignore days where == None
                    for day_mean_wkg_price in act_chart_prices_array:

                        if day_mean_wkg_price != 1000 and day_mean_wkg_price != 0.0:
                            cropped_chart_prices_array.append(day_mean_wkg_price)
                            cropped_chart_prices_std_array.append(act_chart_prs_stds_array[price_day])

                            cropped_opt_prices_array.append(opt_prices_array[price_day])

                        price_day += 1

                    if two_tribes:

                        # sharks
                        price_day = 0

                        for day_mean_wkg_price in act_chart_prices_array_sharks:

                            if day_mean_wkg_price != 1000 and day_mean_wkg_price != 0.0:
                                cropped_chart_prices_array_sharks.append(day_mean_wkg_price)
                                cropped_chart_prices_std_array_sharks.append(act_chart_prs_stds_array_sharks[price_day])

                                cropped_opt_prices_array_sharks.append(opt_prices_array_sharks[price_day])

                            price_day += 1

                        # jets
                        price_day = 0

                        for day_mean_wkg_price in act_chart_prices_array_jets:

                            if day_mean_wkg_price != 1000 and day_mean_wkg_price != 0.0:
                                cropped_chart_prices_array_jets.append(day_mean_wkg_price)
                                cropped_chart_prices_std_array_jets.append(act_chart_prs_stds_array_jets[price_day])

                                cropped_opt_prices_array_jets.append(opt_prices_array_jets[price_day])

                            price_day += 1

                    # convert to np
                    cropped_opt_prices_array = np.array(cropped_opt_prices_array)

                    if two_tribes:
                        cropped_opt_prices_array_sharks = np.array(cropped_opt_prices_array_sharks)
                        cropped_opt_prices_array_jets = np.array(cropped_opt_prices_array_jets)

                    if len(cropped_chart_prices_array) > 0:
                        act_prices_mean = np.mean(cropped_chart_prices_array)
                        act_prices_std = np.std(cropped_chart_prices_array)

                    else:
                        act_prices_mean = None
                        act_prices_std = None

                    if two_tribes:

                        # sharks
                        if len(cropped_chart_prices_array_sharks) > 0:
                            act_prices_mean_sharks = np.mean(cropped_chart_prices_array_sharks)
                            act_prices_std_sharks = np.std(cropped_chart_prices_array_sharks)

                        else:
                            act_prices_mean_sharks = None
                            act_prices_std_sharks = None

                        # jets
                        if len(cropped_chart_prices_array_jets) > 0:
                            act_prices_mean_jets = np.mean(cropped_chart_prices_array_jets)
                            act_prices_std_jets = np.std(cropped_chart_prices_array_jets)

                        else:
                            act_prices_mean_jets = None
                            act_prices_std_jets = None

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\n\nResource %s vs Resource %s - Mean Actual Price = %s (%s)" % (res_1, res_2, act_prices_mean, act_prices_std))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        act_prices_iter[res_1][res_2] = [act_prices_mean, act_prices_std]

                    elif two_tribes:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\n\nResource %s vs Resource %s - Mean Actual Price (all) = %s (%s)  |  Sharks %s (%s)  |  Jets %s (%s)" % (
                        res_1, res_2, act_prices_mean, act_prices_std, act_prices_mean_sharks, act_prices_std_sharks, act_prices_mean_jets, act_prices_std_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        act_prices_iter[res_1][res_2] = [act_prices_mean, act_prices_std, act_prices_mean_sharks, act_prices_std_sharks, act_prices_mean_jets, act_prices_std_jets]

                    if len(cropped_chart_prices_std_array) > 0:
                        mean_std_of_daily_prices = np.mean(cropped_chart_prices_std_array)
                        std_std_of_daily_prices = np.std(cropped_chart_prices_std_array)

                    else:
                        mean_std_of_daily_prices = None
                        std_std_of_daily_prices = None

                    if two_tribes:

                        # sharks
                        if len(cropped_chart_prices_std_array_sharks) > 0:
                            mean_std_of_daily_prices_sharks = np.mean(cropped_chart_prices_std_array_sharks)
                            std_std_of_daily_prices_sharks = np.std(cropped_chart_prices_std_array_sharks)

                        else:
                            mean_std_of_daily_prices_sharks = None
                            std_std_of_daily_prices_sharks = None

                        # jets
                        if len(cropped_chart_prices_std_array_jets) > 0:
                            mean_std_of_daily_prices_jets = np.mean(cropped_chart_prices_std_array_jets)
                            std_std_of_daily_prices_jets = np.std(cropped_chart_prices_std_array_jets)

                        else:
                            mean_std_of_daily_prices_jets = None
                            std_std_of_daily_prices_jets = None

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Average Daily Standard Deviation of Prices = %s (%s)" % (res_1, res_2, mean_std_of_daily_prices, std_std_of_daily_prices))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        act_std_prices_iter[res_1][res_2] = [mean_std_of_daily_prices, std_std_of_daily_prices]

                    elif two_tribes:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Average Daily Standard Deviation of Prices (all) = %s (%s)  |  Sharks %s (%s)  |  Jets %s (%s)" % (
                        res_1, res_2, mean_std_of_daily_prices, std_std_of_daily_prices, mean_std_of_daily_prices_sharks, std_std_of_daily_prices_sharks, mean_std_of_daily_prices_jets, std_std_of_daily_prices_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        act_std_prices_iter[res_1][res_2] = [mean_std_of_daily_prices, std_std_of_daily_prices, mean_std_of_daily_prices_sharks, std_std_of_daily_prices_sharks, mean_std_of_daily_prices_jets, std_std_of_daily_prices_jets]

                    if len(cropped_opt_prices_array) > 0:
                        opt_prices_mean = np.mean(cropped_opt_prices_array)
                        opt_prices_std = np.std(cropped_opt_prices_array)

                    else:
                        opt_prices_mean = None
                        opt_prices_std = None

                    if two_tribes:

                        # sharks
                        if len(cropped_opt_prices_array_sharks) > 0:
                            opt_prices_mean_sharks = np.mean(cropped_opt_prices_array_sharks)
                            opt_prices_std_sharks = np.std(cropped_opt_prices_array_sharks)

                        else:
                            opt_prices_mean_sharks = None
                            opt_prices_std_sharks = None

                        # jets
                        if len(cropped_opt_prices_array_jets) > 0:
                            opt_prices_mean_jets = np.mean(cropped_opt_prices_array_jets)
                            opt_prices_std_jets = np.std(cropped_opt_prices_array_jets)

                        else:
                            opt_prices_mean_jets = None
                            opt_prices_std_jets = None

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Mean Optimal Price (all) = %s (%s)" % (res_1, res_2, opt_prices_mean, opt_prices_std))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        opt_prices_iter[res_1][res_2] = [opt_prices_mean, opt_prices_std]

                    elif two_tribes:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Mean Optimal Price (all) = %s (%s)  |  Sharks %s (%s)  |  Jets %s (%s)" % (
                        res_1, res_2, opt_prices_mean, opt_prices_std, opt_prices_mean_sharks, opt_prices_std_sharks, opt_prices_mean_jets, opt_prices_std_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        opt_prices_iter[res_1][res_2] = [opt_prices_mean, opt_prices_std, opt_prices_mean_sharks, opt_prices_std_sharks, opt_prices_mean_jets, opt_prices_std_jets]

                    price_differences = np.zeros(shape=(len(cropped_chart_prices_array)))

                    for cell_num in range(len(price_differences)):
                        price_differences[cell_num] = math.fabs(cropped_chart_prices_array[cell_num] - cropped_opt_prices_array[cell_num])

                    if two_tribes:

                        # sharks
                        price_differences_sharks = np.zeros(shape=(len(cropped_chart_prices_array_sharks)))

                        for cell_num in range(len(price_differences_sharks)):
                            price_differences_sharks[cell_num] = math.fabs(cropped_chart_prices_array_sharks[cell_num] - cropped_opt_prices_array_sharks[cell_num])

                        # jets
                        price_differences_jets = np.zeros(shape=(len(cropped_chart_prices_array_jets)))

                        for cell_num in range(len(price_differences_jets)):
                            price_differences_jets[cell_num] = math.fabs(cropped_chart_prices_array_jets[cell_num] - cropped_opt_prices_array_jets[cell_num])

                    #                    price_differences = act_chart_prices_array - cropped_opt_prices_array

                    if len(price_differences) > 0:
                        diff_prices_mean = np.mean(price_differences)
                        diff_prices_std = np.std(price_differences)

                    elif len(price_differences) == 0:
                        diff_prices_mean = None
                        diff_prices_std = None

                    if two_tribes:

                        # sharks
                        if len(price_differences_sharks) > 0:
                            diff_prices_mean_sharks = np.mean(price_differences_sharks)
                            diff_prices_std_sharks = np.std(price_differences_sharks)

                        elif len(price_differences_sharks) == 0:
                            diff_prices_mean_sharks = None
                            diff_prices_std_sharks = None

                        # jets
                        if len(price_differences_jets) > 0:
                            diff_prices_mean_jets = np.mean(price_differences_jets)
                            diff_prices_std_jets = np.std(price_differences_jets)

                        elif len(price_differences_jets) == 0:
                            diff_prices_mean_jets = None
                            diff_prices_std_jets = None

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Mean Abs (Actual - Optimal Price) = %s (%s)" % (res_1, res_2, diff_prices_mean, diff_prices_std))
                        if file_type == 'html':
                            fileHandle.write("</p>")
                            fileHandle.write("<p></p>")

                        diff_prices_iter[res_1][res_2] = [diff_prices_mean, diff_prices_std]

                    elif two_tribes:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Mean Abs (Actual - Optimal Price) all = %s (%s)  |  Sharks %s (%s)  |  Jets %s (%s)" % (
                        res_1, res_2, diff_prices_mean, diff_prices_std, diff_prices_mean_sharks, diff_prices_std_sharks, diff_prices_mean_jets, diff_prices_std_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")
                            fileHandle.write("<p></p>")

                        diff_prices_iter[res_1][res_2] = [diff_prices_mean, diff_prices_std, diff_prices_mean_sharks, diff_prices_std_sharks, diff_prices_mean_jets, diff_prices_std_jets]

        act_prices_data.append(act_prices_iter)
        act_std_prices_data.append(act_std_prices_iter)
        opt_prices_data.append(opt_prices_iter)
        diff_prices_data.append(diff_prices_iter)

    if print_fine_dets == 1:
        print('\nact_prices_data =\n', act_prices_data)
        print('\nopt_prices_data =\n', opt_prices_data)
        print('\ndiff_prices_data =\n', diff_prices_data)

    # Here we find the mean and std of the optimal prices for the whole simulation Turnover

    if file_type == 'html':
        fileHandle.write("<p></p>")
        fileHandle.write("<p style='margin:0;'>")
    fileHandle.write("\n\nOptimal Prices: Mean and STD (Resource 0 vs Resource 1 - chart prices): \n")
    #    if file_type == 'html':
    #        fileHandle.write("</p>")

    all_opt_prices = [1 / dbs.optimal_price_array[i][0][1] for i in np.arange(rounds) if dbs.optimal_price_array[i][0][1] != 0.0]

    mean_opt_prices = np.mean(all_opt_prices)
    std_opt_prices = np.std(all_opt_prices)

    whole_sim_opt_prices_array = [mean_opt_prices, std_opt_prices]

    #    if file_type == 'html':
    #        fileHandle.write("<p style='margin:0;'>")
    fileHandle.write("\nMean = %2.4f  |  STD = %2.4f" % (mean_opt_prices, std_opt_prices))
    if file_type == 'html':
        fileHandle.write("</p>")

    # Here we look at the number of home locations which are serviced by markets (recorded in dbs.serviced_locations)

    print('---> Success Data: Percentage of Agent Homes Covered by Markets started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nPercentage of Agent Homes Covered by Markets\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    serviced_locs_data = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        serv_iter_data = [dbs.serviced_locations[i] for i in np.arange(start_round, end_round)]

        mean_iter = np.mean(serv_iter_data)
        std_iter = np.std(serv_iter_data)

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nRounds %4.0f to %4.0f - Percent of agents within market catchment area = %3.2f (std %3.2f percent)" % (start_round, end_round - 1, mean_iter * 100, std_iter * 100))
        if file_type == 'html':
            fileHandle.write("</p>")

        serviced_locs_data.append([mean_iter, std_iter])

    # if there is a Keynesian Institution, we look at that here

    KI_data = []

    if allow_Keynes_Inst == 'total':

        Keynes_Object = KO_pop.pop[0]
        loc_x = Keynes_Object.loc[0]
        loc_y = Keynes_Object.loc[1]

        #        print('\n\n loc_x =', loc_x, 'loc_y', loc_y)

        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\n\nKeynesian Institution Data (location [%d %d])\n" % (loc_x, loc_y))
        if file_type == 'html':
            fileHandle.write("</h2>")

        for iter in range(num_iters):

            start_round = ten_pct_rounds_array[iter]
            end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

            tot_vol_trade = 0.0
            vol_on_KI = 0.0

            #            print('dbs.trans_db =', dbs.trans_db)
            #            print('len(dbs.trans_db) =', len(dbs.trans_db))

            for trans_numb in range(len(dbs.trans_db)):

                #                print('trans_numb =', trans_numb)

                transaction = dbs.trans_db[trans_numb]

                #                print('transaction =', transaction)
                #                print('transaction.day =', transaction.day)
                #                print('transaction.good_a =', transaction.good_a)
                #                print('transaction.tot_trans_ag_sell =', transaction.tot_trans_ag_sell)
                #                print('transaction.location =', transaction.location)

                if start_round <= transaction.day < end_round:

                    if transaction.good_a == 0:

                        tot_vol_trade += transaction.tot_trans_ag_sell

                        if transaction.location[0] == loc_x and transaction.location[1] == loc_y:
                            vol_on_KI += transaction.tot_trans_ag_sell

                    elif transaction.good_b == 0:

                        tot_vol_trade += transaction.tot_trans_ag_buy

                        if transaction.location[0] == loc_x and transaction.location[1] == loc_y:
                            vol_on_KI += transaction.tot_trans_ag_buy

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nRounds %4.0f to %4.0f - Total Volume of Transaction = %4.4f  |  Total Volume on Keynesian Institution = %4.4f  |  Proportion of transactions on KI = %0.4f" % (
            start_round, end_round - 1, tot_vol_trade, vol_on_KI, float(vol_on_KI / tot_vol_trade)))
            if file_type == 'html':
                fileHandle.write("</p>")

            KI_data.append([tot_vol_trade, vol_on_KI, float(vol_on_KI / tot_vol_trade)])

            # print out live agents' resource arrays and birth date and distance from last mkt visited

    print('---> Success Data: Agent Resource Data: Resource Arrays at end of Simulation started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nAgent Resource Data: Resource Arrays at end of Simulation")
    if file_type == 'html':
        fileHandle.write("</h2>")

    if file_type == 'html':
        fileHandle.write("<p style='margin:0;'>")
    fileHandle.write("\n\nNumber of Agents Alive = %d\n\n" % (len(agent_population.pop)))
    if file_type == 'html':
        fileHandle.write("</p>")
        fileHandle.write("<p></p>")

    agent_num = 0

    for agent in agent_population.pop:

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\n Agent %d: \t Birth Date %d  |  Resource Array: [" % (agent_num, agent.birth_date))

        for res in range(num_res_founts):
            fileHandle.write(" %2.2f " % (agent.agent_res_array[0][res]))

        if agent.grid_trgt[0] != None:

            dist_from_last_trgt_x = math.fabs(agent.grid_trgt[0] - agent.home[0])

            if dist_from_last_trgt_x > town_grid.dimen / 2.0:
                dist_from_last_trgt_x = town_grid.dimen - dist_from_last_trgt_x

            dist_from_last_trgt_y = math.fabs(agent.grid_trgt[1] - agent.home[1])

            if dist_from_last_trgt_y > town_grid.dimen / 2.0:
                dist_from_last_trgt_y = town_grid.dimen - dist_from_last_trgt_y

            max_dist = np.max([dist_from_last_trgt_x, dist_from_last_trgt_y])

            moves_to_target = math.ceil(max_dist / float(agent.agent_vision))

            fileHandle.write("]  |  last target location = [ %d %d ]  |  Moves to Target from Home = %d" % (agent.grid_trgt[0], agent.grid_trgt[1], moves_to_target))

        else:

            moves_to_target = None
            fileHandle.write("]  |  last target location = [ None None ]  |  Moves to Target from Home = n/a")

        agent_num += 1

    fileHandle.write("</p></p>")

    slope_data = []             # this need to exist for the return data

    if params.run_dist_to_mkt_OLS:

        mean_res_array = []
        dist_to_target_array = []

        mean_res_array_0 = []
        mean_res_array_1 = []
        dist_to_target_array_0 = []
        dist_to_target_array_1 = []

        X_array_all_agents = []

        save_res_array = []

        agents_dead_or_alive = []

        # we only run the regression in simple, default scenarios when there will be only one market location:
        market_loc = dbs.sign_locs[-1][0]

        print('\n market_loc', market_loc, '\n')

        # we look at all the agents - dead or alive - who went to the dominant market
        for agent in agent_population.pop:

            print(' alive agent home', agent.home, 'target =', agent.grid_trgt)

            if agent.grid_trgt[0] == market_loc[0] and agent.grid_trgt[1] == market_loc[1]:

                agents_dead_or_alive.append(agent)

        print('\n\n')

        for agent in agent_population.dead_agent_array:

            print(' dead agent home', agent.home, 'target =', agent.grid_trgt)

            if agent.grid_trgt[0] == market_loc[0] and agent.grid_trgt[1] == market_loc[1]:

                agents_dead_or_alive.append(agent)

        print('\n len(agents_dead_or_alive)', len(agents_dead_or_alive))
        print('\n OLS_include', OLS_include)

        for agent in agents_dead_or_alive:

            # OLS_include = ['intercept', 'moves_to_target', 'max_det_dummy', 'res_spec_A', 'res_spec_B', 'birth_dummy', 'life_span']

            # this array contains the agent's dep variables
            X_array = []

            # find mean_res for agent
            mean_res = np.mean(agent.total_cons)

            # add intercept if we want it
            if 'intercept' in OLS_include:
                X_array.append(1.0)

            # print(' agent.home', agent.home, 'agent.grid_trgt', agent.grid_trgt, 'town_grid.dimen', town_grid.dimen, 'agent.agent_res_array[0]', agent.agent_res_array[0], 'agent.total_cons', agent.total_cons)

            # now find distance to target
            if 'moves_to_target' in OLS_include:
                moves_to_target = np.max(abs_dist_on_torus(agent.home, agent.grid_trgt, town_grid.dimen))
                X_array.append(moves_to_target)

            # find max detection probability
            if 'max_det_prob' in OLS_include:
                max_det_prob = np.max(agent.detect_skills_array)
                X_array.append(max_det_prob)

            if 'max_det_dummy' in OLS_include:
                if np.max(agent.detect_skills_array[0]) > 0.9:
                    max_det_dummy = 1
                else:
                    max_det_dummy = 0
                X_array.append(max_det_dummy)

            # add data to arrays
            mean_res_array.append(mean_res)
            dist_to_target_array.append(moves_to_target)

            # find resource specialisation - assume the highest det prob; otherwise the fountain most foraged from
            if 'res_spec_A' in OLS_include or 'res_spec_B' in OLS_include:

                if agent.detect_skills_array[0][0] > agent.detect_skills_array[0][1]:
                    res_spec_A = 1
                    res_spec_B = 0
                    # save_res_array.append(0)

                elif agent.detect_skills_array[0][1] > agent.detect_skills_array[0][0]:
                    res_spec_A = 0
                    res_spec_B = 1
                    # save_res_array.append(1)

                else:
                    res_spec_A = 0
                    res_spec_B = 0

                if 'res_spec_A' in OLS_include:
                    X_array.append(res_spec_A)
                if 'res_spec_B' in OLS_include:
                    X_array.append(res_spec_B)

            # elif np.median(agent.for_strat_array) == 1:
            #     res_spec_A = 0
            #     res_spec_B = 1

            # if res_spec_A:
            #     mean_res_array_0.append(0)
            #     dist_to_target_array_0.append(moves_to_target)
            #
            #
            # if res_spec_B:
            #     mean_res_array_1.append(1)
            #     dist_to_target_array_1.append(moves_to_target)

            # create dummy variable for whether agent born in first 500 rounds
            if 'birth_dummy' in OLS_include:

                if agent.birth_date < 500:
                    birth_dummy = 1
                else:
                    birth_dummy = 0

                X_array.append(birth_dummy)

            # find life_span
            if 'life_span' in OLS_include:

                if agent in agent_population.dead_agent_array:
                    life_span = agent.death_date - agent.birth_date

                else:
                    life_span = params.rounds - agent.birth_date

                X_array.append(life_span)

            print(' final X_array =', X_array)

            # this includes all the data in the OLS: intercept term, moves_to_target, resource specialisation, age
            # X_array = [1.0, moves_to_target, max_det_dummy, res_spec_A, res_spec_B, birth_dummy, life_span]

            X_array_all_agents.append(X_array)

        # print('\n mean_res_array', mean_res_array)

        if len(mean_res_array) > 1:

            plot_scatter_2d(dist_to_target_array, mean_res_array, 'Distance to Target / Resources Scatter - All Res', data_folder, filename='distance_resource_scatter_all_res', dpi='high')

            # we convert array to np
            dist_to_target_array = np.array(dist_to_target_array)
            X_array_all_agents = np.array(X_array_all_agents)

            print('\n X_array_all_agents =\n\n', X_array_all_agents)

            results = sm.OLS(mean_res_array, X_array_all_agents).fit()

            print('\n all res results of OLS:\n\n', results.summary())

            fileHandle.write("\n\n All Results: \n\n%s" % (results.summary()))

            # slope_data = [results.params, results.bse, results.pvalues]

            # we create a numpy array manually because the results data can be presented in an odd way
            slope_data = np.zeros(shape=(3, len(OLS_include)), dtype=float)

            for i in range(len(OLS_include)):
                slope_data[0][i] = results.params[i]
                slope_data[1][i] = results.bse[i]
                slope_data[2][i] = results.pvalues[i]

            print('\n slope_data =', slope_data)

            # if 'intercept' in OLS_include:
            #
            #     slope_data = [results.params[1], results.bse[1], results.pvalues[1]]
            #
            # else:
            #
            #     slope_data = [results.params[0], results.bse[0], results.pvalues[0]]

            # print('\n results.params:', results.params)
            # print('\n results.bse:', results.bse)
            # print('\n results.pvalues:', results.pvalues)

            fileHandle.write("<p><p>")

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\nResults from OLS Analysis:\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            fileHandle.write("<p><p>")

            counter = 0
            for dep_var in OLS_include:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("%s :    parameter = %6.6s   |   Standard Error = %6.6s   |   P Value = %6.6s" % (dep_var, results.params[counter], results.bse[counter], results.pvalues[counter]))
                if file_type == 'html':
                    fileHandle.write("</p>")

                counter += 1

        fileHandle.write("<p><p>")

        # if len(mean_res_array_0) > 1:
        #
        #     plot_scatter_2d(dist_to_target_array_0, mean_res_array_0, 'Distance to Target / Resources Scatter Res 0', data_folder, filename='distance_resource_scatter_res_0', dpi='low')
        #
        #     # we convert array to np and add an intercept term
        #     dist_to_target_array_0 = np.array(dist_to_target_array_0)
        #     dist_to_target_array_0 = sm.add_constant(dist_to_target_array_0)
        #
        #     results = sm.OLS(mean_res_array_0, dist_to_target_array_0).fit()
        #
        #     print('\n res_0 results of OLS:\n\n', results.summary())
        #
        #     fileHandle.write("\n\n Results 0: \n\n%s" % (results.summary()))
        #
        #     fileHandle.write("</p></p>")
        #
        # if len(mean_res_array_1) > 1:
        #
        #     plot_scatter_2d(dist_to_target_array_1, mean_res_array_1, 'Distance to Target / Resources Scatter Res 1', data_folder, filename='distance_resource_scatter_res_1', dpi='low')
        #
        #     # we convert array to np and add an intercept term
        #     dist_to_target_array_1 = np.array(dist_to_target_array_1)
        #     dist_to_target_array_1 = sm.add_constant(dist_to_target_array_1)
        #
        #     results = sm.OLS(mean_res_array_1, dist_to_target_array_1).fit()
        #
        #     print('\n res_1 results of OLS:\n\n', results.summary())
        #
        #     fileHandle.write("\n\n Results 1: \n\n%s" % (results.summary()))

    # pause()

    print('---> Success Data: Significant Market Locations (last round) started')

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\nSignificant Market Locations (last round):\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    if len(dbs.sign_mkt_locs[rounds - 1]) > 0:

        for loc in dbs.sign_mkt_locs[rounds - 1]:

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nLocation [ %d, %d ] : volume %6.2f" % (loc[0], loc[1], dbs.last_round_trans_data[loc[0]][loc[1]]))
            if file_type == 'html':
                fileHandle.write("</p>")

    else:

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nThere was no trading")
        if file_type == 'html':
            fileHandle.write("</p>")

    # Now we turn to constitutional matters

    # create matrix to record agents' res accumulations during each experiment ([0] is agent, etc) - these are returned in the function so must always exist
    const_record_res_accum = [[] for i in range(num_experiments + 1)]

    # create array to count votes
    agents_aggr_votes = np.zeros(shape=(num_experiments + 1))

    if constitutional_voting == 1:

        print_fine_dets = 1

        if file_type == 'html':
            fileHandle.write("<h1>")
        fileHandle.write("\n\n\nConstitutional Voting\n\n")
        if file_type == 'html':
            fileHandle.write("</h1>")

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("Notes:")
        fileHandle.write("<br>")
        fileHandle.write("Experiment 1 is floating prices and market start is 0")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("Experiment 2 is floating prices and market start is 20")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("Experiment 4 is optimal prices and market start is 0")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("Experiment 3 is optimal prices and market start is 20")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("Experiment 5 is pure Walrasian Prices and Quantities")
        if file_type == 'html':
            fileHandle.write("</p>")

        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\nAgent votes for each of %d experiments:" % (num_experiments))
        if file_type == 'html':
            fileHandle.write("</h2>")

        # if file_type == 'html':
        #     fileHandle.write("<p style='margin:0;'>")
        # for experiment in range(1, num_experiments + 1):
        #     fileHandle.write("%d\t\t" % (experiment))

        fileHandle.write("\n\n")

        # only agents alive at the end of the constitutional process and who were alive throughout can vote...
        for agent in dbs.constitutional_agents[num_experiments]:

            agent_in_all_exps = 1

            for exp in range(1, num_experiments):

                if agent not in dbs.constitutional_agents[exp]:
                    agent_in_all_exps = 0

            if agent_in_all_exps == 1:

                preferred_system = 0  # this is the system the agent votes for
                best_res_gain = -10000000.0  # make this an absurdly low number which cannot be reached in any experiment

                if print_fine_dets == 1:
                    print('\n\n agent =', agent, 'home', agent.home)

                # fileHandle.write("<br>")
                fileHandle.write("home %s  |  res increase in each voting period:  " % (agent.home))

                const_record_res_accum[0].append(agent.home)

                for experiment in range(1, num_experiments + 1):

                    if print_fine_dets == 1:
                        print('\n experiment ', experiment, ':')

                    iter_counter = 0

                    for ag in dbs.constitutional_agents[experiment - 1]:

                        if agent is ag:

                            res_start = dbs.constitutional_min_ress[experiment - 1][iter_counter]

                            if print_fine_dets == 1:
                                print('res_start =', res_start)

                        else:

                            iter_counter += 1

                    iter_counter = 0

                    for ag in dbs.constitutional_agents[experiment]:

                        if agent is ag:

                            res_end = dbs.constitutional_min_ress[experiment][iter_counter]

                            if print_fine_dets == 1:
                                print('res_end =', res_end)

                        else:

                            iter_counter += 1

                    new_res_gain = res_end - res_start

                    const_record_res_accum[experiment].append(new_res_gain)

                    if new_res_gain > best_res_gain:
                        best_res_gain = new_res_gain
                        preferred_system = experiment

                    fileHandle.write("%3.2f\t\t" % (new_res_gain))

                    if print_fine_dets == 1:
                        print('new_res_gain =', new_res_gain)
                        print('best_res_gain =', best_res_gain)
                        print('preferred_system =', preferred_system)

                fileHandle.write("<br>")

                agents_aggr_votes[preferred_system] += 1

                if print_fine_dets == 1:
                    print('\n agents_aggr_votes so far =', agents_aggr_votes[1:])

        fileHandle.write("<br>")
        fileHandle.write("aggregate votes: %s" % agents_aggr_votes[1:])
        fileHandle.write("<br>")
            # fileHandle.write("\n")
            # fileHandle.write("aggregate votes: %s" % agents_aggr_votes)
            # fileHandle.write("\n")

        if print_fine_dets == 1:
            print('\n\n agents_aggr_votes =', agents_aggr_votes)
            print('\n const_record_res_accum:\n\n', const_record_res_accum)

        fileHandle.write("\n\n\n\n")
        if file_type == 'html':
            fileHandle.write("</p>")

    # Now we move on to data corresponding to the agents respecting property rights or not

    # these databases get returned below
    prop_steal_data = []
    prop_fb_data = []
    num_trans_data = []
    num_fights_data = []
    num_scen_1_data = []
    num_scen_23_data = []
    num_scen_45_data = []

    black_shoop_array = []

    if respect_property_rights == 0:

        # We start by looking at Propensity to Steal and Fight Back

        print('---> Success Data: Propensity to Steal Data started')

        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\n\nPropensity to Steal Data\n")
        if file_type == 'html':
            fileHandle.write("</h2>")

        #        print('\n dbs.prop_steal_std_db_sharks =\n', dbs.prop_steal_std_db_sharks)

        #        pause()

        for iter in range(num_iters):

            start_round = ten_pct_rounds_array[iter]
            end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

            prop_steal_mean_iter_data = [dbs.prop_steal_mean_db[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_mean_db[i] is not None]
            prop_steal_std_iter_data = [dbs.prop_steal_std_db[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_std_db[i] is not None]

            if len(prop_steal_mean_iter_data) > 0:

                mean_iter_steal = np.mean(prop_steal_mean_iter_data)
                std_iter_steal = np.mean(prop_steal_std_iter_data)

            else:

                mean_iter_steal = None
                std_iter_steal = None

            if two_tribes:

                prop_steal_mean_iter_data_sharks = [dbs.prop_steal_mean_db_sharks[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_mean_db_sharks[i] is not None]
                prop_steal_std_iter_data_sharks = [dbs.prop_steal_std_db_sharks[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_std_db_sharks[i] is not None]

                prop_steal_mean_iter_data_jets = [dbs.prop_steal_mean_db_jets[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_mean_db_jets[i] is not None]
                prop_steal_std_iter_data_jets = [dbs.prop_steal_std_db_jets[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_std_db_jets[i] is not None]

                # sharks
                if len(prop_steal_mean_iter_data_sharks) > 0:

                    mean_iter_steal_sharks = np.mean(prop_steal_mean_iter_data_sharks)
                    std_iter_steal_sharks = np.mean(prop_steal_std_iter_data_sharks)

                else:

                    mean_iter_steal_sharks = None
                    std_iter_steal_sharks = None

                # jets
                if len(prop_steal_mean_iter_data_jets) > 0:

                    mean_iter_steal_jets = np.mean(prop_steal_mean_iter_data_jets)
                    std_iter_steal_jets = np.mean(prop_steal_std_iter_data_jets)

                else:

                    mean_iter_steal_jets = None
                    std_iter_steal_jets = None

            prop_fb_mean_iter_data = [dbs.prop_fb_mean_db[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_mean_db[i] is not None]
            prop_fb_std_iter_data = [dbs.prop_fb_std_db[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_std_db[i] is not None]

            if two_tribes:
                prop_fb_mean_iter_data_sharks = [dbs.prop_fb_mean_db_sharks[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_mean_db_sharks[i] is not None]
                prop_fb_std_iter_data_sharks = [dbs.prop_fb_std_db_sharks[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_std_db_sharks[i] is not None]

                prop_fb_mean_iter_data_jets = [dbs.prop_fb_mean_db_jets[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_mean_db_jets[i] is not None]
                prop_fb_std_iter_data_jets = [dbs.prop_fb_std_db_jets[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_std_db_jets[i] is not None]

            if len(prop_fb_mean_iter_data) > 0:

                mean_iter_fb = np.mean(prop_fb_mean_iter_data)
                std_iter_fb = np.mean(prop_fb_std_iter_data)

            else:

                mean_iter_fb = None
                std_iter_fb = None

            if two_tribes:

                # sharks
                if len(prop_fb_mean_iter_data_sharks) > 0:

                    mean_iter_fb_sharks = np.mean(prop_fb_mean_iter_data_sharks)
                    std_iter_fb_sharks = np.mean(prop_fb_std_iter_data_sharks)

                else:

                    mean_iter_fb_sharks = None
                    std_iter_fb_sharks = None

                # jets
                if len(prop_fb_mean_iter_data_jets) > 0:

                    mean_iter_fb_jets = np.mean(prop_fb_mean_iter_data_jets)
                    std_iter_fb_jets = np.mean(prop_fb_std_iter_data_jets)

                else:

                    mean_iter_fb_jets = None
                    std_iter_fb_jets = None

                if file_type == 'html':
                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Sharks Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % (
                start_round, end_round - 1, mean_iter_steal_sharks, std_iter_steal_sharks, mean_iter_fb_sharks, std_iter_fb_sharks))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Jets Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % (
                start_round, end_round - 1, mean_iter_steal_jets, std_iter_steal_jets, mean_iter_fb_jets, std_iter_fb_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nRounds %4d to %4d - All Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % (start_round, end_round - 1, mean_iter_steal, std_iter_steal, mean_iter_fb, std_iter_fb))
            if file_type == 'html':
                fileHandle.write("</p>")

            if two_tribes == 0:

                prop_steal_data.append([mean_iter_steal, std_iter_steal])
                prop_fb_data.append([mean_iter_fb, std_iter_fb])

            elif two_tribes:

                prop_steal_data.append([mean_iter_steal, std_iter_steal, mean_iter_steal_sharks, std_iter_steal_sharks, mean_iter_steal_jets, std_iter_steal_jets])
                prop_fb_data.append([mean_iter_fb, std_iter_fb, mean_iter_fb_sharks, std_iter_fb_sharks, mean_iter_fb_jets, std_iter_fb_jets])

        # Now we look at the number of transactions and fights

        print('---> Success Data: Number of Transactions and Fights In Each Round started')

        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\n\nNumber of Transactions and Fights In Each Round\n")
        if file_type == 'html':
            fileHandle.write("</h2>")

        for iter in range(num_iters):

            start_round = ten_pct_rounds_array[iter]
            end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

            num_trans_iter = [dbs.num_ints_each_round[6][i] for i in np.arange(start_round, end_round) if dbs.num_ints_each_round[6][i] is not None]
            num_fights_iter = [dbs.num_fight_each_round[i] for i in np.arange(start_round, end_round) if dbs.num_fight_each_round[i] is not None]

            if two_tribes:
                num_trans_iter_sharks = [dbs.num_ints_each_round_sharks[6][i] for i in np.arange(start_round, end_round) if dbs.num_ints_each_round_sharks[6][i] is not None]
                num_fights_iter_sharks = [dbs.num_fight_each_round_sharks[i] for i in np.arange(start_round, end_round) if dbs.num_fight_each_round_sharks[i] is not None]

                num_trans_iter_jets = [dbs.num_ints_each_round_jets[6][i] for i in np.arange(start_round, end_round) if dbs.num_ints_each_round_jets[6][i] is not None]
                num_fights_iter_jets = [dbs.num_fight_each_round_jets[i] for i in np.arange(start_round, end_round) if dbs.num_fight_each_round_jets[i] is not None]

                num_trans_iter_inter = [dbs.num_ints_each_round_inter[6][i] for i in np.arange(start_round, end_round) if dbs.num_ints_each_round_inter[6][i] is not None]
                num_fights_iter_inter = [dbs.num_fight_each_round_inter[i] for i in np.arange(start_round, end_round) if dbs.num_fight_each_round_inter[i] is not None]

            if len(num_trans_iter) > 0:
                mean_iter_trans = np.mean(num_trans_iter)
                std_iter_trans = np.std(num_trans_iter)

            else:
                mean_iter_trans = 0
                std_iter_trans = 0

            if len(num_fights_iter) > 0:
                mean_iter_fights = np.mean(num_fights_iter)
                std_iter_fights = np.std(num_fights_iter)

            else:
                mean_iter_fights = 0
                std_iter_fights = 0

            if two_tribes:

                # sharks
                if len(num_trans_iter_sharks) > 0:
                    mean_iter_trans_sharks = np.mean(num_trans_iter_sharks)
                    std_iter_trans_sharks = np.std(num_trans_iter_sharks)

                else:
                    mean_iter_trans_sharks = 0
                    std_iter_trans_sharks = 0

                if len(num_fights_iter_sharks) > 0:
                    mean_iter_fights_sharks = np.mean(num_fights_iter_sharks)
                    std_iter_fights_sharks = np.std(num_fights_iter_sharks)

                else:
                    mean_iter_fights_sharks = 0
                    std_iter_fights_sharks = 0

                # jets
                if len(num_trans_iter_jets) > 0:
                    mean_iter_trans_jets = np.mean(num_trans_iter_jets)
                    std_iter_trans_jets = np.std(num_trans_iter_jets)

                else:
                    mean_iter_trans_jets = 0
                    std_iter_trans_jets = 0

                if len(num_fights_iter_jets) > 0:
                    mean_iter_fights_jets = np.mean(num_fights_iter_jets)
                    std_iter_fights_jets = np.std(num_fights_iter_jets)

                else:
                    mean_iter_fights_jets = 0
                    std_iter_fights_jets = 0

                if len(num_trans_iter_inter) > 0:
                    mean_iter_trans_inter = np.mean(num_trans_iter_inter)
                    std_iter_trans_inter = np.std(num_trans_iter_inter)

                else:
                    mean_iter_trans_inter = 0
                    std_iter_trans_inter = 0

                if len(num_fights_iter_inter) > 0:
                    mean_iter_fights_inter = np.mean(num_fights_iter_inter)
                    std_iter_fights_inter = np.std(num_fights_iter_inter)

                else:
                    mean_iter_fights_inter = 0
                    std_iter_fights_inter = 0

            if two_tribes:

                if file_type == 'html':
                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Sharks Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % (
                start_round, end_round - 1, mean_iter_trans_sharks, std_iter_trans_sharks, mean_iter_fights_sharks, std_iter_fights_sharks))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Jets Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % (
                start_round, end_round - 1, mean_iter_trans_jets, std_iter_trans_jets, mean_iter_fights_jets, std_iter_fights_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Inter Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % (
                start_round, end_round - 1, mean_iter_trans_inter, std_iter_trans_inter, mean_iter_fights_inter, std_iter_fights_inter))
                if file_type == 'html':
                    fileHandle.write("</p>")

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nRounds %4d to %4d - All Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % (start_round, end_round - 1, mean_iter_trans, std_iter_trans, mean_iter_fights, std_iter_fights))
            if file_type == 'html':
                fileHandle.write("</p>")

            if two_tribes == 0:

                num_trans_data.append([mean_iter_trans, std_iter_trans])
                num_fights_data.append([mean_iter_fights, std_iter_fights])

            elif two_tribes:

                num_trans_data.append([mean_iter_trans, std_iter_trans, mean_iter_trans_sharks, std_iter_trans_sharks, mean_iter_trans_jets, std_iter_trans_jets, mean_iter_trans_inter, std_iter_trans_inter])
                num_fights_data.append([mean_iter_fights, std_iter_fights, mean_iter_fights_sharks, std_iter_fights_sharks, mean_iter_fights_jets, std_iter_fights_jets, mean_iter_fights_inter, std_iter_fights_inter])

        # Now we break down the 'fights' in to their 3 types

        print('---> Success Data: Breakdown of Fights by Type started')

        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\n\nBreakdown of Fights by Type\n")
        if file_type == 'html':
            fileHandle.write("</h2>")

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nScenario 1 is: both agents attempted to steal.")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nScenarios 2 & 3 is: one agent attempted to steal, the other wanted to trade but then fought back.")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nScenarios 4 & 5 is: one agent attempted to steal, the other wanted to trade but then acquiesced.")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nNote: pct data below gives scenario 1, 2 & 3, and 4 & 5 fights as proportion of the mean number of fights during the period.\n")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")

        for iter in range(num_iters):

            start_round = ten_pct_rounds_array[iter]
            end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

            scen_1_iter = [dbs.num_ints_each_round[1][i] for i in np.arange(start_round, end_round)]

            no_nones = 1

            if len(scen_1_iter) > 0:
                mean_scen_1 = np.mean(scen_1_iter)
                std_scen_1 = np.std(scen_1_iter)
            else:
                mean_scen_1 = 0
                std_scen_1 = 0
                no_nones = 0

            scen_23_iter = [dbs.num_ints_each_round[2][i] for i in np.arange(start_round, end_round)]

            if len(scen_23_iter) > 0:
                mean_scen_23 = np.mean(scen_23_iter)
                std_scen_23 = np.std(scen_23_iter)
            else:
                mean_scen_23 = 0
                std_scen_23 = 0
                no_nones = 0

            scen_45_iter = [dbs.num_ints_each_round[4][i] for i in np.arange(start_round, end_round)]

            if len(scen_45_iter) > 0:
                mean_scen_45 = np.mean(scen_45_iter)
                std_scen_45 = np.std(scen_45_iter)
            else:
                mean_scen_45 = 0
                std_scen_45 = 0
                no_nones = 0

            if no_nones == 1:

                prop_1_fights = (100 * mean_scen_1) / float(mean_scen_1 + mean_scen_23 + mean_scen_45)
                prop_23_fights = (100 * mean_scen_23) / float(mean_scen_1 + mean_scen_23 + mean_scen_45)
                prop_45_fights = (100 * mean_scen_45) / float(mean_scen_1 + mean_scen_23 + mean_scen_45)

            else:

                prop_1_fights = 0
                prop_23_fights = 0
                prop_45_fights = 0

            if two_tribes:

                # sharks
                scen_1_iter_sharks = [dbs.num_ints_each_round_sharks[1][i] for i in np.arange(start_round, end_round)]

                no_nones_sharks = 1

                if len(scen_1_iter_sharks) > 0:
                    mean_scen_1_sharks = np.mean(scen_1_iter_sharks)
                    std_scen_1_sharks = np.std(scen_1_iter_sharks)
                else:
                    mean_scen_1_sharks = 0
                    std_scen_1_sharks = 0
                    no_nones_sharks = 0

                scen_23_iter_sharks = [dbs.num_ints_each_round_sharks[2][i] for i in np.arange(start_round, end_round)]

                if len(scen_23_iter_sharks) > 0:
                    mean_scen_23_sharks = np.mean(scen_23_iter_sharks)
                    std_scen_23_sharks = np.std(scen_23_iter_sharks)
                else:
                    mean_scen_23_sharks = 0
                    std_scen_23_sharks = 0
                    no_nones_sharks = 0

                scen_45_iter_sharks = [dbs.num_ints_each_round_sharks[4][i] for i in np.arange(start_round, end_round)]

                if len(scen_45_iter_sharks) > 0:
                    mean_scen_45_sharks = np.mean(scen_45_iter_sharks)
                    std_scen_45_sharks = np.std(scen_45_iter_sharks)
                else:
                    mean_scen_45_sharks = 0
                    std_scen_45_sharks = 0
                    no_nones_sharks = 0

                if no_nones_sharks == 1:

                    prop_1_fights_sharks = (100 * mean_scen_1_sharks) / float(mean_scen_1_sharks + mean_scen_23_sharks + mean_scen_45_sharks)
                    prop_23_fights_sharks = (100 * mean_scen_23_sharks) / float(mean_scen_1_sharks + mean_scen_23_sharks + mean_scen_45_sharks)
                    prop_45_fights_sharks = (100 * mean_scen_45_sharks) / float(mean_scen_1_sharks + mean_scen_23_sharks + mean_scen_45_sharks)

                else:

                    prop_1_fights_sharks = 0
                    prop_23_fights_sharks = 0
                    prop_45_fights_sharks = 0

                # jets
                scen_1_iter_jets = [dbs.num_ints_each_round_jets[1][i] for i in np.arange(start_round, end_round)]

                no_nones_jets = 1

                if len(scen_1_iter_jets) > 0:
                    mean_scen_1_jets = np.mean(scen_1_iter_jets)
                    std_scen_1_jets = np.std(scen_1_iter_jets)
                else:
                    mean_scen_1_jets = 0
                    std_scen_1_jets = 0
                    no_nones_jets = 0

                scen_23_iter_jets = [dbs.num_ints_each_round_jets[2][i] for i in np.arange(start_round, end_round)]

                if len(scen_23_iter_jets) > 0:
                    mean_scen_23_jets = np.mean(scen_23_iter_jets)
                    std_scen_23_jets = np.std(scen_23_iter_jets)
                else:
                    mean_scen_23_jets = 0
                    std_scen_23_jets = 0
                    no_nones_jets = 0

                scen_45_iter_jets = [dbs.num_ints_each_round_jets[4][i] for i in np.arange(start_round, end_round)]

                if len(scen_45_iter_jets) > 0:
                    mean_scen_45_jets = np.mean(scen_45_iter_jets)
                    std_scen_45_jets = np.std(scen_45_iter_jets)
                else:
                    mean_scen_45_jets = 0
                    std_scen_45_jets = 0
                    no_nones_jets = 0

                if no_nones_jets == 1:

                    prop_1_fights_jets = (100 * mean_scen_1_jets) / float(mean_scen_1_jets + mean_scen_23_jets + mean_scen_45_jets)
                    prop_23_fights_jets = (100 * mean_scen_23_jets) / float(mean_scen_1_jets + mean_scen_23_jets + mean_scen_45_jets)
                    prop_45_fights_jets = (100 * mean_scen_45_jets) / float(mean_scen_1_jets + mean_scen_23_jets + mean_scen_45_jets)

                else:

                    prop_1_fights_jets = 0
                    prop_23_fights_jets = 0
                    prop_45_fights_jets = 0

                # inter
                scen_1_iter_inter = [dbs.num_ints_each_round_inter[1][i] for i in np.arange(start_round, end_round)]

                no_nones_inter = 1

                if len(scen_1_iter_inter) > 0:
                    mean_scen_1_inter = np.mean(scen_1_iter_inter)
                    std_scen_1_inter = np.std(scen_1_iter_inter)
                else:
                    mean_scen_1_inter = 0
                    std_scen_1_inter = 0
                    no_nones_inter = 0

                scen_23_iter_inter = [dbs.num_ints_each_round_inter[2][i] for i in np.arange(start_round, end_round)]

                if len(scen_23_iter_inter) > 0:
                    mean_scen_23_inter = np.mean(scen_23_iter_inter)
                    std_scen_23_inter = np.std(scen_23_iter_inter)
                else:
                    mean_scen_23_inter = 0
                    std_scen_23_inter = 0
                    no_nones_inter = 0

                scen_45_iter_inter = [dbs.num_ints_each_round_inter[4][i] for i in np.arange(start_round, end_round)]

                if len(scen_45_iter_inter) > 0:
                    mean_scen_45_inter = np.mean(scen_45_iter_inter)
                    std_scen_45_inter = np.std(scen_45_iter_inter)
                else:
                    mean_scen_45_inter = 0
                    std_scen_45_inter = 0
                    no_nones_inter = 0

                if no_nones_inter == 1:

                    prop_1_fights_inter = (100 * mean_scen_1) / float(mean_scen_1_inter + mean_scen_23_inter + mean_scen_45_inter)
                    prop_23_fights_inter = (100 * mean_scen_23_inter) / float(mean_scen_1_inter + mean_scen_23_inter + mean_scen_45_inter)
                    prop_45_fights_inter = (100 * mean_scen_45_inter) / float(mean_scen_1_inter + mean_scen_23_inter + mean_scen_45_inter)

                else:

                    prop_1_fights_inter = 0
                    prop_23_fights_inter = 0
                    prop_45_fights_inter = 0

            if two_tribes:

                if file_type == 'html':
                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Sharks Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                                 (start_round, end_round - 1, mean_scen_1_sharks, prop_1_fights_sharks, std_scen_1_sharks, mean_scen_23_sharks, prop_23_fights_sharks, std_scen_23_sharks, mean_scen_45_sharks, prop_45_fights_sharks,
                                  std_scen_45_sharks))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Jets Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                                 (start_round, end_round - 1, mean_scen_1_jets, prop_1_fights_jets, std_scen_1_jets, mean_scen_23_jets, prop_23_fights_jets, std_scen_23_jets, mean_scen_45_jets, prop_45_fights_jets, std_scen_45_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Inter Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                                 (start_round, end_round - 1, mean_scen_1_inter, prop_1_fights_inter, std_scen_1_inter, mean_scen_23_inter, prop_23_fights_inter, std_scen_23_inter, mean_scen_45_inter, prop_45_fights_inter,
                                  std_scen_45_inter))
                if file_type == 'html':
                    fileHandle.write("</p>")

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nRounds %4d to %4d - All Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                             (start_round, end_round - 1, mean_scen_1, prop_1_fights, std_scen_1, mean_scen_23, prop_23_fights, std_scen_23, mean_scen_45, prop_45_fights, std_scen_45))
            if file_type == 'html':
                fileHandle.write("</p>")

            if two_tribes == 0:

                num_scen_1_data.append([mean_scen_1, std_scen_1])
                num_scen_23_data.append([mean_scen_23, std_scen_23])
                num_scen_45_data.append([mean_scen_45, std_scen_45])

            elif two_tribes:

                num_scen_1_data.append([mean_scen_1, std_scen_1, mean_scen_1_sharks, std_scen_1_sharks, mean_scen_1_jets, std_scen_1_jets, mean_scen_1_inter, std_scen_1_inter])
                num_scen_23_data.append([mean_scen_23, std_scen_23, mean_scen_23_sharks, std_scen_23_sharks, mean_scen_23_jets, std_scen_23_jets, mean_scen_23_inter, std_scen_23_inter])
                num_scen_45_data.append([mean_scen_45, std_scen_45, mean_scen_45_sharks, std_scen_45_sharks, mean_scen_45_jets, std_scen_45_jets, mean_scen_45_inter, std_scen_45_inter])

        # Record game type data here
        game_type_dict = dict()
        game_type_dict_seen = dict()
        game_type_dict_RCT = dict()
        game_type_dict_seen_RCT = dict()
        games_type_dict_2 = dict()
        games_type_dict_3 = dict()
        classic_games_considered_sums = dict()
        classic_games_considered_sums_RCT = dict()
        classic_games_seen_sums = dict()
        classic_games_seen_sums_RCT = dict()
        # quad_inters_dicts = []

        if params.track_game_types and (len(dbs.games_type_considered_dict) > 0 or len(dbs.games_type_dict) > 0):

            print('---> Success Data: Game Type Data started')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nGame Type Data\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            total_sum_cons = 0
            total_sum_seen = 0
            total_sum_2 = 0
            total_sum_3 = 0
            total_sum_cons_RCT = 0
            total_sum_seen_RCT = 0
            total_classic_cons = 0
            total_classic_seen = 0
            total_classic_cons_RCT = 0
            total_classic_seen_RCT = 0

            if print_fine_dets:
                print('\n game_type_dict considered:\n')

            for game_type in dbs.games_type_considered_dict:
                game_type_dict[game_type] = sum(dbs.games_type_considered_dict[game_type])

                total_sum_cons += sum(dbs.games_type_considered_dict[game_type])

                if print_fine_dets:
                    print(' game_type', game_type, 'sum', sum(dbs.games_type_considered_dict[game_type]))

            if print_fine_dets:
                print('\n game_type_dict_seen:\n')

            for game_type in dbs.games_type_dict:
                game_type_dict_seen[game_type] = sum(dbs.games_type_dict[game_type])

                total_sum_seen += sum(dbs.games_type_dict[game_type])

                if print_fine_dets:
                    print(' game_type', game_type, 'sum', sum(dbs.games_type_dict[game_type]))

            if print_fine_dets:
                print('\n dbs.games_type_dict_2:\n')

            for game_type in dbs.games_type_dict_2:
                games_type_dict_2[game_type] = sum(dbs.games_type_dict_2[game_type])

                total_sum_2 += sum(dbs.games_type_dict_2[game_type])

                if print_fine_dets:
                    print(' game_type', game_type, 'sum', sum(dbs.games_type_dict_2[game_type]))

            if print_fine_dets:
                print('\n games_type_dict_3:\n')

            for game_type in dbs.games_type_dict_3:
                games_type_dict_3[game_type] = sum(dbs.games_type_dict_3[game_type])

                total_sum_3 += sum(dbs.games_type_dict_3[game_type])

                if print_fine_dets:
                    print(' game_type', game_type, 'sum', sum(dbs.games_type_dict_3[game_type]))

            if print_fine_dets:
                print('\n game_type_dict_RCT considered_RCT:\n')

            for game_type in dbs.games_type_considered_dict_RCT:
                game_type_dict_RCT[game_type] = sum(dbs.games_type_considered_dict_RCT[game_type])

                total_sum_cons_RCT += sum(dbs.games_type_considered_dict_RCT[game_type])

                if print_fine_dets:
                    print(' game_type', game_type, 'sum', sum(dbs.games_type_considered_dict_RCT[game_type]))

            if print_fine_dets:
                print('\n game_type_dict_seen_RCT:\n')

            for game_type in dbs.games_type_dict_RCT:
                game_type_dict_seen_RCT[game_type] = sum(dbs.games_type_dict_RCT[game_type])

                total_sum_seen_RCT += sum(dbs.games_type_dict_RCT[game_type])

                if print_fine_dets:
                    print(' game_type', game_type, 'sum', sum(dbs.games_type_dict_RCT[game_type]))

            for classic_game_type in dbs.classic_games_considered:
                classic_games_considered_sums[classic_game_type] = sum(dbs.classic_games_considered[classic_game_type])

                total_classic_cons += sum(dbs.classic_games_considered[classic_game_type])

            for classic_game_type in dbs.classic_games_seen:
                classic_games_seen_sums[classic_game_type] = sum(dbs.classic_games_seen[classic_game_type])

                total_classic_seen += sum(dbs.classic_games_seen[classic_game_type])

            for classic_game_type in dbs.classic_games_considered_RCT:
                classic_games_considered_sums_RCT[classic_game_type] = sum(dbs.classic_games_considered_RCT[classic_game_type])

                total_classic_cons_RCT += sum(dbs.classic_games_considered_RCT[classic_game_type])

            for classic_game_type in dbs.classic_games_seen_RCT:
                classic_games_seen_sums_RCT[classic_game_type] = sum(dbs.classic_games_seen_RCT[classic_game_type])

                total_classic_seen_RCT += sum(dbs.classic_games_seen_RCT[classic_game_type])

            if print_fine_dets:
                print('\n classic_games_seen_sums =', classic_games_seen_sums)

                print(' game_type_dict', game_type_dict)

            game_type_array = sorted(game_type_dict.items(), key=lambda item: (item[1], item[0]), reverse=True)
            game_type_dict_seen_array = sorted(game_type_dict_seen.items(), key=lambda item: (item[1], item[0]), reverse=True)
            games_type_array_3 = sorted(games_type_dict_3.items(), key=lambda item: (item[1], item[0]), reverse=True)

            game_type_array_RCT = sorted(game_type_dict_RCT.items(), key=lambda item: (item[1], item[0]), reverse=True)
            game_type_array_seen_RCT = sorted(game_type_dict_seen_RCT.items(), key=lambda item: (item[1], item[0]), reverse=True)

            classic_games_considered_sums_array = sorted(classic_games_considered_sums.items(), key=lambda item: (item[1], item[0]), reverse=True)
            classic_games_seen_sums_array = sorted(classic_games_seen_sums.items(), key=lambda item: (item[1], item[0]), reverse=True)

            # classic_games_considered_sums_array_RCT = sorted(classic_games_considered_sums_RCT.items(), key=lambda item: (item[1], item[0]), reverse=True)
            # classic_games_seen_sums_array_RCT = sorted(classic_games_seen_sums_RCT.items(), key=lambda item: (item[1], item[0]), reverse=True)

            if print_fine_dets:
                print('\n game_type_array ', game_type_array)
                print('\n games_type_array_3 ', games_type_array_3)
                print('\n classic_games_considered_sums_array ', classic_games_considered_sums_array)
                print('\n classic_games_seen_sums_array ', classic_games_seen_sums_array)
                print(' total_sum_cons', total_sum_cons)
                print('\n game_type_dict_seen ', game_type_dict_seen)
                print(' total_sum_seen ', total_sum_seen)
                print(' total_classic_cons =', total_classic_cons)
                print(' total_classic_seen =', total_classic_seen)

            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nRaw Considered Game Types (and number of each seen) - not Substantive Rationality")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

            counter = 1

            for game_type in game_type_array:

                #                    fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

                if print_fine_dets:
                    print('\n game_type =', game_type)

                if game_type[0] in game_type_dict_seen:

                    seen_num = game_type_dict_seen[game_type[0]]

                else:

                    seen_num = 0

                #                    print("\n considered %s : %s (%s pct)  |  seen %s (%s pct)") % (game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen))

                if total_sum_cons > 0:

                    prop_cons = 100 * game_type[1] / float(total_sum_cons)

                else:

                    prop_cons = 0.0

                if print_fine_dets:
                    print('\n cons_num =', game_type[1])
                    print(' total_sum_cons =', total_sum_cons)
                    print(' prop_cons =', prop_cons)

                if total_sum_seen > 0:

                    prop_seen = 100 * seen_num / float(total_sum_seen)

                else:

                    prop_seen = 0.0

                if print_fine_dets:
                    print('\n seen_num =', seen_num)
                    print(' total_sum_seen =', total_sum_seen)
                    print(' prop_seen =', prop_seen)

                fileHandle.write("\n%3d considered %s : %d (%1.6f pct)  |  seen %d (%1.6f pct)" % (counter, game_type[0], game_type[1], prop_cons, seen_num, prop_seen))

                if print_fine_dets:
                    print("\n%3d considered %s : %d (%1.6f pct)  |  seen %d (%1.6f pct)" % (counter, game_type[0], game_type[1], prop_cons, seen_num, prop_seen))

                counter += 1

            fileHandle.write("<br><br>There might be interactions which were not considered but seen - we list those here is so:<br><br>")

            # print('\n game_type_dict_seen_array =\n', game_type_dict_seen_array, '\n')

            # now there might be games considered by not seen (considered is by the instigating agent only and seen includes the counterpart also)
            counter -= 1

            for game_type in game_type_dict_seen_array:
                if game_type[0] not in dbs.games_type_considered_dict:

                    # print(' game_type =', game_type)

                    prop_seen = game_type[1] / float(total_sum_seen)

                    fileHandle.write("%3d seen only %s : %d (%1.6f pct)<br>" % (counter, game_type[0], game_type[1], prop_seen))

                counter += 1

            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nTotal considered = %d, total seen = %d (num unique interactions considered = %d, num unique seen = %d)" % (total_sum_cons, total_sum_seen, len(dbs.games_type_considered_dict), len(game_type_dict_seen_array)))
            fileHandle.write("</p>")

            fileHandle.write("<p></p>")
            fileHandle.write("Note: data is from dbs.game_type_considered_dict and dbs.game_type_dict.  If strat_choice == 'propensities' then payoffs in Quads 2 & 3 are derived from a weighted average")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("of the interacting agents' propensities to fight back, i.e., we do not assume backward induction to a derive substantive rationality outcome.")

            # Now consider RCT-equivalent data
            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nRaw Considered Game Types (and number of each seen) - Substantive Rationality")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

            counter = 1

            for game_type in game_type_array_RCT:

                #                    fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

                if print_fine_dets:
                    print('\n game_type =', game_type)

                if game_type[0] in game_type_dict_seen_RCT:

                    seen_num = game_type_dict_seen_RCT[game_type[0]]

                else:

                    seen_num = 0

                #                    print("\n considered %s : %s (%s pct)  |  seen %s (%s pct)") % (game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen))

                if total_sum_cons_RCT > 0:

                    prop_cons = 100 * game_type[1] / float(total_sum_cons_RCT)

                else:

                    prop_cons = 0.0

                if print_fine_dets:
                    print('\n cons_num =', game_type[1])
                    print(' total_sum_cons_RCT =', total_sum_cons_RCT)
                    print(' prop_cons =', prop_cons)

                if total_sum_seen_RCT > 0:

                    prop_seen = 100 * seen_num / float(total_sum_seen_RCT)

                else:

                    prop_seen = 0.0

                if print_fine_dets:
                    print('\n seen_num =', seen_num)
                    print(' total_sum_seen_RCT =', total_sum_seen_RCT)
                    print(' prop_seen =', prop_seen)

                fileHandle.write("\n%3d considered %s : %d (%1.6f pct)  |  seen %d (%1.6f pct)" % (counter, game_type[0], game_type[1], prop_cons, seen_num, prop_seen))

                if print_fine_dets:
                    print("\n%3d considered %s : %d (%1.6f pct)  |  seen %d (%1.6f pct)" % (counter, game_type[0], game_type[1], prop_cons, seen_num, prop_seen))

                counter += 1

            fileHandle.write("<br><br>There might be interactions which were not considered but seen - we list those here is so:<br><br>")

            # print('\n game_type_array_seen_RCT =\n', game_type_array_seen_RCT, '\n')

            # now there might be games considered by not seen (considered is by the instigating agent only and seen includes the counterpart also)
            counter -= 1

            for game_type in game_type_array_seen_RCT:
                if game_type[0] not in dbs.games_type_considered_dict_RCT:

                    # print(' game_type =', game_type)

                    prop_seen = game_type[1] / float(total_sum_seen_RCT)

                    fileHandle.write("%3d seen only %s : %d (%1.6f pct)<br>" % (counter, game_type[0], game_type[1], prop_seen))

                counter += 1

            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nTotal considered = %d, total seen = %d" % (total_sum_cons_RCT, total_sum_seen_RCT))
            fileHandle.write("</p>")

            fileHandle.write("<p></p>")
            fileHandle.write("Note: data is from dbs.game_type_considered_dict_RCT and dbs.game_type_dict_RCT.  The payoffs in Quads 2 & 3 are derived from")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("the highest payoff of the acquiesce and fight back strategies (randomly chosen if equal), i.e., we DO assume backward induction to a derive substantive rationality outcome.")

            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nSeen Game Types (number of game types seen (unweighted) and volume (benefit to instigating agent)) - not RCT")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

            counter = 1

            for game_type in games_type_array_3:

                #                    fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

                if print_fine_dets:
                    print('\n game_type =', game_type)

                if game_type[0] in games_type_dict_2:

                    seen_num = games_type_dict_2[game_type[0]]

                else:

                    seen_num = 0

                if print_fine_dets:
                    print('\n seen_num =', seen_num)

                #                    print("\n considered %s : %s (%s pct)  |  seen %s (%s pct)") % (game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen))

                if total_sum_3 > 0:

                    prop_cons = 100 * game_type[1] / float(total_sum_3)

                else:

                    prop_cons = 0.0

                if total_sum_2 > 0:

                    prop_seen = 100 * seen_num / float(total_sum_2)

                else:

                    prop_seen = 0.0

                fileHandle.write("\n%2d %s : %d (%1.6f pct)  |  volume %1.6f (%1.6f pct)" % (counter, game_type[0], game_type[1], prop_cons, seen_num, prop_seen))

                counter += 1

            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nAggregated number of games = %d, total volume = %s" % (total_sum_3, total_sum_2))
            fileHandle.write("</p>")

            fileHandle.write("<p></p>")
            fileHandle.write("Note: data is from dbs.game_type_dict_2 (numbers) and dbs.game_type_dict_3 (volume).  As above, if strat_choice == 'propensities' then payoffs in Quads 2 & 3 are derived from a weighted average")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("of the interacting agents' propensities to fight back, i.e., we do not assume backward induction to derive a substantive rationality outcome.")

            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nClassic Games Considered")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

                for classic_game_type in classic_games_considered_sums_array:
                    fileHandle.write("<p style='margin:0;'>")

                    if print_fine_dets:
                        print('\n classic_game_type =', classic_game_type)

                    num = classic_game_type[1]

                    if total_classic_cons > 0.0:

                        prop_cons = 100 * num / float(total_classic_cons)

                    else:

                        prop_cons = 0.0

                    fileHandle.write("\n%s : total %d (%1.6f pct)" % (classic_game_type[0], num, prop_cons))

                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nAggregated number of classic games considered = %d" % (total_classic_cons))
                fileHandle.write("</p>")

            fileHandle.write("<p></p>")
            fileHandle.write("Note: data is from dbs.classic_games_considered.  As above, if strat_choice == 'propensities' then payoffs in Quads 2 & 3 are derived from a weighted average")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("of the interacting agents' propensities to fight back, i.e., we do not assume backward induction to derive a substantive rationality outcome.")

            if print_fine_dets:
                print('\n classic_games_seen_sums_array =', classic_games_seen_sums_array)

            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nClassic Games Seen")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

                for classic_game_type in classic_games_seen_sums_array:
                    fileHandle.write("<p style='margin:0;'>")

                    if print_fine_dets:
                        print('\n seen classic_game_type =', classic_game_type)

                    if total_classic_seen > 0.0:

                        prop_seen = 100 * classic_game_type[1] / float(total_classic_seen)

                    else:

                        prop_seen = 0.0

                    fileHandle.write("\n%s : %d (%1.6f pct)" % (classic_game_type[0], classic_game_type[1], prop_seen))

                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nAggregated number of classic games seen = %d" % (total_classic_seen))
                fileHandle.write("</p>")

            fileHandle.write("<p></p>")
            fileHandle.write("Note: data is from dbs.classic_games_seen.  As above, if strat_choice == 'propensities' then payoffs in Quads 2 & 3 are derived from a weighted average")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("of the interacting agents' propensities to fight back, i.e., we do not assume backward induction to derive a substantive rationality outcome.")

            # if file_type == 'html':
            #     fileHandle.write("<h3>")
            # fileHandle.write("\n\nClassic Games Considered (RCT)")
            # if file_type == 'html':
            #     fileHandle.write("</h3>")
            #
            # if file_type == 'html':
            #     fileHandle.write("<p></p>")
            #     fileHandle.write("<p style='margin:0;'>")
            #
            #     for classic_game_type in classic_games_considered_sums_array_RCT:
            #         fileHandle.write("<p style='margin:0;'>")
            #
            #         if print_fine_dets:
            #             print('\n classic_game_type =', classic_game_type)
            #
            #         num = classic_game_type[1]
            #
            #         if total_classic_cons_RCT > 0.0:
            #
            #             prop_cons = 100 * num / float(total_classic_cons_RCT)
            #
            #         else:
            #
            #             prop_cons = 0.0
            #
            #         fileHandle.write("\n%s : total %d (%1.6f pct)" % (classic_game_type[0], num, prop_cons))
            #
            #     fileHandle.write("<p></p>")
            #     fileHandle.write("<p style='margin:0;'>")
            #     fileHandle.write("\nAggregated number of classic games considered = %d" % (total_classic_cons_RCT))
            #     fileHandle.write("</p>")
            #
            # fileHandle.write("<p></p>")
            # fileHandle.write("Note: data is from dbs.classic_games_considered_RCT.  The payoffs in Quads 2 & 3 are derived from")
            # fileHandle.write("<p style='margin:0;'>")
            # fileHandle.write("the highest payoff of the acquiesce and fight back strategies (randomly chosen if equal), i.e., we DO assume backward induction to a derive substantive rationality outcome.")
            #
            # if print_fine_dets:
            #     print('\n classic_games_seen_sums_array =', classic_games_seen_sums_array)
            #
            # if file_type == 'html':
            #     fileHandle.write("<h3>")
            # fileHandle.write("\n\nClassic Games Seen (RCT)")
            # if file_type == 'html':
            #     fileHandle.write("</h3>")
            #
            # if file_type == 'html':
            #     fileHandle.write("<p></p>")
            #     fileHandle.write("<p style='margin:0;'>")
            #
            #     for classic_game_type in classic_games_seen_sums_array_RCT:
            #         fileHandle.write("<p style='margin:0;'>")
            #
            #         if print_fine_dets:
            #             print('\n seen classic_game_type =', classic_game_type)
            #
            #         if total_classic_seen_RCT > 0.0:
            #
            #             prop_seen = 100 * classic_game_type[1] / float(total_classic_seen_RCT)
            #
            #         else:
            #
            #             prop_seen = 0.0
            #
            #         fileHandle.write("\n%s : %d (%1.6f pct)" % (classic_game_type[0], classic_game_type[1], prop_seen))
            #
            #     fileHandle.write("<p></p>")
            #     fileHandle.write("<p style='margin:0;'>")
            #     fileHandle.write("\nAggregated number of classic games seen = %d" % (total_classic_seen_RCT))
            #     fileHandle.write("</p>")
            #
            # fileHandle.write("<p></p>")
            # fileHandle.write("Note: data is from dbs.classic_games_seen_RCT.  The payoffs in Quads 2 & 3 are derived from")
            # fileHandle.write("<p style='margin:0;'>")
            # fileHandle.write("the highest payoff of the acquiesce and fight back strategies (randomly chosen if equal), i.e., we DO assume backward induction to a derive substantive rationality outcome.")

            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nReflexive Entanglement?")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if dbs.num_RE_games + dbs.num_known_outcome_games > 0:
                pct_data = (100 * dbs.num_RE_games) / (dbs.num_RE_games + dbs.num_known_outcome_games)
            else:
                pct_data = 0.0

            if dbs.num_RE_games + dbs.num_known_outcome_games > 0.0:
                pct_data_2 = (100 * dbs.num_known_outcome_games) / (dbs.num_RE_games + dbs.num_known_outcome_games)
            else:
                pct_data_2 = 0.0

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nNumber of reflexively entangled games seen = %d (%4.2f pct)" % (dbs.num_RE_games, pct_data))
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nNumber of known outcome games seen = %d (%4.2f pct)" % (dbs.num_known_outcome_games, pct_data_2))
                fileHandle.write("</p>")

            fileHandle.write("<p></p>")
            fileHandle.write("Note: data is from dbs.num_RE_games and dbs.num_known_outcome_games.  This data uses 2x2 data which is derived assuming substanive rationality & backward induction is used for")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("deriving the payoffs in Quads 2 & 3.")

            # now we count the number of interactions in each quadrant
            total_quad_ints = 0
            last_100_rounds_ints = 0

            quad_inters_dicts = []

            for quad in ['1', '2F', '2A', '3F', '3A', '4']:

                total_quad_ints += np.sum(dbs.quadrants_tallies_RCT[quad])
                last_100_rounds_ints += np.sum(dbs.quadrants_tallies_RCT[quad][-100:])
                quad_inters_dicts.append(dbs.quadrants_tallies_RCT[quad])

            if file_type == 'html':
                fileHandle.write("<h1>")
            fileHandle.write("\n\nInteractions by Quadrant (Assuming Substantive Rationality)")
            if file_type == 'html':
                fileHandle.write("</h1>")

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\nWhole Simulation")
            if file_type == 'html':
                fileHandle.write("</h2>")

            fileHandle.write("<p></p>")

            for quad in ['1', '2F', '2A', '3F', '3A', '4']:

                # print('\n quad', quad)
                # print('np.sum(dbs.quadrants_tallies_RCT)', np.sum(dbs.quadrants_tallies_RCT))
                # print('np.sum(dbs.quadrants_tallies_RCT[quad])', np.sum(dbs.quadrants_tallies_RCT[quad]))
                # print('np.sum(dbs.quadrants_tallies_RCT[quad]) / float(total_quad_ints))', np.sum(dbs.quadrants_tallies_RCT[quad]) / float(total_quad_ints))

                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n%s:  \t %d (%5.3f pct) \t (%5.3f pct of all interactions)" % (quad, np.sum(dbs.quadrants_tallies_RCT[quad]), (100 * np.sum(dbs.quadrants_tallies_RCT[quad])) / float(total_quad_ints), (100 * np.sum(dbs.quadrants_tallies_RCT[quad])) / float(total_sum_3)))
                fileHandle.write("</p>")

            fileHandle.write("<p></p>")

            # print('\n total_quad_ints =', total_quad_ints)

            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nTotal %d" % (total_quad_ints))
            fileHandle.write("</p>")

            fileHandle.write("<p></p>")

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\nLast 100 Rounds")
            if file_type == 'html':
                fileHandle.write("</h2>")

            fileHandle.write("<p></p>")

            for quad in ['1', '2F', '2A', '3F', '3A', '4']:

                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n%s:  \t %d (%5.3f pct)" % (quad, np.sum(dbs.quadrants_tallies_RCT[quad][-100:]), (100 * np.sum(dbs.quadrants_tallies_RCT[quad][-100:])) / float(last_100_rounds_ints)))
                fileHandle.write("</p>")

            fileHandle.write("<p></p>")

            # print('\n total_quad_ints =', last_100_rounds_ints)

            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nTotal %d" % (last_100_rounds_ints))
            fileHandle.write("</p>")

            fileHandle.write("<p></p>")
            fileHandle.write("Note: data is from dbs.quadrants_tallies_RCT.  This data uses 2x2 data which is derived assuming substanive rationality & backward induction is used for")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("deriving the payoffs in Quads 2 & 3.")

            fileHandle.write("<p></p>")

        # dbs.pfb_net_contr_by_scen[quad] dbs.ps_net_contr_by_scen

        # print('\n dbs.ps_net_contr_by_scen =', dbs.ps_net_contr_by_scen)
        # print('\n dbs.pfb_net_contr_by_scen =', dbs.pfb_net_contr_by_scen)

        fileHandle.write("<h2>")
        fileHandle.write("\n\nContributions to propensities by quadrants:")
        fileHandle.write("</h2>")

        fileHandle.write('<p> <span style="font-weight:bold"> Propensities to Steal</span><br><br>')

        fileHandle.write('Scen. 1 %1.4f <br>' % np.sum(dbs.ps_net_contr_by_scen['1']))
        fileHandle.write('Scen. 2F %1.4f <br>' % np.sum(dbs.ps_net_contr_by_scen['2F']))
        fileHandle.write('Scen. 2A %1.4f <br>' % np.sum(dbs.ps_net_contr_by_scen['2A']))
        fileHandle.write('Scen. 3F %1.4f <br>' % np.sum(dbs.ps_net_contr_by_scen['3F']))
        fileHandle.write('Scen. 3A %1.4f <br>' % np.sum(dbs.ps_net_contr_by_scen['3A']))
        fileHandle.write('Scen. 4 %1.4f <br>' % np.sum(dbs.ps_net_contr_by_scen['4']))

        fileHandle.write('<p> <span style="font-weight:bold"> Propensities to Fight Back</span><br><br>')

        fileHandle.write('Scen. 2F %1.4f <br>' % np.sum(dbs.pfb_net_contr_by_scen['2F']))
        fileHandle.write('Scen. 2A %1.4f <br>' % np.sum(dbs.pfb_net_contr_by_scen['2A']))
        fileHandle.write('Scen. 3F %1.4f <br>' % np.sum(dbs.pfb_net_contr_by_scen['3F']))
        fileHandle.write('Scen. 3A %1.4f <br><br>' % np.sum(dbs.pfb_net_contr_by_scen['3A']))

        fileHandle.write('check: Scen. 1 %1.4f <br>' % np.sum(dbs.pfb_net_contr_by_scen['1']))
        fileHandle.write('check: Scen. 4 %1.4f <br><br>' % np.sum(dbs.pfb_net_contr_by_scen['4']))

        # Now we look at NN analysis if we are using NNs
        if params.use_NNs:

            sub_folder = "%s/NN_singles_data/" % (filepath)  # "%ssim_sets/z_france_holiday_sims/"

            if os.path.exists(sub_folder) == False:
                os.makedirs(sub_folder)

            main_data_array = dbs.NN_tests_ps_ag_res_0

            # print('\n params.plotly_online =', params.plotly_online)

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nNeural Network Analysis\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            for data_name in ['NN_tests_ps_ag_res_0', 'NN_tests_ps_ag_res_1', 'NN_tests_ps_ag_bsk_0', 'NN_tests_ps_ag_bsk_1', 'NN_tests_ps_cp_ps', 'NN_tests_ps_cp_pfb', 'NN_tests_ps_cp_res_0', 'NN_tests_ps_cp_res_1', 'NN_tests_ps_cp_bsk_0', 'NN_tests_ps_cp_bsk_1', \
                              'NN_tests_pfb_ag_res_0', 'NN_tests_pfb_ag_res_1', 'NN_tests_pfb_ag_bsk_0', 'NN_tests_pfb_ag_bsk_1', 'NN_tests_pfb_cp_ps', 'NN_tests_pfb_cp_pfb', 'NN_tests_pfb_cp_res_0', 'NN_tests_pfb_cp_res_1', 'NN_tests_pfb_cp_bsk_0', 'NN_tests_pfb_cp_bsk_1']:

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nVariable: %s" % data_name)
                if file_type == 'html':
                    fileHandle.write("</h3>")

                file_name = data_name
                main_data_array = dbs.NNs_names_dict[data_name]
                iter_array = dbs.NNs_iterations_dict[file_name]

                chart_data_array = []

                # print('\n printing data_name =', data_name)

                if file_type == 'html':
                    fileHandle.write("<p></p>")

                for day_index in range(len(dbs.NN_tests_rounds)):

                    if print_fine_dets:
                        print(' day_index =', day_index)

                    day_end = dbs.NN_tests_rounds[day_index]

                    day_data_string = []
                    day_data_string_std = []

                    for iter_index in range(len(iter_array)):

                        if print_fine_dets:
                            print('\n res_index =', iter_index)

                        agents_data = main_data_array[day_index][iter_index]

                        if print_fine_dets:
                            res = iter_array[iter_index]
                            print('\n\n day', day_end, ' res', res, ' agents_data :\n', agents_data)

                        mean_agents_data = np.mean(agents_data)
                        std_agents_data = np.std(agents_data)

                        if print_fine_dets:
                            print('\n mean_agents_data', mean_agents_data, 'std_agents_data', std_agents_data)

                        day_data_string.append(mean_agents_data)
                        day_data_string_std.append(std_agents_data)

                    neutral_int_mean = day_data_string[dbs.index_values_dict[data_name]]
                    neutral_int_std = day_data_string_std[dbs.index_values_dict[data_name]]

                    # print('\n data_name', data_name, 'day_end', day_end)
                    # print('\n dbs.index_values_dict[data_name]', dbs.index_values_dict[data_name])
                    # print('\n day_data_string =', day_data_string)
                    # print('\n dbs.NNs_iterations_dict[data_name]', dbs.NNs_iterations_dict[data_name])
                    # print('\n day_data_string[dbs.index_values_dict[data_name] + 1]', day_data_string[dbs.index_values_dict[data_name] + 1])
                    # print(' day_data_string[dbs.index_values_dict[data_name] - 1]', day_data_string[dbs.index_values_dict[data_name] - 1])
                    # print('\n dbs.NNs_iterations_dict[dbs.index_values_dict[data_name] + 1]', dbs.NNs_iterations_dict[data_name][dbs.index_values_dict[data_name] + 1])
                    # print(' dbs.NNs_iterations_dict[dbs.index_values_dict[data_name] - 1]', dbs.NNs_iterations_dict[data_name][dbs.index_values_dict[data_name] - 1])

                    slope_of_line = (day_data_string[dbs.index_values_dict[data_name] + 1] - day_data_string[dbs.index_values_dict[data_name] - 1]) / float(dbs.NNs_iterations_dict[data_name][dbs.index_values_dict[data_name] + 1] - dbs.NNs_iterations_dict[data_name][dbs.index_values_dict[data_name] - 1])

                    # print('\n slope_of_line =', slope_of_line)

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\nday end %4s  |  mean prob = %4.2f (%4.2f)  |  slope of line %8.7f" % (day_end, neutral_int_mean, neutral_int_std, slope_of_line))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                    single_day_data = day_data_string

                    # print('\n day_data_string', day_data_string)
                    # print(' iter_array', iter_array)

                    single_day_trace = go.Scatter(x=np.array(iter_array), y=np.array(single_day_data), connectgaps=False)
                    single_day_array = [single_day_trace]
                    data_for_single_day_chart = dict(data=single_day_array)
                    file_name_single_day = '%s_day_%d' % (file_name, day_end)

                    filename_day = '%s/%s_%d-%d-%d-%d-%d.html' % (sub_folder, file_name_single_day, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                    plotly.offline.plot(data_for_single_day_chart, filename=filename_day, auto_open=False)

                    trace_data = go.Scatter(x=np.array(iter_array), y=np.array(day_data_string), connectgaps=False, name='Day %d' % day_end)

                    chart_data_array.append(trace_data)

                    if print_fine_dets:
                        print('\n day_data_string =', day_data_string)

                data_for_chart = dict(data=chart_data_array)

                filename_final = '%s/%s_%d-%d-%d-%d-%d.html' % (filepath, file_name, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                plotly.offline.plot(data_for_chart, filename=filename_final, auto_open=False)

                if params.plotly_online:

                    filename_final = '%s/%s_%d-%d-%d-%d-%d.html' % (filepath, file_name, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

                    try:

                        dbs.agents_prop_steal_url = py.plot(data_for_chart, filename=filename_final, auto_open=False, sharing=params.plotly_sharing)

                    except Exception as e:

                        print('\n error:\n\n', e)
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')


            # print('\n dbs.final_layer_ps_breakdown \n', dbs.final_layer_ps_breakdown)
            # print(' len(dbs.final_layer_ps_breakdown)', len(dbs.final_layer_ps_breakdown))
            # print(' len(dbs.final_layer_ps_breakdown[0])', len(dbs.final_layer_ps_breakdown[0]))
            # print(' len(dbs.final_layer_ps_breakdown[0][0])', len(dbs.final_layer_ps_breakdown[0][0]))
            # #
            # print('\n dbs.final_layer_pfb_breakdown \n', dbs.final_layer_pfb_breakdown)
            # print(' len(dbs.final_layer_pfb_breakdown)', len(dbs.final_layer_pfb_breakdown))
            # print(' len(dbs.final_layer_pfb_breakdown[0])', len(dbs.final_layer_pfb_breakdown[0]))
            # print(' len(dbs.final_layer_pfb_breakdown[0][0])', len(dbs.final_layer_pfb_breakdown[0][0]))

            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nFinal Layer Breakdown (parameters vs intercept term): propensity to steal")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")

            all_rounds_data_WA_prev = []
            all_rounds_data_beta = []
            all_rounds_data_Z = []
            all_rounds_data_Z_W1_zero = []

            for day_index in range(len(dbs.NN_tests_rounds)):

                if print_fine_dets:
                    print(' day_index =', day_index)

                day_end = dbs.NN_tests_rounds[day_index]

                day_end_data = dbs.final_layer_ps_breakdown[day_index]

                WA_Prev_array = []
                beta_array = []
                Z_array = []
                Z_W1_zeros_array = []

                for agent_data in day_end_data:

                    WA_Prev_array.append(agent_data[0])
                    beta_array.append(agent_data[1])
                    Z_array.append(agent_data[2])
                    Z_W1_zeros_array.append(agent_data[3])

                # process data for text
                Z_mean = np.mean(WA_Prev_array) + np.mean(beta_array)
                prop_WA_Prev = (np.mean(WA_Prev_array) / float(Z_mean))
                prop_beta = (np.mean(beta_array) / float(Z_mean))
                Z_alt_prop = (np.mean(all_rounds_data_Z_W1_zero) / float(np.mean(all_rounds_data_Z))) * 100

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nday end %4s  |  mean A_Prev.W = %6.4f (%6.4f) [prop of Z %2.2f pct]  |  mean beta = %6.4f (%6.4f) [prop of Z %2.2f pct]  |  total Z = %6.4f  |  Z-alt (input coeffs zero) = %6.4f (%2.4f pct of Z)" % (day_end, np.mean(WA_Prev_array), np.std(WA_Prev_array), prop_WA_Prev * 100, np.mean(beta_array), np.std(beta_array), prop_beta * 100, Z_mean, np.mean(Z_W1_zeros_array), Z_alt_prop))
                if file_type == 'html':
                    fileHandle.write("</p>")

                # now update data for charts
                all_rounds_data_WA_prev.append(np.mean(WA_Prev_array))
                all_rounds_data_beta.append(np.mean(beta_array))
                all_rounds_data_Z.append(np.mean(Z_array))
                all_rounds_data_Z_W1_zero.append(np.mean(Z_W1_zeros_array))

            trace_data_WA_prev = go.Scatter(x=np.array(dbs.NN_tests_rounds), y=np.array(all_rounds_data_WA_prev), name='inputs')
            trace_data_beta = go.Scatter(x=np.array(dbs.NN_tests_rounds), y=np.array(all_rounds_data_beta), name='beta')
            trace_data_Z = go.Scatter(x=np.array(dbs.NN_tests_rounds), y=np.array(all_rounds_data_Z), name='Z')
            trace_data_Z_W1_zero = go.Scatter(x=np.array(dbs.NN_tests_rounds), y=np.array(all_rounds_data_Z_W1_zero), name='Z_W1_zero')

            # trace_data_WA_prev = go.Scatter(x=np.array(dbs.NN_tests_rounds), y=np.array(all_rounds_data_WA_prev), mode='lines', fill='tonexty', name='inputs')
            # trace_data_beta = go.Scatter(x=np.array(dbs.NN_tests_rounds), y=np.array(all_rounds_data_beta), mode='lines', fill='tonexty', name='beta')

            chart_data_array = [trace_data_WA_prev, trace_data_beta]
            chart_data_dict = dict(data=chart_data_array)

            chart_data_array_Zs = [trace_data_Z, trace_data_Z_W1_zero]
            chart_data_dict_Zs = dict(data=chart_data_array)

            # print('\n all_rounds_data_WA_prev \n', all_rounds_data_WA_prev)
            # print('\n all_rounds_data_beta \n', all_rounds_data_beta)

            filename_final = '%s/NN_tests_final_layer_ps_z_breakdown_%d-%d-%d-%d-%d.html' % (filepath, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_final_zs = '%s/NN_tests_final_layer_ps_z_vs_alt_z_%d-%d-%d-%d-%d.html' % (filepath, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

            layout = go.Layout(yaxis=dict(type='linear'))
            fig = go.Figure(data=chart_data_array, layout=layout)

            fig_zs = go.Figure(data=chart_data_array_Zs, layout=layout)

            plotly.offline.plot(fig, filename=filename_final, auto_open=False)
            plotly.offline.plot(fig_zs, filename=filename_final_zs, auto_open=False)

            # now for propensity to fight back
            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nFinal Layer Breakdown (parameters vs intercept term): propensity to fight back")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")

            all_rounds_data_WA_prev = []
            all_rounds_data_beta = []
            all_rounds_data_Z = []
            all_rounds_data_Z_W1_zero = []

            for day_index in range(len(dbs.NN_tests_rounds)):

                if print_fine_dets:
                    print(' day_index =', day_index)

                day_end = dbs.NN_tests_rounds[day_index]

                day_end_data = dbs.final_layer_pfb_breakdown[day_index]

                WA_Prev_array = []
                beta_array = []
                Z_array = []
                Z_W1_zeros_array = []

                for agent_data in day_end_data:

                    WA_Prev_array.append(agent_data[0])
                    beta_array.append(agent_data[1])
                    Z_array.append(agent_data[2])
                    Z_W1_zeros_array.append(agent_data[3])

                # process data for text
                Z_mean = np.mean(WA_Prev_array) + np.mean(beta_array)
                prop_WA_Prev = (np.mean(WA_Prev_array) / float(Z_mean))
                prop_beta = (np.mean(beta_array) / float(Z_mean))
                Z_alt_prop = (np.mean(Z_W1_zeros_array) / float(np.mean(Z_array))) * 100

                # print('\n day_end =', day_end)
                # print('\n Z_mean =', Z_mean)
                # print(' np.mean(Z_array) =', np.mean(Z_array))
                # print(' prop_WA_Prev =', prop_WA_Prev)
                # print(' prop_beta =', prop_beta)
                # print(' np.mean(Z_W1_zeros_array) =', np.mean(Z_W1_zeros_array))
                # print(' Z_alt_prop =', Z_alt_prop)

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nday end %4s  |  mean A_Prev.W = %6.4f (%6.4f) [prop of Z %2.2f pct]  |  mean beta = %6.4f (%6.4f) [prop of Z %2.2f pct]  |  total Z = %6.4f  |  Z-alt (input coeffs zero) = %6.4f (%2.4f pct of Z)" % (day_end, np.mean(WA_Prev_array), np.std(WA_Prev_array), prop_WA_Prev * 100, np.mean(beta_array), np.std(beta_array), prop_beta * 100, Z_mean, np.mean(Z_W1_zeros_array), Z_alt_prop))
                if file_type == 'html':
                    fileHandle.write("</p>")

                # now update data for charts
                all_rounds_data_WA_prev.append(np.mean(WA_Prev_array))
                all_rounds_data_beta.append(np.mean(beta_array))
                all_rounds_data_Z.append(np.mean(Z_array))
                all_rounds_data_Z_W1_zero.append(np.mean(Z_W1_zeros_array))

            trace_data_WA_prev = go.Scatter(x=np.array(dbs.NN_tests_rounds), y=np.array(all_rounds_data_WA_prev), name='inputs')
            trace_data_beta = go.Scatter(x=np.array(dbs.NN_tests_rounds), y=np.array(all_rounds_data_beta), name='beta')
            trace_data_Z = go.Scatter(x=np.array(dbs.NN_tests_rounds), y=np.array(all_rounds_data_Z), name='Z')
            trace_data_Z_W1_zero = go.Scatter(x=np.array(dbs.NN_tests_rounds), y=np.array(all_rounds_data_Z_W1_zero), name='Z_W1_zero')

            chart_data_array = [trace_data_WA_prev, trace_data_beta]
            chart_data_dict = dict(data=chart_data_array)

            chart_data_array_Zs = [trace_data_Z, trace_data_Z_W1_zero]
            chart_data_dict_Zs = dict(data=chart_data_array)

            # print('\n all_rounds_data_WA_prev \n', all_rounds_data_WA_prev)
            # print('\n all_rounds_data_beta \n', all_rounds_data_beta)

            filename_final = '%s/NN_tests_final_layer_pfb_z_breakdown__%d-%d-%d-%d-%d.html' % (filepath, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)
            filename_final_zs = '%s/NN_tests_final_layer_pfb_z_vs_alt_z_%d-%d-%d-%d-%d.html' % (filepath, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

            layout = go.Layout(yaxis=dict(type='linear'))
            fig = go.Figure(data=chart_data_array, layout=layout)

            fig_zs = go.Figure(data=chart_data_array_Zs, layout=layout)

            plotly.offline.plot(fig, filename=filename_final, auto_open=False)
            plotly.offline.plot(fig_zs, filename=filename_final_zs, auto_open=False)

        # pause()


        # Now for the plotly charts' urls
        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\n\nurls for plotly charts (if used):\n")
        if file_type == 'html':
            fileHandle.write("</h2>")

        if file_type == 'html':
            fileHandle.write("<p><p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n individual agents' prop_steals: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.agents_prop_steal_url, dbs.agents_prop_steal_url))

            # dbs.agents_prop_steal_url.write_html()

        else:
            fileHandle.write("\n individual agents' prop_steals: \t\t\t\t%s" % dbs.agents_prop_steal_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n individual agents' prop_fight_back: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.agents_prop_fb_url, dbs.agents_prop_fb_url))
        else:
            fileHandle.write("\n individual agents' prop_fight_back: \t\t\t\t%s" % dbs.agents_prop_fb_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n individual agents' prop_steals >= and < 0.5: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.prop_steal_above_below_50_url, dbs.prop_steal_above_below_50_url))
        else:
            fileHandle.write("\n individual agents' prop_steals >= and < 0.5: \t\t%s" % dbs.prop_steal_above_below_50_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n individual agents' prop_fight_backs >= and < 0.5: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.prop_fb_above_below_50_url, dbs.prop_fb_above_below_50_url))
        else:
            fileHandle.write("\n individual agents' prop_fight_backs >= and < 0.5: \t\t%s" % dbs.prop_fb_above_below_50_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n prop_means (steal and fb): \t\t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.props_means_url, dbs.props_means_url))
        else:
            fileHandle.write("\n prop_means (steal and fb): \t\t\t\t\t%s" % dbs.props_means_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n prop_means start and end agents (steal and fb): \t\t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.props_means_start_end_agents_url, dbs.props_means_start_end_agents_url))
        else:
            fileHandle.write("\n prop_means start and end agents (steal and fb): \t\t\t\t\t%s" % dbs.props_means_start_end_agents_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n number of transactions and fights per round - all: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.trans_and_fights_url, dbs.trans_and_fights_url))
        else:
            fileHandle.write("\n number of transactions and fights per round - all: \t\t%s" % dbs.trans_and_fights_url)

        if two_tribes:

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of transactions and fights per round - sharks: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.trans_and_fights_url_sharks, dbs.trans_and_fights_url_sharks))
            else:
                fileHandle.write("\n number of transactions and fights per round - sharks: \t\t%s" % dbs.trans_and_fights_url_sharks)

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of transactions and fights per round - jets: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.trans_and_fights_url_jets, dbs.trans_and_fights_url_jets))
            else:
                fileHandle.write("\n number of transactions and fights per round - jets: \t\t%s" % dbs.trans_and_fights_url_jets)

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of transactions and fights per round - inter: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.trans_and_fights_url_inter, dbs.trans_and_fights_url_inter))
            else:
                fileHandle.write("\n number of transactions and fights per round - inter: \t\t%s" % dbs.trans_and_fights_url_inter)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n number of fight types per round - all: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.fight_types_url, dbs.fight_types_url))
        else:
            fileHandle.write("\n number of fight types per round: \t\t\t\t%s" % dbs.fight_types_url)

        if two_tribes:

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of fight types per round - sharks: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.fight_types_url_sharks, dbs.fight_types_url_sharks))
            else:
                fileHandle.write("\n number of fight types per round - sharks: \t\t\t\t%s" % dbs.fight_types_url_sharks)

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of fight types per round - jets: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.fight_types_url_jets, dbs.fight_types_url_jets))
            else:
                fileHandle.write("\n number of fight types per round - jets: \t\t\t\t%s" % dbs.fight_types_url_jets)

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of fight types per round - inter: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.fight_types_url_inter, dbs.fight_types_url_inter))
            else:
                fileHandle.write("\n number of fight types per round - inter: \t\t\t\t%s" % dbs.fight_types_url_inter)

        # if the agent's fight_skill was allowed to vary:
        if fight_skill is not None:

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n evolution of fight skills: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.fight_skill_url, dbs.fight_skill_url))
            else:
                fileHandle.write("\n evolution of fight skills: \t\t%s" % dbs.fight_skill_url)

        if file_type == 'html':
            fileHandle.write("</p>")

        # here we generate the results of the black_shoop_exp if there was one run
        if black_shoop_exp:

            print('---> Success Data: Black Shoop Experiment Results started')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nBlack Shoop Experiment Results\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            black_shoop_num = 0
            num_dead_black_shoops = 0
            black_shoop_aggr_birth_date = 0
            black_shoop_aggr_death_date = 0

            for black_shoop in agent_population.black_shoop_list:

                black_shoop_num += 1

                if black_shoop.death_date < rounds:

                    black_shoop_aggr_birth_date += black_shoop.birth_date
                    black_shoop_aggr_death_date += black_shoop.death_date

                    num_dead_black_shoops += 1

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\nBlack Shoop %d was born on day %d and died on day %d (life = %d days)\n" % (black_shoop_num, black_shoop.birth_date, black_shoop.death_date, black_shoop.death_date - black_shoop.birth_date))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                else:

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\nBlack Shoop %d was born on day %d and was alive at the end of the sim\n" % (black_shoop_num, black_shoop.birth_date))
                    if file_type == 'html':
                        fileHandle.write("</p>")

            mean_black_shoop_birth_date = 0
            mean_black_shoop_death_date = 0
            mean_age = 0

            if num_dead_black_shoops > 0:
                mean_black_shoop_birth_date = black_shoop_aggr_birth_date / float(num_dead_black_shoops)
                mean_black_shoop_death_date = black_shoop_aggr_death_date / float(num_dead_black_shoops)
                mean_age = mean_black_shoop_death_date - mean_black_shoop_birth_date

            if file_type == 'html':
                fileHandle.write("<p>")
                fileHandle.write("</p>")
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n\nShoops who lived and died: mean birth = %4.3f, mean death = %4.3f (mean life = %3.3f days)\n" % (mean_black_shoop_birth_date, mean_black_shoop_death_date, mean_age))
            if file_type == 'html':
                fileHandle.write("</p>")

            black_shoop_array.append(mean_black_shoop_birth_date)
            black_shoop_array.append(mean_black_shoop_death_date)

        fileHandle.write("\n\n\n\n\n\n")

        if file_type == 'html':
            fileHandle.write("<p></p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p></p>")
            fileHandle.write("</body>\n\n</html>")

        fileHandle.close()

        # copy the dbs data we wish to return before clearing dbs, which will hopefully prevent data build up
        # print('\n dbs.mkt_emerged_round =', dbs.mkt_emerged_round)
        dbs_mkt_emerged_round = copy.copy(dbs.mkt_emerged_round)
        dbs_agents_prop_steal_url = copy.copy(dbs.agents_prop_steal_url)
        dbs_agents_prop_fb_url = copy.copy(dbs.agents_prop_fb_url)
        dbs_prop_steal_above_below_50_url = copy.copy(dbs.prop_steal_above_below_50_url)
        dbs_prop_fb_above_below_50_url = copy.copy(dbs.prop_fb_above_below_50_url)
        dbs_props_means_url = copy.copy(dbs.props_means_url)
        dbs_trans_and_fights_url = copy.copy(dbs.trans_and_fights_url)
        dbs_trans_and_fights_url_sharks = copy.copy(dbs.trans_and_fights_url_sharks)
        dbs_trans_and_fights_url_jets = copy.copy(dbs.trans_and_fights_url_jets)
        dbs_trans_and_fights_url_inter = copy.copy(dbs.trans_and_fights_url_inter)
        dbs_fight_types_url = copy.copy(dbs.fight_types_url)
        dbs_fight_types_url_sharks = copy.copy(dbs.fight_types_url_sharks)
        dbs_fight_types_url_jets = copy.copy(dbs.fight_types_url_jets)
        dbs_fight_types_url_inter = copy.copy(dbs.fight_types_url_inter)
        dbs_prop_steal_mean_db = copy.copy(dbs.prop_steal_mean_db)
        dbs_prop_fb_mean_db = copy.copy(dbs.prop_fb_mean_db)
        dbs_prop_steal_means_end_agents = copy.copy(dbs.prop_steal_means_end_agents)
        dbs_prop_fb_means_end_agents = copy.copy(dbs.prop_fb_means_end_agents)
        dbs_num_ints_each_round = copy.copy(dbs.num_ints_each_round)
        dbs_num_fight_each_round = copy.copy(dbs.num_fight_each_round)
        dbs_fight_skill_url = copy.copy(dbs.fight_skill_url)
        dbs_pfb_net_contr_by_scen = dbs.pfb_net_contr_by_scen
        dbs_ps_net_contr_by_scen = dbs.ps_net_contr_by_scen

        if print_fine_dets:

            print('\n\n\n Memory Check: \n\n')

            print('\n population_data \n', population_data)
            print('\n end_foraging_data \n', end_foraging_data)
            print('\n spec_degr_data \n', spec_degr_data)
            print('\n mean_spec_array \n', mean_spec_array)
            print('\n num_spec_agents_array \n', num_spec_agents_array)
            print('\n max_probs_data \n', max_probs_data)
            print('\n res_array_data \n', res_array_data)
            print('\n actual_turnover_array \n', actual_turnover_array)
            print('\n optimal_turnover_array \n', optimal_turnover_array)
            print('\n ratio_turnover_array \n', ratio_turnover_array)

            print('\n all_age_arry \n', all_age_arry)
            print('\n num_sq_array \n', num_sq_array)
            print('\n trading_prop_array \n', trading_prop_array)
            print('\n trading_gini_array \n', trading_gini_array)
            print('\n act_prices_data \n', act_prices_data)
            print('\n act_std_prices_data \n', act_std_prices_data)
            print('\n opt_prices_data \n', opt_prices_data)
            print('\n whole_sim_opt_prices_array \n', whole_sim_opt_prices_array)
            print('\n diff_prices_data \n', diff_prices_data)
            print('\n serviced_locs_data \n', serviced_locs_data)
            print('\n dbs_mkt_emerged_round \n', dbs_mkt_emerged_round)

            print('\n KI_data \n', KI_data)
            print('\n agents_aggr_votes \n', agents_aggr_votes)
            print('\n const_record_res_accum \n', const_record_res_accum)
            print('\n slope_data \n', slope_data)
            print('\n prop_steal_data \n', prop_steal_data)
            print('\n prop_fb_data \n', prop_fb_data)
            print('\n num_trans_data \n', num_trans_data)
            print('\n num_fights_data \n', num_fights_data)
            print('\n num_scen_1_data \n', num_scen_1_data)
            print('\n num_scen_23_data \n', num_scen_23_data)
            print('\n num_scen_45_data \n', num_scen_45_data)

            print('\n dbs_agents_prop_steal_url \n', dbs_agents_prop_steal_url)
            print('\n dbs_agents_prop_fb_url \n', dbs_agents_prop_fb_url)
            print('\n dbs_prop_steal_above_below_50_url \n', dbs_prop_steal_above_below_50_url)
            print('\n dbs_prop_fb_above_below_50_url \n', dbs_prop_fb_above_below_50_url)
            print('\n dbs_props_means_url \n', dbs_props_means_url)
            print('\n dbs_trans_and_fights_url \n', dbs_trans_and_fights_url)
            print('\n dbs_trans_and_fights_url_sharks \n', dbs_trans_and_fights_url_sharks)
            print('\n dbs_trans_and_fights_url_jets \n', dbs_trans_and_fights_url_jets)

            print('\n dbs_trans_and_fights_url_inter \n', dbs_trans_and_fights_url_inter)
            print('\n dbs_fight_types_url \n', dbs_fight_types_url)
            print('\n dbs_fight_types_url_sharks \n', dbs_fight_types_url_sharks)
            print('\n dbs_fight_types_url_jets \n', dbs_fight_types_url_jets)
            print('\n dbs_fight_types_url_inter \n', dbs_fight_types_url_inter)
            print('\n black_shoop_array \n', black_shoop_array)
            print('\n dbs_prop_steal_mean_db \n', dbs_prop_steal_mean_db)
            print('\n dbs_prop_fb_mean_db \n', dbs_prop_fb_mean_db)
            print('\n dbs_num_ints_each_round \n', dbs_num_ints_each_round)

            print('\n dbs_num_fight_each_round \n', dbs_num_fight_each_round)
            print('\n dbs_fight_skill_url \n', dbs_fight_skill_url)
            print('\n game_type_dict \n', game_type_dict)
            print('\n game_type_dict_seen \n', game_type_dict_seen)
            print('\n games_type_dict_2 \n', games_type_dict_2)
            print('\n games_type_dict_3 \n', games_type_dict_3)
            print('\n classic_games_considered_sums \n', classic_games_considered_sums)
            print('\n classic_games_seen_sums \n', classic_games_seen_sums)
            print('\n\n\n')

    if respect_property_rights:

        # print('\n dbs.mkt_emerged_round =', dbs.mkt_emerged_round)
        # pause()

        dbs_mkt_emerged_round = copy.copy(dbs.mkt_emerged_round)
        dbs_agents_prop_steal_url = None
        dbs_agents_prop_fb_url = None
        dbs_prop_steal_above_below_50_url = None
        dbs_prop_fb_above_below_50_url = None
        dbs_props_means_url = None
        dbs_trans_and_fights_url = None
        dbs_trans_and_fights_url_sharks = None
        dbs_trans_and_fights_url_jets = None
        dbs_trans_and_fights_url_inter = None
        dbs_fight_types_url = None
        dbs_fight_types_url_sharks = None
        dbs_fight_types_url_jets = None
        dbs_fight_types_url_inter = None
        dbs_prop_steal_mean_db = None
        dbs_prop_fb_mean_db = None
        dbs_prop_steal_means_end_agents = None
        dbs_prop_fb_means_end_agents = None
        dbs_num_ints_each_round = None
        dbs_num_fight_each_round = None
        dbs_fight_skill_url = None
        game_type_dict = None
        game_type_dict_seen = None
        games_type_dict_2 = None
        games_type_dict_3 = None
        classic_games_considered_sums = None
        classic_games_seen_sums = None
        dbs.num_RE_games = None
        dbs.num_known_outcome_games = None
        quad_inters_dicts = None
        game_type_dict_RCT = None
        game_type_dict_seen_RCT = None
        classic_games_considered_sums_RCT = None
        classic_games_seen_sums_RCT = None
        dbs_pfb_net_contr_by_scen = None
        dbs_ps_net_contr_by_scen = None
        dbs.ps_corr_array = None
        dbs.num_doves = None
        dbs.num_PA = None
        dbs.num_hawks = None

    print('---> Success Data function ended')

    return population_data, end_foraging_data, spec_degr_data, mean_spec_array, num_spec_agents_array, max_probs_data, res_array_data, actual_turnover_array, optimal_turnover_array, ratio_turnover_array, \
           all_age_arry, num_sq_array, trading_prop_array, trading_gini_array, act_prices_data, act_std_prices_data, opt_prices_data, whole_sim_opt_prices_array, diff_prices_data, serviced_locs_data, dbs_mkt_emerged_round, \
           KI_data, agents_aggr_votes, const_record_res_accum, slope_data, prop_steal_data, prop_fb_data, num_trans_data, num_fights_data, num_scen_1_data, num_scen_23_data, num_scen_45_data, \
           dbs_agents_prop_steal_url, dbs_agents_prop_fb_url, dbs_prop_steal_above_below_50_url, dbs_prop_fb_above_below_50_url, dbs_props_means_url, dbs_trans_and_fights_url, dbs_trans_and_fights_url_sharks, dbs_trans_and_fights_url_jets, \
           dbs_trans_and_fights_url_inter, dbs_fight_types_url, dbs_fight_types_url_sharks, dbs_fight_types_url_jets, dbs_fight_types_url_inter, black_shoop_array, dbs_prop_steal_mean_db, dbs_prop_fb_mean_db, dbs_prop_steal_means_end_agents, \
           dbs_prop_fb_means_end_agents, dbs_num_ints_each_round, dbs_num_fight_each_round, dbs_fight_skill_url, game_type_dict, game_type_dict_seen, games_type_dict_2, games_type_dict_3, classic_games_considered_sums, classic_games_seen_sums,\
           dbs.num_RE_games, dbs.num_known_outcome_games, quad_inters_dicts, game_type_dict_RCT, game_type_dict_seen_RCT, classic_games_considered_sums_RCT, classic_games_seen_sums_RCT, dbs_pfb_net_contr_by_scen, dbs_ps_net_contr_by_scen,\
           dbs.res_conc_gini_starts, dbs.res_conc_gini, dbs.ps_corr_array, dbs.num_doves, dbs.num_PA, dbs.num_hawks


def write_turnover_acc_report(data_folder, rounds, dbs, gen_equ_thresh):
    """This function write a report to show the accuracy of the turnover data."""

    filepath = data_folder
    filename = "text_turnover_acc_report"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
    fileHandle.write("Turnover Accuracy Report\n\n")

    fileHandle.write("Day\tIterations\tErrors\n\n")

    for i in np.arange(rounds):

        if np.any(np.abs(dbs.optimal_bskt_errors[i]) > gen_equ_thresh):

            fileHandle.write('\n%3.0f\t%2.0d\t\t%s \t\t********' % (i, dbs.optimal_bskt_iters[i], dbs.optimal_bskt_errors[i]))

        else:

            fileHandle.write('\n%3.0f\t%2.0d\t\t%s' % (i, dbs.optimal_bskt_iters[i], dbs.optimal_bskt_errors[i]))

    fileHandle.close()


def write_succ_trans_data(dbs, day, town_grid, print_dets, data_folder, daily, daily_db):
    print('\n---> writing successful transaction data')

    if daily == 0:

        filepath = data_folder
        filename = "text_succ_trans"

        fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
        fileHandle.write("Agent Successful Transactions Data\n\n\n")

        #        print '\ndbs.trans_db =\n'
        #        for n in np.arange(len(dbs.trans_db)):
        #            print dbs.trans_db[n]

        outString = "  num\t  day\tmove\tlocation\tcp_sell\tcp_buy\ttrans\tagent_home\tcp agent home\n\n"
        fileHandle.write(outString)

        # create 2d array to record number of transactions
        grid = []
        row = []
        for k in np.arange(town_grid.dimen):
            row.append([])
        for l in np.arange(town_grid.dimen):
            grid.append(copy.deepcopy(row))

        for num in np.arange(len(dbs.trans_db)):

            inst = dbs.trans_db[num]

            #            if print_dets == 1:
            #            print '\ninst =', inst
            #            print 'inst.location =', inst.location

            if inst.good_a is not None:
                loc_x = inst.location[0]
                loc_y = inst.location[1]
                day = inst.day
                cp_ag = inst.agent_b
                subj_agent = inst.agent_a
                cp_sell_good = inst.good_b
                cp_buy_good = inst.good_a
                move_num = inst.move_num

                num_trans = inst.tot_trans_ag_sell

                grid[loc_x][loc_y].append(num)

                outString = "%5.0f" % (num) + "\t%5.0f\t" % (day) + str(move_num) + "\t[%2.0f" % (loc_x) + ", %2.0f" % (loc_y) + "]\t" + str(cp_sell_good) + "\t" + str(cp_buy_good) + "\t" + str(num_trans) + "\t[%2.0f" % (
                subj_agent.home[0]) + ", %2.0f" % (subj_agent.home[1]) + "]\t[%2.0f" % (cp_ag.home[0]) + ", %2.0f" % (cp_ag.home[1]) + "]\n"
                fileHandle.write(outString)

        # create an array to show transaction pairings:
        trans_pairs = []
        for fount in np.arange(num_res_founts - 1):
            remain_array = np.arange(fount + 1, num_res_founts)
            for el in remain_array:
                pair = np.array([fount, el])
                trans_pairs.append(pair)

        num_res_pairs = len(trans_pairs)

        if print_dets == 1:
            print('\ntrans_pairs =\n', trans_pairs)
            print('\nnum_res_pairs =', num_res_pairs)
            print('\n\n\nday =', day)

        grid_decomp = np.zeros(shape=(num_res_pairs, town_grid.dimen, town_grid.dimen))

        if print_dets == 1:
            print('\ngrid =\n\n')
            for p in np.arange(len(grid)):
                print(grid[p])

        for row in np.arange(len(grid)):
            for col in np.arange(len(grid[row])):
                if len(grid[row][col]) > 0:

                    outString = "\nLocation [" + str(row) + ", " + str(col) + "]\n\n"
                    fileHandle.write(outString)

                    data = grid[row][col]

                    if print_dets == 1:
                        print('\n\nrow =', row, 'col =', col, ' | data_array =', data)

                    tally_matrix = np.zeros(shape=(num_res_founts, num_res_founts), dtype=float)

                    for numb in data:

                        trans = dbs.trans_db[numb]

                        if print_dets == 1:
                            print('\ntrans =', trans, ' | numb =', numb)

                        for i in np.arange(num_res_founts):
                            for j in np.arange(num_res_founts):

                                if (trans.good_a == i and trans.good_b == j) or (trans.good_b == i and trans.good_a == j):

                                    if print_dets == 1:
                                        print('\ni =', i, 'j = ', j, 'tot_trans =', trans.tot_trans_ag_sell)

                                    tally_matrix[i][j] = tally_matrix[i][j] + trans.tot_trans_ag_sell

                                    if print_dets == 1:
                                        print('tally_matrix[i][j] =', tally_matrix[i][j])

                            if print_dets == 1:
                                print('\ntally_matrix =\n\n', tally_matrix)

                    for i in np.arange(num_res_founts - 1):
                        for j in np.arange(i + 1, num_res_founts):

                            if tally_matrix[i][j] > 0:
                                outString = "Pair: " + str(i) + " & " + str(j) + " (buy or sell) = " + str(tally_matrix[i][j]) + "\n"
                                fileHandle.write(outString)

        for row in np.arange(len(grid)):
            for col in np.arange(len(grid[row])):
                if len(grid[row][col]) > 0:

                    for p in np.arange(num_res_pairs):

                        pair = trans_pairs[p]
                        i = pair[0]
                        j = pair[1]

                        data = grid[row][col]

                        if print_dets == 1:
                            print('\n\nrow =', row, 'col =', col, ' | data_array =', data)

                        for numb in data:

                            trans = dbs.trans_db[numb]

                            if print_dets == 1:
                                print('\ntrans =', trans, ' | numb =', numb)

                            if (trans.good_a == i and trans.good_b == j) or (trans.good_b == i and trans.good_a == j):

                                if print_dets == 1:
                                    print('\ni =', i, 'j = ', j, 'tot_trans =', trans.tot_trans_ag_sell)

                                grid_decomp[p][row][col] += trans.tot_trans_ag_sell

        # create a colors array
        heatmap_cols = ['Reds', 'Purples', 'Greens', 'BuGn', 'BuPu', 'GnBu', 'Greys', 'OrRd', 'PuBu', 'PuBuGn', 'PuRd',
                        'Oranges', 'RdPu', 'YlGn', 'YlGnBu', 'YlOrBr', 'YlOrRd']

        for ar in np.arange(num_res_pairs):

            if print_dets == 1:
                print('\ngrid_decomp[ar] =', grid_decomp[ar])

            col = heatmap_cols[ar]
            title = 'Transaction Pair : %s - %s' % (trans_pairs[ar][0], trans_pairs[ar][1])
            create_heat_map(town_grid.dimen, grid_decomp[ar], data_folder, col, title, 'transs_pairs', dpi='low')

    elif daily == 1:

        filepath = data_folder
        filename = "text_succ_trans_daily_%s" % (day)

        fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
        fileHandle.write("Agent Successful Transactions Daily Data\n\n\n")

        #        print '\ndbs.trans_db =\n'
        #        for n in np.arange(len(dbs.trans_db)):
        #            print dbs.trans_db[n]

        outString = "  num\t  day\tmove\tlocation\tcp_sell\tcp_buy\ttrans\tagent_home\tcp agent home\n\n"
        fileHandle.write(outString)

        # create 2d array to record number of transactions
        grid = []
        row = []
        for k in np.arange(town_grid.dimen):
            row.append([])
        for l in np.arange(town_grid.dimen):
            grid.append(copy.deepcopy(row))

        for num in daily_db:

            inst = dbs.trans_db[num]

            if inst.good_a is not None:
                loc_x = inst.location[0]
                loc_y = inst.location[1]
                day = inst.day
                cp_ag = inst.agent_b
                subj_agent = inst.agent_a
                cp_sell_good = inst.good_b
                cp_buy_good = inst.good_a
                move_num = inst.move_num
                num_trans = inst.tot_trans_ag_sell

                grid[loc_x][loc_y].append(num)

                outString = "%5.0f" % (num) + "\t%5.0f\t" % (day) + str(move_num) + "\t[%2.0f" % (loc_x) + ", %2.0f" % (loc_y) + "]\t" + str(cp_sell_good) + "\t" + str(cp_buy_good) + "\t" + str(num_trans) + "\t[%2.0f" % (
                subj_agent.home[0]) + ", %2.0f" % (subj_agent.home[1]) + "]\t[%2.0f" % (cp_ag.home[0]) + ", %2.0f" % (cp_ag.home[1]) + "]\n"
                fileHandle.write(outString)

        outString = "\n\n\nData by Grid Location\n"
        fileHandle.write(outString)

        if print_dets == 1:
            print('\n\n\nday =', day)
            print('\ngrid =\n\n')
            for p in np.arange(len(grid)):
                print(grid[p])

        for row in np.arange(len(grid)):
            for col in np.arange(len(grid[row])):
                if len(grid[row][col]) > 0:

                    outString = "\nLocation [" + str(row) + ", " + str(col) + "]\n\n"
                    fileHandle.write(outString)

                    data = grid[row][col]

                    if print_dets == 1:
                        print('\n\nrow =', row, 'col =', col, ' | data_array =', data)

                    tally_matrix = np.zeros(shape=(num_res_founts, num_res_founts), dtype=int)

                    for numb in data:

                        trans = dbs.trans_db[numb]

                        if print_dets == 1:
                            print('\ntrans =', trans, ' | numb =', numb)

                        for i in np.arange(num_res_founts):
                            for j in np.arange(num_res_founts):

                                if (trans.good_a == i and trans.good_b == j) or (trans.good_b == i and trans.good_a == j):

                                    if print_dets == 1:
                                        print('\ni =', i, 'j = ', j, 'tot_trans =', trans.tot_trans_ag_sell)

                                    tally_matrix[i][j] = tally_matrix[i][j] + trans.tot_trans_ag_sell

                                    if print_dets == 1:
                                        print('tally_matrix[i][j] =', tally_matrix[i][j])

                    if print_dets == 1:
                        print('\ntally_matrix =\n\n', tally_matrix)

                    for i in np.arange(num_res_founts - 1):
                        for j in np.arange(i + 1, num_res_founts):

                            if tally_matrix[i][j] > 0:
                                outString = "Pair: " + str(i) + " & " + str(j) + " (buy or sell) = " + str(tally_matrix[i][j]) + "\n"
                                fileHandle.write(outString)


def write_for_strat_data(print_dets, print_fine_dets, dbs, fountain_population, agent_population, data_folder, rounds, two_tribes, params):
    """This function processes foraging strategy data and prints the data to a file, which is saved."""

    print('---> writing data to file: Foraging Strategy Data')

    filepath = params.run_specialisation_folder
    filename = "text_foraging_strat"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
    fileHandle.write("Foraging Strategy Data\n\n")

    fileHandle.write("Total Number of foraging slots by resource:\n\n")

    if two_tribes == 0:

        outString = "round\t\t"

        total_forag_slots_array = np.zeros(shape=(rounds, num_res_founts))

        for day in np.arange(rounds):
            for for_strat_array in dbs.for_strat_db[day]:
                for strat in for_strat_array:
                    total_forag_slots_array[day][strat] += 1

        for res in np.arange(num_res_founts):
            outString = outString + 'res ' + str(res) + '\t\t'

        outString = outString + '\n\n'

        fileHandle.write(outString)

        for day in np.arange(rounds):

            fileHandle.write('%5.0f' % (day) + '\t\t')

            for res in np.arange(num_res_founts):
                fileHandle.write('%4.0f' % (total_forag_slots_array[day][res]) + '\t\t')

            fileHandle.write('\n')

    elif two_tribes:

        total_forag_slots_array_sharks = np.zeros(shape=(rounds, 2))
        total_forag_slots_array_jets = np.zeros(shape=(rounds, 2))

        for day in np.arange(rounds):
            for for_strat_array in dbs.for_strat_db_sharks[day]:
                for strat in for_strat_array:
                    total_forag_slots_array_sharks[day][strat] += 1

            for for_strat_array in dbs.for_strat_db_jets[day]:
                for strat in for_strat_array:
                    total_forag_slots_array_jets[day][strat] += 1

        outString = "round\t\tsharks\t\tjets\n\n"
        fileHandle.write(outString)

        outString = "\t\tres 0\tres 1\tres 0\tres 1\n\n"
        fileHandle.write(outString)

        for day in np.arange(rounds):
            fileHandle.write('%5.0f' % (day) + '\t\t')

            fileHandle.write('%4.0f\t%4.0f\t%4.0f\t%4.0f\n' % (total_forag_slots_array_sharks[day][0], total_forag_slots_array_sharks[day][1], total_forag_slots_array_jets[day][0], total_forag_slots_array_jets[day][1]))

    # Now write agent-by-agent data

    fileHandle.write('\n\nAgent-by-Agent Foraging Strategy Data:\n\nStart with agents alive at the end of the simulation\n')

    for agent in agent_population.pop:

        fileHandle.write('\nAgent: ' + str(agent) + ' tribe' + agent.tribe + '\n\n')

        for day in np.arange(rounds):

            if agent.birth_date <= day <= agent.death_date:
                fileHandle.write('Day %5.0f' % (day) + ':\t' + str(agent.for_strat_hist[day]) + '\n')

    fileHandle.write('\n\nAgents who sadly died during the simulation ****************************************************\n\n')

    for agent in agent_population.dead_agent_array:

        fileHandle.write('\nAgent: ' + str(agent) + ' tribe' + agent.tribe + '\n\n')

        for day in np.arange(rounds):

            if agent.birth_date <= day <= agent.death_date:
                fileHandle.write('Day %5.0f' % (day) + ':\t' + str(agent.for_strat_hist[day]) + '\n')

    fileHandle.close()


def write_agreed_locs(dbs, data_folder, rounds):
    """This function writes the agreed location information when agree_loction is 'strong' or 'super_strong'"""

    print('---> writing data to file: agreed locations')

    filepath = data_folder
    filename = "text_agreed_locations"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
    fileHandle.write("Locations Where Agents Organised to Meet\n\n")

    for day in range(rounds):

        fileHandle.write("\n%5d \t" % day)

        if len(dbs.agreed_locs[day]) == 0:

            fileHandle.write("None")

        else:

            tot_agents = 0

            for loc in dbs.agreed_locs[day]:
                tot_agents += loc[2]

            fileHandle.write("tot locs %2d  tot org'd ags %2d  mean  %2.3f\t\t" % (len(dbs.agreed_locs[day]), tot_agents, float(tot_agents) / float(len(dbs.agreed_locs[day]))))

            for loc in dbs.agreed_locs[day]:
                fileHandle.write("loc [%2d, %2d] num %2d \t" % (loc[0], loc[1], loc[2]))

    fileHandle.close()


def write_key_agent_data(dbs, agent_population, fountain_population, data_folder, vision_len, town_grid, rounds, params):

    print('---> writing data to file: Important Agent Data')

    filepath = params.run_population_folder
    filename = "text_agent_raw_data"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
    fileHandle.write("Important Agent Data\n\n")
    fileHandle.write("Ag Num\tBirth\tForaging Strat\tAgent Res Arr\tLoc\t\t\t\tHome\t\tDist\t\tMoves to loc\tDet Skills\n\n")

    #    for i in np.arange(len(agent_population.pop)):
    #
    #        agent = agent_population.pop[i]
    #
    #        x_dist = agent.location[0] - agent.home[0]
    #
    #        if x_dist > 32:
    #            x_dist = 64 - x_dist
    #        elif 0 > x_dist > -32:
    #            x_dist = x_dist * -1
    #        elif -63 <= x_dist <= -32:
    #            x_dist = 64 + x_dist
    #
    #        y_dist = agent.location[1] - agent.home[1]
    #
    #        if y_dist > 32:
    #            y_dist = 64 - y_dist
    #        elif 0 > y_dist > -32:
    #            y_dist = y_dist * -1
    #        elif -63 <= y_dist <= -32:
    #            y_dist = 64 + y_dist
    #
    #        dist = np.array([[x_dist, y_dist]])
    #
    #        moves_to_loc = math.ceil(np.max(dist[0]) / vision_len)
    #
    #        outString = str(i) + "\t" + str(agent.birth_date) + '\t' + str(agent.for_strat_array) + '\t' + str(agent.agent_res_array) + '\t' + str(agent.location) + '\t' + str(agent.home) + '\t' + str(dist) + '\t' + str(moves_to_loc) + '\t\t' + str(agent.detect_skills_array) + '\t' + '\n'
    #        fileHandle.write(outString)
    #
    #    outString = "\n\n\nTransactions Data per Agent (surviving after the final round)\n"
    #    fileHandle.write(outString)
    #
    #    for j in np.arange(len(agent_population.pop)):
    #
    #        agent = agent_population.pop[j]
    #
    #        outString = "\n\nAgent " + str(j) + " | name :" + str(agent) + "  |  birth date: " + str(agent.birth_date)
    #        fileHandle.write(outString)
    #        outString = "\n\n day\tmove\thome\t\ttarget\t\ttrans loc\ttravel\tsale\tbuy\ttype\tcp home\t\tno trs\t\tfor_strat_array\t\tloc rec\n"
    #        fileHandle.write(outString)
    #
    #        agent_trans_array = []
    #
    #        for day in np.arange(rounds):
    #            for res_1 in np.arange(num_res_founts):
    #                for res_2 in np.arange(num_res_founts):
    #                    for trans_num in agent.loc_mems_array[day][res_1][res_2]:
    #                        agent_trans_array.append(trans_num)
    #
    #        for trans_num in agent_trans_array:
    #
    #            trans = dbs.trans_db[trans_num]
    #
    #            if trans.agent_a == agent:
    #                ag_type = 'inst'
    #                sell_good = trans.good_a
    #                buy_good = trans.good_b
    #                trgt = trans.agent_a_trgt
    #                loc_rec = trans.a_loc_rec
    #                cp = trans.agent_b
    #                for_strat_array = trans.ag_for_strat_array
    #
    #            else:
    #                ag_type = 'c/p'
    #                sell_good = trans.good_b
    #                buy_good = trans.good_a
    #                trgt = trans.agent_b_trgt
    #                loc_rec = trans.b_loc_rec
    #                cp = trans.agent_a
    #                for_strat_array = trans.cp_for_strat_array
    #
    #            # work out distance to trading point
    #            x_dist = trans.location[0] - agent.home[0]
    #
    #            if x_dist > 32:
    #                x_dist = 64 - x_dist
    #            elif 0 > x_dist > -32:
    #                x_dist = x_dist * -1
    #            elif -63 <= x_dist <= -32:
    #                x_dist = 64 + x_dist
    #
    #            y_dist = trans.location[1] - agent.home[1]
    #
    #            if y_dist > 32:
    #                y_dist = 64 - y_dist
    #            elif 0 > y_dist > -32:
    #                y_dist = y_dist * -1
    #            elif -63 <= y_dist <= -32:
    #                y_dist = 64 + y_dist
    #
    #            travel_time = np.max([x_dist, y_dist]) / float(vision_len)
    #            travel_time = int(math.ceil(travel_time))
    #
    #            loc_rec_flat = []
    #            for i in np.arange(len(loc_rec)):
    #                loc_rec_flat.append(list(loc_rec[i]))
    #
    #            outString = "\n" + "%4.0f" % (trans.day) + "\t" + str(trans.move_num) + "\t" + "[%3.0f," % (agent.home[0]) + " %3.0f]" % (agent.home[1]) + "\t" + "[%3.0f," % (trgt[0]) + " %3.0f]" % (trgt[1]) + "\t" + "[%3.0f," % (trans.location[0]) + " %3.0f]" % (trans.location[1]) + "\t" + str(travel_time) + "\t" + str(sell_good) + "\t" + str(buy_good)  + "\t" + str(ag_type) + "\t" + "[%3.0f," % (cp.home[0]) + " %3.0f]" % (cp.home[1]) + "\t" + str(trans.tot_trans_ag_sell) + "\t" + str(for_strat_array) + "\t" + "\t" + str(loc_rec_flat)
    #            fileHandle.write(outString)

    # overview of foraging and transacting

    if num_res_founts == 2:

        outString = "\n\n\nForaging, Trading & Specialisation - Some Key Data\n\n"
        fileHandle.write(outString)

        for agent in agent_population.pop:

            outString = "\n\n\nAgent " + str(agent) + "\tHome:" + str(agent.home) + "\t tribe: " + str(agent.tribe) + "\t birth " + str(agent.birth_date) + "\t death date " + str(agent.death_date) + "\n\n"
            fileHandle.write(outString)

            outString = "\nday\tfor_str_st\tstart_ress\tbskt_st\ttrans\tactual\tratio\toptimal\t\tend bskt\tdet_skills\tpr_stl\tpr_f_b\tslot\tr_min\tf_0\tf_1\tprice\tEy_0\tEy_1\tLast Loc\n"
            fileHandle.write(outString)

            start_date = np.min([agent.birth_date, rounds - 2])

            for day in range(start_date, rounds):

                #                print('agent.hist_trade_loc_rec =', agent.hist_trade_loc_rec)

                if len(agent.hist_trade_loc_rec[day]) > 0:

                    outString = "\n" + str(day) + "\t[%d %d %d %d %d]" % (agent.for_strat_hist[day][0], agent.for_strat_hist[day][1], agent.for_strat_hist[day][2], agent.for_strat_hist[day][3], agent.for_strat_hist[day][4]) + "\t[%3.2f %3.2f]" % (
                    agent.agent_res_array_hist[day - 1][0], agent.agent_res_array_hist[day - 1][1]) + "\t[%d %d]" % (agent.basket_array_start_hist[day][0], agent.basket_array_start_hist[day][1]) + "\t%d" % (
                                agent.num_act_transs[day]) + "\t%1.2f" % (agent.total_actual_agent_sales[day]) + "\t%1.2f" % (agent.personal_turnover_ratio[day]) + "\t[%1.2f %1.2f]" % (
                                agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1]) + "\t[%1.2f %1.2f]" % (agent.basket_array_hist[day][0], agent.basket_array_hist[day][1]) + "\t[%1.3f %1.3f]" % (
                                agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1]) + "\t%1.4f" % (agent.prop_steal_history[day]) + "\t%1.4f" % (agent.prop_fight_back_history[day]) + "\t%d" % (
                                agent.foraging_strat_data[day][0]) + "\t%d" % (agent.foraging_strat_data[day][1]) + "\t%2.2f" % (agent.foraging_strat_data[day][2]) + "\t%2.2f" % (agent.foraging_strat_data[day][3]) + "\t%2.4f" % (
                                agent.foraging_strat_data[day][4]) + "\t%2.4f" % (agent.foraging_strat_data[day][5]) + "\t%2.4f" % (agent.foraging_strat_data[day][6]) + "\t%s" % (agent.hist_trade_loc_rec[day][-1])

                else:

                    outString = "\n" + str(day) + "\t[%d %d %d %d %d]" % (agent.for_strat_hist[day][0], agent.for_strat_hist[day][1], agent.for_strat_hist[day][2], agent.for_strat_hist[day][3], agent.for_strat_hist[day][4]) + "\t[%3.2f %3.2f]" % (
                    agent.agent_res_array_hist[day - 1][0], agent.agent_res_array_hist[day - 1][1]) + "\t[%d %d]" % (agent.basket_array_start_hist[day][0], agent.basket_array_start_hist[day][1]) + "\t%d" % (
                                agent.num_act_transs[day]) + "\t%1.2f" % (agent.total_actual_agent_sales[day]) + "\t%1.2f" % (agent.personal_turnover_ratio[day]) + "\t[%1.2f %1.2f]" % (
                                agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1]) + "\t[%1.2f %1.2f]" % (agent.basket_array_hist[day][0], agent.basket_array_hist[day][1]) + "\t[%1.3f %1.3f]" % (
                                agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1]) + "\t%1.4f" % (agent.prop_steal_history[day]) + "\t%1.4f" % (agent.prop_fight_back_history[day]) + "\t%d" % (
                                agent.foraging_strat_data[day][0]) + "\t%d" % (agent.foraging_strat_data[day][1]) + "\t%2.2f" % (agent.foraging_strat_data[day][2]) + "\t%2.2f" % (agent.foraging_strat_data[day][3]) + "\t%2.4f" % (
                                agent.foraging_strat_data[day][4]) + "\t%2.4f" % (agent.foraging_strat_data[day][5]) + "\t%2.4f" % (agent.foraging_strat_data[day][6]) + "\tNone"

                fileHandle.write(outString)

    fileHandle.close()

#    here = 0

#    # focus on transactions & turnover
#    if num_res_founts == 2:
#
#        outString = "\n\n\nPersonal Turnover Ratio Data (Actual / Optimal Transactions)\n\n"
#        fileHandle.write(outString)
#
#        outString = "Notes: 'trans' is the number of transactions the agent was involved in, whether they traded or not.\n\n"
#        fileHandle.write(outString)
#
#        outString = "\n\nday\t"
#        fileHandle.write(outString)
#
#        for agent in agent_population.pop:
#
#            outString = str(agent.home) + "\t\t\t\t\t"
#            fileHandle.write(outString)
#
#        outString = "\n"
#        fileHandle.write(outString)
#
#        for agent in agent_population.pop:
#
#            outString = "\ttrans\tactual\tratio\toptimal\t"
#            fileHandle.write(outString)
#
#        outString = "\n"
#        fileHandle.write(outString)
#
#        for day in range(rounds):
#
#            outString = "\n" + str(day) + "\t"
#            fileHandle.write(outString)
#
#            for agent in agent_population.pop:
#
#    #            print('agent.num_act_transs[day] =', agent.num_act_transs[day], 'agent.optimal_transs_systemic[day] =', agent.optimal_transs_systemic[day], 'agent.personal_turnover_ratio[day] =', agent.personal_turnover_ratio[day])
#                outString = "%d" % (agent.num_act_transs[day]) + "\t%1.2f" % (agent.total_actual_agent_sales[day]) + "\t%1.2f" % (agent.personal_turnover_ratio[day]) + "\t[%1.2f %1.2f]\t" % (agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1])
#                fileHandle.write(outString)


def write_key_dead_agent_data(dbs, agent_population, fountain_population, data_folder, vision_len, town_grid, rounds, params):
    print('---> writing data to file: Important Dead Agent Data')

    filepath = params.run_population_folder
    filename = "text_agent_dead_raw_data"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
    fileHandle.write("Important Dead Agent Data\n\n")
    fileHandle.write("Ag Name\t\t\t\t\t\tBirth\tForaging Strat\tAgent Res Arr\tLoc\t\tHome\t\tDist\t\tMoves to loc\tDet Skills\t\t\t\tStrat Array\t\t\t\t\t\t\t\t\t\t\t\tdeath\n\n")

    #    for agent in agent_population.dead_agent_array:
    #
    #        x_dist = agent.location[0] - agent.home[0]
    #
    #        if x_dist > 32:
    #            x_dist = 64 - x_dist
    #        elif 0 > x_dist > -32:
    #            x_dist = x_dist * -1
    #        elif -63 <= x_dist <= -32:
    #            x_dist = 64 + x_dist
    #
    #        y_dist = agent.location[1] - agent.home[1]
    #
    #        if y_dist > 32:
    #            y_dist = 64 - y_dist
    #        elif 0 > y_dist > -32:
    #            y_dist = y_dist * -1
    #        elif -63 <= y_dist <= -32:
    #            y_dist = 64 + y_dist
    #
    #        dist = np.array([[x_dist, y_dist]])
    #
    #        moves_to_loc = math.ceil(np.max(dist[0]) / vision_len)
    #
    #        outString = str(agent) + "\t" + str(agent.birth_date) + '\t' + str(agent.for_strat_array) + '\t' + str(agent.agent_res_array) + '\t' + str(agent.location) + '\t' + str(agent.home) + '\t' + str(dist) + '\t' + str(moves_to_loc) + '\t\t' + str(agent.detect_skills_array) + '\t' + '\t' + str(agent.death_date) + '\n'
    #        fileHandle.write(outString)
    #
    #    outString = "\n\n\nTransactions Data per Dead Agent\n"
    #    fileHandle.write(outString)
    #
    #    for agent in agent_population.dead_agent_array:
    #
    #        outString = "\n\nAgent name" + str(agent) + "  |  home =" + str(agent.home) + "  |  birth date: " + str(agent.birth_date) + "  |  death date: " + str(agent.death_date)
    #        fileHandle.write(outString)
    #        outString = "\n\n day\tmove\thome\t\ttarget\t\ttrans loc\ttravel\tsale\tbuy\ttype\tcp home\t\tno trs\t\tfor_strat_array\ttrad_bskt\tloc rec\n"
    #        fileHandle.write(outString)
    #
    #        agent_trans_array = []
    #
    #        for day in np.arange(rounds):
    #            for res_1 in np.arange(num_res_founts):
    #                for res_2 in np.arange(num_res_founts):
    #                    for trans_num in agent.loc_mems_array[day][res_1][res_2]:
    #                        agent_trans_array.append(trans_num)
    #
    #        for trans_num in agent_trans_array:
    #
    #            trans = dbs.trans_db[trans_num]
    #
    #            if trans.agent_a == agent:
    #                ag_type = 'inst'
    #                sell_good = trans.good_a
    #                buy_good = trans.good_b
    #                trgt = trans.agent_a_trgt
    #                tb = trans.a_tb         # trading basket
    #                loc_rec = trans.a_loc_rec
    #                cp = trans.agent_b
    #                for_strat_array = trans.ag_for_strat_array
    #
    #            else:
    #                ag_type = 'c/p'
    #                sell_good = trans.good_b
    #                buy_good = trans.good_a
    #                trgt = trans.agent_b_trgt
    #                tb = trans.b_tb
    #                loc_rec = trans.b_loc_rec
    #                cp = trans.agent_a
    #                for_strat_array = trans.cp_for_strat_array
    #
    #            # work out distance to trading point
    #            x_dist = trans.location[0] - agent.home[0]
    #
    #            if x_dist > 32:
    #                x_dist = 64 - x_dist
    #            elif 0 > x_dist > -32:
    #                x_dist = x_dist * -1
    #            elif -63 <= x_dist <= -32:
    #                x_dist = 64 + x_dist
    #
    #            y_dist = trans.location[1] - agent.home[1]
    #
    #            if y_dist > 32:
    #                y_dist = 64 - y_dist
    #            elif 0 > y_dist > -32:
    #                y_dist = y_dist * -1
    #            elif -63 <= y_dist <= -32:
    #                y_dist = 64 + y_dist
    #
    #            travel_time = np.max([x_dist, y_dist]) / float(vision_len)
    #            travel_time = int(math.ceil(travel_time))
    #
    #            loc_rec_flat = []
    #            for i in np.arange(len(loc_rec)):
    #                loc_rec_flat.append(list(loc_rec[i]))
    #
    #            outString = "\n" + "%4.0f" % (trans.day) + "\t" + str(trans.move_num) + "\t" + "[%3.0f," % (agent.home[0]) + " %3.0f]" % (agent.home[1]) + "\t" + "[%3.0f," % (trgt[0]) + " %3.0f]" % (trgt[1]) + "\t" + "[%3.0f," % (trans.location[0]) + " %3.0f]" % (trans.location[1]) + "\t" + str(travel_time) + "\t" + str(sell_good) + "\t" + str(buy_good)  + "\t" + str(ag_type) + "\t" + "[%3.0f," % (cp.home[0]) + " %3.0f]" % (cp.home[1]) + "\t" + str(trans.tot_trans_ag_sell) + "\t" + str(for_strat_array) + "\t" + "\t" + str(tb) + "\t" + str(loc_rec_flat)
    #            fileHandle.write(outString)

    if num_res_founts == 2:

        outString = "\n\n\nPersonal Turnover Ratio Data (Actual / Optimal Transactions)\n\n"
        fileHandle.write(outString)

        for agent in agent_population.dead_agent_array:

            outString = "\n\n\nAgent " + str(agent) + "\tHome:" + str(agent.home) + "\t tribe: " + str(agent.tribe) + "\t birth " + str(agent.birth_date) + "\t death date " + str(agent.death_date) + "\n\n"
            fileHandle.write(outString)

            outString = "\nday\tfor_str_st\tstart_ress\tbskt_st\ttrans\tactual\tratio\toptimal\t\tend bskt\tdet_skills\tpr_stl\tpr_f_b\tslot\tr_min\tf_0\tf_1\tprice\tEy_0\tEy_1\tLast Loc\n"
            fileHandle.write(outString)

            for day in range(agent.birth_date + 1, agent.death_date + 1):

                if len(agent.hist_trade_loc_rec[day]) > 0:

                    outString = "\n" + str(day) + "\t[%d %d %d %d %d]" % (agent.for_strat_hist[day][0], agent.for_strat_hist[day][1], agent.for_strat_hist[day][2], agent.for_strat_hist[day][3], agent.for_strat_hist[day][4]) + "\t[%3.2f %3.2f]" % (
                    agent.agent_res_array_hist[day - 1][0], agent.agent_res_array_hist[day - 1][1]) + "\t[%d %d]" % (agent.basket_array_start_hist[day][0], agent.basket_array_start_hist[day][1]) + "\t%d" % (
                                agent.num_act_transs[day]) + "\t%1.2f" % (agent.total_actual_agent_sales[day]) + "\t%1.2f" % (agent.personal_turnover_ratio[day]) + "\t[%1.2f %1.2f]" % (
                                agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1]) + "\t[%1.2f %1.2f]" % (agent.basket_array_hist[day][0], agent.basket_array_hist[day][1]) + "\t[%1.3f %1.3f]" % (
                                agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1]) + "\t%1.4f" % (agent.prop_steal_history[day]) + "\t%1.4f" % (agent.prop_fight_back_history[day]) + "\t%d" % (
                                agent.foraging_strat_data[day][0]) + "\t%d" % (agent.foraging_strat_data[day][1]) + "\t%2.2f" % (agent.foraging_strat_data[day][2]) + "\t%2.2f" % (agent.foraging_strat_data[day][3]) + "\t%2.4f" % (
                                agent.foraging_strat_data[day][4]) + "\t%2.4f" % (agent.foraging_strat_data[day][5]) + "\t%2.4f" % (agent.foraging_strat_data[day][6]) + "\t%s" % (agent.hist_trade_loc_rec[day][-1])

                else:

                    outString = "\n" + str(day) + "\t[%d %d %d %d %d]" % (agent.for_strat_hist[day][0], agent.for_strat_hist[day][1], agent.for_strat_hist[day][2], agent.for_strat_hist[day][3], agent.for_strat_hist[day][4]) + "\t[%3.2f %3.2f]" % (
                    agent.agent_res_array_hist[day - 1][0], agent.agent_res_array_hist[day - 1][1]) + "\t[%d %d]" % (agent.basket_array_start_hist[day][0], agent.basket_array_start_hist[day][1]) + "\t%d" % (
                                agent.num_act_transs[day]) + "\t%1.2f" % (agent.total_actual_agent_sales[day]) + "\t%1.2f" % (agent.personal_turnover_ratio[day]) + "\t[%1.2f %1.2f]" % (
                                agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1]) + "\t[%1.2f %1.2f]" % (agent.basket_array_hist[day][0], agent.basket_array_hist[day][1]) + "\t[%1.3f %1.3f]" % (
                                agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1]) + "\t%1.4f" % (agent.prop_steal_history[day]) + "\t%1.4f" % (agent.prop_fight_back_history[day]) + "\t%d" % (
                                agent.foraging_strat_data[day][0]) + "\t%d" % (agent.foraging_strat_data[day][1]) + "\t%2.2f" % (agent.foraging_strat_data[day][2]) + "\t%2.2f" % (agent.foraging_strat_data[day][3]) + "\t%2.4f" % (
                                agent.foraging_strat_data[day][4]) + "\t%2.4f" % (agent.foraging_strat_data[day][5]) + "\t%2.4f" % (agent.foraging_strat_data[day][6]) + "\tNone"

                fileHandle.write(outString)

    fileHandle.close()


def write_key_agent_data_round(dbs, agent_population, data_folder, vision_len, day, peak_locs_array, town_grid):

    filepath = data_folder
    filename = "daily_data_%s" % (day)

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
    fileHandle.write("Daily Agent Data - Round %s\n\n" % (day))
    #    fileHandle.write("Ag Num\tBirth\tForaging Strat\tAgent Res Arr\tLoc\t\tHome\t\tDist\t\tMoves to loc\tDet Skills\t\t\t\tStrat Array\n\n")

    outString = "\npeak_locs_array =" + str(peak_locs_array) + "\n"
    fileHandle.write(outString)

    for loc in peak_locs_array:
        outString = "\npeak loc =" + str(loc) + "\n"
        fileHandle.write(outString)

        for agent in agent_population.pop:

            # note that trans_loc_mat_new2 records other-agent data i.e. what counterparty sold and bought, not agent so we must flip the good_sell and good_buy numbers:
            for good_sell in agent.buy_array:
                for good_buy in agent.sell_array:
                    for trans_loc_num in agent.trans_loc_mat_new2[good_sell][good_buy]:  # warning - this database no longer exists - re-write when needing this data

                        trans_loc = dbs.trans_db[trans_loc_num].location

                        if loc[0] == trans_loc[0][0] and loc[1] == trans_loc[0][1]:
                            # if this condition is true then the agent transacted at this location with these sell & buy goods

                            x_dist = agent.location[0] - agent.home[0]

                            if x_dist > 32:
                                x_dist = 64 - x_dist
                            elif 0 > x_dist > -32:
                                x_dist = x_dist * -1
                            elif -63 <= x_dist <= -32:
                                x_dist = 64 + x_dist

                            y_dist = agent.location[1] - agent.home[1]

                            if y_dist > 32:
                                y_dist = 64 - y_dist
                            elif 0 > y_dist > -32:
                                y_dist = y_dist * -1
                            elif -63 <= y_dist <= -32:
                                y_dist = 64 + y_dist

                            travel_time = np.max([x_dist, y_dist]) / float(vision_len)
                            travel_time = int(math.ceil(travel_time))

                            outString = "agent transacted here: home is " + str(agent.home) + "  |  dist = " + str(int(x_dist)) + ", " + str(int(y_dist)) + "  |  Travel Time = " + str(travel_time) + " moves\n"
                            fileHandle.write(outString)


#    fileHandle.close()


def write_ag_age_data(dbs, data_folder, params):

    filepath = params.run_population_folder
    filename = "population_age_written"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute), 'w')
    fileHandle.write("Average Age of Agents\n\n")
    fileHandle.write("Round\tAv Age\n")

    for day in dbs.ag_age_db[0]:
        outString = str(dbs.ag_age_db[0][day]) + "\t" + str(dbs.ag_age_db[1][day]) + "\n"
        fileHandle.write(outString)

    fileHandle.close()

class Parameters_Object():

    def __init__(self, params_dict, ststst, fount_dep, applied_constitutions, NN_dimensions, NN_dimensions_ps,
                 NN_dimensions_pfb, write_detailed_S_D_data, child_res, show_res_conc_charts, learning_feedback_scale,
                 pop_av):

        for item in params_dict:

            # print('item =', item, 'params_dict[item] =', params_dict[item], 'type(params_dict[item]) =', type(params_dict[item]))

            if type(params_dict[item]) is int:

                exec('self.%s = %d' % (item, params_dict[item]))

            if type(params_dict[item]) is float:

                exec('self.%s = %f' % (item, params_dict[item]))

            elif type(params_dict[item]) is str:

                exec('self.%s = "%s"' % (item, params_dict[item]))

            elif params_dict[item] is None:

                exec('self.%s = None' % item)

            elif item == 'ststst':

                self.ststst = ststst

            elif item == 'fount_dep':

                self.fount_dep = fount_dep

            elif item == 'applied_constitutions':

                self.applied_constitutions = applied_constitutions

            elif item == 'NN_dimensions':

                self.NN_dimensions = NN_dimensions

            elif item == 'NN_dimensions_ps':

                self.NN_dimensions_ps = NN_dimensions_ps

            elif item == 'NN_dimensions_pfb':

                self.NN_dimensions_pfb = NN_dimensions_pfb

            elif item == 'write_detailed_S_D_data':

                self.write_detailed_S_D_data = write_detailed_S_D_data

            elif item == 'child_res':

                self.child_res = child_res

            elif item == 'for_skill_change':

                self.for_skill_change = for_skill_change

            elif item == 'propensities_change':

                self.propensities_change = propensities_change

            elif item == 'show_res_conc_charts':

                self.show_res_conc_charts = show_res_conc_charts

            elif item == 'learning_feedback_scale' and type(learning_feedback_scale) == str:

                self.show_res_conc_charts = self.show_res_conc_charts

            elif item == 'pop_av':

                self.pop_av = pop_av

            # if type(params_dict[item]) is not int and type(params_dict[item]) is not float and type(params_dict[item]) is not str and params_dict[item] is not None:
            #
            #     print('\n ****** PROBLEM ******')
            #     pause()

        # print('\n resulting self.ststst', self.ststst, 'self.fount_dep', self.fount_dep, 'self.applied_constitutions', self.applied_constitutions)
        #
        # pause()


class Sim_Suite_Object():

    def __init__(self, allow_Keynes_Inst, print_voting_only, print_local_policy_data, num_experiments, applied_constitutions, popn_ch, total_num_sims, track_game_types, respect_property_rights, run_dist_to_mkt_OLS, OLS_include):

        self.respect_property_rights = respect_property_rights
        self.total_num_sims = total_num_sims
        self.track_game_types = track_game_types
        self.numb_of_sims = 0

        self.allow_Keynes_Inst = allow_Keynes_Inst
        self.print_voting_only = print_voting_only
        self.print_local_policy_data = print_local_policy_data
        self.num_experiments = num_experiments
        self.applied_constitutions = applied_constitutions
        self.popn_ch = popn_ch
        self.results_to_email = ''  # this is a file which is copied from the last results txt file, so it can be emailed
        self.run_dist_to_mkt_OLS = run_dist_to_mkt_OLS
        self.OLS_include = OLS_include

        self.population_data = []
        self.foraging_data = []
        self.spec_data = []
        self.mean_spec_data = []
        self.num_spec_agents_data = []
        self.max_probability_data = []
        self.resource_array_data = []
        self.actual_turnover_data = []
        self.optimal_turnover_data = []
        self.ratio_turnover_data = []
        self.all_age_data = []
        self.num_sq_data = []
        self.trading_prop_data = []
        self.trading_gini_data = []
        self.act_prices_data = []
        self.act_std_prices_data = []
        self.opt_prices_data = []
        self.whole_sim_opt_prices_data = []
        self.diff_prices_data = []
        self.serviced_locs_data = []
        self.mkt_emerged_round = []
        self.KI_data_all = []
        self.agents_aggr_votes_data = []
        self.const_record_res_accum_data = []
        self.slope_data = []
        self.prop_steal_data = []
        self.prop_fb_data = []
        self.num_trans_data = []
        self.num_fights_data = []
        self.num_scen_1_data = []
        self.num_scen_23_data = []
        self.num_scen_45_data = []

        self.agents_prop_steal_urls = []
        self.agents_prop_fb_urls = []
        self.prop_steal_above_below_50_urls = []
        self.prop_fb_above_below_50_urls = []
        self.props_means_urls = []
        self.trans_and_fights_urls = []
        self.trans_and_fights_urls_sharks = []
        self.trans_and_fights_urls_jets = []
        self.trans_and_fights_urls_inter = []
        self.fight_skills_urls = []

        self.prop_steal_mean_db = []
        self.prop_fb_mean_db = []
        self.prop_steal_mean_start_end_ags_db = []
        self.prop_fb_mean_start_end_ags_db = []
        self.num_ints_each_round = []
        self.num_fight_each_round = []

        self.fight_types_urls = []
        self.fight_types_urls_sharks = []
        self.fight_types_urls_jets = []
        self.fight_types_urls_inter = []

        self.black_shoop_data = []

        self.dbss = []

        self.game_type_dict = dict()
        self.game_type_dict_seen = dict()
        self.games_type_dict_2 = dict()
        self.games_type_dict_3 = dict()

        self.classic_games_considered_sums = dict()
        self.classic_games_seen_sums = dict()

        self.game_type_dict_RCT = dict()
        self.game_type_dict_seen_RCT = dict()
        self.classic_games_considered_sums_RCT = dict()
        self.classic_games_seen_sums_RCT = dict()

        self.num_RE_games = 0
        self.num_known_outcome_games = 0

        self.quad_inters_dicts = dict()

        self.quad_inters_dicts['1'] = []
        self.quad_inters_dicts['2F'] = []
        self.quad_inters_dicts['2A'] = []
        self.quad_inters_dicts['3F'] = []
        self.quad_inters_dicts['3A'] = []
        self.quad_inters_dicts['4'] = []

        self.dbs_pfb_net_contr_by_scen = {'1' : 0, '2F' : 0, '2A' : 0, '3F' : 0, '3A' : 0, '4' : 0}
        self.dbs_ps_net_contr_by_scen = {'1' : 0, '2F' : 0, '2A' : 0, '3F' : 0, '3A' : 0, '4' : 0}

        self.res_conc_gini_starts = []
        self.res_conc_gini = []

        self.ps_corr_arrays = []

        self.num_doves_db = []
        self.num_PA_db = []
        self.num_hawks_db = []

    def add_sub_folder(self, sub_folder):

        self.sub_folder = sub_folder

    def add_segment_size(self, segment_size):

        self.segment_size = segment_size

    def add_to_dbs(self, single_sim_data):

        # unpack single_sim_data
        pop_data, end_foraging_data, spec_degr_data, mean_spec_array, num_spec_agents_array, max_probs_data, res_array_data, actual_turnover_array, optimal_turnover_array, ratio_turnover_array, all_age_arry, \
        num_sq_array, trading_prop_array, trading_gini_array, act_prices_array, act_std_prices_array, opt_prices_array, whole_sim_opt_prices_array, diff_prices_array, serviced_locs_data, mkt_emerged_round, \
        KI_data, agents_aggr_votes, const_record_res_accum, slope_data, prop_steal_data, prop_fb_data, num_trans_data, num_fights_data, num_scen_1_data, num_scen_23_data, num_scen_45_data, \
        agents_prop_steal_url, agents_prop_fb_url, prop_steal_above_below_50_url, prop_fb_above_below_50_url, props_means_url, trans_and_fights_url, trans_and_fights_url_sharks, trans_and_fights_url_jets, \
        trans_and_fights_url_inter, fight_types_url, fight_types_url_sharks, fight_types_url_jets, fight_types_url_inter, black_shoop_array, prop_steal_mean_db, prop_fb_mean_db, prop_steal_mean_start_end_ags_db, prop_fb_mean_start_end_ags_db, \
        num_ints_each_round, num_fight_each_round, fight_skill_url, game_type_dict, game_type_dict_seen, games_type_dict_2, games_type_dict_3, classic_games_considered_sums, classic_games_seen_sums, num_RE_games, num_known_outcome_games, \
        quad_inters_dicts_single_run, game_type_dict_RCT, game_type_dict_seen_RCT, classic_games_considered_sums_RCT, classic_games_seen_sums_RCT, dbs_pfb_net_contr_by_scen, dbs_ps_net_contr_by_scen, res_conc_gini_starts, \
        res_conc_gini, ps_corr_array, num_doves_sim, num_PA_sim, num_hawks_sim = single_sim_data

        if self.print_voting_only == 0:

            self.foraging_data.append(end_foraging_data)
            self.spec_data.append(spec_degr_data)
            self.mean_spec_data.append(mean_spec_array)
            self.num_spec_agents_data.append(num_spec_agents_array)
            self.max_probability_data.append(max_probs_data)
            self.resource_array_data.append(res_array_data)
            self.actual_turnover_data.append(actual_turnover_array)
            self.optimal_turnover_data.append(optimal_turnover_array)
            self.ratio_turnover_data.append(ratio_turnover_array)
            self.all_age_data.append(all_age_arry)
            self.num_sq_data.append(num_sq_array)
            self.trading_prop_data.append(trading_prop_array)
            self.trading_gini_data.append(trading_gini_array)
            self.serviced_locs_data.append(serviced_locs_data)
            self.mkt_emerged_round.append(mkt_emerged_round)
            self.KI_data_all.append(KI_data)
            self.slope_data.append(slope_data)
            self.prop_steal_data.append(prop_steal_data)
            self.prop_fb_data.append(prop_fb_data)
            self.num_trans_data.append(num_trans_data)
            self.num_fights_data.append(num_fights_data)
            self.num_scen_1_data.append(num_scen_1_data)
            self.num_scen_23_data.append(num_scen_23_data)
            self.num_scen_45_data.append(num_scen_45_data)

            self.agents_prop_steal_urls.append(agents_prop_steal_url)
            self.agents_prop_fb_urls.append(agents_prop_fb_url)
            self.prop_steal_above_below_50_urls.append(prop_steal_above_below_50_url)
            self.prop_fb_above_below_50_urls.append(prop_fb_above_below_50_url)
            self.props_means_urls.append(props_means_url)
            self.trans_and_fights_urls.append(trans_and_fights_url)
            self.trans_and_fights_urls_sharks.append(trans_and_fights_url_sharks)
            self.trans_and_fights_urls_jets.append(trans_and_fights_url_jets)
            self.trans_and_fights_urls_inter.append(trans_and_fights_url_inter)
            self.fight_types_urls.append(fight_types_url)
            self.fight_types_urls_sharks.append(fight_types_url_sharks)
            self.fight_types_urls_jets.append(fight_types_url_jets)
            self.fight_types_urls_inter.append(fight_types_url_inter)

            self.prop_steal_mean_db.append(prop_steal_mean_db)
            self.prop_fb_mean_db.append(prop_fb_mean_db)

            self.prop_steal_mean_start_end_ags_db.append(prop_steal_mean_start_end_ags_db)
            self.prop_fb_mean_start_end_ags_db.append(prop_fb_mean_start_end_ags_db)

            self.num_ints_each_round.append(num_ints_each_round)
            self.num_fight_each_round.append(num_fight_each_round)

            self.fight_skills_urls.append(fight_skill_url)

            self.black_shoop_data.append(black_shoop_array)

            if self.respect_property_rights == 0 and len(game_type_dict) > 0:

                for game_type in game_type_dict:

                    if game_type in self.game_type_dict:

                        self.game_type_dict[game_type] += game_type_dict[game_type]

                    else:

                        self.game_type_dict[game_type] = game_type_dict[game_type]

            if self.respect_property_rights == 0 and len(game_type_dict_seen) > 0:

                for game_type in game_type_dict_seen:

                    if game_type in self.game_type_dict_seen:

                        self.game_type_dict_seen[game_type] += game_type_dict_seen[game_type]

                    else:

                        self.game_type_dict_seen[game_type] = game_type_dict_seen[game_type]

            if self.respect_property_rights == 0 and len(game_type_dict_RCT) > 0:

                for game_type in game_type_dict_RCT:

                    if game_type in self.game_type_dict_RCT:

                        self.game_type_dict_RCT[game_type] += game_type_dict_RCT[game_type]

                    else:

                        self.game_type_dict_RCT[game_type] = game_type_dict_RCT[game_type]

            if self.respect_property_rights == 0 and len(game_type_dict_seen_RCT) > 0:

                for game_type in game_type_dict_seen_RCT:

                    if game_type in self.game_type_dict_seen_RCT:

                        self.game_type_dict_seen_RCT[game_type] += game_type_dict_seen_RCT[game_type]

                    else:

                        self.game_type_dict_seen_RCT[game_type] = game_type_dict_seen_RCT[game_type]

            if self.respect_property_rights == 0 and len(games_type_dict_2) > 0:

                for game_type in games_type_dict_2:

                    if game_type in self.games_type_dict_2:

                        self.games_type_dict_2[game_type] += games_type_dict_2[game_type]

                    else:

                        self.games_type_dict_2[game_type] = games_type_dict_2[game_type]

            if self.respect_property_rights == 0 and len(games_type_dict_3) > 0:

                for game_type in games_type_dict_3:

                    if game_type in self.games_type_dict_3:

                        self.games_type_dict_3[game_type] += games_type_dict_3[game_type]

                    else:

                        self.games_type_dict_3[game_type] = games_type_dict_3[game_type]

            if self.respect_property_rights == 0 and len(classic_games_considered_sums) > 0:

                for classic_game_type in classic_games_considered_sums:

                    if classic_game_type in self.classic_games_considered_sums:

                        self.classic_games_considered_sums[classic_game_type] += classic_games_considered_sums[
                            classic_game_type]

                    else:

                        self.classic_games_considered_sums[classic_game_type] = classic_games_considered_sums[
                            classic_game_type]

            if self.respect_property_rights == 0 and len(classic_games_seen_sums) > 0:

                for classic_game_type in classic_games_seen_sums:

                    if classic_game_type in self.classic_games_seen_sums:

                        self.classic_games_seen_sums[classic_game_type] += classic_games_seen_sums[classic_game_type]

                    else:

                        self.classic_games_seen_sums[classic_game_type] = classic_games_seen_sums[classic_game_type]


            if self.respect_property_rights == 0 and len(classic_games_considered_sums_RCT) > 0:

                for classic_game_type in classic_games_considered_sums_RCT:

                    if classic_game_type in self.classic_games_considered_sums_RCT:

                        self.classic_games_considered_sums_RCT[classic_game_type] += classic_games_considered_sums_RCT[classic_game_type]

                    else:

                        self.classic_games_considered_sums_RCT[classic_game_type] = classic_games_considered_sums_RCT[classic_game_type]

            if self.respect_property_rights == 0 and len(classic_games_seen_sums_RCT) > 0:

                for classic_game_type in classic_games_seen_sums_RCT:

                    if classic_game_type in self.classic_games_seen_sums_RCT:

                        self.classic_games_seen_sums_RCT[classic_game_type] += classic_games_seen_sums_RCT[classic_game_type]

                    else:

                        self.classic_games_seen_sums_RCT[classic_game_type] = classic_games_seen_sums_RCT[classic_game_type]

            if self.respect_property_rights == 0:

                self.num_RE_games += num_RE_games
                self.num_known_outcome_games += num_known_outcome_games

                for scen in ['1', '2F', '2A', '3F', '3A', '4']:

                    self.dbs_pfb_net_contr_by_scen[scen] += np.sum(dbs_pfb_net_contr_by_scen[scen])
                    self.dbs_ps_net_contr_by_scen[scen] += np.sum(dbs_ps_net_contr_by_scen[scen])

        # now delete the dictionaries we received - I suspect these dictionaries lead to a large accumulation of memory
        if self.respect_property_rights == 0:

            game_type_dict.clear
            game_type_dict_seen.clear
            games_type_dict_2.clear
            games_type_dict_3.clear
            classic_games_considered_sums.clear
            classic_games_seen_sums.clear

        if self.popn_ch != 'fixed':
            self.population_data.append(pop_data)

        self.agents_aggr_votes_data.append(agents_aggr_votes)
        self.const_record_res_accum_data.append(const_record_res_accum)

        if self.print_local_policy_data == 0 or self.print_voting_only == 1:
            self.act_prices_data.append(act_prices_array)
            self.act_std_prices_data.append(act_std_prices_array)
            self.opt_prices_data.append(opt_prices_array)
            self.diff_prices_data.append(diff_prices_array)
            self.whole_sim_opt_prices_data.append(whole_sim_opt_prices_array)

    #        self.dbss.append(run_dbs)

        dict_num = 0

        if self.respect_property_rights == 0:

            for dict_name in ['1', '2F', '2A', '3F', '3A', '4']:

                self.quad_inters_dicts[dict_name].append(quad_inters_dicts_single_run[dict_num])

                dict_num += 1

        self.res_conc_gini_starts.append(res_conc_gini_starts)
        self.res_conc_gini.append(res_conc_gini)
        self.ps_corr_arrays.append(ps_corr_array)

        self.num_doves_db.append(num_doves_sim)
        self.num_PA_db.append(num_PA_sim)
        self.num_hawks_db.append(num_hawks_sim)

    def remove_run_data(self, run_num):

        """In the event of one of the runs having bad data, we can remove it with this function.  We just need a run
        number."""

        del self.foraging_data[run_num]
        del self.spec_data[run_num]
        del self.mean_spec_data[run_num]
        del self.max_probability_data[run_num]
        del self.resource_array_data[run_num]
        del self.actual_turnover_data[run_num]
        del self.optimal_turnover_data[run_num]
        del self.all_age_data[run_num]
        del self.cc_data[run_num]
        del self.num_sq_data[run_num]
        del self.act_prices_data[run_num]
        del self.opt_prices_data[run_num]
        del self.diff_prices_data[run_num]

        del self.dbss[run_num]

        self.numb_of_sims -= 1

    def save_sim_set_data(self, sub_folder, rounds, for_strat_parts, constitutional_voting, start_const_proces, const_proc_test_period, constitutional_exp, respect_property_rights,
                          file_type, black_shoop_exp, two_tribes, fight_skill, plotly_online, print_fine_dets=0):

        """This function writes all of the relevant sim set data to file."""

        print('\n---> writing data to file: save_sim_set_data')

        print_fine_dets = 0

        # filename = "sim_set_data_%d" % (self.numb_of_sims)

        new_file = '%s/sim_set_data.html' % self.sub_folder

        # if file_type == 'html':
        #
        #     new_file = '%s/%s %d-%d-%d-%d-%d-%d.html' % (
        #     self.sub_folder, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day,
        #     dt.datetime.now().hour, dt.datetime.now().minute, dt.datetime.now().second)
        #
        # else:
        #
        #     new_file = '%s/%s %d-%d-%d-%d-%d-%d.txt' % (
        #     self.sub_folder, filename, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day,
        #     dt.datetime.now().hour, dt.datetime.now().minute, dt.datetime.now().second)

        fileHandle = open(new_file, 'w')

        if file_type == 'html':
            fileHandle.write("<html>")
            fileHandle.write("<h1>")
        fileHandle.write("Data For a Single Sim Set\n\n")
        if file_type == 'html':
            fileHandle.write("</h1>")

        if file_type == 'html':
            fileHandle.write("<p>")
        fileHandle.write("Number of Runs in the Simulation Suite = %d\n\n\n" % (self.numb_of_sims))
        if file_type == 'html':
            fileHandle.write("</p>")

        # this is in order to identify the set of results to email

        self.results_to_email = new_file

        ten_pct_rounds_array = list(range(0, rounds, int(self.segment_size)))
        ten_pct_gap = int(self.segment_size)

        data_segments = int(rounds / self.segment_size)

        if self.print_voting_only == 0:

            # Population Data
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("Population Data (agents per round)\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.population_data =\n', self.population_data)

            if self.popn_ch == 'fixed':

                fileHandle.write("\nThe population was fixed at %d agents in all simulations" % (num_agents))

            else:

                for segment in range(data_segments):

                    if print_fine_dets == 1:
                        print('\n\nsegment =', segment)

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    if two_tribes == 0:

                        mean_array = [run[segment] for run in self.population_data]

                        mean_pop = np.mean(mean_array)
                        std_pop = np.std(mean_array)

                        min_pop = np.min(mean_array)
                        max_pop = np.max(mean_array)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nRounds %04d to %04d: mean popn = %4.1f (%4.1f) [min %2.2f max %2.2f] - array [" % (
                        start_round, end_round - 1, mean_pop, std_pop, min_pop, max_pop))
                        for i in mean_array:
                            fileHandle.write("%2.1f &nbsp; " % i)
                        fileHandle.write("]")
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    elif two_tribes:

                        mean_array = [run[segment][0] for run in self.population_data]

                        mean_pop = np.mean(mean_array)
                        std_pop = np.std(mean_array)

                        mean_array_sharks = [run[segment][1] for run in self.population_data]

                        mean_pop_sharks = np.mean(mean_array_sharks)
                        std_pop_sharks = np.std(mean_array_sharks)

                        mean_array_jets = [run[segment][2] for run in self.population_data]

                        mean_pop_jets = np.mean(mean_array_jets)
                        std_pop_jets = np.std(mean_array_jets)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %d to %d: mean popn (all) = %2.4f (%2.4f)  |  sharks  %2.4f (%2.4f)  |  jets %2.4f (%2.4f)" % (
                            start_round, end_round - 1, mean_pop, std_pop, mean_pop_sharks, std_pop_sharks,
                            mean_pop_jets, std_pop_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

            # Doves, Passive_Aggressive Agents, and Hawks

            # print('\n self.num_doves_db =', self.num_doves_db)
            # print('\n self.num_PA_db =', self.num_PA_db)
            # print('\n self.num_hawks_db =', self.num_hawks_db)
            #
            # pause()     # xxxx

            if respect_property_rights == 0:

                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("Number of Doves, Passive_Aggressive Agents, and Hawks (agents per round)\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("Number of Doves (agents per round)\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for segment in range(data_segments):

                    # if print_fine_dets == 1:      xxxx
                    # print('\n\nsegment =', segment)

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    # print('\n start_round =', start_round)
                    # print(' end_round =', end_round)

                    mean_array = []

                    for run in self.num_doves_db:
                        mean_run_val = np.mean(run[start_round:end_round])
                        mean_array.append(mean_run_val)

                    # print('\n mean_array =', mean_array)

                    # mean_array = [run[segment] for run in self.num_doves_db]

                    mean_pop = np.mean(mean_array)
                    std_pop = np.std(mean_array)

                    min_pop = np.min(mean_array)
                    max_pop = np.max(mean_array)

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\nRounds %04d to %04d: mean doves = %4.1f (%4.1f) [min %2.2f max %2.2f] - array [" % (
                    start_round, end_round - 1, mean_pop, std_pop, min_pop, max_pop))
                    for i in mean_array:
                        fileHandle.write("%2.1f &nbsp; " % i)
                    fileHandle.write("]")
                    if file_type == 'html':
                        fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("Number of P-A Agents (agents per round)\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for segment in range(data_segments):

                    if print_fine_dets == 1:
                        print('\n\nsegment =', segment)

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    mean_array = []

                    for run in self.num_PA_db:
                        mean_run_val = np.mean(run[start_round:end_round])
                        mean_array.append(mean_run_val)

                    # print('\n mean_array =', mean_array)

                    # mean_array = [run[segment] for run in self.num_PA_db]

                    mean_pop = np.mean(mean_array)
                    std_pop = np.std(mean_array)

                    min_pop = np.min(mean_array)
                    max_pop = np.max(mean_array)

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\nRounds %04d to %04d: mean P-A Agents = %4.1f (%4.1f) [min %2.2f max %2.2f] - array [" % (
                    start_round, end_round - 1, mean_pop, std_pop, min_pop, max_pop))
                    for i in mean_array:
                        fileHandle.write("%2.1f &nbsp; " % i)
                    fileHandle.write("]")
                    if file_type == 'html':
                        fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("Number of Hawks (agents per round)\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for segment in range(data_segments):

                    if print_fine_dets == 1:
                        print('\n\nsegment =', segment)

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    mean_array = []

                    for run in self.num_hawks_db:
                        mean_run_val = np.mean(run[start_round:end_round])
                        mean_array.append(mean_run_val)

                    # print('\n mean_array =', mean_array)

                    # mean_array = [run[segment] for run in self.num_hawks_db]

                    mean_pop = np.mean(mean_array)
                    std_pop = np.std(mean_array)

                    min_pop = np.min(mean_array)
                    max_pop = np.max(mean_array)

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\nRounds %04d to %04d: mean hawks = %4.1f (%4.1f) [min %2.2f max %2.2f] - array [" % (
                    start_round, end_round - 1, mean_pop, std_pop, min_pop, max_pop))
                    for i in mean_array:
                        fileHandle.write("%2.1f &nbsp; " % i)
                    fileHandle.write("]")
                    if file_type == 'html':
                        fileHandle.write("</p>")

            # Foraging Data

            print('---> writing Foraging Data')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\nForaging Data (total foraged from fountains in each round)")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.foraging_data =\n', self.foraging_data)

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
                if file_type == 'html':
                    fileHandle.write("</h3>")

                # create array to record all means
                all_means = []
                all_stds = []

                for res in range(num_res_founts):

                    if print_fine_dets == 1:
                        print('\nres =', res)

                    mean_array = [run[segment][res][1] for run in self.foraging_data]
                    std_array = [run[segment][res][2] for run in self.foraging_data]

                    mean_mean = np.mean(mean_array)
                    mean_std = np.mean(std_array)

                    if two_tribes == 0:

                        if print_fine_dets == 1:
                            print('\nmean_array =', mean_array)
                            print('\nstd_array =', std_array)

                            print('mean mean = ', np.mean(mean_array))
                            print('mean std = ', np.mean(std_array))

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s Mean = %3.4f (%3.2f)" % (res, mean_mean, mean_std))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    if two_tribes:

                        mean_array_sharks = [run[segment][res][1] for run in self.foraging_data]
                        std_array_sharks = [run[segment][res][2] for run in self.foraging_data]

                        mean_mean_sharks = np.mean(mean_array_sharks)
                        mean_std_sharks = np.mean(std_array_sharks)

                        mean_array_jets = [run[segment][res][3] for run in self.foraging_data]
                        std_array_jets = [run[segment][res][4] for run in self.foraging_data]

                        mean_mean_jets = np.mean(mean_array_jets)
                        mean_std_jets = np.mean(std_array_jets)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s Mean Sharks = %3.4f (%3.2f)  |  Jets = %3.4f (%3.2f)" % (
                        res, mean_mean_sharks, mean_std_sharks, mean_mean_jets, mean_std_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    if segment == data_segments - 1:
                        all_means.append(mean_mean)
                        all_stds.append(mean_std)

                    # now find table data
                    tab_for_mean = np.mean(all_means)
                    tab_for_std = np.mean(all_stds)

            # Specialisation Data

            print('---> writing Specialisation Data')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nSpecialisation Data (numbers of agents in specialisation buckets)")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.spec_data =\n', self.spec_data)
                print('\nself.mean_spec_data =\n', self.mean_spec_data)

            # find minimum value of max foraging value
            min_max_spec = int(for_strat_parts / float(num_res_founts))

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for spec_value in np.arange(min_max_spec, for_strat_parts + 1, dtype=int):

                    if print_fine_dets == 1:
                        print('\nspec_value =', spec_value)

                    mean_array = [run[segment][spec_value][1] for run in self.spec_data]
                    std_array = [run[segment][spec_value][2] for run in self.spec_data]

                    mean_mean = np.mean(mean_array)
                    mean_std = np.mean(std_array)

                    # Note: the mean_mean and mean_std values are in units of no. of agents with these spec_values, so the data shows the average number of agents with these values in each segment

                    if print_fine_dets == 1:
                        print('\nmean_array =', mean_array)
                        print('\nstd_array =', std_array)

                        print('mean mean = ', np.mean(mean_array))
                        print('mean std = ', np.mean(std_array))

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nSpecialisation Bucket %d Mean = %3.4f (%3.2f)" % (spec_value, mean_mean, mean_std))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                #            print(' segment ', segment, '[run[segment][0] for run in self.mean_spec_data]:\n\n', [run[segment][0] for run in self.mean_spec_data])
                #            print('\n segment ', segment, '[run[segment][1] for run in self.mean_spec_data]:\n\n', [run[segment][1] for run in self.mean_spec_data])

                mean_specs_array = [run[segment][0] for run in self.mean_spec_data if run[segment][0] is not None]

                if len(mean_specs_array) > 0:

                    mean_of_mean_specs = np.mean(mean_specs_array)

                else:

                    mean_of_mean_specs = None

                std_specs_array = [run[segment][1] for run in self.mean_spec_data if run[segment][1] is not None]

                if len(std_specs_array) > 0:

                    mean_of_std_specs = np.mean(std_specs_array)

                else:

                    mean_of_std_specs = None

                # Note: the values of mean_of_mean_specs and mean_of_std_specs are in units of no. of rousure fountains visited, showing mean (and std) of mean_max_spec value in each segment
                # so if we run 1000 rounds in each sim, each segment will be 100 rounds.  In each of these 100 rounds we find a mean_max_spec value over all agents; we then find the mean and std of that value
                # over the 100 rounds.  We then find the means of these two values, which are mean_of_mean_specs and mean_of_std_specs

                if file_type == 'html':
                    fileHandle.write("<p>")
                fileHandle.write("\n\nOverall Mean Specialisation = %s (%s)" % (mean_of_mean_specs, mean_of_std_specs))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if segment == data_segments - 1:
                    tab_spec_mean = mean_of_mean_specs
                    tab_spec_std = mean_of_std_specs

            # Number of Specialists

            print('---> writing Specialisation Data (number of agents fully specialised)')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write(
                "\n\n\n\nSpecialisation Data (number of agents fully specialised (detection prob > 0.99))\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets:
                print('\n self.num_spec_agents_data =\n\n', self.num_spec_agents_data)

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\nsegment =', segment)

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                mean_of_segment = np.mean([run[segment][0] for run in self.num_spec_agents_data])
                mean_of_std = np.mean([run[segment][1] for run in self.num_spec_agents_data])
                std_of_means = np.std([run[segment][0] for run in self.num_spec_agents_data])

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %d to %d: mean num = %2.4f (%2.4f)  |  std of means = %2.4f" % (
                start_round, end_round - 1, mean_of_segment, mean_of_std, std_of_means))
                if file_type == 'html':
                    fileHandle.write("</p>")

            # Max probability data

            print('---> writing Detection Probabilities Data')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write(
                "\n\n\n\nDetection Probabilities Data (mean maximum probabilities of detection) at end of rounds\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.max_probability_data =\n', self.max_probability_data)

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                mean_array = [run[segment][0] for run in self.max_probability_data if run[segment][0] is not None]
                std_array = [run[segment][1] for run in self.max_probability_data if run[segment][1] is not None]

                if len(mean_array) > 0:

                    mean_mean = np.mean(mean_array)

                else:

                    mean_mean = None

                if len(std_array) > 0:

                    mean_std = np.mean(std_array)

                else:

                    mean_std = None

                if print_fine_dets == 1:
                    print('\nmean_array =', mean_array)
                    print('\nstd_array =', std_array)

                    print('mean mean = ', mean_mean)
                    print('mean std = ', mean_std)

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nEnd of Round %d Mean = %s (%s)" % (end_round - 1, mean_mean, mean_std))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if segment == data_segments - 1:
                    tab_det_prob_mean = mean_mean
                    tab_det_prob_std = mean_std

            # Agent Resource Data

            print('---> writing Agent Personal Resource Levels Data')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nAgent Personal Resource Levels Data at end of rounds")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.resource_array_data =\n', self.resource_array_data)

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nEnd Round %d" % (end_round - 1))
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for var_index in range(3):

                    var_array = ['Min', 'Max', 'Mean']

                    var = var_array[var_index]

                    if print_fine_dets == 1:
                        print('\nvar =', var)

                    mean_array = [run[segment][var_index][0] for run in self.resource_array_data]
                    std_array = [run[segment][var_index][1] for run in self.resource_array_data]

                    mean_mean = np.mean(mean_array)
                    mean_std = np.mean(std_array)

                    if print_fine_dets == 1:
                        print('\nmean_array =', mean_array)
                        print('\nstd_array =', std_array)

                        print('mean mean = ', np.mean(mean_array))
                        print('mean std = ', np.mean(std_array))

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\n%s Mean = %3.4f (%3.2f)" % (var, mean_mean, mean_std))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                if segment == data_segments - 1:
                    tab_min_res_mean = mean_mean
                    tab_min_res_std = mean_std

                    # Turnover Data

            # print_fine_dets = 1

            print('---> writing Turnover Data')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nTurnover Data (volume of transactions of each resource)")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nactual_turnover_data =\n', self.actual_turnover_data)
                print('\noptimal_turnover_data =\n', self.optimal_turnover_data)

            # for table data:
            saved_means = []
            saved_stds = []

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nRounds %d to %d" % (start_round, end_round - 1))
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for res in range(num_res_founts):

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\nResource %d:" % (res))
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    if print_fine_dets == 1:
                        print('\nres =', res)

                    # Start with actuals data
                    mean_array = []
                    std_array = []

                    # populate the mean and std arrays but only if population exceeds 0 in this run and segment
                    run_num = 0
                    for run in self.actual_turnover_data:

                        if self.population_data[run_num][segment] > 0:

                            mean_array.append(run[segment][res][0])
                            std_array.append(run[segment][res][1])

                        run_num += 1

                    if print_fine_dets:

                        print('\n mean_array =', mean_array)

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\n\nActual Turnover Array (Time Series of Means):<br><br>[")

                    for i in mean_array:
                        fileHandle.write("%6.5s  " % i)

                    fileHandle.write("]<br><br>")

                    if file_type == 'html':
                        fileHandle.write("</p'>")

                    if len(mean_array) > 0:

                        mean_mean_act = np.mean(mean_array)
                        mean_std_act = np.std(mean_array)

                    else:

                        mean_mean_act = 0.0
                        mean_std_act = 0.0

                    if print_fine_dets == 1:
                        print('\nmean_array =', mean_array)
                        print('\nstd_array =', std_array)

                        print('mean_mean_act = ', mean_mean_act)
                        print('mean_std_act = ', mean_std_act)

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\n\nActual Mean = %3.4f (%3.2f)" % (mean_mean_act, mean_std_act))
                        if file_type == 'html':
                            fileHandle.write("</p'>")

                    if two_tribes:

                        mean_array_sharks = [run[segment][res][2] for run in self.actual_turnover_data]
                        std_array_sharks = [run[segment][res][3] for run in self.actual_turnover_data]

                        mean_mean_act_sharks = np.mean(mean_array_sharks)
                        mean_std_act_sharks = np.mean(std_array_sharks)

                        mean_array_jets = [run[segment][res][4] for run in self.actual_turnover_data]
                        std_array_jets = [run[segment][res][5] for run in self.actual_turnover_data]

                        mean_mean_act_jets = np.mean(mean_array_jets)
                        mean_std_act_jets = np.mean(std_array_jets)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\n\nActual Mean all = %3.4f (%3.2f)  |  Sharks = %3.4f (%3.2f)  |  Jets = %3.4f (%3.2f)" % (
                            mean_mean_act, mean_std_act, mean_mean_act_sharks, mean_std_act_sharks,
                            mean_mean_act_jets, mean_std_act_jets))
                        if file_type == 'html':
                            fileHandle.write("</p'>")

                    # now for the optimals data
                    mean_array = []
                    std_array = []

                    # populate the mean and std arrays but only if population exceeds 0 in this run and segment
                    run_num = 0
                    for run in self.optimal_turnover_data:

                        if self.population_data[run_num][segment] > 0:

                            mean_array.append(run[segment][res][0])
                            std_array.append(run[segment][res][1])

                        run_num += 1

                    if len(mean_array) > 0:

                        mean_mean_opt = np.mean(mean_array)
                        mean_std_opt = np.std(mean_array)

                    else:

                        mean_mean_opt = 0.0
                        mean_std_opt = 0.0

                    if two_tribes == 0:

                        if print_fine_dets:
                            print('\n optimal_array =', mean_array)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\n\n<br>Optimal Turnover Array (Time Series of Means):<br><br>[")

                        for i in mean_array:
                            fileHandle.write("%6.5s  " % i)

                        fileHandle.write("]<br><br>")

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nOptimal Mean = %3.4f (%3.2f)" % (mean_mean_opt, mean_std_opt))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    if print_fine_dets == 1:
                        print('\nmean_array =', mean_array)
                        print('\nstd_array =', std_array)

                        print('mean_mean_opt = ', mean_mean_opt)
                        print('mean_std_opt = ', mean_std_opt)

                    if two_tribes:

                        mean_array_sharks = [run[segment][res][2] for run in self.optimal_turnover_data]
                        std_array_sharks = [run[segment][res][3] for run in self.optimal_turnover_data]

                        mean_mean_opt_sharks = np.mean(mean_array_sharks)
                        mean_std_opt_sharks = np.mean(std_array_sharks)

                        mean_array_jets = [run[segment][res][4] for run in self.optimal_turnover_data]
                        std_array_jets = [run[segment][res][5] for run in self.optimal_turnover_data]

                        mean_mean_opt_jets = np.mean(mean_array_jets)
                        mean_std_opt_jets = np.mean(std_array_jets)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nOptimal Mean all = %3.4f (%3.2f)  |  Sharks = %3.4f (%3.2f)  |  Jets = %3.4f (%3.2f)" % (
                            mean_mean_opt, mean_std_opt, mean_mean_opt_sharks, mean_std_opt_sharks,
                            mean_mean_opt_jets, mean_std_opt_jets))
                        if file_type == 'html':
                            fileHandle.write("</p><br>")

                    # now for ratios
                    mean_array = []
                    std_array = []

                    # populate the mean and std arrays but only if population exceeds 0 in this run and segment
                    run_num = 0
                    for run in self.ratio_turnover_data:

                        if self.population_data[run_num][segment] > 0:

                            mean_array.append(run[segment][res][0])
                            # std_array.append(run[segment][res][1])

                        run_num += 1

                    # mean_array = [run[segment][res][0] for run in self.ratio_turnover_data]
                    # std_array = [run[segment][res][1] for run in self.ratio_turnover_data]

                    mean_mean_rat = np.mean(mean_array)
                    std_of_means_rat = np.std(mean_array)

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\n\n<br>Ratios Turnover Array (Time Series of Means):<br><br>[")

                        for i in mean_array:
                            fileHandle.write("%6.5s  " % i)

                        fileHandle.write("]<br><br>")

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nMean Ratio: %3.4f (%3.3f)" % (mean_mean_rat, std_of_means_rat))
                        if file_type == 'html':
                            fileHandle.write("</p>")
                            fileHandle.write("<p> </p>")

                    if two_tribes:

                        mean_array_sharks = [run[segment][res][2] for run in self.ratio_turnover_data]
                        std_array_sharks = [run[segment][res][3] for run in self.ratio_turnover_data]

                        mean_mean_rat_sharks = np.mean(mean_array_sharks)
                        mean_std_rat_sharks = np.mean(std_array_sharks)

                        mean_array_jets = [run[segment][res][4] for run in self.ratio_turnover_data]
                        std_array_jets = [run[segment][res][5] for run in self.ratio_turnover_data]

                        mean_mean_rat_jets = np.mean(mean_array_jets)
                        mean_std_rat_jets = np.mean(std_array_jets)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRatio all: %3.4f (%3.3f)  |  Sharks: %3.4f (%3.3f)  |  Jets: %3.4f (%3.3f)" % (
                            mean_mean_rat, mean_std_rat, mean_mean_rat_sharks, mean_std_rat_sharks, mean_mean_rat_jets,
                            mean_std_rat_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")
                            fileHandle.write("<p> </p>")

                    if segment == data_segments - 1:
                        saved_means.append(mean_mean_rat)
                        saved_stds.append(std_of_means_rat)

                tab_turnover_mean = np.mean(saved_means)
                tab_turnover_std = np.mean(saved_stds)

            # pause()

            # Age Data

            print('---> writing Average Age Data')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nAverage Age Data\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\n self.all_age_data =\n', self.all_age_data)

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\n segment =', segment)

                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                mean_array = [run[segment][0] for run in self.all_age_data if run[segment][0] is not None]
                std_array = [run[segment][1] for run in self.all_age_data if run[segment][0] is not None]

                if len(mean_array) > 0:

                    mean_mean = np.mean(mean_array)

                else:

                    mean_mean = None

                if len(std_array) > 0:

                    mean_std = np.mean(std_array)

                else:

                    mean_std = None

                if print_fine_dets == 1:
                    print('\n mean_array =', mean_array)
                    print('\n std_array =', std_array)

                    print(' mean mean = ', np.mean(mean_array))
                    print(' mean std = ', np.mean(std_array))

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nEnd of Round %d Mean = %s (%s)" % (end_round - 1, mean_mean, mean_std))
                if file_type == 'html':
                    fileHandle.write("</p>")

            #        # Clustering Coefficient
            #
            #        fileHandle.write("\n\n\n\nCustering Coefficient Data\n")
            #
            #        if print_fine_dets == 1:
            #            print('\nself.cc_data =\n', self.cc_data)
            #
            #        for segment in range(len(self.cc_data[0])):
            #
            #            mean_array = [run[segment][2] for run in self.cc_data]
            #            std_array = [run[segment][3] for run in self.cc_data]
            #
            #            mean_mean = np.mean(mean_array)
            #            mean_std = np.mean(std_array)
            #
            #            if print_fine_dets == 1:
            #                print('\nmean_array =', mean_array)
            #                print('\nstd_array =', std_array)
            #
            #                print('mean mean = ', np.mean(mean_array))
            #                print('mean std = ', np.mean(std_array))
            #
            #            start_round = self.cc_data[0][segment][0]
            #            end_round = self.cc_data[0][segment][1]
            #
            #            fileHandle.write("\nRounds %d to %d - Clustering Coefficient = %3.4f (%3.2f)" % (start_round, end_round, mean_mean, mean_std))

            # Number of Squares with transactions

            print('---> writing Number of Squares with Transactions Data')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nNumber of Squares with Transactions Data\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\n self.num_sq_data =\n', self.num_sq_data)

            for segment in range(data_segments):

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                mean_array = [run[segment] for run in self.num_sq_data]

                mean_mean = np.mean(mean_array)
                std_mean = np.std(mean_array)

                if print_fine_dets == 1:
                    print('\n mean_array =', mean_array)
                    print('\n std_array =', std_array)

                    print(' mean mean = ', mean_mean)
                    print(' std_mean = ', std_mean)

                # now deal with proportion of trading on one square
                mean_array = [run[segment] for run in self.trading_prop_data]

                mean_mean_prop = np.mean(mean_array)
                std_mean_prop = np.std(mean_array)

                mean_gini_array = [run[segment] for run in self.trading_gini_data]

                mean_mean_gini = np.mean(mean_gini_array)
                std_mean_gini = np.std(mean_gini_array)

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nRounds %d to %d - Number of Squares with transactions = %3.4f (%3.4f)  |  Proportion of Transactions on One Square = %1.4f (%1.4f)  |  Mean Gini = %1.4f (%1.4f)" % (
                    start_round, end_round - 1, mean_mean, std_mean, mean_mean_prop, std_mean_prop, mean_mean_gini,
                    std_mean_gini))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if segment == data_segments - 1:
                    tab_num_sqs_mean = mean_mean
                    tab_num_sqs_std = std_mean

                    tab_mean_mean_prop = mean_mean_prop
                    tab_mean_std_prop = std_mean_prop

            #                tab_mean_mean_gini = mean_mean_gini
            #                tab_std_mean_gini = std_mean_gini

            #            print('\nsegment', segment, '[run[segment][0] for run in self.num_sq_data] :', [run[segment][0] for run in self.num_sq_data])

            # By what stage did a market emerge?  If at all?

            print('---> writing When Did a Market Emerge')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nWhen Did a Market Emerge (if at all)?\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            #        print("\n\nWhen Did a Market Emerge (if at all)?\n")
            #        print("\n self.mkt_emerged_round =", self.mkt_emerged_round)

            above_90_pct_array = []
            above_95_pct_array = []
            above_99_pct_array = []

            #            print('\n self.mkt_emerged_round =', self.mkt_emerged_round)

            for sim in range(self.numb_of_sims):

                #            print("\n self.mkt_emerged_round[sim] =", self.mkt_emerged_round[sim])

                if self.mkt_emerged_round[sim][0] > 0:
                    above_90_pct_array.append(self.mkt_emerged_round[sim][0])

                if self.mkt_emerged_round[sim][1] > 0:
                    above_95_pct_array.append(self.mkt_emerged_round[sim][1])

                if self.mkt_emerged_round[sim][2] > 0:
                    above_99_pct_array.append(self.mkt_emerged_round[sim][2])

            if len(above_90_pct_array) > 0:  # then the MA moved above 90% in at least 1 sim

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nTurnover exceeeded 90pct in at least 1 round in %d of %d simulations. Of those, mean = %2.2f (std = %2.2f)" % (
                    len(above_90_pct_array), self.numb_of_sims, np.mean(above_90_pct_array),
                    np.std(above_90_pct_array)))
                if file_type == 'html':
                    fileHandle.write("</p>")

            else:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nTurnover never exceeeded 90pct in at least 1 round in any simulation")
                if file_type == 'html':
                    fileHandle.write("</p>")

            if len(above_95_pct_array) > 0:  # then the MA moved above 90% in at least 1 sim

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nTurnover exceeeded 95pct in at least 1 round in %d of %d simulations. Of those, mean = %2.2f (std = %2.2f)" % (
                    len(above_95_pct_array), self.numb_of_sims, np.mean(above_95_pct_array),
                    np.std(above_95_pct_array)))
                if file_type == 'html':
                    fileHandle.write("</p>")

            else:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nTurnover never exceeeded 95pct in at least 1 round in any simulation")
                if file_type == 'html':
                    fileHandle.write("</p>")

            if len(above_99_pct_array) > 0:  # then the MA moved above 90% in at least 1 sim

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nTurnover exceeeded 99pct in at least 1 round in %d of %d simulations. Of those, mean = %2.2f (std = %2.2f)" % (
                    len(above_99_pct_array), self.numb_of_sims, np.mean(above_99_pct_array),
                    np.std(above_99_pct_array)))
                if file_type == 'html':
                    fileHandle.write("</p>")

            else:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nTurnover never exceeeded 90pct in at least 1 round in any simulation")
                if file_type == 'html':
                    fileHandle.write("</p>")

                    # Now to prices and price differences
            if self.print_local_policy_data == 0:

                print('---> writing Price and Price Difference Data')

                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nPrice and Price Difference Data\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                    # Pricing Data
                for segment in range(data_segments):

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\nRounds %d to %d" % (start_round, end_round - 1))
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    for res_1 in np.arange(num_res_founts):
                        for res_2 in np.arange(num_res_founts):

                            if res_1 != res_2:

                                act_mean_array = [run[segment][res_1][res_2][0] for run in self.act_prices_data if
                                                  run[segment][res_1][res_2][0] is not None]
                                act_std_array = [run[segment][res_1][res_2][1] for run in self.act_prices_data if
                                                 run[segment][res_1][res_2][1] is not None]

                                if len(act_mean_array) > 0:

                                    act_mean_mean = np.mean(act_mean_array)

                                else:

                                    act_mean_mean = None

                                if len(act_std_array) > 0:

                                    act_mean_std = np.mean(act_std_array)

                                else:

                                    act_mean_std = None

                                if two_tribes == 0:

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write("\n\nResource %s vs Resource %s - Mean Actual Price = %s (%s)" % (
                                    res_1, res_2, act_mean_mean, act_mean_std))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                if two_tribes:

                                    # sharks
                                    act_mean_array_sharks = [run[segment][res_1][res_2][2] for run in
                                                             self.act_prices_data if
                                                             run[segment][res_1][res_2][2] is not None]
                                    act_std_array_sharks = [run[segment][res_1][res_2][3] for run in
                                                            self.act_prices_data if
                                                            run[segment][res_1][res_2][3] is not None]

                                    if len(act_mean_array_sharks) > 0:

                                        act_mean_mean_sharks = np.mean(act_mean_array_sharks)

                                    else:

                                        act_mean_mean_sharks = None

                                    if len(act_std_array_sharks) > 0:

                                        act_mean_std_sharks = np.mean(act_std_array_sharks)

                                    else:

                                        act_mean_std_sharks = None

                                    # jets
                                    act_mean_array_jets = [run[segment][res_1][res_2][4] for run in self.act_prices_data
                                                           if run[segment][res_1][res_2][4] is not None]
                                    act_std_array_jets = [run[segment][res_1][res_2][5] for run in self.act_prices_data
                                                          if run[segment][res_1][res_2][5] is not None]

                                    if len(act_mean_array_jets) > 0:

                                        act_mean_mean_jets = np.mean(act_mean_array_jets)

                                    else:

                                        act_mean_mean_jets = None

                                    if len(act_std_array_jets) > 0:

                                        act_mean_std_jets = np.mean(act_std_array_jets)

                                    else:

                                        act_mean_std_jets = None

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\n\nResource %s vs Resource %s - Mean Actual Price (all) = %s (%s)  |  Sharks %s (%s)  |  Jets %s (%s)" % (
                                        res_1, res_2, act_mean_mean, act_mean_std, act_mean_mean_sharks,
                                        act_mean_std_sharks, act_mean_mean_jets, act_mean_std_jets))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                act_std_mean_array = [run[segment][res_1][res_2][0] for run in self.act_std_prices_data
                                                      if run[segment][res_1][res_2][0] is not None]
                                act_std_std_array = [run[segment][res_1][res_2][1] for run in self.act_std_prices_data
                                                     if run[segment][res_1][res_2][1] is not None]

                                if len(act_std_mean_array) > 0:

                                    act_std_mean = np.mean(act_std_mean_array)

                                else:

                                    act_std_mean = None

                                if len(act_std_std_array) > 0:

                                    act_std_std = np.mean(act_std_std_array)

                                else:

                                    act_std_std = None

                                if two_tribes == 0:

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\nResource %s vs Resource %s - Mean Daily STD of Actual Price = %s (%s)" % (
                                        res_1, res_2, act_std_mean, act_std_std))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                if two_tribes:

                                    # sharks
                                    act_std_mean_array_sharks = [run[segment][res_1][res_2][2] for run in
                                                                 self.act_std_prices_data if
                                                                 run[segment][res_1][res_2][2] is not None]
                                    act_std_std_array_sharks = [run[segment][res_1][res_2][3] for run in
                                                                self.act_std_prices_data if
                                                                run[segment][res_1][res_2][3] is not None]

                                    if len(act_std_mean_array_sharks) > 0:

                                        act_std_mean_sharks = np.mean(act_std_mean_array_sharks)

                                    else:

                                        act_std_mean_sharks = None

                                    if len(act_std_std_array_sharks) > 0:

                                        act_std_std_sharks = np.mean(act_std_std_array_sharks)

                                    else:

                                        act_std_std_sharks = None

                                    # jets
                                    act_std_mean_array_jets = [run[segment][res_1][res_2][4] for run in
                                                               self.act_std_prices_data if
                                                               run[segment][res_1][res_2][4] is not None]
                                    act_std_std_array_jets = [run[segment][res_1][res_2][5] for run in
                                                              self.act_std_prices_data if
                                                              run[segment][res_1][res_2][5] is not None]

                                    if len(act_std_mean_array_jets) > 0:

                                        act_std_mean_jets = np.mean(act_std_mean_array_jets)

                                    else:

                                        act_std_mean_jets = None

                                    if len(act_std_std_array_jets) > 0:

                                        act_std_std_jets = np.mean(act_std_std_array_jets)

                                    else:

                                        act_std_std_jets = None

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\nResource %s vs Resource %s - Mean Daily STD of Actual Price (all) = %s (%s)  |  Sharks = %s (%s)  |  Jets = %s (%s)" % (
                                        res_1, res_2, act_std_mean, act_std_std, act_std_mean_sharks,
                                        act_std_std_sharks, act_std_mean_jets, act_std_std_jets))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                opt_mean_array = [run[segment][res_1][res_2][0] for run in self.opt_prices_data if
                                                  run[segment][res_1][res_2][0] is not None]
                                opt_std_array = [run[segment][res_1][res_2][1] for run in self.opt_prices_data if
                                                 run[segment][res_1][res_2][1] is not None]

                                if len(opt_mean_array) > 0:

                                    opt_mean_mean = np.mean(opt_mean_array)

                                else:

                                    opt_mean_mean = None

                                if len(opt_std_array) > 0:

                                    opt_mean_std = np.mean(opt_std_array)

                                else:

                                    opt_mean_std = None

                                if two_tribes == 0:

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write("\nResource %s vs Resource %s - Mean Optimal Price = %s (%s)" % (
                                    res_1, res_2, opt_mean_mean, opt_mean_std))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                if two_tribes:

                                    # sharks
                                    opt_mean_array_sharks = [run[segment][res_1][res_2][2] for run in
                                                             self.opt_prices_data if
                                                             run[segment][res_1][res_2][2] is not None]
                                    opt_std_array_sharks = [run[segment][res_1][res_2][3] for run in
                                                            self.opt_prices_data if
                                                            run[segment][res_1][res_2][3] is not None]

                                    if len(opt_mean_array_sharks) > 0:

                                        opt_mean_mean_sharks = np.mean(opt_mean_array_sharks)

                                    else:

                                        opt_mean_mean_sharks = None

                                    if len(opt_std_array_sharks) > 0:

                                        opt_mean_std_sharks = np.mean(opt_std_array_sharks)

                                    else:

                                        opt_mean_std_sharks = None

                                    # jets
                                    opt_mean_array_jets = [run[segment][res_1][res_2][4] for run in self.opt_prices_data
                                                           if run[segment][res_1][res_2][4] is not None]
                                    opt_std_array_jets = [run[segment][res_1][res_2][5] for run in self.opt_prices_data
                                                          if run[segment][res_1][res_2][5] is not None]

                                    if len(opt_mean_array_jets) > 0:

                                        opt_mean_mean_jets = np.mean(opt_mean_array_jets)

                                    else:

                                        opt_mean_mean_jets = None

                                    if len(opt_std_array_jets) > 0:

                                        opt_mean_std_jets = np.mean(opt_std_array_jets)

                                    else:

                                        opt_mean_std_jets = None

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\nResource %s vs Resource %s - Mean Optimal Price (all) = %s (%s)  |  Sharks = %s (%s)  |  Jets = %s (%s)" % (
                                        res_1, res_2, opt_mean_mean, opt_mean_std, opt_mean_mean_sharks,
                                        opt_mean_std_sharks, opt_mean_mean_jets, opt_mean_std_jets))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                diff_mean_array = [run[segment][res_1][res_2][0] for run in self.diff_prices_data if
                                                   run[segment][res_1][res_2][0] is not None]
                                diff_std_array = [run[segment][res_1][res_2][1] for run in self.diff_prices_data if
                                                  run[segment][res_1][res_2][1] is not None]

                                if len(diff_mean_array) > 0:

                                    diff_mean_mean = np.mean(diff_mean_array)

                                else:

                                    diff_mean_mean = None

                                if len(diff_std_array) > 0:

                                    diff_mean_std = np.mean(diff_std_array)

                                else:

                                    diff_mean_std = None

                                if two_tribes == 0:

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\nResource %s vs Resource %s - Mean Absolute Price Difference = %s (%s)" % (
                                        res_1, res_2, diff_mean_mean, diff_mean_std))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")
                                        fileHandle.write("<p> </p>")

                                if two_tribes:

                                    # sharks
                                    diff_mean_array_sharks = [run[segment][res_1][res_2][2] for run in
                                                              self.diff_prices_data if
                                                              run[segment][res_1][res_2][2] is not None]
                                    diff_std_array_sharks = [run[segment][res_1][res_2][3] for run in
                                                             self.diff_prices_data if
                                                             run[segment][res_1][res_2][3] is not None]

                                    if len(diff_mean_array_sharks) > 0:

                                        diff_mean_mean_sharks = np.mean(diff_mean_array_sharks)

                                    else:

                                        diff_mean_mean_sharks = None

                                    if len(diff_std_array_sharks) > 0:

                                        diff_mean_std_sharks = np.mean(diff_std_array_sharks)

                                    else:

                                        diff_mean_std_sharks = None

                                    # jets
                                    diff_mean_array_jets = [run[segment][res_1][res_2][4] for run in
                                                            self.diff_prices_data if
                                                            run[segment][res_1][res_2][4] is not None]
                                    diff_std_array_jets = [run[segment][res_1][res_2][5] for run in
                                                           self.diff_prices_data if
                                                           run[segment][res_1][res_2][5] is not None]

                                    if len(diff_mean_array_jets) > 0:

                                        diff_mean_mean_jets = np.mean(diff_mean_array_jets)

                                    else:

                                        diff_mean_mean_jets = None

                                    if len(diff_std_array_jets) > 0:

                                        diff_mean_std_jets = np.mean(diff_std_array_jets)

                                    else:

                                        diff_mean_std_jets = None

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\nResource %s vs Resource %s - Mean Absolute Price Difference (all) = %s (%s)  |  Sharks = %s (%s)  |  Jets = %s (%s)" % (
                                        res_1, res_2, diff_mean_mean, diff_mean_std, diff_mean_mean_sharks,
                                        diff_mean_std_sharks, diff_mean_mean_jets, diff_mean_std_jets))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")
                                        fileHandle.write("<p> </p>")

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nOptimal Prices over Sims:\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                means_array = []
                stds_array = []

                #        print('\n self.whole_sim_opt_prices_data =', self.whole_sim_opt_prices_data)

                for sim in range(self.numb_of_sims):

                    means_array.append(self.whole_sim_opt_prices_data[sim][0])
                    stds_array.append(self.whole_sim_opt_prices_data[sim][1])

                    if len(means_array) > 0:

                        whole_sim_mean = np.mean(means_array)

                    else:

                        whole_sim_mean = None

                    if len(stds_array) > 0:

                        whole_sim_std = np.mean(stds_array)

                    else:

                        whole_sim_std = None

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nAverage Mean and Standard Deviation of Prices Over Whole Simulations (Chart Price of Res 0 in Res 1 Units): Mean = %2.5f  |  STD = %2.5f\n" % (
                    whole_sim_mean, whole_sim_std))
                if file_type == 'html':
                    fileHandle.write("</p>")

            # Here we look at the number of home locations which are serviced by markets (dbs.serviced_locations)

            print('---> writing Percentage of Agent Squares Covered by Markets')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nPercentage of Agent Squares Covered by Markets\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\n self.serviced_locs_data =\n', self.serviced_locs_data)

            for segment in range(data_segments):

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                mean_array = [run[segment][0] for run in self.serviced_locs_data]
                pct_array = [run[segment][1] for run in self.serviced_locs_data]

                mean_mean = np.mean(mean_array)
                mean_pct = np.mean(pct_array)

                if print_fine_dets == 1:
                    print('\n mean_array =', mean_array)
                    print('\n mean_pct =', mean_pct)

                    print(' mean mean = ', mean_mean)
                    print(' mean_pct = ', mean_pct)

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nRounds %4.0f to %4.0f - Percent of agents within market catchment area = %3.2f (std %3.2f pct)" % (
                    start_round, end_round - 1, mean_mean * 100, mean_pct * 100))
                if file_type == 'html':
                    fileHandle.write("</p>")

            # Here we look at slope data
            if self.run_dist_to_mkt_OLS:

                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\nThe Relationship Between Distance from Market and Resource Holdings at The End of Simulations\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                # fileHandle.write("\n\n\n\nThe Relationship Between Distance from Market and Resource Holdings at The End of Simulations\n")
                # fileHandle.write("\nSim \tSlope Coeff \tSt Error\tp value\n")

                # print('self.slope_data =', self.slope_data)

                counter = 0
                for dep_var in self.OLS_include:

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\nDependent Variable:   %s\n" % dep_var)
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    for sim in range(self.numb_of_sims):

                       # if len(self.slope_data[sim][0]) > 0:

                       if file_type == 'html':
                           fileHandle.write("<p style='margin:0;'>")
                       fileHandle.write("\nSim %d     Slope Coeff %6.6f       St Error %6.6f      P Ratio %6.6f" % (sim, self.slope_data[sim][0][counter], self.slope_data[sim][1][counter], self.slope_data[sim][2][counter]))
                       if file_type == 'html':
                           fileHandle.write("</p>")

                       # fileHandle.write("\n%d \t %3.2f \t\t %3.2f \t\t %3.2f" % (sim, self.slope_data[sim][0], self.slope_data[sim][1], self.slope_data[sim][2]))

                    # slope_array = [results.params[1], results.bse[1], results.pvalues[1]]
                    slopes_array = [run[0][counter] for run in self.slope_data]
                    mean_slope = np.mean(slopes_array)
                    std_slope = np.std(slopes_array)

                    std_errors_array = [run[1][counter] for run in self.slope_data]
                    mean_std_err = np.mean(std_errors_array)
                    std_std_err = np.std(std_errors_array)

                    p_ratio_array = [run[2][counter] for run in self.slope_data]
                    mean_p_ratio = np.mean(p_ratio_array)
                    std_p_ratio = np.std(p_ratio_array)

                    if file_type == 'html':
                        fileHandle.write("<p><p>")
                    fileHandle.write("\n\n\nMean Slope = %6.6f (%6.6f)  |  Mean St Err = %6.6f (%6.6f)  |  Mean P Ratio = %6.6f (%6.6f)" % (mean_slope, std_slope, mean_std_err, std_std_err, mean_p_ratio, std_p_ratio))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                    counter += 1

                # fileHandle.write("\n\n\nMean Slope = %3.2f (%3.2f)  |  Mean St Err = %3.2f (%3.2f)  |  Mean P Ratio = %3.2f (%3.2f)" % (mean_slope, std_slope, mean_std_err, std_std_err, mean_p_ratio, std_p_ratio))

            # Keynesian Institution Data, if any

            if self.allow_Keynes_Inst == 'total':

                #            print('\n\n self.KI_data_all\n\n', self.KI_data_all)
                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nKeynesian Institution Data\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                for segment in range(data_segments):

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    tot_vol_array = [run[segment][0] for run in self.KI_data_all]
                    KI_vol_array = [run[segment][1] for run in self.KI_data_all]
                    prop_array = [run[segment][2] for run in self.KI_data_all]

                    mean_tot_vol = np.mean(tot_vol_array)
                    std_tot_vol = np.std(tot_vol_array)

                    mean_KI_vol = np.mean(KI_vol_array)
                    std_KI_vol = np.std(KI_vol_array)

                    mean_prop = np.mean(prop_array)
                    std_prop = np.std(prop_array)

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nRounds %4.0f to %4.0f - Volume of Transactions (res 0 only) = %4.4f (%4.4f)  |  Volume on KI = %4.4f (%4.4f)  |  Proportion on KI = %4.4f (%4.4f)" % (
                        start_round, end_round - 1, mean_tot_vol, std_tot_vol, mean_KI_vol, std_KI_vol, mean_prop,
                        std_prop))
                    if file_type == 'html':
                        fileHandle.write("</p>")

            #                if segment == data_segments - 1 and mean_prop > 0:
            #
            #                    print('\n POSITIVE VALUE: market moved in this round')
            #
            #                    input("Press Enter to continue...")

            if respect_property_rights == 0:

                # there are 3 sets of data to look at: props steal and fb; num trans and fights; and breakdown of fights

                print('---> writing Propensity to Steal and Fight Back Data')

                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nPropensity to Steal and Fight Back Data\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                if print_fine_dets == 1:
                    print('\n self.prop_steal_data =\n', self.prop_steal_data)
                    print('\n self.prop_fb_data =\n', self.prop_fb_data)

                for segment in range(data_segments):

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    if two_tribes:

                        # sharks
                        mean_steal_array_sharks = [run[segment][2] for run in self.prop_steal_data if
                                                   run[segment][2] is not None]
                        std_steal_array_sharks = [run[segment][3] for run in self.prop_steal_data if
                                                  run[segment][3] is not None]

                        if len(mean_steal_array_sharks) > 0:

                            mean_mean_steal_sharks = np.mean(mean_steal_array_sharks)

                        else:

                            mean_mean_steal_sharks = None

                        if len(std_steal_array_sharks) > 0:

                            mean_std_steal_sharks = np.mean(std_steal_array_sharks)

                        else:

                            mean_std_steal_sharks = None

                        mean_fb_array_sharks = [run[segment][2] for run in self.prop_fb_data if
                                                run[segment][2] is not None]
                        std_fb_array_sharks = [run[segment][3] for run in self.prop_fb_data if
                                               run[segment][3] is not None]

                        if len(mean_fb_array_sharks) > 0:

                            mean_mean_fb_sharks = np.mean(mean_fb_array_sharks)

                        else:

                            mean_mean_fb_sharks = None

                        if len(std_fb_array_sharks) > 0:

                            mean_std_fb_sharks = np.mean(std_fb_array_sharks)

                        else:

                            mean_std_fb_sharks = None

                        # jets
                        mean_steal_array_jets = [run[segment][2] for run in self.prop_steal_data if
                                                 run[segment][2] is not None]
                        std_steal_array_jets = [run[segment][3] for run in self.prop_steal_data if
                                                run[segment][3] is not None]

                        if len(mean_steal_array_jets) > 0:

                            mean_mean_steal_jets = np.mean(mean_steal_array_jets)

                        else:

                            mean_mean_steal_jets = None

                        if len(std_steal_array_jets) > 0:

                            mean_std_steal_jets = np.mean(std_steal_array_jets)

                        else:

                            mean_std_steal_jets = None

                        mean_fb_array_jets = [run[segment][4] for run in self.prop_fb_data if
                                              run[segment][4] is not None]
                        std_fb_array_jets = [run[segment][5] for run in self.prop_fb_data if
                                             run[segment][5] is not None]

                        if len(mean_fb_array_jets) > 0:

                            mean_mean_fb_jets = np.mean(mean_fb_array_jets)

                        else:

                            mean_mean_fb_jets = None

                        if len(std_fb_array_jets) > 0:

                            mean_std_fb_jets = np.mean(std_fb_array_jets)

                        else:

                            mean_std_fb_jets = None

                        if file_type == 'html':
                            fileHandle.write("<p></p>")
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Sharks Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % \
                            (start_round, end_round - 1, mean_mean_steal_sharks, mean_std_steal_sharks,
                             mean_mean_fb_sharks, mean_std_fb_sharks))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Jets Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % \
                            (start_round, end_round - 1, mean_mean_steal_jets, mean_std_steal_jets, mean_mean_fb_jets,
                             mean_std_fb_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    mean_steal_array = [run[segment][0] for run in self.prop_steal_data if run[segment][0] is not None]
                    std_steal_array = [run[segment][1] for run in self.prop_steal_data if run[segment][1] is not None]

                    if len(mean_steal_array) > 0:

                        mean_mean_steal = np.mean(mean_steal_array)

                    else:

                        mean_mean_steal = None

                    if len(std_steal_array) > 0:

                        mean_std_steal = np.mean(std_steal_array)

                    else:

                        mean_std_steal = None

                    mean_fb_array = [run[segment][0] for run in self.prop_fb_data if run[segment][0] is not None]
                    std_fb_array = [run[segment][1] for run in self.prop_fb_data if run[segment][1] is not None]

                    if len(mean_fb_array) > 0:

                        mean_mean_fb = np.mean(mean_fb_array)

                    else:

                        mean_mean_fb = None

                    if len(std_fb_array) > 0:

                        mean_std_fb = np.mean(std_fb_array)

                    else:

                        mean_std_fb = None

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nRounds %4d to %4d - Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % \
                        (start_round, end_round - 1, mean_mean_steal, mean_std_steal, mean_mean_fb, mean_std_fb))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                print('---> writing Number of Transactions and Fights Data')

                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nNumber of Transactions and Fights\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                if print_fine_dets == 1:
                    print('\n self.num_trans_data =\n', self.num_trans_data)
                    print('\n self.num_fights_data =\n', self.num_fights_data)

                for segment in range(data_segments):

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    if two_tribes:

                        # sharks
                        mean_trans_array_sharks = [run[segment][2] for run in self.num_trans_data if
                                                   run[segment][2] is not None]
                        std_trans_array_sharks = [run[segment][3] for run in self.num_trans_data if
                                                  run[segment][3] is not None]

                        if len(mean_trans_array_sharks) > 0:

                            mean_mean_trans_sharks = np.mean(mean_trans_array_sharks)

                        else:

                            mean_mean_trans_sharks = None

                        if len(std_trans_array_sharks) > 0:

                            mean_std_trans_sharks = np.mean(std_trans_array_sharks)

                        else:

                            mean_std_trans_sharks = None

                        mean_fights_array_sharks = [run[segment][2] for run in self.num_fights_data if
                                                    run[segment][2] is not None]
                        std_fights_array_sharks = [run[segment][3] for run in self.num_fights_data if
                                                   run[segment][3] is not None]

                        if len(mean_fights_array_sharks) > 0:

                            mean_mean_fights_sharks = np.mean(mean_fights_array_sharks)

                        else:

                            mean_mean_fights_sharks = None

                        if len(std_fights_array_sharks) > 0:

                            mean_std_fights_sharks = np.mean(std_fights_array_sharks)

                        else:

                            mean_std_fights_sharks = None

                        # jets
                        mean_trans_array_jets = [run[segment][4] for run in self.num_trans_data if
                                                 run[segment][4] is not None]
                        std_trans_array_jets = [run[segment][5] for run in self.num_trans_data if
                                                run[segment][5] is not None]

                        if len(mean_trans_array_jets) > 0:

                            mean_mean_trans_jets = np.mean(mean_trans_array_jets)

                        else:

                            mean_mean_trans_jets = None

                        if len(std_trans_array_jets) > 0:

                            mean_std_trans_jets = np.mean(std_trans_array_jets)

                        else:

                            mean_std_trans_jets = None

                        mean_fights_array_jets = [run[segment][4] for run in self.num_fights_data if
                                                  run[segment][4] is not None]
                        std_fights_array_jets = [run[segment][5] for run in self.num_fights_data if
                                                 run[segment][5] is not None]

                        if len(mean_fights_array_jets) > 0:

                            mean_mean_fights_jets = np.mean(mean_fights_array_jets)

                        else:

                            mean_mean_fights_jets = None

                        if len(std_fights_array_jets) > 0:

                            mean_std_fights_jets = np.mean(std_fights_array_jets)

                        else:

                            mean_std_fights_jets = None

                        # inter
                        mean_trans_array_inter = [run[segment][6] for run in self.num_trans_data if
                                                  run[segment][6] is not None]
                        std_trans_array_inter = [run[segment][7] for run in self.num_trans_data if
                                                 run[segment][7] is not None]

                        if len(mean_trans_array_inter) > 0:

                            mean_mean_trans_inter = np.mean(mean_trans_array_inter)

                        else:

                            mean_mean_trans_inter = None

                        if len(std_trans_array_inter) > 0:

                            mean_std_trans_inter = np.mean(std_trans_array_inter)

                        else:

                            mean_std_trans_inter = None

                        mean_fights_array_inter = [run[segment][6] for run in self.num_fights_data if
                                                   run[segment][6] is not None]
                        std_fights_array_inter = [run[segment][7] for run in self.num_fights_data if
                                                  run[segment][7] is not None]

                        if len(mean_fights_array_inter) > 0:

                            mean_mean_fights_inter = np.mean(mean_fights_array_inter)

                        else:

                            mean_mean_fights_inter = None

                        if len(std_fights_array_inter) > 0:

                            mean_std_fights_inter = np.mean(std_fights_array_inter)

                        else:

                            mean_std_fights_inter = None

                        if file_type == 'html':
                            fileHandle.write("<p></p'>")
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Sharks Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % \
                            (start_round, end_round - 1, mean_mean_trans_sharks, mean_std_trans_sharks,
                             mean_mean_fights_sharks, mean_std_fights_sharks))
                        if file_type == 'html':
                            fileHandle.write("</p'>")

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Jets Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % \
                            (start_round, end_round - 1, mean_mean_trans_jets, mean_std_trans_jets,
                             mean_mean_fights_jets, mean_std_fights_jets))
                        if file_type == 'html':
                            fileHandle.write("</p'>")

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Inter-Tribe Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % \
                            (start_round, end_round - 1, mean_mean_trans_inter, mean_std_trans_inter,
                             mean_mean_fights_inter, mean_std_fights_inter))
                        if file_type == 'html':
                            fileHandle.write("</p'>")

                    mean_trans_array = [run[segment][0] for run in self.num_trans_data if run[segment][0] is not None]
                    std_trans_array = [run[segment][1] for run in self.num_trans_data if run[segment][1] is not None]

                    if len(mean_trans_array) > 0:

                        mean_mean_trans = np.mean(mean_trans_array)

                    else:

                        mean_mean_trans = None

                    if len(std_trans_array) > 0:

                        mean_std_trans = np.mean(std_trans_array)

                    else:

                        mean_std_trans = None

                    mean_fights_array = [run[segment][0] for run in self.num_fights_data if run[segment][0] is not None]
                    std_fights_array = [run[segment][1] for run in self.num_fights_data if run[segment][1] is not None]

                    if len(mean_fights_array) > 0:

                        mean_mean_fights = np.mean(mean_fights_array)

                    else:

                        mean_mean_fights = None

                    if len(std_fights_array) > 0:

                        mean_std_fights = np.mean(std_fights_array)

                    else:

                        mean_std_fights = None

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nRounds %4d to %4d - Mean Number of Transaction = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % \
                        (
                        start_round, end_round - 1, mean_mean_trans, mean_std_trans, mean_mean_fights, mean_std_fights))
                    if file_type == 'html':
                        fileHandle.write("</p'>")

                print('---> writing Types of Fights Data')

                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nTypes of Fights\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                # define fight types:
                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nScenario 1 is: both agents attempted to steal.")
                if file_type == 'html':
                    fileHandle.write("</p'>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nScenarios 2 & 3 is: one agent attempted to steal, the other wanted to trade but then fought back.")
                if file_type == 'html':
                    fileHandle.write("</p'>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nScenarios 4 & 5 is: one agent attempted to steal, the other wanted to trade but then acquiesced.")
                if file_type == 'html':
                    fileHandle.write("</p'>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nNote: pct data below give scenario 1, 2 & 3, and 4 & 5 fights as proportion of the mean number of fights during the period.\n")
                if file_type == 'html':
                    fileHandle.write("</p>")
                    fileHandle.write("<p> </p>")

                if print_fine_dets == 1:
                    print('\n self.num_scen_1_data =\n', self.num_scen_1_data)
                    print('\n self.num_scen_23_data =\n', self.num_scen_23_data)
                    print('\n self.num_scen_45_data =\n', self.num_scen_45_data)

                for segment in range(data_segments):

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    if two_tribes:

                        # sharks
                        # scen 1
                        mean_scen_1_array_sharks = [run[segment][2] for run in self.num_scen_1_data if
                                                    run[segment][2] is not None]
                        std_scen_1_array_sharks = [run[segment][3] for run in self.num_scen_1_data if
                                                   run[segment][3] is not None]

                        if len(mean_scen_1_array_sharks) > 0:

                            mean_mean_scen_1_sharks = np.mean(mean_scen_1_array_sharks)

                        else:

                            mean_mean_scen_1_sharks = 0

                        if len(std_scen_1_array_sharks) > 0:

                            mean_std_scen_1_sharks = np.mean(std_scen_1_array_sharks)

                        else:

                            mean_std_scen_1_sharks = 0

                        # scen 2 & 3
                        mean_scen_23_array_sharks = [run[segment][2] for run in self.num_scen_23_data if
                                                     run[segment][2] is not None]
                        std_scen_23_array_sharks = [run[segment][3] for run in self.num_scen_23_data if
                                                    run[segment][3] is not None]

                        if len(mean_scen_23_array_sharks) > 0:

                            mean_mean_scen_23_sharks = np.mean(mean_scen_23_array_sharks)

                        else:

                            mean_mean_scen_23_sharks = 0

                        if len(std_scen_23_array_sharks) > 0:

                            mean_std_scen_23_sharks = np.mean(std_scen_23_array_sharks)

                        else:

                            mean_std_scen_23_sharks = 0

                        # scen 4 & 5
                        mean_scen_45_array_sharks = [run[segment][2] for run in self.num_scen_45_data if
                                                     run[segment][2] is not None]
                        std_scen_45_array_sharks = [run[segment][3] for run in self.num_scen_45_data if
                                                    run[segment][3] is not None]

                        if len(mean_scen_45_array_sharks) > 0:

                            mean_mean_scen_45_sharks = np.mean(mean_scen_45_array_sharks)

                        else:

                            mean_mean_scen_45_sharks = 0

                        if len(std_scen_45_array_sharks) > 0:

                            mean_std_scen_45_sharks = np.mean(std_scen_45_array_sharks)

                        else:

                            mean_std_scen_45_sharks = 0

                        if (mean_mean_scen_1_sharks + mean_mean_scen_23_sharks + mean_mean_scen_45_sharks) > 0:

                            prop_1 = (100 * mean_mean_scen_1_sharks) / float(
                                mean_mean_scen_1_sharks + mean_mean_scen_23_sharks + mean_mean_scen_45_sharks)
                            prop_23 = (100 * mean_mean_scen_23_sharks) / float(
                                mean_mean_scen_1_sharks + mean_mean_scen_23_sharks + mean_mean_scen_45_sharks)
                            prop_45 = (100 * mean_mean_scen_45_sharks) / float(
                                mean_mean_scen_1_sharks + mean_mean_scen_23_sharks + mean_mean_scen_45_sharks)

                        else:

                            prop_1 = 0
                            prop_23 = 0
                            prop_45 = 0

                        if file_type == 'html':
                            fileHandle.write("<p></p>")
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Sharks Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                            (start_round, end_round - 1, mean_mean_scen_1_sharks, prop_1, mean_std_scen_1_sharks,
                             mean_mean_scen_23_sharks, prop_23, mean_std_scen_23_sharks, mean_mean_scen_45_sharks,
                             prop_45, mean_std_scen_45_sharks))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        # jets
                        # scen 1
                        mean_scen_1_array_jets = [run[segment][4] for run in self.num_scen_1_data if
                                                  run[segment][4] is not None]
                        std_scen_1_array_jets = [run[segment][5] for run in self.num_scen_1_data if
                                                 run[segment][5] is not None]

                        if len(mean_scen_1_array_jets) > 0:

                            mean_mean_scen_1_jets = np.mean(mean_scen_1_array_jets)

                        else:

                            mean_mean_scen_1_jets = 0

                        if len(std_scen_1_array_jets) > 0:

                            mean_std_scen_1_jets = np.mean(std_scen_1_array_jets)

                        else:

                            mean_std_scen_1_jets = 0

                        # scen 2 & 3
                        mean_scen_23_array_jets = [run[segment][4] for run in self.num_scen_23_data if
                                                   run[segment][4] is not None]
                        std_scen_23_array_jets = [run[segment][5] for run in self.num_scen_23_data if
                                                  run[segment][5] is not None]

                        if len(mean_scen_23_array_jets) > 0:

                            mean_mean_scen_23_jets = np.mean(mean_scen_23_array_jets)

                        else:

                            mean_mean_scen_23_jets = 0

                        if len(std_scen_23_array_jets) > 0:

                            mean_std_scen_23_jets = np.mean(std_scen_23_array_jets)

                        else:

                            mean_std_scen_23_jets = 0

                        # scen 4 & 5
                        mean_scen_45_array_jets = [run[segment][4] for run in self.num_scen_45_data if
                                                   run[segment][4] is not None]
                        std_scen_45_array_jets = [run[segment][5] for run in self.num_scen_45_data if
                                                  run[segment][5] is not None]

                        if len(mean_scen_45_array_jets) > 0:

                            mean_mean_scen_45_jets = np.mean(mean_scen_45_array_jets)

                        else:

                            mean_mean_scen_45_jets = 0

                        if len(std_scen_45_array_jets) > 0:

                            mean_std_scen_45_jets = np.mean(std_scen_45_array_jets)

                        else:

                            mean_std_scen_45_jets = 0

                        if (mean_mean_scen_1_jets + mean_mean_scen_23_jets + mean_mean_scen_45_jets) > 0:

                            prop_1 = (100 * mean_mean_scen_1_jets) / float(
                                mean_mean_scen_1_jets + mean_mean_scen_23_jets + mean_mean_scen_45_jets)
                            prop_23 = (100 * mean_mean_scen_23_jets) / float(
                                mean_mean_scen_1_jets + mean_mean_scen_23_jets + mean_mean_scen_45_jets)
                            prop_45 = (100 * mean_mean_scen_45_jets) / float(
                                mean_mean_scen_1_jets + mean_mean_scen_23_jets + mean_mean_scen_45_jets)

                        else:

                            prop_1 = 0
                            prop_23 = 0
                            prop_45 = 0

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Jets Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                            (start_round, end_round - 1, mean_mean_scen_1_jets, prop_1, mean_std_scen_1_jets,
                             mean_mean_scen_23_jets, prop_23, mean_std_scen_23_jets, mean_mean_scen_45_jets, prop_45,
                             mean_std_scen_45_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        # inter
                        # scen 1
                        mean_scen_1_array_inter = [run[segment][6] for run in self.num_scen_1_data if
                                                   run[segment][6] is not None]
                        std_scen_1_array_inter = [run[segment][7] for run in self.num_scen_1_data if
                                                  run[segment][7] is not None]

                        if len(mean_scen_1_array_inter) > 0:

                            mean_mean_scen_1_inter = np.mean(mean_scen_1_array_inter)

                        else:

                            mean_mean_scen_1_inter = 0

                        if len(std_scen_1_array_inter) > 0:

                            mean_std_scen_1_inter = np.mean(std_scen_1_array_inter)

                        else:

                            mean_std_scen_1_inter = 0

                        # scen 2 & 3
                        mean_scen_23_array_inter = [run[segment][6] for run in self.num_scen_23_data if
                                                    run[segment][6] is not None]
                        std_scen_23_array_inter = [run[segment][7] for run in self.num_scen_23_data if
                                                   run[segment][7] is not None]

                        if len(mean_scen_23_array_inter) > 0:

                            mean_mean_scen_23_inter = np.mean(mean_scen_23_array_inter)

                        else:

                            mean_mean_scen_23_inter = 0

                        if len(std_scen_23_array_inter) > 0:

                            mean_std_scen_23_inter = np.mean(std_scen_23_array_inter)

                        else:

                            mean_std_scen_23_inter = 0

                        # scen 4 & 5
                        mean_scen_45_array_inter = [run[segment][6] for run in self.num_scen_45_data if
                                                    run[segment][6] is not None]
                        std_scen_45_array_inter = [run[segment][7] for run in self.num_scen_45_data if
                                                   run[segment][7] is not None]

                        if len(mean_scen_45_array_inter) > 0:

                            mean_mean_scen_45_inter = np.mean(mean_scen_45_array_inter)

                        else:

                            mean_mean_scen_45_inter = 0

                        if len(std_scen_45_array_inter) > 0:

                            mean_std_scen_45_inter = np.mean(std_scen_45_array_inter)

                        else:

                            mean_std_scen_45_inter = 0

                        if (mean_mean_scen_1_inter + mean_mean_scen_23_inter + mean_mean_scen_45_inter) > 0:

                            prop_1 = (100 * mean_mean_scen_1_inter) / float(
                                mean_mean_scen_1_inter + mean_mean_scen_23_inter + mean_mean_scen_45_inter)
                            prop_23 = (100 * mean_mean_scen_23_inter) / float(
                                mean_mean_scen_1_inter + mean_mean_scen_23_inter + mean_mean_scen_45_inter)
                            prop_45 = (100 * mean_mean_scen_45_inter) / float(
                                mean_mean_scen_1_inter + mean_mean_scen_23_inter + mean_mean_scen_45_inter)

                        else:

                            prop_1 = 0
                            prop_23 = 0
                            prop_45 = 0

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Inter-Tribe Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                            (start_round, end_round - 1, mean_mean_scen_1_inter, prop_1, mean_std_scen_1_inter,
                             mean_mean_scen_23_inter, prop_23, mean_std_scen_23_inter, mean_mean_scen_45_inter, prop_45,
                             mean_std_scen_45_inter))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    # scen 1
                    mean_scen_1_array = [run[segment][0] for run in self.num_scen_1_data if run[segment][0] is not None]
                    std_scen_1_array = [run[segment][1] for run in self.num_scen_1_data if run[segment][1] is not None]

                    if len(mean_scen_1_array) > 0:

                        mean_mean_scen_1 = np.mean(mean_scen_1_array)

                    else:

                        mean_mean_scen_1 = 0

                    if len(std_scen_1_array) > 0:

                        mean_std_scen_1 = np.mean(std_scen_1_array)

                    else:

                        mean_std_scen_1 = 0

                    # scen 2 & 3
                    mean_scen_23_array = [run[segment][0] for run in self.num_scen_23_data if
                                          run[segment][0] is not None]
                    std_scen_23_array = [run[segment][1] for run in self.num_scen_23_data if
                                         run[segment][1] is not None]

                    if len(mean_scen_23_array) > 0:

                        mean_mean_scen_23 = np.mean(mean_scen_23_array)

                    else:

                        mean_mean_scen_23 = 0

                    if len(std_scen_23_array) > 0:

                        mean_std_scen_23 = np.mean(std_scen_23_array)

                    else:

                        mean_std_scen_23 = 0

                    # scen 4 & 5
                    mean_scen_45_array = [run[segment][0] for run in self.num_scen_45_data if
                                          run[segment][0] is not None]
                    std_scen_45_array = [run[segment][1] for run in self.num_scen_45_data if
                                         run[segment][1] is not None]

                    if len(mean_scen_45_array) > 0:

                        mean_mean_scen_45 = np.mean(mean_scen_45_array)

                    else:

                        mean_mean_scen_45 = 0

                    if len(std_scen_45_array) > 0:

                        mean_std_scen_45 = np.mean(std_scen_45_array)

                    else:

                        mean_std_scen_45 = 0

                    if (mean_mean_scen_1 + mean_mean_scen_23 + mean_mean_scen_45) > 0:

                        prop_1 = (100 * mean_mean_scen_1) / float(
                            mean_mean_scen_1 + mean_mean_scen_23 + mean_mean_scen_45)
                        prop_23 = (100 * mean_mean_scen_23) / float(
                            mean_mean_scen_1 + mean_mean_scen_23 + mean_mean_scen_45)
                        prop_45 = (100 * mean_mean_scen_45) / float(
                            mean_mean_scen_1 + mean_mean_scen_23 + mean_mean_scen_45)

                    else:

                        prop_1 = 0
                        prop_23 = 0
                        prop_45 = 0

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nRounds %4d to %4d - Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                        (start_round, end_round - 1, mean_mean_scen_1, prop_1, mean_std_scen_1, mean_mean_scen_23,
                         prop_23, mean_std_scen_23, mean_mean_scen_45, prop_45, mean_std_scen_45))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                if self.track_game_types:

                    # print_fine_dets = 1

                    print('---> writing Game Type Data')

                    if file_type == 'html':
                        fileHandle.write("<h2>")
                    fileHandle.write("\n\n\n\nGame Type Data\n")
                    if file_type == 'html':
                        fileHandle.write("</h2>")

                    total_sum_cons = 0
                    total_sum_seen = 0
                    total_sum_cons_RCT = 0
                    total_sum_seen_RCT = 0
                    total_sum_2 = 0
                    total_sum_3 = 0
                    total_sum_classics_cons = 0
                    total_sum_classics_seen = 0
                    total_sum_classics_cons_RCT = 0
                    total_sum_classics_seen_RCT = 0

                    for game_type in self.game_type_dict:
                        total_sum_cons += self.game_type_dict[game_type]

                    game_type_dict_run = sorted(self.game_type_dict.items(), key=lambda item: (item[1], item[0]), reverse=True)

                    # print('\n self.game_type_dict :\n\n', self.game_type_dict)
                    # print('\n game_type_dict_run :\n\n', game_type_dict_run)

                    game_type_seen_dict_run = sorted(self.game_type_dict_seen.items(), key=lambda item: (item[1], item[0]), reverse=True)

                    # print('\n self.game_type_dict_seen :\n\n', self.game_type_dict_seen)
                    # print('\n game_type_seen_dict_run :\n\n', game_type_seen_dict_run)

                    for game_type in self.game_type_dict_seen:
                        total_sum_seen += self.game_type_dict_seen[game_type]

                    for game_type in self.game_type_dict_RCT:
                        total_sum_cons_RCT += self.game_type_dict_RCT[game_type]

                    game_type_dict_run_RCT = sorted(self.game_type_dict_RCT.items(), key=lambda item: (item[1], item[0]), reverse=True)

                    for game_type in self.game_type_dict_seen_RCT:
                        total_sum_seen_RCT += self.game_type_dict_seen_RCT[game_type]

                    game_type_dict_run_seen_RCT = sorted(self.game_type_dict_seen_RCT.items(), key=lambda item: (item[1], item[0]), reverse=True)

                    for game_type in self.games_type_dict_2:
                        total_sum_2 += self.games_type_dict_2[game_type]

                    for game_type in self.games_type_dict_3:
                        total_sum_3 += self.games_type_dict_3[game_type]

                    games_type_dict_3_seen = sorted(self.games_type_dict_3.items(), key=lambda item: (item[1], item[0]), reverse=True)

                    for classic_game_type in self.classic_games_considered_sums:
                        total_sum_classics_cons += self.classic_games_considered_sums[classic_game_type]

                    for classic_game_type in self.classic_games_seen_sums:
                        total_sum_classics_seen += self.classic_games_seen_sums[classic_game_type]

                    for classic_game_type in self.classic_games_considered_sums_RCT:
                        total_sum_classics_cons_RCT += self.classic_games_considered_sums_RCT[classic_game_type]

                    for classic_game_type in self.classic_games_seen_sums_RCT:
                        total_sum_classics_seen_RCT += self.classic_games_seen_sums_RCT[classic_game_type]

                    classic_games_considered_sums_array = sorted(self.classic_games_considered_sums.items(), key=lambda item: (item[1], item[0]), reverse=True)
                    classic_games_seen_sums_array = sorted(self.classic_games_seen_sums.items(), key=lambda item: (item[1], item[0]), reverse=True)

                    classic_games_considered_sums_array_RCT = sorted(self.classic_games_considered_sums_RCT.items(), key=lambda item: (item[1], item[0]), reverse=True)
                    classic_games_seen_sums_array_RCT = sorted(self.classic_games_seen_sums_RCT.items(), key=lambda item: (item[1], item[0]), reverse=True)

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\nRaw Considered Game Types (and how many of each were seen) - not RCT")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    if file_type == 'html':
                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                    counter = 1

                    for game_type in game_type_dict_run:

                        #                    fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                        if print_fine_dets:
                            print('\n game_type =', game_type)

                        if game_type[0] in self.game_type_dict_seen:

                            seen_num = self.game_type_dict_seen[game_type[0]]

                        else:

                            seen_num = 0

                        #                   Serviced print("\n considered %s : %s (%s pct)  |  seen %s (%s pct)") % (game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen))

                        if total_sum_cons > 0.0:

                            prop_cons = 100 * game_type[1] / float(total_sum_cons)

                        else:

                            prop_cons = 0

                        if print_fine_dets:
                            print('\n num_cons =', game_type[1])
                            print(' total_sum_cons =', total_sum_cons)
                            print(' prop_cons =', prop_cons)

                        if total_sum_seen > 0.0:

                            prop_seen = 100 * seen_num / float(total_sum_seen)

                        else:

                            prop_seen = 0.0

                        if print_fine_dets:
                            print('\n seen_num =', seen_num)
                            print(' total_sum_seen =', total_sum_seen)
                            print(' prop_seen =', prop_seen)

                        fileHandle.write("\n%2d considered %s : %d (%1.6f pct)  |  seen %d (%1.6f pct)" % (counter, game_type[0], game_type[1], prop_cons, seen_num, prop_seen))

                        if print_fine_dets:
                            print("\n%2d considered %s : %d (%1.6f pct)  |  seen %d (%1.6f pct)" % (counter, game_type[0], game_type[1], prop_cons, seen_num, prop_seen))

                        counter += 1

                    fileHandle.write("<br><br>There might be interactions which were not considered but seen - we list those here is so:<br><br>")

                    # now there might be games considered by not seen (considered is by the instigating agent only and seen includes the counterpart also)
                    counter -= 1

                    for game_type in game_type_seen_dict_run:
                        if game_type[0] not in self.game_type_dict:
                            # print(' game_type =', game_type)

                            prop_seen = game_type[1] / float(total_sum_seen)

                            fileHandle.write("%3d seen only %s : %d (%1.6f pct)<br>" % (counter, game_type[0], game_type[1], prop_seen))

                        counter += 1

                    fileHandle.write("<br><br> Total unique game types considered = %d | Total unique game types seen = %d<br>" % (len(game_type_dict_run), len(self.game_type_dict_seen)))

                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nTotal considered = %d (mean per sim = %1.3f), total seen = %d (mean per sim = %1.3f)" % (
                        total_sum_cons, total_sum_cons / float(self.numb_of_sims), total_sum_seen,
                        total_sum_seen / float(self.numb_of_sims)))
                    fileHandle.write("</p>")

                    fileHandle.write("<p></p>")
                    fileHandle.write("Note: data is from dbs.game_type_considered_dict and dbs.game_type_dict.  If strat_choice == 'propensities' then payoffs in Quads 2 & 3 are derived from a weighted average")
                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("of the interacting agents' propensities to fight back, i.e., we do not assume backward induction to a derive substantive rationality outcome.")

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\nRaw Considered Game Types (and how many of each were seen) - RCT")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    if file_type == 'html':
                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                    counter = 1

                    for game_type in game_type_dict_run_RCT:

                        #                    fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                        if print_fine_dets:
                            print('\n game_type =', game_type)

                        if game_type[0] in self.game_type_dict_seen_RCT:

                            seen_num = self.game_type_dict_seen_RCT[game_type[0]]

                        else:

                            seen_num = 0

                        #                   Serviced print("\n considered %s : %s (%s pct)  |  seen %s (%s pct)") % (game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen))

                        if total_sum_cons_RCT > 0.0:

                            prop_cons = 100 * game_type[1] / float(total_sum_cons_RCT)

                        else:

                            prop_cons = 0

                        if print_fine_dets:
                            print('\n num_cons =', game_type[1])
                            print(' total_sum_cons =', total_sum_cons)
                            print(' prop_cons =', prop_cons)

                        if total_sum_seen_RCT > 0.0:

                            prop_seen = 100 * seen_num / float(total_sum_seen_RCT)

                        else:

                            prop_seen = 0.0

                        if print_fine_dets:
                            print('\n seen_num =', seen_num)
                            print(' total_sum_seen =', total_sum_seen_RCT)
                            print(' prop_seen =', prop_seen)

                        fileHandle.write("\n%2d considered %s : %d (%1.6f pct)  |  seen %d (%1.6f pct)" % (counter, game_type[0], game_type[1], prop_cons, seen_num, prop_seen))

                        if print_fine_dets:
                            print("\n%2d considered %s : %d (%1.6f pct)  |  seen %d (%1.6f pct)" % (counter, game_type[0], game_type[1], prop_cons, seen_num, prop_seen))

                        counter += 1

                    fileHandle.write("<br><br>There might be interactions which were not considered but seen - we list those here is so:<br><br>")

                    # now there might be games considered by not seen (considered is by the instigating agent only and seen includes the counterpart also)
                    counter -= 1

                    for game_type in game_type_dict_run_seen_RCT:
                        if game_type[0] not in self.game_type_dict_RCT:
                            # print(' game_type =', game_type)

                            prop_seen = game_type[1] / float(total_sum_seen_RCT)

                            fileHandle.write("%3d seen only %s : %d (%1.6f pct)<br>" % (counter, game_type[0], game_type[1], prop_seen))

                        counter += 1

                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nTotal considered = %d (mean per sim = %1.3f), total seen = %d (mean per sim = %1.3f)" % (
                        total_sum_cons_RCT, total_sum_cons_RCT / float(self.numb_of_sims), total_sum_seen_RCT,
                        total_sum_seen_RCT / float(self.numb_of_sims)))
                    fileHandle.write("</p>")

                    fileHandle.write("<p></p>")
                    fileHandle.write("Note: data is from dbs.game_type_considered_dict_RCT and dbs.game_type_dict_RCT.  The payoffs in Quads 2 & 3 are derived from")
                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("the highest payoff of the acquiesce and fight back strategies (randomly chosen if equal), i.e., we DO assume backward induction to a derive substantive rationality outcome.")

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write(
                        "\n\nSeen Game Types (number of game types seen (unweighted) and volume (benefit to instigating agent)) - not RCT")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    if file_type == 'html':
                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                    counter = 1

                    for game_type in games_type_dict_3_seen:

                        #                    fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                        if print_fine_dets:
                            print('\n game_type =', game_type)

                        if game_type[0] in self.games_type_dict_2:

                            seen_num = self.games_type_dict_2[game_type[0]]

                        else:

                            seen_num = 0

                        if print_fine_dets:
                            print('\n seen_num =', seen_num)

                        #                    print("\n considered %s : %s (%s pct)  |  seen %s (%s pct)") % (game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen))

                        if total_sum_3 > 0.0:

                            prop_cons = 100 * game_type[1] / float(total_sum_3)

                        else:

                            prop_cons = 0

                        if total_sum_2 > 0.0:

                            prop_seen = 100 * seen_num / float(total_sum_2)

                        else:

                            prop_seen = 0.0

                        fileHandle.write("\n%2d %s : total %d (%1.6f pct)  |  volume %1.6f (%1.6f pct)" % (counter, game_type[0], game_type[1], prop_cons, seen_num, prop_seen))

                        counter += 1

                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nAggregated number of games = %d (mean per sim = %1.3f), total volume = %1.3f (mean per sim = %1.3f)" % (
                        total_sum_3, total_sum_3 / float(self.numb_of_sims), total_sum_2,
                        total_sum_2 / float(self.numb_of_sims)))
                    fileHandle.write("</p>")

                    fileHandle.write("<p></p>")
                    fileHandle.write("Note: data is from dbs.game_type_dict_2 (numbers) and dbs.game_type_dict_3 (volume).  As above, if strat_choice == 'propensities' then payoffs in Quads 2 & 3 are derived from a weighted average")
                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("of the interacting agents' propensities to fight back, i.e., we do not assume backward induction to derive a substantive rationality outcome.")

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\nClassic Games Considered (not RCT)")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    if file_type == 'html':
                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                        for classic_game_type in classic_games_considered_sums_array:
                            fileHandle.write("<p style='margin:0;'>")

                            if total_sum_classics_cons > 0.0:

                                prop_cons = 100 * classic_game_type[1] / float(total_sum_classics_cons)

                            else:

                                prop_cons = 0.0

                            fileHandle.write("\n%s : %d (%1.6f pct)" % (classic_game_type[0], classic_game_type[1], prop_cons))

                    fileHandle.write("<p></p>")
                    fileHandle.write("Note: data is from dbs.classic_games_considered.  As above, if strat_choice == 'propensities' then payoffs in Quads 2 & 3 are derived from a weighted average")
                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("of the interacting agents' propensities to fight back, i.e., we do not assume backward induction to derive a substantive rationality outcome.")

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\nClassic Games Seen (not RCT)")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    if file_type == 'html':
                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                        for classic_game_type in classic_games_seen_sums_array:
                            fileHandle.write("<p style='margin:0;'>")

                            if total_sum_classics_seen > 0.0:

                                prop_seen = 100 * classic_game_type[1] / float(total_sum_classics_seen)

                            else:

                                prop_seen = 0.0

                            fileHandle.write("\n%s : %d (%1.6f pct)" % (classic_game_type[0], classic_game_type[1], prop_seen))

                    fileHandle.write("<p></p>")
                    fileHandle.write("Note: data is from dbs.classic_games_seen.  As above, if strat_choice == 'propensities' then payoffs in Quads 2 & 3 are derived from a weighted average")
                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("of the interacting agents' propensities to fight back, i.e., we do not assume backward induction to derive a substantive rationality outcome.")

                    # if file_type == 'html':
                    #     fileHandle.write("<h3>")
                    # fileHandle.write("\n\nClassic Games Considered (RCT)")
                    # if file_type == 'html':
                    #     fileHandle.write("</h3>")
                    #
                    # if file_type == 'html':
                    #     fileHandle.write("<p></p>")
                    #     fileHandle.write("<p style='margin:0;'>")
                    #
                    #     for classic_game_type in classic_games_considered_sums_array_RCT:
                    #         fileHandle.write("<p style='margin:0;'>")
                    #
                    #         if total_sum_classics_cons_RCT > 0.0:
                    #
                    #             prop_cons = 100 * classic_game_type[1] / float(total_sum_classics_cons_RCT)
                    #
                    #         else:
                    #
                    #             prop_cons = 0.0
                    #
                    #         fileHandle.write("\n%s : %d (%1.6f pct)" % (classic_game_type[0], classic_game_type[1], prop_cons))
                    #
                    # fileHandle.write("<p></p>")
                    # fileHandle.write("Note: data is from dbs.classic_games_considered_RCT.  The payoffs in Quads 2 & 3 are derived from")
                    # fileHandle.write("<p style='margin:0;'>")
                    # fileHandle.write("the highest payoff of the acquiesce and fight back strategies (randomly chosen if equal), i.e., we DO assume backward induction to a derive substantive rationality outcome.")
                    #
                    # if file_type == 'html':
                    #     fileHandle.write("<h3>")
                    # fileHandle.write("\n\nClassic Games Seen (RCT)")
                    # if file_type == 'html':
                    #     fileHandle.write("</h3>")
                    #
                    # if file_type == 'html':
                    #     fileHandle.write("<p></p>")
                    #     fileHandle.write("<p style='margin:0;'>")
                    #
                    #     for classic_game_type in classic_games_seen_sums_array_RCT:
                    #         fileHandle.write("<p style='margin:0;'>")
                    #
                    #         if total_sum_classics_seen_RCT > 0.0:
                    #
                    #             prop_seen = 100 * classic_game_type[1] / float(total_sum_classics_seen_RCT)
                    #
                    #         else:
                    #
                    #             prop_seen = 0.0
                    #
                    #         fileHandle.write("\n%s : %d (%1.6f pct)" % (classic_game_type[0], classic_game_type[1], prop_seen))
                    #
                    # fileHandle.write("<p></p>")
                    # fileHandle.write("Note: data is from dbs.classic_games_seen_RCT.  The payoffs in Quads 2 & 3 are derived from")
                    # fileHandle.write("<p style='margin:0;'>")
                    # fileHandle.write("the highest payoff of the acquiesce and fight back strategies (randomly chosen if equal), i.e., we DO assume backward induction to a derive substantive rationality outcome.")

                    mean_num_RE_games = self.num_RE_games / float(self.numb_of_sims)
                    mean_num_known_outcome_games = self.num_known_outcome_games / float(self.numb_of_sims)

                    if file_type == 'html':
                        fileHandle.write("<h2>")
                    fileHandle.write("\n\n\n\nNumber of Reflexively Entangled Games and Known Outcome Games")
                    if file_type == 'html':
                        fileHandle.write("</h2>")

                    if file_type == 'html':
                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                        if mean_num_RE_games + mean_num_known_outcome_games > 0:
                            pct_mean_num_RE_games =  (100 * mean_num_RE_games) / float(mean_num_RE_games + mean_num_known_outcome_games)
                        else:
                            pct_mean_num_RE_games = 0.0

                        if mean_num_RE_games + mean_num_known_outcome_games > 0:
                            pct_mean_num_known_outcome_games = (100 * mean_num_known_outcome_games) / float(mean_num_RE_games + mean_num_known_outcome_games)
                        else:
                            pct_mean_num_known_outcome_games = 0.0

                        fileHandle.write("\nMean Number of RE Games = %10.3f (%5.3f pct)" % (mean_num_RE_games, pct_mean_num_RE_games))
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nMean Number of Known Outcome Games = %10.3f (%5.3f pct)" % (mean_num_known_outcome_games, pct_mean_num_known_outcome_games))
                        fileHandle.write("<p style='margin:0;'>")

                    fileHandle.write("<p></p>")
                    fileHandle.write("Note: data is from dbs.num_RE_games and dbs.num_known_outcome_games.  This data uses 2x2 data which is derived assuming substanive rationality & backward induction is used for")
                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("deriving the payoffs in Quads 2 & 3.")

                    # now we count the number of interactions in each quadrant (applying RCT)
                    total_quad_ints = 0
                    last_100_rounds_ints = 0

                    for quad in ['1', '2F', '2A', '3F', '3A', '4']:

                        # print(' self.quad_inters_dicts[quad]', self.quad_inters_dicts[quad])

                        for sim in range(self.numb_of_sims):
                            # print(' self.quad_inters_dicts[quad][sim]', self.quad_inters_dicts[quad][sim])

                            total_quad_ints += np.sum(self.quad_inters_dicts[quad][sim])
                            last_100_rounds_ints += np.sum(self.quad_inters_dicts[quad][sim][-100:])

                    if file_type == 'html':
                        fileHandle.write("<h1>")
                    fileHandle.write("\n\nInteractions by Quadrant")
                    if file_type == 'html':
                        fileHandle.write("</h1>")

                    if file_type == 'html':
                        fileHandle.write("<h2>")
                    fileHandle.write("\n\nWhole Simulation")
                    if file_type == 'html':
                        fileHandle.write("</h2>")

                    fileHandle.write("<p></p>")

                    for quad in ['1', '2F', '2A', '3F', '3A', '4']:

                        # print('\n quad', quad)
                        # print('np.sum(dbs.quadrants_tallies_RCT)', np.sum(dbs.quadrants_tallies_RCT))
                        # print('np.sum(dbs.quadrants_tallies_RCT[quad])', np.sum(dbs.quadrants_tallies_RCT[quad]))
                        # print('np.sum(dbs.quadrants_tallies_RCT[quad]) / float(total_quad_ints))', np.sum(dbs.quadrants_tallies_RCT[quad]) / float(total_quad_ints))

                        total_for_quad = 0

                        for sim in range(self.numb_of_sims):
                            total_for_quad += np.sum(self.quad_inters_dicts[quad][sim])

                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\n%s:  \t %d (%5.3f pct) \t (%5.3f pct of all interactions)" % (quad, total_for_quad, (100 * total_for_quad) / float(total_quad_ints), (100 * total_for_quad) / float(total_sum_3)))
                        fileHandle.write("</p>")

                    fileHandle.write("<p></p>")

                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\nTotal %d" % (total_quad_ints))
                    fileHandle.write("</p>")

                    fileHandle.write("<p></p>")

                    if file_type == 'html':
                        fileHandle.write("<h2>")
                    fileHandle.write("\n\nLast 100 Rounds")
                    if file_type == 'html':
                        fileHandle.write("</h2>")

                    fileHandle.write("<p></p>")

                    for quad in ['1', '2F', '2A', '3F', '3A', '4']:

                        total_for_quad = 0

                        for sim in range(self.numb_of_sims):
                            total_for_quad += np.sum(self.quad_inters_dicts[quad][sim][-100:])

                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\n%s:  \t %d (%5.3f pct)" % (quad, total_for_quad, (100 * total_for_quad) / float(last_100_rounds_ints)))
                        fileHandle.write("</p>")

                    fileHandle.write("<p></p>")

                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\nTotal %d" % (last_100_rounds_ints))
                    fileHandle.write("</p>")

                    fileHandle.write("<p></p>")

                    fileHandle.write("<p></p>")
                    fileHandle.write("Note: data is from dbs.quad_inters_dicts.  This data uses 2x2 data which is derived assuming substanive rationality & backward induction is used for")
                    fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("deriving the payoffs in Quads 2 & 3.")

                # now we write the urls for the plotly charts
                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nurls for plotly charts by chart category")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nagents' prop_steals\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.agents_prop_steal_urls[sim], self.agents_prop_steal_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.agents_prop_steal_urls[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nagents' prop_fight_backs\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.agents_prop_fb_urls[sim], self.agents_prop_fb_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.agents_prop_fb_urls[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nprop_steals >= 0.5 and < 0.5\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.prop_steal_above_below_50_urls[sim], self.prop_steal_above_below_50_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.prop_steal_above_below_50_urls[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nprop_fight_backs >= 0.5 and < 0.5\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.prop_fb_above_below_50_urls[sim], self.prop_fb_above_below_50_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.prop_fb_above_below_50_urls[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nprop means\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.props_means_urls[sim], self.props_means_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.props_means_urls[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\ntransactions and fights\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.trans_and_fights_urls[sim], self.trans_and_fights_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.trans_and_fights_urls[sim]))

                if two_tribes:

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nSharks\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.trans_and_fights_urls_sharks[sim], self.trans_and_fights_urls_sharks[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.trans_and_fights_urls_sharks[sim]))

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nJets\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.trans_and_fights_urls_jets[sim], self.trans_and_fights_urls_jets[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.trans_and_fights_urls_jets[sim]))

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nInter-Tribe\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.trans_and_fights_urls_inter[sim], self.trans_and_fights_urls_inter[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.trans_and_fights_urls_inter[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nfight types\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.fight_types_urls[sim], self.fight_types_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.fight_types_urls[sim]))

                if two_tribes:

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nSharks\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.fight_types_urls_sharks[sim], self.fight_types_urls_sharks[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.fight_types_urls_sharks[sim]))

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nJets\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.fight_types_urls_jets[sim], self.fight_types_urls_jets[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.fight_types_urls_jets[sim]))

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nInter-Tribe\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.fight_types_urls_inter[sim], self.fight_types_urls_inter[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.fight_types_urls_inter[sim]))

                if fight_skill:

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\n\nfight skills:\n")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.fight_skills_urls[sim], self.fight_skills_urls[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.fight_skills_urls[sim]))

        # if we conduct a constitutional experiment:
        if constitutional_voting == 1:

            if file_type == 'html':
                fileHandle.write("<h1>")
            fileHandle.write("Constitutional Voting")
            if file_type == 'html':
                fileHandle.write("</h1>")

            # Now to prices and price differences
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("Price and Price Difference Data for Voting\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            # Pricing Data
            for experiment in range(self.num_experiments):

                if experiment == 0:

                    start_round = 0
                    end_round = start_const_proces

                else:

                    start_round = start_const_proces + ((experiment - 1) * const_proc_test_period)
                    end_round = start_const_proces + (experiment * const_proc_test_period)

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nRounds %d to %d" % (start_round, end_round - 1))
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for res_1 in np.arange(num_res_founts):
                    for res_2 in np.arange(num_res_founts):

                        if res_1 != res_2:
                            act_mean_array = [run[experiment][res_1][res_2][0] for run in self.act_prices_data]
                            act_std_array = [run[experiment][res_1][res_2][1] for run in self.act_prices_data]

                            act_mean_mean = np.mean(act_mean_array)
                            act_mean_std = np.mean(act_std_array)

                            fileHandle.write("\n\nResource %s vs Resource %s - Mean Actual Price = %3.5f (%3.5f)" % (
                            res_1, res_2, act_mean_mean, act_mean_std))

                            act_std_mean_array = [run[experiment][res_1][res_2][0] for run in self.act_std_prices_data]
                            act_std_std_array = [run[experiment][res_1][res_2][1] for run in self.act_std_prices_data]

                            act_std_mean = np.mean(act_std_mean_array)
                            act_std_std = np.mean(act_std_std_array)

                            fileHandle.write(
                                "\nResource %s vs Resource %s - Mean Daily STD of Actual Price = %3.5f (%3.5f)" % (
                                res_1, res_2, act_std_mean, act_std_std))
                            fileHandle.write("<br>")

                            opt_mean_array = [run[experiment][res_1][res_2][0] for run in self.opt_prices_data]
                            opt_std_array = [run[experiment][res_1][res_2][1] for run in self.opt_prices_data]

                            opt_mean_mean = np.mean(opt_mean_array)
                            opt_mean_std = np.mean(opt_std_array)

                            fileHandle.write("\nResource %s vs Resource %s - Mean Optimal Price = %3.5f (%3.5f)" % (
                            res_1, res_2, opt_mean_mean, opt_mean_std))

                            diff_mean_array = [run[experiment][res_1][res_2][0] for run in self.diff_prices_data]
                            diff_std_array = [run[experiment][res_1][res_2][1] for run in self.diff_prices_data]

                            diff_mean_mean = np.mean(diff_mean_array)
                            diff_mean_std = np.mean(diff_std_array)

                            fileHandle.write(
                                "\nResource %s vs Resource %s - Mean Absolute Price Difference = %3.5f (%3.5f)" % (
                                res_1, res_2, diff_mean_mean, diff_mean_std))

                            fileHandle.write("<br>")

                    fileHandle.write("<br>")

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\nConstitutional Voting: Optimal Prices over Sims:\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            means_array = np.zeros(shape=(self.numb_of_sims))
            stds_array = np.zeros(shape=(self.numb_of_sims))

            #        print('\n self.whole_sim_opt_prices_data =', self.whole_sim_opt_prices_data)

            for sim in range(self.numb_of_sims):
                means_array[sim] = self.whole_sim_opt_prices_data[sim][0]
                stds_array[sim] = self.whole_sim_opt_prices_data[sim][1]

            if file_type == 'html':
                fileHandle.write("<p>")
            fileHandle.write(
                "\nAverage Mean and Standard Deviation of Prices Over Whole Simulations (Chart Price of Res 0 in Res 1 Units): Mean = %2.5f  |  STD = %2.5f\n" % (
                np.mean(means_array), np.mean(stds_array)))
            if file_type == 'html':
                fileHandle.write("</p>")

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nConstitutional Voting: Applied Constitutions = %s" % (self.applied_constitutions))
            if file_type == 'html':
                fileHandle.write("</h2>")

            if file_type == 'html':
                fileHandle.write("<p>")
            fileHandle.write("\n\nNotes:")
            fileHandle.write("<br>")
            fileHandle.write("<br>")
            fileHandle.write("\n\nExperiment 1 is floating prices and market start = 0")
            fileHandle.write("<br>")
            fileHandle.write("\nExperiment 2 is floating prices and market start = 20")
            fileHandle.write("<br>")
            fileHandle.write("\nExperiment 4 is optimal prices and market start = 0")
            fileHandle.write("<br>")
            fileHandle.write("\nExperiment 3 is optimal prices and market start = 20")
            fileHandle.write("<br>")
            fileHandle.write("\nExperiment 5 is pure Walrasian Prices and Quantities")
            if file_type == 'html':
                fileHandle.write("<br>")
                fileHandle.write("</p>")

            fileHandle.write("\n\nConstitution Process Starts = %d  |  Test Period Length = %d" % (start_const_proces, const_proc_test_period))
            fileHandle.write("<br>")

            total_votes = np.zeros(shape=(self.num_experiments + 1), dtype=float)
            num_times_won_vote_array = np.zeros(shape=(self.num_experiments + 1), dtype=float)

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("Voting in Each Sim:")
            if file_type == 'html':
                fileHandle.write("</h2>")
            # fileHandle.write("<br>")

            for sim in range(self.numb_of_sims):

                if print_fine_dets:
                    print('\n sim', sim)
                    print(' self.agents_aggr_votes_data[sim] =', self.agents_aggr_votes_data[sim])

                fileHandle.write("Sim no. %2d:   " % (sim))

                for experiment in range(1, self.num_experiments + 1):
                    fileHandle.write("  %3d" % (self.agents_aggr_votes_data[sim][experiment]))

                fileHandle.write("<br>")

                total_votes += self.agents_aggr_votes_data[sim]

                # we also want to find how many times each constitutional system was voted for
                max_votes = np.max(self.agents_aggr_votes_data[sim])

                if print_fine_dets:
                    print('\n max_votes', max_votes)

                max_votes_array = []

                for experiment in range(1, self.num_experiments + 1):

                    if max_votes == self.agents_aggr_votes_data[sim][experiment]:
                        max_votes_array.append(experiment)

                if print_fine_dets:
                    print('\n max_votes_array =', max_votes_array)

                for voted_experiment in max_votes_array:
                    num_times_won_vote_array[voted_experiment] += 1 / float(len(max_votes_array))

            if print_fine_dets:
                print('\n num_times_won_vote_array =', num_times_won_vote_array)

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\nNumber of Times Each Constitution Voted For\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            for experiment in range(1, self.num_experiments + 1):
                fileHandle.write("\nExperiment %d: %2.2f" % (experiment, num_times_won_vote_array[experiment]))
                fileHandle.write("<br>")

            total_votes_prop = total_votes / float(np.sum(total_votes))

            if print_fine_dets:
                print('\n total_votes_prop =', total_votes_prop)

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\nTotal Votes (in percentage terms):\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            for experiment in range(1, self.num_experiments + 1):
                fileHandle.write(
                    "\nExperiment %d: Percentage of Votes = %3.2f" % (experiment, total_votes_prop[experiment] * 100))
                fileHandle.write("<br>")

            if print_fine_dets:
                print('\n self.const_record_res_accum_data =\n\n', self.const_record_res_accum_data)

            # Now I want to find the average gain in each experiment and the std
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write(
                "\n\nMean and Standard Deviations of Resources Accumulated During the Constitutional Experiment\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            means_array = np.zeros(shape=(self.numb_of_sims, self.num_experiments + 1))
            stds_array = np.zeros(shape=(self.numb_of_sims, self.num_experiments + 1))

            for experiment in range(1, self.num_experiments + 1):

                if print_fine_dets:
                    print('\n\n experiment ', experiment, 'self.numb_of_sims =', self.numb_of_sims)

                experiment_array = []
                sim_means = []

                for sim in range(self.numb_of_sims):

                    if print_fine_dets:
                        print('\n sim =', sim)

                    if print_fine_dets:
                        print('len(self.const_record_res_accum_data[sim][experiment]) =',
                          len(self.const_record_res_accum_data[sim][experiment]))

                    agent_data_array = np.zeros(shape=(len(self.const_record_res_accum_data[sim][experiment])))

                    for agent_num in range(len(self.const_record_res_accum_data[sim][experiment])):
                        if print_fine_dets:
                            print('\n agent_num =', agent_num)
                            print(' self.const_record_res_accum_data[sim][experiment][agent_num]=',
                              self.const_record_res_accum_data[sim][experiment][agent_num])

                        experiment_array.append(self.const_record_res_accum_data[sim][experiment][agent_num])

                        agent_data_array[agent_num] = self.const_record_res_accum_data[sim][experiment][agent_num]

                    if print_fine_dets:
                        print('\n agent_data_array =', agent_data_array)

                    mean = np.mean(agent_data_array)
                    std = np.std(agent_data_array)

                    means_array[sim][experiment] = mean
                    stds_array[sim][experiment] = std

                    sim_means.append(mean)

                if print_fine_dets:
                    print('\n experiment_array \n\n', experiment_array)

                exp_mean = np.mean(experiment_array)
                std_of_sim_means = np.std(sim_means)
                exp_std = np.std(experiment_array)

                if print_fine_dets:
                    print('\n exp_mean', exp_mean)
                    print('\n exp_std', exp_std)

                fileHandle.write("\nExperiment %d: Mean = %4.4f (std of sim means %4.4f) [mean of stds %4.4f]" % (experiment, exp_mean, std_of_sim_means, exp_std))
                fileHandle.write("<br>")

            fileHandle.write("<br>")
            fileHandle.write("\n\nMean and STD of Agents' Accumulated Resources for Each Sim:")
            fileHandle.write("<br>")
            # fileHandle.write("\n\nExperiment\t\t")
            #
            # for exp in range(self.num_experiments):
            #     fileHandle.write("%d\t\t" % (exp))
            #
            # fileHandle.write("\n")

            if print_fine_dets:
                print('\n means_array :', means_array)
                print('\n stds_array :', stds_array)

            for sim in range(self.numb_of_sims):

                if print_fine_dets:
                    print('\n sim', sim)
                    print(' self.agents_aggr_votes_data[sim] =', self.agents_aggr_votes_data[sim])

                fileHandle.write("<br>")
                fileHandle.write("\nSim no. %d:\t" % (sim))

                for experiment in range(1, self.num_experiments + 1):
                    fileHandle.write("%4.2f (%4.2f)\t" % (means_array[sim][experiment], stds_array[sim][experiment]))

        if black_shoop_exp:

            print('---> writing Black Shoop Experiment Data')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nBlack Shoop Experiment Results\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            birth_date_array = [run[0] for run in self.black_shoop_data]
            death_date_array = [run[1] for run in self.black_shoop_data]

            mean_birth_date = np.mean(birth_date_array)
            mean_death_date = np.mean(death_date_array)

            mean_life_span = mean_death_date - mean_birth_date

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write(
                "\nBlack Shoops were born on (mean) day %4.3f and died on (mean) day %4.3f (mean life span = %4.3f days)\n" % (
                mean_birth_date, mean_death_date, mean_life_span))
            if file_type == 'html':
                fileHandle.write("</p>")

        if self.respect_property_rights == 0:

            # create charts to show correlations between props steal

            # create directory for prop steal correlation data
            run_ps_correlations_folder = "%s/Prop_Steal_Correlations" % self.sub_folder

            if os.path.exists(run_ps_correlations_folder) == False:
                os.makedirs(run_ps_correlations_folder)

            # we use all of these as the base round against which all the other data are compared
            ps_corr = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 250, 300, 400, 450]

            # first we have to find the maximum size of the chart (rounds on the x axis)
            max_round_length = 1000000
            for round_data in self.ps_corr_arrays:
                if len(round_data) < max_round_length:
                    max_round_length = len(round_data)

            # print('\n max_round_length =', max_round_length)
            # print('\n self.ps_corr_arrays:', self.ps_corr_arrays)

            for base_round in ps_corr:

                if max_round_length > base_round:

                    # print('\n base_round =', base_round)

                    data_prop_steal_corrs = [[] for i in range(max_round_length)]

                    for round_data in self.ps_corr_arrays:

                        for day in range(max_round_length):

                            corr_matrix = np.corrcoef(round_data[day], round_data[base_round])

                            data_prop_steal_corrs[day].append(corr_matrix[0][1])

                    # print('\n data_prop_steal_corrs =', data_prop_steal_corrs)

                    filename_ps_corrs = '%s/ps_correlation_base_%d' % (run_ps_correlations_folder, base_round)

                    fan_chart(data_prop_steal_corrs, colour='blue', include_max_min=0, file_name=filename_ps_corrs, num_rounds=max_round_length, bands=False)

            # print some aggregated charts

            print('---> writing Simulation Means Charts')

            # print gini coefficient charts
            # self.res_conc_gini_starts
            # self.res_conc_gini

            gini_data = np.zeros(shape=(3, len(self.res_conc_gini[0])))
            gini_data[0] = np.arange(len(self.res_conc_gini[0]))

            for day in np.arange(len(self.res_conc_gini[0])):

                gini_sum = 0.0
                counter = 0
                for sim_data in self.res_conc_gini_starts:

                    gini_sum += sim_data[day]
                    counter += 1

                mean_gini = gini_sum / float(counter)
                gini_data[1][day] = mean_gini

                gini_sum = 0.0
                counter = 0
                for sim_data in self.res_conc_gini:

                    gini_sum += sim_data[day]
                    counter += 1

                mean_gini = gini_sum / float(counter)
                gini_data[2][day] = mean_gini

            print_chart(database=gini_data, labels_array=['Start of Round', 'End of Round'], axis_labels=['Rounds', 'Gini Coefficient'], line_width=3, colors=('blueviolet', 'darkblue'), data_folder=self.sub_folder, filename='gini_res_conc', keep_name=1)

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\nSimulation Means Charts:\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            props_means_url = ''
            fight_types_url = ''

            # create files which will be sent to plotly
            prop_steal_means = np.zeros(shape=rounds)
            prop_fb_means = np.zeros(shape=rounds)

            prop_steal_start_end_ags_means = np.zeros(shape=rounds)
            prop_fb_start_end_ags_means = np.zeros(shape=rounds)

            proport_fights = np.zeros(shape=rounds)
            proport_fight_back = np.zeros(shape=rounds)
            proport_acqu = np.zeros(shape=rounds)
            proport_trans = np.zeros(shape=rounds)

            # print('\n self.prop_fb_mean_db[sim]:\n')
            # for sim in range(self.numb_of_sims):
            #     print(self.prop_fb_mean_db[sim])

            for day in range(rounds):

                aggr_prop_steal = 0
                aggr_prop_fb = 0

                num_sim_count_ps = 0
                num_sim_count_pfb = 0

                for sim in range(self.numb_of_sims):

                    if self.prop_steal_mean_db[sim][day] is not None:
                        aggr_prop_steal += self.prop_steal_mean_db[sim][day]
                        num_sim_count_ps += 1

                    if self.prop_fb_mean_db[sim][day] is not None:
                        aggr_prop_fb += self.prop_fb_mean_db[sim][day]
                        num_sim_count_pfb += 1

                if num_sim_count_ps != 0:

                    prop_steal_means[day] = aggr_prop_steal / num_sim_count_ps

                else:

                    prop_steal_means[day] = None

                if num_sim_count_pfb != 0:

                    prop_fb_means[day] = aggr_prop_fb / num_sim_count_pfb

                else:

                    prop_fb_means[day] = None

            # print('\nprop_fb_means: \n\n', prop_fb_means)

            for day in range(rounds):

                aggr_prop_steal_start_end_ags = 0
                aggr_prop_fb_start_end_ags = 0

                num_sim_count_ps = 0
                num_sim_count_pfb = 0

                for sim in range(self.numb_of_sims):

                    if self.prop_steal_mean_start_end_ags_db[sim][day] is not None:
                        aggr_prop_steal_start_end_ags += self.prop_steal_mean_start_end_ags_db[sim][day]
                        num_sim_count_ps += 1

                    if self.prop_fb_mean_start_end_ags_db[sim][day] is not None:
                        aggr_prop_fb_start_end_ags += self.prop_fb_mean_start_end_ags_db[sim][day]
                        num_sim_count_pfb += 1

                if num_sim_count_ps != 0:

                    prop_steal_start_end_ags_means[day] = aggr_prop_steal_start_end_ags / num_sim_count_ps

                else:

                    prop_steal_start_end_ags_means[day] = None

                if num_sim_count_pfb != 0:

                    prop_fb_start_end_ags_means[day] = aggr_prop_fb_start_end_ags / num_sim_count_pfb

                else:

                    prop_fb_start_end_ags_means[day] = None

            # now generate charts
            data_prop_means = []
            data_prop_means_start_end_ags = []

            data_prop_means.append(
                go.Scatter(x=np.arange(rounds), y=prop_steal_means, connectgaps=False, name='Prop. Steal'))
            data_prop_means.append(
                go.Scatter(x=np.arange(rounds), y=prop_fb_means, connectgaps=False, name='Prop. Fight Back'))

            # do the scatter chart with just means line
            create_plotly_2d_scatter(x_data=[], y_data=[], title='', x_axis_label='Propensity to Steal', y_axis_label='Propensity to Steal', dot_size=1, color='blue', line_x=prop_steal_means, line_y=prop_fb_means, data_folder=self.sub_folder, filename='props_scatter', keep_name=1)

            print_chart(database=[np.arange(rounds), prop_steal_means], axis_labels=['Rounds', 'Propensity to Steal'], line_width=3, colors=['blue'], data_folder=self.sub_folder, filename='prop_steal_mean', show_legend=False, keep_name=1)

            data_prop_means_start_end_ags.append(go.Scatter(x=np.arange(rounds), y=prop_steal_start_end_ags_means, connectgaps=False, name='Mean Propensity to Steal'))
            data_prop_means_start_end_ags.append(go.Scatter(x=np.arange(rounds), y=prop_fb_start_end_ags_means, connectgaps=False, name='Mean Propensity to Steal'))

            filename_prop_steal = '%s/prop_means.html' % self.sub_folder

            # filename_prop_steal = '%s/prop_means_%d-%d-%d-%d-%d.html' % (self.sub_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour, dt.datetime.now().minute)

            props_means_url = plotly.offline.plot(data_prop_means, filename=filename_prop_steal, auto_open=False)

            filename_prop_steal_start_end_ags = '%s/prop_means_start_end_ags.html' % self.sub_folder

            # filename_prop_steal_start_end_ags = '%s/prop_means_start_end_ags_%d-%d-%d-%d-%d.html' % (
            # self.sub_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour,
            # dt.datetime.now().minute)

            props_means_start_end_ags_url = plotly.offline.plot(data_prop_means_start_end_ags, filename=filename_prop_steal_start_end_ags, auto_open=False)

            if plotly_online:

                filename_prop_steal = '%s/prop_means_%d-%d-%d-%d-%d.html' % (
                self.sub_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day,
                dt.datetime.now().hour, dt.datetime.now().minute)

                try:

                    props_means_url = py.plot(data_prop_means, filename=filename_prop_steal, auto_open=False,
                                              sharing='private')

                except:

                    print('\n *** There was a problem connecting to plotly so place chart on local drive ***\n')

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n prop_means (steal and fb): \t\t\t\t\t<a href='%s' target='_blank'>%s</a>" % (
                props_means_url, props_means_url))
                fileHandle.write("</p>")
            else:
                fileHandle.write("\n prop_means (steal and fb): \t\t\t\t\t%s" % props_means_url)

            for day in range(rounds):

                aggr_both_steal = 0
                aggr_fb = 0
                aggr_acq = 0
                aggr_trade = 0

                for sim in range(self.numb_of_sims):
                    aggr_both_steal += self.num_ints_each_round[sim][1][day]
                    aggr_fb += self.num_ints_each_round[sim][2][day]
                    aggr_acq += self.num_ints_each_round[sim][4][day]
                    aggr_trade += self.num_ints_each_round[sim][6][day]

                tot_ints = aggr_both_steal + aggr_fb + aggr_acq + aggr_trade

                if tot_ints > 0 and aggr_both_steal > 0:

                    proport_fights[day] = aggr_both_steal / float(tot_ints)

                else:

                    proport_fights[day] = None

                if tot_ints > 0 and aggr_fb > 0:

                    proport_fight_back[day] = aggr_fb / float(tot_ints)

                else:

                    proport_fight_back[day] = None

                if tot_ints > 0 and aggr_acq > 0:

                    proport_acqu[day] = aggr_acq / float(tot_ints)

                else:

                    proport_acqu[day] = None

                if tot_ints > 0 and aggr_trade > 0:

                    proport_trans[day] = aggr_trade / float(tot_ints)

                else:

                    proport_trans[day] = None

            #        proport_fights = generate_MA_array(proport_fights, 10)
            #        proport_fight_back = generate_MA_array(proport_fight_back, 10)
            #        proport_acqu = generate_MA_array(proport_acqu, 10)
            #        proport_trans = generate_MA_array(proport_trans, 10)

            # now send data to plotly:
            fight_types_data = [np.arange(rounds), proport_fights, proport_fight_back, proport_acqu, proport_trans]
            labels_array = ['Both Steal', 'One Steals, Other Fights Back', 'One Steals, Other Acquiesces', 'Transactions']
            filename = 'fight_types_2'
            title = None
            axis_labels = ['Rounds', 'Proportion']
            line_width=3
            colors=[]
            data_type = None
            dpi=None

            print_chart(fight_types_data, labels_array, title, axis_labels, line_width, colors, self.sub_folder, filename, data_type, dpi, keep_name=1)

            fight_types = []

            fight_types.append(go.Scatter(x=np.arange(rounds), y=proport_fights, connectgaps=False, name='Both Steal'))
            fight_types.append(go.Scatter(x=np.arange(rounds), y=proport_fight_back, connectgaps=False, name='One Steals, Other Fights Back'))
            fight_types.append(go.Scatter(x=np.arange(rounds), y=proport_acqu, connectgaps=False, name='One Steals, Other Acquiesces'))
            fight_types.append(go.Scatter(x=np.arange(rounds), y=proport_trans, connectgaps=False, name='Transactions'))

            filename_fight_types = '%s/fight_types.html' % self.sub_folder

            # filename_fight_types = '%s/fight_types_%d-%d-%d-%d-%d.html' % (
            # self.sub_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, dt.datetime.now().hour,
            # dt.datetime.now().minute)

            fight_types_url = plotly.offline.plot(fight_types, filename=filename_fight_types, auto_open=False)

            if plotly_online:

                filename_fight_types = '%s/fight_types_%d-%d-%d-%d-%d' % (
                self.sub_folder, dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day,
                dt.datetime.now().hour, dt.datetime.now().minute)

                try:

                    fight_types_url = py.plot(fight_types, filename=filename_fight_types, auto_open=False,
                                              sharing='private')

                except:

                    print('\n *** There was a problem connecting to plotly so place chart on local drive ***\n')

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n Interaction Types: \t\t\t\t\t<a href='%s' target='_blank'>%s</a>" % (
                fight_types_url, fight_types_url))
                fileHandle.write("</p>")
            else:
                fileHandle.write("\n Interaction Types: \t\t\t\t\t%s" % fight_types_url)

            # print('\n self.dbs_ps_net_contr_by_scen =', self.dbs_ps_net_contr_by_scen)
            # print('\n self.dbs_pfb_net_contr_by_scen =', self.dbs_pfb_net_contr_by_scen)

            fileHandle.write("<h2>")
            fileHandle.write("\n\nContributions to propensities by quadrants:")
            fileHandle.write("</h2>")

            fileHandle.write('<p> <span style="font-weight:bold"> Propensities to Steal</span><br><br>')

            fileHandle.write('Scen. 1 %1.4f <br>' % (self.dbs_ps_net_contr_by_scen['1'] / float(self.numb_of_sims)))
            fileHandle.write('Scen. 2F %1.4f <br>' % (self.dbs_ps_net_contr_by_scen['2F'] / float(self.numb_of_sims)))
            fileHandle.write('Scen. 2A %1.4f <br>' % (self.dbs_ps_net_contr_by_scen['2A'] / float(self.numb_of_sims)))
            fileHandle.write('Scen. 3F %1.4f <br>' % (self.dbs_ps_net_contr_by_scen['3F'] / float(self.numb_of_sims)))
            fileHandle.write('Scen. 3A %1.4f <br>' % (self.dbs_ps_net_contr_by_scen['3A'] / float(self.numb_of_sims)))
            fileHandle.write('Scen. 4 %1.4f <br>' % (self.dbs_ps_net_contr_by_scen['4'] / float(self.numb_of_sims)))

            fileHandle.write('<p> <span style="font-weight:bold"> Propensities to Fight Back</span><br><br>')

            fileHandle.write('Scen. 2F %1.4f <br>' % (self.dbs_pfb_net_contr_by_scen['2F'] / float(self.numb_of_sims)))
            fileHandle.write('Scen. 2A %1.4f <br>' % (self.dbs_pfb_net_contr_by_scen['2A'] / float(self.numb_of_sims)))
            fileHandle.write('Scen. 3F %1.4f <br>' % (self.dbs_pfb_net_contr_by_scen['3F'] / float(self.numb_of_sims)))
            fileHandle.write('Scen. 3A %1.4f <br><br>' % (self.dbs_pfb_net_contr_by_scen['3A'] / float(self.numb_of_sims)))

            fileHandle.write('check: Scen. 1 %1.4f <br>' % (self.dbs_pfb_net_contr_by_scen['1'] / float(self.numb_of_sims)))
            fileHandle.write('check: Scen. 4 %1.4f <br><br>' % (self.dbs_pfb_net_contr_by_scen['4'] / float(self.numb_of_sims)))

        if self.print_voting_only == 0:

            # now we print out the data for the tables in the paper

            print('---> writing Table Data')

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nTable Data (re table in the paper)\n\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if file_type == 'html':
                fileHandle.write("<table style='width:100%'>")

                fileHandle.write("<tr>")

                fileHandle.write("<th style = 'text-align: left;'>Mean Foragd (all res)</th>")
                fileHandle.write("<th style = 'text-align: left;'>Mean Spec Val</th>")
                fileHandle.write("<th style = 'text-align: left;'>Mean Max Det Prob</th>")
                fileHandle.write("<th style = 'text-align: left;'>Mean Min Res</th>")
                fileHandle.write("<th style = 'text-align: left;'>Num Sqs w trans</th>")
                fileHandle.write("<th style = 'text-align: left;'>Prop One Squared</th>")
                fileHandle.write("<th style = 'text-align: left;'>Turnover Mean</th>")

                fileHandle.write("</tr>")

                fileHandle.write("<tr>")

                fileHandle.write("<td>%s (%s)</td>" % (tab_for_mean, tab_for_std))
                fileHandle.write("<td>%s (%s)</td>" % (tab_spec_mean, tab_spec_std))
                fileHandle.write("<td>%s (%s)</td>" % (tab_det_prob_mean, tab_det_prob_std))
                fileHandle.write("<td>%s (%s)</td>" % (tab_min_res_mean, tab_min_res_std))
                fileHandle.write("<td>%s (%s)</td>" % (tab_num_sqs_mean, tab_num_sqs_std))
                fileHandle.write("<td>%s (%s)</td>" % (tab_mean_mean_prop, tab_mean_std_prop))
                fileHandle.write("<td>%s (%s)</td>" % (tab_turnover_mean, tab_turnover_std))

                fileHandle.write("</tr>")
                fileHandle.write("</table>")

            if file_type != 'html':
                fileHandle.write(
                    "\n Mean Foragd (all res) \t Mean Spec Val \t\t Mean Max Detection Prob \t Mean Min Res \t\t Num Sqs w\ Trans \t\t Proportion one square \t\t Turnover Mean \n")
                fileHandle.write(
                    "\n %s (%s)\t\t %s (%s) \t %s (%s) \t\t %s (%s) \t %s (%s) \t\t %s (%s) \t\t %s (%s)\n\n\n\n" % (
                    tab_for_mean, tab_for_std, tab_spec_mean, tab_spec_std, tab_det_prob_mean, tab_det_prob_std,
                    tab_min_res_mean, tab_min_res_std, tab_num_sqs_mean, tab_num_sqs_std, tab_mean_mean_prop,
                    tab_mean_std_prop, tab_turnover_mean, tab_turnover_std))

            if file_type == 'html':
                fileHandle.write("<p>")
            fileHandle.write(
                "\n\nNotes on data: each simulation is divided in to segments (default 10).  We find the mean and std of each metric in each segment in each run,\nso by default this gives us 10 x 2 pieces of data.\nWe then find the mean across each segment in all of the simulations.\nSo the mean is a mean of means and the std is the mean of a stds.\nFor the specialisation data, each measure in each round is a mean across agents.")
            fileHandle.write(
                "\nIn addition, the data re number of squares with transactions adds up the number of squares with transactions in each segment.  The mean is the mean of these values and the standard deviation is the std of these so it is not a mean of a std but a std of a mean...")
            fileHandle.write(
                "\n For proportion of transaction volume on one square, there is a single value for each run, for each segment so the mean is a mean of means and the std a std of means.\n\n\n")
            if file_type == 'html':
                fileHandle.write("</p>")

        if file_type == 'html':
            if file_type == 'html':
                fileHandle.write("<p> </p>")
                fileHandle.write("<p> </p>")
            fileHandle.write("</html>")

        fileHandle.close()


class Agent():
    """A class for instantiating agents."""

    def __init__(self, params, birth_date, death_date, for_strat_array, agent_res_array, detect_skills_array, basket_array,
                 location, agent_vision, grid_trgt, trading_basket, home,
                 neighs, goods_2_mkt, trade_proby,
                 trans_loc_mat, trade_loc_rec, trgt_loc_rec, sell_array, buy_array, can_trade, ag_trans_array,
                 sell_good,
                 buy_good, loc_mems_array, loc_mems_array_cp, thresh_probs_array, agent_mem_length, cp_trans_weight,
                 wait_at_tgt_moves, reached_trgt, MRS_array, aggr_res_array,
                 dummy_basket_array, for_strat_hist, equil_price_SD_exps,
                 num_act_transs, MRS_history, agent_res_array_hist, detect_skills_array_hist, optimal_transs_systemic,
                 optimal_transs_local, wkg_prices_memory, personal_turnover_ratio, basket_array_hist,
                 basket_array_start_hist,
                 total_actual_agent_sales, total_optimal_agent_sales, cognition_factor, over_sell_counter,
                 didnt_over_sell_counter, trade_movemnt,
                 foraging_strat_data, resources_to_children, hist_trade_loc_rec,
                 prop_steal, prop_fight_back, reputations_dict, fights_array, loc_fights_array, loc_fights_array_cp,
                 prop_steal_history, prop_fight_back_history, agreed_meeting_point, meeting_point_cps, tribe,
                 fight_skill, agents_die_old_age,
                 fight_skill_history):

        if params.agents_die_old_age:

            self.age = random.randint(0, params.max_age_at_birth)  # we create a variable to record the agent's age - note we don't use birth_date (which is really an instantiation date)
            # to track age this is used in the code to start certain charts

        else:

            self.age = 0

        self.birth_date = birth_date  # record agent's date of birth
        self.death_date = death_date
        self.for_strat_array = for_strat_array  # forraging strategy array
        self.agent_res_array = agent_res_array  # agent personal resource levels
        self.agent_res_array_start = copy.copy(agent_res_array)
        self.detect_skills_array = detect_skills_array  # an array of probabilities: prob of detecting each resource
        self.basket_array = basket_array  # a 'basket' for holding collected resources
        self.basket_array_start = copy.copy(basket_array)  # to record the basket array prior to trading, after foraging
        self.location = location  # the location of an agent on the town_grid (assuming they seek to trade)
        self.agent_vision = agent_vision  # the distance an agent can see in the town_grid
        self.grid_trgt = grid_trgt
        self.trading_basket = trading_basket
        self.home = home
        self.neighs = neighs
        self.goods_2_mkt = goods_2_mkt
        self.trade_proby = trade_proby
        self.trans_loc_mat = trans_loc_mat
        self.trade_loc_rec = trade_loc_rec
        self.trgt_loc_rec = trgt_loc_rec
        self.sell_array = sell_array
        self.buy_array = buy_array
        # can_trade: the default of this value is 1, which means the agent can trade.  It is only set to 0 when the agent is heading straight to target without trading on the way
        self.can_trade = can_trade
        self.ag_trans_array = ag_trans_array
        self.sell_good = sell_good
        self.buy_good = buy_good
        self.loc_mems_array = loc_mems_array
        self.loc_mems_array_cp = loc_mems_array_cp
        self.thresh_probs_array = thresh_probs_array
        self.agent_mem_length = agent_mem_length
        self.cp_trans_weight = cp_trans_weight
        self.wait_at_tgt_moves = wait_at_tgt_moves
        self.reached_trgt = reached_trgt
        self.MRS_array = MRS_array
        self.aggr_res_array = aggr_res_array  # this records the total resources 'held' by the agent, which is the summation of agent_res_array and basket_array
        self.dummy_basket_array = dummy_basket_array
        self.for_strat_hist = for_strat_hist
        self.equil_price_SD_exps = equil_price_SD_exps
        self.num_act_transs = num_act_transs
        self.MRS_history = MRS_history
        self.agent_res_array_hist = agent_res_array_hist
        self.agent_res_array_start_hist = np.zeros(shape=(params.rounds, num_res_founts), dtype=float)
        self.detect_skills_array_hist = detect_skills_array_hist
        self.optimal_transs_systemic = optimal_transs_systemic
        self.optimal_transs_local = optimal_transs_local
        self.wkg_prices_memory = wkg_prices_memory
        self.personal_turnover_ratio = personal_turnover_ratio
        self.basket_array_hist = basket_array_hist
        self.basket_array_start_hist = basket_array_start_hist
        self.total_actual_agent_sales = total_actual_agent_sales
        self.total_optimal_agent_sales = total_optimal_agent_sales
        self.cognition_factor = cognition_factor
        self.over_sell_counter = over_sell_counter
        self.didnt_over_sell_counter = didnt_over_sell_counter
        self.reached_tgt_on_move = 0
        self.last_transaction = 0
        self.wait_at_tgt_moves_pro_rata = wait_at_tgt_moves
        self.ignore_agents_array = []
        self.trade_movemnt = trade_movemnt
        self.number_of_children = 0
        self.resources_to_children = resources_to_children
        self.foraging_strat_data = foraging_strat_data
        self.hist_trade_loc_rec = hist_trade_loc_rec
        self.prop_steal = prop_steal
        self.prop_fight_back = prop_fight_back
        self.reputations_dict = reputations_dict
        self.fights_array = fights_array
        self.trades_array = []
        self.trans_known_about = []
        self.loc_fights_array = loc_fights_array
        self.loc_fights_array_cp = loc_fights_array_cp
        self.prop_steal_history = prop_steal_history
        self.prop_fight_back_history = prop_fight_back_history
        self.agreed_meeting_point = agreed_meeting_point
        self.meeting_point_cps = meeting_point_cps
        self.agent_last_traded_with = None  # this helps prevent agents trading repeatedly
        self.exp_returns_dict = dict()  # this records the expected returns each agent has if interacting with another agent
        self.previous_trgt = []
        self.exp_int_gains_dict = dict()
        self.exp_int_gains_dict_strangers = dict()
        self.last_intn = None
        self.tribe = tribe
        self.fight_skill = fight_skill
        self.fight_skill_history = fight_skill_history

        if fight_skill is not None:
            self.num_fights_today = 0

        self.black_shoop_file = None

        # useful data for updating black_shoop_file
        self.trans = []
        self.fights = []
        self.move_nums = []

        # create a dictionary which records the 6 expected outcomes in an interaction between 2 agents
        self.exp_rtns_matrix = dict()

        # create a dictionary to record expected returns for agent pairs
        self.expected_gains_dict = dict()

        self.parents = [None, None]

        self.agent_knows_cp_dict = dict()

        # create 2 dictionaries for last known reputations - for when agents don't have information in memory but they have had in the past
        self.last_known_rep_ps_dict = dict()
        self.last_known_rep_pfb_dict = dict()

        self.location_memories_dict = dict()

        self.need_to_update_reps = dict()
        self.latest_cps_dict = dict()

        # Neural network
        # if params.num_NNs == 1:
        #
        #     self.NN_parameters = initialize_parameters_deep(params.NN_dimensions, random_multiplier=params.NN_initial_random_multiplier, keep_random=0)
        #
        #     # print('\n self.NN_parameters: \n')
        #     # for item in self.NN_parameters:
        #     #     print('\n item', item, 'self.NN_parameters[item]', self.NN_parameters[item])
        #
        # elif params.num_NNs == 2:
        #
        #     params.NN_dimensions[-1] = 1
        #     params.NN_dimensions_ps[-1] = 1
        #     params.NN_dimensions_pfb[-1] = 1
        #
        #     if params.NN_inputs == 'game_6':
        #
        #         self.NN_parameters_ps = initialize_parameters_deep(params.NN_dimensions, random_multiplier=params.NN_initial_random_multiplier, keep_random=0)
        #         self.NN_parameters_pfb = initialize_parameters_deep(params.NN_dimensions, random_multiplier=params.NN_initial_random_multiplier, keep_random=0)
        #
        #     elif params.NN_inputs == 'mixed':
        #
        #         self.NN_parameters_ps = initialize_parameters_deep(params.NN_dimensions_ps, random_multiplier=params.NN_initial_random_multiplier, keep_random=0)
        #         self.NN_parameters_pfb = initialize_parameters_deep(params.NN_dimensions_pfb, random_multiplier=params.NN_initial_random_multiplier, keep_random=0)
        #
        # #     print('\n self.NN_parameters_ps: \n')
        # #     for item in self.NN_parameters_ps:
        # #         print('\n item', item, 'self.NN_parameters_ps[item]', self.NN_parameters_ps[item])
        # #
        # #     print('\n self.NN_parameters_pfb: \n')
        # #     for item in self.NN_parameters_pfb:
        # #         print('\n item', item, 'self.NN_parameters_pfb[item]', self.NN_parameters_pfb[item])
        # #
        # # pause()
        #
        # self.NN_caches = dict()

        self.params = params

        self.start_trgt_loc_rec = [[] for i in range(params.rounds)]

        self.total_cons = np.zeros(shape=2, dtype=float)           # records the agent's total consumption
        self.num_children = 0
        self.num_children_hist = np.zeros(shape=params.rounds, dtype=int)

        # for markets model habituation experiments:
        self.locations_weights_hist_dict = {}
        self.location_memories_habits_dict = {}

        # four databases that record contributions to the agents' prop_steal changes (reinforcement learning and habituation)
        self.ps_contr_RL_pos = np.zeros(shape=params.rounds, dtype=float)
        self.ps_contr_RL_neg = np.zeros(shape=params.rounds, dtype=float)
        self.ps_contr_hab_pos = np.zeros(shape=params.rounds, dtype=float)
        self.ps_contr_hab_neg = np.zeros(shape=params.rounds, dtype=float)

    def add_tracking_agent_data(self):

        """This method adds two variables to the tracking agent."""

        self.pre_basket_array = np.zeros(shape=(1, num_res_founts), dtype=int)
        self.pre_trading_basket = np.zeros(shape=(1, num_res_founts), dtype=int)

    def moves_randomly(self, print_fine_dets, town_grid):

        """This method moves the agent on the grid, both horizontally and vertically."""

        rand_move_vert = random.choice(np.arange(self.agent_vision * -1, (self.agent_vision * 1) + 1))

        if print_fine_dets == 1:
            print('rand_move_vert =', rand_move_vert)

        rand_move_hor = random.choice(np.arange(self.agent_vision * -1, (self.agent_vision * 1) + 1))

        if print_fine_dets == 1:
            print('rand_move_hor =', rand_move_hor)
            print('\npre agent.location[0] =', self.location[0])

        self.location[0] = (self.location[0] + rand_move_vert) % town_grid.dimen
        self.location[1] = (self.location[1] + rand_move_hor) % town_grid.dimen

        if print_fine_dets == 1:
            print('\npost agent.location =', self.location)

    def choose_new_loc(self, town_grid, print_dets, print_fine_dets, trade_movemnt, move, day, trade_when_trgt,
                       trade_moves, wait_at_tgt_moves, dbs, respect_property_rights, trade_at_trgt_precise):

        """This function selects for an individual agent a grid square to move to, which is nearest its target but not full."""

        # print_fine_dets = 1

        # if self.heads_home and self.location[0] == self.home[0] and self.location[1] == self.home[1]:
        # if random.random() < 0.001:
        #     print_fine_dets = 1

        if print_fine_dets == 1:
            print('\n move', move)
            print('\n self.can_trade =', self.can_trade)
            print('trade_movemnt =', trade_movemnt)
            print('self.trade_movemnt =', self.trade_movemnt)
            print('self.home', self.home)
            print('\n trade_moves', trade_moves)
            print(' wait_at_tgt_moves', wait_at_tgt_moves)
            print(' trade_moves - wait_at_tgt_moves', trade_moves - wait_at_tgt_moves)
            print(' trade_when_trgt =', trade_when_trgt)
            print(' self.grid_trgt =', self.grid_trgt)

            print('\n agent.home =', self.home)
            print('\n agent.trade_loc_rec =\n')
            for mo in np.arange(len(self.trade_loc_rec)):
                print(self.trade_loc_rec[mo])

            print(self.location, '<-- agent.location')
            print('\n agent.trgt_loc_rec =\n')

            for mo in np.arange(len(self.trgt_loc_rec)):
                print(self.trgt_loc_rec[mo])

            print(self.grid_trgt, '<-- agent.grid_trgt')

        if trade_movemnt == 'random' or self.trade_movemnt == 'random':

            if print_fine_dets == 1:
                print('\n Agent is moving randomly')
                print(' Old loc =', self.location)

            # create random movements:
            random_move_x = np.random.randint(-1 * self.agent_vision, self.agent_vision + 1)
            random_move_y = np.random.randint(-1 * self.agent_vision, self.agent_vision + 1)

            proposed_x = (self.location[0] + random_move_x) % town_grid.dimen
            proposed_y = (self.location[1] + random_move_y) % town_grid.dimen

            x_dist_to_home_x = math.fabs(proposed_x - self.home[0])
            x_dist_to_home_y = math.fabs(proposed_y - self.home[1])

            if x_dist_to_home_x > town_grid.dimen / 2.0:
                x_dist_to_home_x -= town_grid.dimen / 2.0

            if x_dist_to_home_y > town_grid.dimen / 2.0:
                x_dist_to_home_y -= town_grid.dimen / 2.0

            if print_fine_dets == 1:
                print('\n random_move_x', random_move_x)
                print(' random_move_y', random_move_y)
                print('x_dist_to_home_x =', x_dist_to_home_x)
                print('x_dist_to_home_y =', x_dist_to_home_y)
                print('propsed loc =', self.location[0] + random_move_x, self.location[1] + random_move_y)

            # only allow the agent to move randomly in each dimension if it is within travel bounds ((trade_moves - wait_at_tgt_moves))
            if x_dist_to_home_x <= (trade_moves - wait_at_tgt_moves):
                self.location[0] = proposed_x

            if x_dist_to_home_y <= (trade_moves - wait_at_tgt_moves):
                self.location[1] = proposed_y

            if print_fine_dets == 1:
                print('New loc =', self.location)

        elif trade_movemnt == 'set' and self.trade_movemnt == 'set':

            if trade_when_trgt == 1:

                #                self.location
                #                self.agent_vision
                #                self.grid_trgt

                x_dist = self.grid_trgt[0] - self.location[0]
                y_dist = self.grid_trgt[1] - self.location[1]

                if print_fine_dets == 1:
                    print('\n Start loc =', self.location)
                    print('self.grid_trgt =', self.grid_trgt)
                    print('self.agent_vision =', self.agent_vision)
                    print('start x_dist =', x_dist)
                    print('start y_dist =', y_dist)

                # x_dist correct distances given the grid is a torus so agents will travel shortest distance
                if x_dist >= (town_grid.dimen / 2.0):

                    x_dist = -1 * (town_grid.dimen - x_dist)

                elif x_dist < -1 * (town_grid.dimen / 2.0):

                    x_dist = town_grid.dimen + x_dist

                # Now the agents move an appropriate amount
                if x_dist >= self.agent_vision:

                    self.location[0] = (self.location[0] + self.agent_vision) % town_grid.dimen

                elif 0 < x_dist < self.agent_vision:

                    self.location[0] = (self.location[0] + x_dist) % town_grid.dimen

                elif x_dist <= -1 * self.agent_vision:

                    self.location[0] = (self.location[0] - self.agent_vision) % town_grid.dimen

                elif -1 * self.agent_vision < x_dist < 0:

                    self.location[0] = (self.location[0] - x_dist) % town_grid.dimen

                # y_dist: correct distances given the grid is a torus so agents will travel shortest distance
                if y_dist >= (town_grid.dimen / 2.0):

                    y_dist = -1 * (town_grid.dimen - y_dist)

                elif y_dist < -1 * (town_grid.dimen / 2.0):

                    y_dist = town_grid.dimen + y_dist

                # Now the agents move an appropriate amount
                if y_dist >= self.agent_vision:

                    self.location[1] = (self.location[1] + self.agent_vision) % town_grid.dimen

                elif 0 < y_dist < self.agent_vision:

                    self.location[1] = (self.location[1] + y_dist) % town_grid.dimen

                elif y_dist <= -1 * self.agent_vision:

                    self.location[1] = (self.location[1] - self.agent_vision) % town_grid.dimen

                elif -1 * self.agent_vision < y_dist < 0:

                    self.location[1] = (self.location[1] - y_dist) % town_grid.dimen

                if print_fine_dets == 1:
                    #                    print('\n end x_dist =', x_dist)
                    #                    print(' end y_dist =', y_dist)
                    print('\n Final loc =', self.location)

                # update x_dist and y_dist post-move
                x_dist_post_move = self.grid_trgt[0] - self.location[0]
                y_dist_post_move = self.grid_trgt[1] - self.location[1]

                # x_dist correct distances given the grid is a torus so agents will travel shortest distance
                if x_dist_post_move > (town_grid.dimen / 2.0):
                    x_dist_post_move = town_grid.dimen - x_dist_post_move

                if y_dist_post_move > (town_grid.dimen / 2.0):
                    y_dist_post_move = town_grid.dimen - y_dist_post_move

                if print_fine_dets == 1:
                    print('\n x_dist_post_move =', x_dist_post_move)
                    print(' y_dist_post_move =', y_dist_post_move)

                # if the agent respects property rights then it doesn't trade until it reaches its target
                if respect_property_rights == 1 and x_dist_post_move == 0 and y_dist_post_move == 0:

                    if print_fine_dets == 1:
                        print('\n setting can_trade = 1, reached_trgt = 1, reached_tgt_on_move =', move)

                    self.can_trade = 1
                    self.reached_trgt = 1
                    self.reached_tgt_on_move = move

                # agents can trade when they are next to the market when they do not respect property rights -
                # this prevents them going on to a location blindly and getting mugged: then they are 1 step away so they evaluate whether to go on it
                if respect_property_rights == 0 and self.heads_home == 0:

                    if trade_at_trgt_precise == 0 and np.abs(x_dist_post_move) <= 1 and np.abs(y_dist_post_move) <= 1:

                        if print_fine_dets == 1:
                            print(
                                '\n respect_property_rights == 0 and x_dist <= 1 and y_dist <= 1 so setting can_trade = 1, reached_trgt = 1, reached_tgt_on_move =',
                                move)

                        self.can_trade = 1
                        self.reached_trgt = 1
                        self.reached_tgt_on_move = copy.copy(move)

                    elif trade_at_trgt_precise == 1 and x_dist_post_move == 0 and y_dist_post_move == 0:

                        if print_fine_dets == 1:
                            print(
                                '\n trade_at_trgt_precise == 0 and x_dist_post_move == 0 and y_dist_post_move == 0 so setting can_trade = 1, reached_trgt = 1, reached_tgt_on_move =',
                                move)

                        self.can_trade = 1
                        self.reached_trgt = 1
                        self.reached_tgt_on_move = copy.copy(move)

            # in this situation, the agent has headed home and reached it - we take it off the board
            if self.params.agents_can_head_home and self.heads_home and self.location[0] == self.home[0] and self.location[1] == self.home[1]:

                if self not in dbs.agents_reached_home:

                    dbs.agents_reached_home.append(self)

                # print('\n day', day, 'move ', move, ': agent reached home and is now being ignored by the other agents')
                # print(' self.home =', self.home, 'self.basket_array_start', self.basket_array_start, 'self.basket_array', self.basket_array)
                # print(' dbs.agents_reached_home:', dbs.agents_reached_home)
                # print(' self.can_trade', self.can_trade)
                # print_fine_dets = 1

                # pause()

            # we only want to use this more complicated approach if the agents are trading on their way to the target
            elif trade_when_trgt == 0 and self.heads_home == 0:

                poss_locs_dimen = (self.agent_vision * 2) + 1

                if print_dets == 1:
                    print('\n*** starting choose_new_loc function ***')
                    print('\nagent.location =', self.location)
                    print('agent.grid_trgt =', self.grid_trgt)
                    print('\nposs_locs_dimen =', poss_locs_dimen)

                poss_locs_array = np.zeros(shape=(poss_locs_dimen, poss_locs_dimen), dtype=float)
                # e.g. if agent_vision = 3 then it can choose among a 7 x 7 grid.

                agent_tally_array = np.zeros(shape=(poss_locs_dimen, poss_locs_dimen), dtype=float)

                #        if print_fine_dets == 1:
                #            print '\ntown_grid.grid_agents:\n', town_grid.grid_agents

                for poss_locs_x_coord in np.arange(poss_locs_dimen):

                    grid_equiv_x = (poss_locs_x_coord + self.location[0] - self.agent_vision) % town_grid.dimen

                    x_dist = math.fabs(self.grid_trgt[0] - grid_equiv_x)

                    if x_dist > town_grid.dimen / 2.0:
                        x_dist = town_grid.dimen - x_dist

                    for poss_locs_y_coord in np.arange(poss_locs_dimen):

                        grid_equiv_y = (poss_locs_y_coord + self.location[1] - self.agent_vision) % town_grid.dimen

                        y_dist = math.fabs(self.grid_trgt[1] - grid_equiv_y)

                        if y_dist > town_grid.dimen / 2.0:
                            y_dist = town_grid.dimen - y_dist

                        #                if print_fine_dets == 1:
                        #                    print '\nposs_locs_x_coord =', poss_locs_x_coord
                        #                    print 'poss_locs_y_coord =', poss_locs_y_coord
                        #                    print 'grid_equiv_x =', grid_equiv_x
                        #                    print 'x_dist =', x_dist
                        #                    print 'grid_equiv_y =', grid_equiv_y
                        #                    print 'y_dist =', y_dist
                        #                    print 'town_grid.grid_agents[grid_equiv_x][grid_equiv_y] =', town_grid.grid_agents[grid_equiv_x][grid_equiv_y]
                        #                    print 'grid_equiv_x, grid_equiv_y', grid_equiv_x, grid_equiv_y, 'len =', len(town_grid.grid_agents[grid_equiv_x][grid_equiv_y])

                        # Here we set agent.can_trade = 1 if one of the agent's possible locations (full or not) is its grid_trgt
                        if x_dist == 0 and y_dist == 0:
                            self.can_trade = 1
                            self.reached_trgt = 1
                            self.reached_tgt_on_move = move

                            # we set ignore_agents_array to blank - agent can now trade with whomever
                            self.ignore_agents_array = []

                        # Now we work out how many moves to target from current location
                        moves_to_trgt = int(
                            math.ceil(np.max([np.fabs(x_dist), np.fabs(y_dist)]) / float(self.agent_vision)))

                        # For monitoring:
                        if len(town_grid.grid_agents[grid_equiv_x][grid_equiv_y]) > 0:
                            #                        print 'poss_locs_x_coord, poss_locs_y_coord', poss_locs_x_coord, poss_locs_y_coord, 'len =', len(town_grid.grid_agents[grid_equiv_x][grid_equiv_y])
                            agent_tally_array[poss_locs_x_coord][poss_locs_y_coord] = len(
                                town_grid.grid_agents[grid_equiv_x][grid_equiv_y])

                        # We have removed the agent from town_grid.grid_agents prior to running this function so we add 1 manually to agent_tally_array
                        if grid_equiv_x == self.location[0] and grid_equiv_y == self.location[1]:
                            agent_tally_array[poss_locs_x_coord][poss_locs_y_coord] += 1

                        poss_locs_array[poss_locs_x_coord][poss_locs_y_coord] = moves_to_trgt

                if print_dets == 1:
                    print('\nagent_tally_array:\n')
                    for array in agent_tally_array:
                        print(array)

                    print('\nposs_locs_array:\n')
                    for array in poss_locs_array:
                        print(array)

                # Now we need to find the minimum of poss_locs_array: this is the square we want to move on to.

                min_crow_dist = np.min(poss_locs_array)
                if print_dets == 1:
                    print('\nmin_crow_dist =', min_crow_dist, '\n')

                # Now find out which square(s) for which this is true
                # In case there is more than one, create an array to record all of the possible new locations

                new_locs_choices_array = []

                for x_coord in np.arange(poss_locs_dimen):
                    for y_coord in np.arange(poss_locs_dimen):

                        #                if print_fine_dets == 1:
                        #                    print 'x, y =', (x_coord + self.location[0] - self.agent_vision) % town_grid.dimen, ',', (y_coord + self.location[1] - self.agent_vision) % town_grid.dimen, '=', poss_locs_array[x_coord][y_coord]

                        if poss_locs_array[x_coord][y_coord] == min_crow_dist:

                            if print_dets == 1:
                                print('min_distance at [', x_coord, ',', y_coord, ']')

                            new_locs_choices_array.append(np.array(
                                [(x_coord + self.location[0] - self.agent_vision) % town_grid.dimen,
                                 (y_coord + self.location[1] - self.agent_vision) % town_grid.dimen]))

                        if poss_locs_array[x_coord][y_coord] == town_grid.dimen ** 2:

                            if print_dets == 1:
                                print('----> grid square', x_coord, y_coord, 'is full <----')

                if print_dets == 1:
                    print('\n new_locs_choices_array =', new_locs_choices_array)

                # There is a possibility (v minor with default parameters) that all of the potential new locations are full - if this is
                # the case the then agent remains in its current location

                # We will know all the squares are not full if this condition holds (if all full then all array values will be the same):
                if min_crow_dist != np.max(poss_locs_array):
                    # If this is true, we choose a location from new_locs_choices_array randomly
                    self.location = random.choice(new_locs_choices_array)

                if print_dets == 1:
                    print('\nagent.home =', self.home)
                    print('\nagent.trade_loc_rec =\n')
                    for mo in np.arange(len(self.trade_loc_rec)):
                        print(self.trade_loc_rec[mo])

                    print(self.location, '<-- agent.location')
                    print('\nagent.trgt_loc_rec =\n')

                    for mo in np.arange(len(self.trgt_loc_rec)):
                        print(self.trgt_loc_rec[mo])

                    print(self.grid_trgt, '<-- agent.grid_trgt')

        # if print_fine_dets:
        #     pause()

    #        if print_fine_dets == 1:
    #
    #            input("Press Enter to continue...")

    def update_agent_MRS_array(self, print_dets, print_fine_dets, agent_population):

        """This method updates the agent's MRS_array."""

        if print_dets == 1:
            print('\n\n\n*** starting update_agent_MRS_array ***')

        # First find the agents' total amounts of each resource
        self.aggr_res_array = self.agent_res_array + self.basket_array

        if print_fine_dets == 1:
            print('\n--> ag =', self)
            print('ag.agent_res_array =', self.agent_res_array)
            print('ag.basket_array =', self.basket_array)
            print('ag.aggr_res_array =', self.aggr_res_array)

        self.MRS_array = generate_MRS_array(self.aggr_res_array, print_fine_dets)

        if print_dets == 1:
            print('\nagent.MRS_array:\n', self.MRS_array)
            print('\n*** ENDING update_agent_MRS_array ***')

    def find_exp_returns_intn(self, params, pot_cp, agent_population, print_dets, price_mean, force_prices, fixed_price, day, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std, print_fine_dets, fight_balance,
                              adjust_props_r, agent_intn_beta, move, formal_inst, prob_fine, fine, simulated_int, fight_skill, fix_ps_fb_0, stranger_int, strat_choice, strangers_if_unknown):

        """This method calculates the expected gains from interaction given the agents' prop_steal and prop_fight_back; and each other's perception of those two values."""

        # print_fine_dets = 1

        if params.calc_timings:
            start_find_exp_rtnn_time = dt.datetime.now()

        if (params.track_agent and params.track_agent <= day) and (self == agent_population.tracking_agent or pot_cp == agent_population.tracking_agent):
            print_for_tracking = 1
            print('\n starting agent.find_exp_returns_intn (move = ', move, ')')
        else:
            print_for_tracking = 0

        # if str(pot_cp) in self.exp_int_gains_dict and (self.exp_int_gains_dict[str(pot_cp)][0] is not pot_cp.last_intn or self.exp_int_gains_dict[str(pot_cp)][1] is not self.last_intn):
        # if str(pot_cp) in self.exp_int_gains_dict and (self.exp_int_gains_dict[str(pot_cp)][0] is pot_cp.last_intn or self.exp_int_gains_dict[str(pot_cp)][1] is self.last_intn):
        # if simulated_int:
        #     print_dets = print_fine_dets = 1

        # print_fine_dets = 1

        if print_fine_dets:

            print('\n\n\n -------------------------- starting agent.find_exp_returns_intn (move = ', move, ') ----------------------------\n')

            if str(pot_cp) in self.exp_int_gains_dict:
                print('\n self.exp_int_gains_dict[str(pot_cp)] =', self.exp_int_gains_dict[str(pot_cp)])
            print(' pot_cp.last_intn', pot_cp.last_intn)
            print(' self.last_intn', self.last_intn)
            print(' simulated_int', simulated_int)
            print(' len_reputations_mem = ', len_reputations_mem)

        # we first use a short cut - if neither agent has interacted since the last time 'self' evaluated this pot_cp agent then we can use the previous evaluation's agent_total_exp_gain
        # and pot_cp_total_exp_gain (before any variation).  This means we don't process more code than we need to.  Note this does not mean, conceptually, that the agents are omniscient, it's
        # just a coding short cut.

        # we assume a new evaluation is required unless certain criteria met
        new_eval_requd = 1

        if str(pot_cp) in self.exp_int_gains_dict and simulated_int == 0:

            known_cp_int_data = self.exp_int_gains_dict[str(pot_cp)]

            # if this condition is true then neither the cp_agent nor the agent have interacted since the last time the agent evaluated the outcomes for cp_agent so we can use the previous evaluation
            if known_cp_int_data[0] == pot_cp.last_intn and known_cp_int_data[1] == self.last_intn:

                if print_fine_dets:
                    print('\n we are using a previous evaluation as a short cut')

                agent_total_exp_gain, pot_cp_total_exp_gain, cp_exp_cp_total_exp_gain = known_cp_int_data[2]

                if params.track_game_types:
                    des_string = known_cp_int_data[3]
                    classic_game_type = known_cp_int_data[4]

                    des_string_RCT = known_cp_int_data[5]
                    classic_game_type_RCT = known_cp_int_data[6]

                new_eval_requd = 0

        if new_eval_requd:

            if print_fine_dets:
                print('\n A new evaluation is required')

            # the first thing we do is to estimate the pot_cp's propensities to steal and fight back
            pot_cp_prop_steal, pot_cp_prop_fight_back, num_interactions = find_cp_props(params, self, pot_cp, day, len_reputations_mem, print_fine_dets)

            if print_fine_dets == 1:
                print('\n estimated pot_cp_prop_steal', pot_cp_prop_steal, '\t\t actual =', pot_cp.prop_steal)
                print(' estimated pot_cp_prop_fight_back', pot_cp_prop_fight_back, '\t actual =', pot_cp.prop_fight_back)

                print('\n agent.prop_steal =', self.prop_steal)
                print(' agent.prop_fight_back =', self.prop_fight_back)

            # we run a function, form_exps_rtns_props()
            agent_total_exp_gain, pot_cp_total_exp_gain, exp_rtns_matrix, pot_cp_exp_pot_cp_gain = \
                form_exps_rtns_props(params, self, pot_cp, pot_cp_prop_steal, pot_cp_prop_fight_back, agent_population, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, simulated_int, adjust_props_r,
                                     agent_intn_beta, fight_balance, fight_cost, formal_inst, prob_fine, fine, print_fine_dets, fight_skill, stranger_int, strat_choice, strangers_if_unknown)

            # update self.exp_int_gains_dict[str(pot_cp)] so we might shortcut later
            self.exp_int_gains_dict[str(pot_cp)] = [pot_cp.last_intn, self.last_intn, [agent_total_exp_gain, pot_cp_total_exp_gain, pot_cp_exp_pot_cp_gain]]

            # apply exp_rtns_matrix to agent's own self.exp_rtns_matrix - if this cp_agent is selected to interact with the agent, this matrix will be used to record what type of 'game' it is
            self.exp_rtns_matrix[str(pot_cp)] = exp_rtns_matrix

            # if we are recording game types:
            if simulated_int == 0 and params.track_game_types:

                self.exp_int_gains_dict[str(pot_cp)].append(exp_rtns_matrix[6])
                self.exp_int_gains_dict[str(pot_cp)].append(exp_rtns_matrix[7])
                self.exp_int_gains_dict[str(pot_cp)].append(exp_rtns_matrix[8])
                self.exp_int_gains_dict[str(pot_cp)].append(exp_rtns_matrix[9])

                des_string = exp_rtns_matrix[6]
                classic_game_type = exp_rtns_matrix[7]

                des_string_RCT = exp_rtns_matrix[8]
                classic_game_type_RCT = exp_rtns_matrix[9]

                # print('\n des_string:', des_string)
                # print(' classic_game_type:', classic_game_type)
                #
                # print('\n des_string_RCT:', des_string_RCT)
                # print(' classic_game_type_RCT:', classic_game_type_RCT)
                #
                # pause()

        # add to dictionaries if not simulating the interaction
        if simulated_int == 0 and params.track_game_types:

            if des_string not in dbs.games_type_considered_dict:

                dbs.games_type_considered_dict[des_string] = np.zeros(shape=dbs.num_rounds, dtype=int)

            dbs.games_type_considered_dict[des_string][day] += 1

            if classic_game_type not in dbs.classic_games_considered:

                dbs.classic_games_considered[classic_game_type] = np.zeros(shape=dbs.num_rounds, dtype=int)

            dbs.classic_games_considered[classic_game_type][day] += 1

            if des_string_RCT not in dbs.games_type_considered_dict_RCT:

                dbs.games_type_considered_dict_RCT[des_string_RCT] = np.zeros(shape=dbs.num_rounds, dtype=int)

            dbs.games_type_considered_dict_RCT[des_string_RCT][day] += 1

            if classic_game_type_RCT not in dbs.classic_games_considered_RCT:

                dbs.classic_games_considered_RCT[classic_game_type_RCT] = np.zeros(shape=dbs.num_rounds, dtype=int)

            dbs.classic_games_considered_RCT[classic_game_type_RCT][day] += 1

        if print_fine_dets == 1 and str(pot_cp) in self.exp_int_gains_dict:
            print('\n New Evaluation: self.exp_int_gains_dict[str(pot_cp)] =', self.exp_int_gains_dict[str(pot_cp)], '\n')

        if print_fine_dets:
            print('\n self.exp_rtns_matrix[str(pot_cp)]', self.exp_rtns_matrix[str(pot_cp)])

        # Now we add an error value to the expected gains / losses
        # if we are testing code or printing code then we do this long hand; otherwise, go straight for shorthand
        if params.run_code_tests or print_fine_dets:

            ag_gain_no_error = copy.copy(agent_total_exp_gain)
            cp_gain_no_error = copy.copy(pot_cp_total_exp_gain)

            if np.sum(pot_cp.basket_array) > 0:

                agent_intn_error = random.normalvariate(0, intn_error_std)
                pot_cp_intn_error = random.normalvariate(0, intn_error_std)

            else:

                agent_intn_error = 0.0
                pot_cp_intn_error = 0.0

            agent_total_exp_gain += agent_intn_error
            pot_cp_total_exp_gain += pot_cp_intn_error

            if print_fine_dets:

                print('\n agent_intn_error %4.3f' % agent_intn_error, 'ag_gain_no_error %4.3f => post-error %4.3f ' % (ag_gain_no_error, agent_total_exp_gain))
                print(' pot_cp_intn_error %4.3f' % pot_cp_intn_error, 'cp_gain_no_error %4.3f => post-error %4.3f ' % (cp_gain_no_error, pot_cp_total_exp_gain))

        else:

            if np.sum(pot_cp.basket_array) > 0:

                agent_total_exp_gain += random.normalvariate(0, intn_error_std)
                pot_cp_total_exp_gain += random.normalvariate(0, intn_error_std)

        if print_fine_dets:

            print('\n self.agent_res_array', self.agent_res_array, 'pot_cp.agent_res_array', pot_cp.agent_res_array)
            print(' self.basket_array', self.basket_array, '\t\t\t\t\tpot_cp.basket_array', pot_cp.basket_array, '\n')

            # pause()

        if params.run_code_tests:

            # a test to ensure code working ok - this test the returns matrix, specifically the values regarding acquiescing
            if (simulated_int and agent_basket_array[0][0] > 0.0 and agent_basket_array[0][1] > 0.0 and self.exp_rtns_matrix[str(pot_cp)][2][0] == 0.0) or\
                (simulated_int == 0 and self.basket_array[0][0] > 0.0 and self.basket_array[0][1] > 0.0 and self.exp_rtns_matrix[str(pot_cp)][2][0] == 0.0):

                print('\n ok euston we have a problem... in Agent.find_exp_returns_intn method')
                print('\n agent_basket_array =', agent_basket_array)
                print('\n cp_agent_basket_array =', cp_agent_basket_array)
                print('\n self.exp_rtns_matrix[str(pot_cp)] =', self.exp_rtns_matrix[str(pot_cp)])
                print('\n self.exp_int_gains_dict[str(pot_cp)] =', self.exp_int_gains_dict[str(pot_cp)])
                pause()

            # Another test of the code
            if (simulated_int == 0 and (pot_cp.basket_array[0][0] == 0 and pot_cp.basket_array[0][1] == 0) and (self.basket_array[0][0] > 0 or self.basket_array[0][1] > 0)) or \
                    (simulated_int and (cp_agent_basket_array[0][0] == 0 and cp_agent_basket_array[0][1] == 0) and (agent_basket_array[0][0] > 0 or agent_basket_array[0][1] > 0)):

                if ag_gain_no_error > 0 and cp_gain_no_error < 0:

                    print('\n BIIIIG PROBLEM in find_exp_returns_intn - day ', day, 'move', move)
                    print('\n self.home', self.home, 'self.basket_array', self.basket_array)
                    print('\n pot_cp.home', pot_cp.home, 'pot_cp.basket_array', pot_cp.basket_array)
                    print('\n agent_total_exp_gain', agent_total_exp_gain)
                    print(' pot_cp_total_exp_gain', pot_cp_total_exp_gain)
                    print(' new_eval_requd', new_eval_requd)
                    print(' simulated_int', simulated_int)
                    print(' ag_gain_no_error', ag_gain_no_error)
                    print(' cp_gain_no_error', cp_gain_no_error)

                    print('\n New Evaluation: self.exp_int_gains_dict[str(pot_cp)] =', self.exp_int_gains_dict[str(pot_cp)],
                          '\n')

                    print('\n self.exp_rtns_matrix[str(pot_cp)] =', self.exp_rtns_matrix[str(pot_cp)])

                    pause()

        if (print_for_tracking and simulated_int) or (len_reputations_mem == 0 and new_eval_requd and pot_cp_prop_steal != 0.5):
            print('\n end of find_exp_returns_intn \n')
            pause()

        if params.calc_timings:
            dbs.timings_dict['trading_move_agent_bilat_eval'][day] += dt.datetime.now() - start_find_exp_rtnn_time

        return agent_total_exp_gain, pot_cp_total_exp_gain

    def evaluate_exp_rtns_all_grid_sqs(self, params, town_grid, own_loc_exp_rtn, exp_cp_returns_array, agent_population,
                                       print_dets, price_mean, force_prices, fixed_price,
                                       day, move, dbs, fountain_population, fight_cost, len_reputations_mem,
                                       intn_error_std, print_fine_dets, agent_avoid_muggers, fight_balance,
                                       adjust_props_r, agent_intn_beta, two_tribes, formal_inst, prob_fine, fine,
                                       fight_skill, fix_ps_fb_0, two_tribes_inst, strat_choice,
                                       stranger_int, strangers_if_unknown, respect_property_rights, trade_when_trgt,
                                       track_agent):

        """This method looks at all the grid squares around the agent and evaluates the expected return from interacting with any of the agents, and provides a mean expected
        return for each of the grid squares"""

        no_neighs = 0
        tracking_agent_here = 0

        if (params.track_agent and params.track_agent <= day) and agent_population.tracking_agent == self:
            print_fine_dets = 1

        # if day > -1:
        #     print_fine_dets = 1

        # if len(town_grid.grid_agents[self.location[0]][self.location[1]]) == 2:
        #     print_fine_dets = 1

        # if self.grid_trgt[0] is not None:
        #     print_fine_dets = 1

        # if track_agent is not None:
        #
        #     for i in [-1, 0, 1]:
        #
        #         for j in [-1, 0, 1]:
        #
        #             x_coord = (self.location[0] + i) % town_grid.dimen
        #             y_coord = (self.location[1] + j) % town_grid.dimen
        #
        #             if i == 0 and j == 0 and len(town_grid.grid_agents[x_coord][y_coord]) > 1:
        #
        #                 for ag in town_grid.grid_agents[x_coord][y_coord]:
        #                     if ag not in agent_population.tracking_agent.ignore_agents_array:
        #
        #                         no_neighs += 1
        #
        #             if (i == 0 and j == 0) == False and len(town_grid.grid_agents[x_coord][y_coord]) > 0:
        #
        #                 for ag in town_grid.grid_agents[x_coord][y_coord]:
        #                     if ag not in agent_population.tracking_agent.ignore_agents_array:
        #
        #                         no_neighs += 1
        #
        #             if agent_population.tracking_agent in town_grid.grid_agents[x_coord][y_coord]:
        #                 tracking_agent_here = 1
        #
        #             if self is not agent_population.tracking_agent and agent_population.tracking_agent in \
        #                     town_grid.grid_agents[x_coord][y_coord]:
        #                 print('\n evaluate_exp_rtns_all_grid_sqs: our tracking agent is in the vicinity of another agent')
        #
        #     if no_neighs >= 1 and tracking_agent_here:
        #
        #         print_fine_dets = 1

        if (params.track_agent and params.track_agent <= day) and self == agent_population.tracking_agent:
            print_for_tracking = 1
        else:
            print_for_tracking = 0

        if print_fine_dets or print_for_tracking:
            print('\n\n **** Starting evaluate_exp_rtns_all_grid_sqs (day = %d, move = %d)' % (day, move))

        # we quickly look to see if the agent has any neighbours in neighbouring squares - if not, we ignore most of the code below and set head_to_target = 1
        tot_neighs_adj_squares = 0
        for i in range(-1, 2):
            for j in range(-1, 2):
                if (i == 0 and j == 0) is False:
                    x_coord = (self.location[0] + i) % town_grid.dimen
                    y_coord = (self.location[1] + j) % town_grid.dimen

                    tot_neighs_adj_squares += len(town_grid.grid_agents[x_coord][y_coord])

        # if len(town_grid.grid_agents[self.location[0]][self.location[1]]) >= 0 and tot_neighs_adj_squares > 1:
        #     print_fine_dets = 1

        if print_fine_dets:

            print('\n tot_neighs_adj_squares = ', tot_neighs_adj_squares)
            print('\n self.grid_trgt :', self.grid_trgt)
            print('\n agent.trade_loc_rec =\n')
            print(self.home, '<-- agent.home')
            for mo in np.arange(len(self.trade_loc_rec)):
                print('end of move', mo, '\t', self.trade_loc_rec[mo])

            print(self.location, '<-- self.location')

            print('\n   self.basket_array', self.basket_array)
            print('  self.agent_res_array', self.agent_res_array)

            print('\n Looking around to see who is in vicinity:')

            for i in range(-1, 2):

                for j in range(-1, 2):

                    x_coord = (self.location[0] + i) % town_grid.dimen
                    y_coord = (self.location[1] + j) % town_grid.dimen

                    if len(town_grid.grid_agents[x_coord][y_coord]) > 0:

                        print('\n grid loc', x_coord, y_coord, 'i', i, 'j', j,
                              'len(town_grid.grid_agents[x_coord][y_coord]) ',
                              len(town_grid.grid_agents[x_coord][y_coord]))

                        for ag in town_grid.grid_agents[x_coord][y_coord]:

                            if ag is not self:

                                print('\n   ag.basket_array', ag.basket_array)
                                print(' ag.agent_res_array', ag.agent_res_array)

                                print('\n ag.trade_loc_rec =\n')
                                print(ag.home, '<-- ag.home')
                                for mo in np.arange(len(ag.trade_loc_rec)):
                                    print('end of move', mo, '\t', ag.trade_loc_rec[mo])

                                print(ag.location, '<-- ag.location')

            print('\n ----------- \n')

            #                        no_neighs = 1

            # if no_neighs:
            #     pause()

        # this contains the str(location)s of each of the 9 grid squares and their corresponding mean expected return for the agent
        agent_exp_mean_returns_dict = {}
        # similar, for cps
        cps_exp_mean_returns_dict = {}

        neigh_exp_returns_array = np.zeros(shape=(3, 3))

        # and own expected return at current square
        neigh_exp_returns_array[1][1] = own_loc_exp_rtn

        agent_exp_mean_returns_dict[str(self.location)] = float(own_loc_exp_rtn)

        line = [[] for i in range(3)]
        neigh_cp_exp_returns_array = [copy.deepcopy(line) for j in range(3)]

        # place own square cp_returns in neigh_cp_exp_returns_array
        neigh_cp_exp_returns_array[1][1] = exp_cp_returns_array

        if len(exp_cp_returns_array) > 0:
            cps_exp_mean_returns_dict[str(self.location)] = np.mean(exp_cp_returns_array)
        else:
            cps_exp_mean_returns_dict[str(self.location)] = 0.0

        if print_fine_dets == 1:
            print('\n self.home', self.home)
            print(' self.location', self.location)
            #            print('\n neigh_exp_returns_array\n\n', neigh_exp_returns_array)
            print(' own_loc_exp_rtn', own_loc_exp_rtn)
            print(' exp_cp_returns_array', exp_cp_returns_array)
            print(' self.ignore_agents_array:', self.ignore_agents_array)
            print(' strangers_if_unknown', strangers_if_unknown, '\n')

        # these values default to the current location
        max_mean_exp_return = own_loc_exp_rtn
        max_grid_square = copy.copy(self.location)

        # we start with number of neighbours equal to the number of pot_cps on current square
        number_neighbours = len(neigh_cp_exp_returns_array[1][1])

        # we have to record the squares where there are no agents and the expected return is zero - if the max_mean_exp_return ends up as zero then we choose one of these randomly
        squares_w_zero_exp_rtn = []

        if tot_neighs_adj_squares == 0:

            if self.grid_trgt[0] is None:       # agent moving randomly

                x_move = random.choice([-1, 0, 1])
                y_move = random.choice([-1, 0, 1])

                town_grid.max_grid_square[0] = (self.location[0] + x_move) % town_grid.dimen
                town_grid.max_grid_square[1] = (self.location[1] + y_move) % town_grid.dimen

                head_to_target = 0

            else:

                head_to_target = 1

        elif tot_neighs_adj_squares > 0:

            head_to_target = 0

            for i in [-1, 0, 1]:

                for j in [-1, 0, 1]:

                    if (i == 0 and j == 0) is False:

                        x_coord = (self.location[0] + i) % town_grid.dimen
                        y_coord = (self.location[1] + j) % town_grid.dimen

                        # if len(town_grid.grid_agents[x_coord][y_coord]) > 5:
                        #     print_fine_dets = 1

                        if print_fine_dets == 1:
                            print('\n i ', i, 'j ', j)
                            print(' x_coord', x_coord, 'y_coord', y_coord)

                        # agents_on_squ = copy.copy(town_grid.grid_agents[x_coord][y_coord])
                        agent_list = []

                        # start with iter of zero - this will help iterate through agents on square
                        iter = 0
                        # one condition for ending while loop is finished_iter = 1 (last agent)
                        finished_iter = 0

                        if len(town_grid.grid_agents[x_coord][y_coord]) > 0:

                            # we create a while loop which works whether params.limit_agent_interaction is positive or None.  If positive, the while loop continues until the number of selected agents equals the limit; and
                            # if None, agents are selected based on the criteria below - there is no limit
                            while (params.limit_agent_interaction and len(agent_list) < params.limit_agent_interaction and finished_iter == 0) or \
                                  (params.limit_agent_interaction == None and finished_iter == 0):

                                pot_cp = town_grid.grid_agents[x_coord][y_coord][iter]

                                if print_fine_dets:
                                    print('\n iter =', iter)
                                    print(' pot_cp: ', pot_cp)

                                accept_agent = 1

                                if respect_property_rights and pot_cp.can_trade == 0:
                                    accept_agent = 0

                                    if print_fine_dets:
                                        print('\n respect_property_rights == 1 and pot_cp.can_trade == 0')

                                elif self.agent_last_traded_with is pot_cp and pot_cp.agent_last_traded_with is self:
                                    accept_agent = 0

                                    if print_fine_dets:
                                        print('\n agent.agent_last_traded_with is pot_cp and pot_cp.agent_last_traded_with is agent')

                                elif any(res < 0.0 for res in pot_cp.agent_res_array[0]):
                                    accept_agent = 0

                                    if print_fine_dets:
                                        print('\n any(res < 0.0 for res in pot_cp.agent_res_array[0])')

                                elif trade_when_trgt == 0 and self.reached_trgt == 0 and pot_cp in self.ignore_agents_array:
                                    accept_agent = 0

                                    if print_fine_dets:
                                        print('\n trade_when_trgt == 0 and agent.reached_trgt == 0 and pot_cp in agent.ignore_agents_array')

                                elif two_tribes and agent_population.ignore_strangers and pot_cp.tribe != agent.tribe:
                                    accept_agent = 0

                                    if print_fine_dets:
                                        print('\n two_tribes == 1 and agent_population.ignore_strangers == 1 and pot_cp.tribe != agent.tribe')

                                elif pot_cp in dbs.agents_reached_home:
                                    accept_agent = 0

                                    if print_fine_dets:
                                        print('\n pot_cp went back home')

                                # if none of the above conditions are true, add pot_cp to agent_crop_list
                                if accept_agent == 1:
                                    agent_list.append(pot_cp)

                                    if print_fine_dets:
                                        print('\n agent passed all tests - added to agent_crop_list')

                                # add 1 to iter
                                if iter < len(town_grid.grid_agents[x_coord][y_coord]) - 1:
                                    iter += 1

                                # unless we have come to the end of the iterations
                                else:
                                    finished_iter = 1
                                    if print_fine_dets:
                                        print('\n this was the last iteration')

                            if print_fine_dets:
                                print('\n END agent_list:', agent_list)
                                # pause()
                                # print_fine_dets = 0

                        exp_returns_array = []
                        exp_returns_array_cps = []

                        for pot_cp in agent_list:

                            number_neighbours += 1

                            if print_fine_dets:
                                print('\n strat_choice', strat_choice)
                                print(' strangers_if_unknown', strangers_if_unknown)
                                print(' self.agent_knows_cp_dict[str(pot_cp)]', self.agent_knows_cp_dict[str(pot_cp)])
                                print(' pot_cp.agent_knows_cp_dict[str(self)]', pot_cp.agent_knows_cp_dict[str(self)])

                            if self.tribe == pot_cp.tribe and strat_choice == 'propensities' and (
                                    strangers_if_unknown == 0 or (
                                    strangers_if_unknown and self.agent_knows_cp_dict[str(pot_cp)] and
                                    pot_cp.agent_knows_cp_dict[str(self)])):

                                # print_fine_dets = 0
                                agent_exp_rtn, pot_cp_exp_rtn = self.find_exp_returns_intn(params, pot_cp, agent_population,
                                                                                           print_dets, price_mean,
                                                                                           force_prices, fixed_price, day,
                                                                                           dbs, fountain_population,
                                                                                           fight_cost, len_reputations_mem,
                                                                                           intn_error_std, print_fine_dets,
                                                                                           fight_balance, adjust_props_r,
                                                                                           agent_intn_beta,
                                                                                           move, formal_inst, prob_fine,
                                                                                           fine, simulated_int=0,
                                                                                           fight_skill=fight_skill,
                                                                                           fix_ps_fb_0=fix_ps_fb_0,
                                                                                           stranger_int=stranger_int,
                                                                                           strat_choice=strat_choice,
                                                                                           strangers_if_unknown=strangers_if_unknown)

                                exp_returns_array.append(agent_exp_rtn)
                                exp_returns_array_cps.append(pot_cp_exp_rtn)
                                neigh_cp_exp_returns_array[i + 1][j + 1].append(pot_cp_exp_rtn)
                            #                            if no_neighs:
                            #                                print_fine_dets = 1

                            # if they are strangers
                            elif (agent_population.ignore_strangers == 0 and self.tribe != pot_cp.tribe) or \
                                  strat_choice == 'rational' or \
                                  strat_choice == 'propensities' and strangers_if_unknown and (self.agent_knows_cp_dict[str(pot_cp)] == 0 or pot_cp.agent_knows_cp_dict[str(self)] == 0):

                                use_start_basket = 0
                                agent_dec, cp_agent_dec, agent_exp_rtn, pot_cp_exp_rtn = strangers_interact(
                                    params, agent_population.min_trans_Q, price_mean,
                                    force_prices, fixed_price, day, dbs, agent_population, fountain_population,
                                    print_dets, print_fine_dets, use_start_basket, self, pot_cp,
                                    agent_population.stranger_int, formal_inst, prob_fine, fine, two_tribes_inst,
                                    fight_cost)

                                # we only include them is there is a clear dominant strategy from both
                                if agent_dec != 'none' and cp_agent_dec != 'none':
                                    exp_returns_array.append(agent_exp_rtn)
                                    neigh_cp_exp_returns_array[i + 1][j + 1].append(pot_cp_exp_rtn)

                            else:

                                print(
                                    '\n PROBLEM in agent.evaluate_exp_rtns_all_grid_sqs - neither condition held above but one of them must')
                                print_fine_dets = 1

                            #                        pause()

                            if print_fine_dets == 1:
                                print('\n agent.prop_steal', self.prop_steal, 'self.prop_fight_back', self.prop_fight_back)
                                print(' agent.agent_res_array', self.agent_res_array[0])
                                print(' agent.basket_array', self.basket_array[0])
                                print(' agent.tribe', self.tribe)

                                print('\n pot_cp.home', pot_cp.home, 'pot_cp.prop_steal', pot_cp.prop_steal,
                                      'pot_cp.prop_fight_back', pot_cp.prop_fight_back)
                                print(' pot_cp.agent_res_array', pot_cp.agent_res_array[0])
                                print(' pot_cp.basket_array', pot_cp.basket_array[0])
                                print(' pot_cp.tribe', pot_cp.tribe)

                                print('\n pot_cp', pot_cp, 'agent_exp_rtn', agent_exp_rtn, 'pot_cp_exp_rtn', pot_cp_exp_rtn)

                        if print_fine_dets:
                            print(' exp_returns_array', exp_returns_array)

                        if len(exp_returns_array) > 0:

                            mean_exp_return = np.mean(exp_returns_array)

                            agent_exp_mean_returns_dict[str(np.array([x_coord, y_coord], dtype=int))] = mean_exp_return

                            # if this is true, we definitely don't want to head back to target (assuming agent isn't wondering around randomly)
                            if mean_exp_return > 0.0:
                                head_to_target = 0

                        elif len(exp_returns_array) == 0:

                            mean_exp_return = 0
                            agent_exp_mean_returns_dict[str(np.array([x_coord, y_coord], dtype=int))] = 0.0

                        if mean_exp_return == 0:
                            squares_w_zero_exp_rtn.append(np.array([x_coord, y_coord], dtype=int))

                        if mean_exp_return != 0 and print_fine_dets == 1:
                            print(' mean_exp_return', mean_exp_return)

                        if mean_exp_return > max_mean_exp_return:

                            max_mean_exp_return = mean_exp_return
                            max_grid_square = np.array([x_coord, y_coord], dtype=int)

                            if print_fine_dets == 1:
                                print('\n max_mean_exp_return', max_mean_exp_return)
                                print(' max_grid_square', max_grid_square)

                        if len(exp_returns_array_cps) > 0:

                            mean_exp_return_cps = np.mean(exp_returns_array_cps)

                        else:

                            mean_exp_return_cps = 0.0

                        cps_exp_mean_returns_dict[str(np.array([x_coord, y_coord], dtype=int))] = mean_exp_return_cps

                        neigh_exp_returns_array[i + 1][j + 1] = mean_exp_return

            # Now we enter the next stage of this function.  We have so far checked all the surrounding squares and evaluated all the agents in those squares.  The question is: where would the agent prefer to move to?
            # We have formed dictionaries of agent_exp_mean_returns_dict and cps_exp_mean_returns_dict, which contain most of the data we want; and we have max_mean_exp_return

            # The structure we follow is relatively simple:
            # (1) find the squares with expected returns == max_mean_exp_return: if there is only one, go to that square; if more than one, go to next step... (typically there wil be 2 scenarios - one where there
            # is only one square with this value (> 0); and another where there are several squares with their value == 0);
            # (2) for all the squares with values == max_mean_exp_return, remove those with an expected mean exp cp return of > 0.  We assume this would mean the agent would expect some possibility of being mugged -
            # an issue here is whether this means we'd avoid trading with agents who would show a small positive exp return, however, it is likely this would be matched with the agent having a positive return ie we'd
            # pick this up in the first state;
            # (3) if there are still a number of candidate squares (typically the agent's exp return is zero and cp exp return is zero), the agent will move further away from squares with positive exp cp returns, to
            # minimize the chances of being mugged (to do this we find the total cp exp return (if >0) for the adjacent squares and choose the square with the lowest total value).  If there is more than one...
            # (4) if the agent is targetting a square, find out which of the remaining squares is closest to the target and move there (if more than one, choose randomly); or if the agent is moving randomly, choose
            # from the remaining squares randomly.

            # start with deleting from both main dicts any squares with returns not equal to the max return (i.e., all those less than)
            # we might need a copy of this below
            cps_exp_mean_returns_dict_copy = copy.copy(cps_exp_mean_returns_dict)

            if print_fine_dets:

                print('\n max_mean_exp_return =', max_mean_exp_return)

                print('\n agent_exp_mean_returns_dict[item] (start selection pricess):\n')
                for item in agent_exp_mean_returns_dict:
                    if print_fine_dets:
                        print(' item =', item, 'value', agent_exp_mean_returns_dict[item])

                print('\n cps_exp_mean_returns_dict[item] (start selection pricess):\n')
                for item in cps_exp_mean_returns_dict:
                    if print_fine_dets:
                        print(' item =', item, 'value', cps_exp_mean_returns_dict[item])

            # (1) remove items from dictionary if value <= max_mean_exp_return so we are left with items where value == max_mean_exp_return
            # to max speed of cropping dictionaries, we take one of 1 of 2 approaches, depending on whether max_mean_exp_return <= 0.0 (likely to remove 1 item) or max_mean_exp_return > 0.0 (likely to remove 8 items)
            if max_mean_exp_return <= 0.0:

                to_be_removed = []
                for item in agent_exp_mean_returns_dict:

                    if agent_exp_mean_returns_dict[item] != max_mean_exp_return:
                        to_be_removed.append(item)

                for item in to_be_removed:
                    del agent_exp_mean_returns_dict[item]
                    del cps_exp_mean_returns_dict[item]

            elif max_mean_exp_return > 0.0:

                agent_exp_mean_returns_dict_cropped = {}
                cps_exp_mean_returns_dict_cropped = {}

                for item in agent_exp_mean_returns_dict:

                    if agent_exp_mean_returns_dict[item] == max_mean_exp_return:
                        agent_exp_mean_returns_dict_cropped[item] = agent_exp_mean_returns_dict[item]
                        cps_exp_mean_returns_dict_cropped[item] = cps_exp_mean_returns_dict[item]

                # now associate label with these dictionaries
                agent_exp_mean_returns_dict = agent_exp_mean_returns_dict_cropped
                cps_exp_mean_returns_dict = cps_exp_mean_returns_dict_cropped

            if print_fine_dets:
                print('\n agent_exp_mean_returns_dict (end of selection process):\n')
                for item in agent_exp_mean_returns_dict:
                    if print_fine_dets:
                        print(' item =', item, 'value', agent_exp_mean_returns_dict[item])

                print('\n cps_exp_mean_returns_dict (end of selection process):\n')
                for item in cps_exp_mean_returns_dict:
                    if print_fine_dets:
                        print(' item =', item, 'value', cps_exp_mean_returns_dict[item])

                print('\n len(agent_exp_mean_returns_dict) =', len(agent_exp_mean_returns_dict))

            # agent_exp_mean_returns_dict[item] now only has locations with the maximum mean expected return
            if len(agent_exp_mean_returns_dict) == 1:           # then we simple head to this one location

                if print_fine_dets:
                    print('\n agent_exp_mean_returns_dict.keys()', agent_exp_mean_returns_dict.keys())
                max_grid_square_str = list(agent_exp_mean_returns_dict.keys())[0]

                # convert string to list
                exec('town_grid.max_grid_square[0] = %s' % max_grid_square_str[1:3])
                exec('town_grid.max_grid_square[1] = %s' % max_grid_square_str[-3:-1])

            # In this situation, there is more than one square with value == max_mean_exp_return - step (2) avoid any locations with a positive mean expected cp return
            elif len(agent_exp_mean_returns_dict) > 1:          # then we need to decide which of these squares to move toward

                # need to remove any locations with mean exp cp return > 0
                min_items_array = []

                if print_fine_dets:
                    print('\n cps_exp_mean_returns_dict (cropped):\n')

                for item in cps_exp_mean_returns_dict:
                    if print_fine_dets:
                        print(' item ', item, 'value =', cps_exp_mean_returns_dict[item])
                    if cps_exp_mean_returns_dict[item] <= 0.0:
                        min_items_array.append(item)
                    # elif cps_exp_mean_returns_dict[item] < min_mean_exp_cp_rtn:
                    #     min_items_array = [item]
                    #     min_mean_exp_cp_rtn = cps_exp_mean_returns_dict[item]

                if print_fine_dets:
                    # print('\n min_mean_exp_cp_rtn =', min_mean_exp_cp_rtn)
                    print(' min_items_array:', min_items_array)
                    print(' len(min_items_array):', len(min_items_array))

                # again, if there is only one location left in this process, we select this, otherwise continue to stage (3)
                if len(min_items_array) == 1:
                    # convert string to list
                    # exec('town_grid.max_grid_square = %s' % min_items_array[0])

                    exec('town_grid.max_grid_square[0] = %s' % min_items_array[0][1:3])
                    exec('town_grid.max_grid_square[1] = %s' % min_items_array[0][-3:-1])

                # here there are multiple candidate locations we move to the least-bad square vis-a-vis mean exp cp returns are concerned
                elif len(min_items_array) > 1:

                    if print_fine_dets:
                        print('\n self.grid_trgt =', self.grid_trgt)

                    # shuffling this ensures the resulting selection of a square with highest value of max_value_aggr_exp_cp_rtns is random if there's more than one square
                    random.shuffle(min_items_array)

                    if print_fine_dets:
                        print('\n shuffled min_items_array =', min_items_array)
                        print('\n cps_exp_mean_returns_dict_copy :', cps_exp_mean_returns_dict_copy)
                        print('\n dodgy square values:\n')

                    # create a variable to record highest value for all candidate squares
                    min_value_aggr_exp_cp_rtns = 100.0
                    best_squares = []

                    for item in min_items_array:

                        # convert string to list
                        exec('town_grid.item_loc[0] = %s' % item[1:3])
                        exec('town_grid.item_loc[1] = %s' % item[-3:-1])

                        if print_fine_dets:
                            print('\n town_grid.item_loc:', town_grid.item_loc, '\n')

                        # create aggregator
                        tot_cp_exp_value = 0.0
                        for i in [-1, 0, 1]:
                            for j in [-1, 0, 1]:

                                test_square = np.array([(town_grid.item_loc[0] + i) % town_grid.dimen, (town_grid.item_loc[1] + j) % town_grid.dimen], dtype=int)

                                if print_fine_dets:
                                    print(' i', i, 'j', j, 'test_square', test_square)

                                if str(test_square) in cps_exp_mean_returns_dict_copy and cps_exp_mean_returns_dict_copy[str(test_square)] >= 0:

                                    tot_cp_exp_value += cps_exp_mean_returns_dict_copy[str(test_square)]

                                    if print_fine_dets:
                                        print(' str(test_square) in cps_exp_mean_returns_dict_copy: cps_exp_mean_returns_dict_copy[str(test_square)] is', cps_exp_mean_returns_dict_copy[str(test_square)])

                        if print_fine_dets:
                            print(' resulting tot_cp_exp_value =', tot_cp_exp_value)

                        # if this is the lowest total value square so far, we reset both min_value_aggr_exp_cp_rtns and best_squares
                        if tot_cp_exp_value < min_value_aggr_exp_cp_rtns:

                            min_value_aggr_exp_cp_rtns = tot_cp_exp_value
                            best_squares = [copy.copy(town_grid.item_loc)]

                            if print_fine_dets:
                                print('\n tot_cp_exp_value < min_value_aggr_exp_cp_rtns')
                                print(' best_squares =', best_squares)

                        # otherwise, if it's the same as the lowest value square, append best_squares (ignore if tot_cp_exp_value > min_value_aggr_exp_cp_rtns)
                        elif tot_cp_exp_value == min_value_aggr_exp_cp_rtns:

                            best_squares.append(copy.copy(town_grid.item_loc))

                            if print_fine_dets:
                                print('\n tot_cp_exp_value == min_value_aggr_exp_cp_rtns')
                                print(' best_squares =', best_squares)

                    # there is a chance that min_value_aggr_exp_cp_rtns hasn't changed - this would be a problem with the code so check here and pause if it's seen
                    if min_value_aggr_exp_cp_rtns == 100.0:

                        best_square = random.choice(min_items_array)

                        if print_fine_dets:
                            print('\n PROBLEM: NO target - best_square =', best_square)

                        exec('town_grid.max_grid_square[0] = %s' % best_square[1:3])
                        exec('town_grid.max_grid_square[1] = %s' % best_square[-3:-1])
                        pause()

                    # by this point we have completed stage 3 - we have found the least bad squares to move towards.  If there's only one, choose that, otherwise, move to next step (stage 4):
                    if len(best_squares) == 1:
                        town_grid.max_grid_square = best_squares[0]

                    # (4) if len(best_squares) > 1, what we now do depends on whether the agent has a target or not.  If so: move toward the target location given best_squares; if not, choose a square randomly
                    # if the agent has a target location then we choose the square closest to the target; if moving randomly, we account for
                    elif len(best_squares) > 1:

                        if self.grid_trgt[0] is not None:          # then the agent has a target location in mind

                            # shuffling this ensures the selection of square with shortest distance to target (if more than 1) is randomised
                            random.shuffle(best_squares)

                            if print_fine_dets:
                                print('\n shuffled best_squares =', best_squares)
                                print('\n distances to target:\n')

                            # start with silly minimum distance to target
                            min_dist_to_target = 100
                            for item_loc in best_squares:

                                distance_to_target = np.max(abs_dist_on_torus(item_loc, self.grid_trgt, town_grid.dimen))

                                if print_fine_dets:
                                    print(' item_loc =', item_loc, 'self.grid_trgt', self.grid_trgt, 'distance_to_target', distance_to_target)

                                if distance_to_target < min_dist_to_target:
                                    town_grid.max_grid_square = copy.copy(item_loc)
                                    min_dist_to_target = copy.copy(distance_to_target)

                            if print_fine_dets:
                                print('min_dist_to_target =', min_dist_to_target, 'town_grid.max_grid_square', town_grid.max_grid_square)

                        else:

                            town_grid.max_grid_square = random.choice(best_squares)

                            if print_fine_dets:
                                print('\n agent is moving randomly ')

            if print_fine_dets:
                print('\n FINAL town_grid.max_grid_square is ', town_grid.max_grid_square)

            #
            # # here we account for avoidance: if the mean exp gain is negative on a particular square and any one of the cp_agents has an expected positive gain then I will move
            # # away from that cp_agent
            # min_mean_exp_rtn = np.min(neigh_exp_returns_array)
            # max_mean_exp_rtn = np.max(neigh_exp_returns_array)
            #
            # if print_fine_dets or print_for_tracking:
            #     print('\n neigh_exp_returns_array: \n\n', neigh_exp_returns_array)
            #     print('\n neigh_cp_exp_returns_array: \n')
            #     for line in neigh_cp_exp_returns_array:
            #         print(' ', line)
            #     print('\n min_mean_exp_rtn =', min_mean_exp_rtn)
            #     print(' max_mean_exp_rtn =', max_mean_exp_rtn)
            #     # print('\n len(squares_w_zero_exp_rtn) =', len(squares_w_zero_exp_rtn))
            #
            # # By this stage, if there is a 'good' square for the agent to head toward (it has a positive value, so max_mean_exp_rtn > 0) then we are essentially finished with this
            # # function.  If, however, the max_mean_exp_rtn is zero then we must choose the least-bad square to move toward.  If max_mean_exp_rtn == 0 then we choose from any of
            # # the 8 squares in squares_w_zero_exp_rtn if the length of this array is 8.  If max_mean_exp_rtn = 0 and the length of squares_w_zero_exp_rtn < 8 then we have to
            # # find the square the agent dislikes least.  We do this by looking at every grid square the agent could move to: we add the values from neigh_cp_exp_returns_array
            # # which are within striking distance from each square (provided it is negative and there is at least one positive value in neigh_cp_exp_returns_array).  The agent then
            # # chooses the square with the least negative value.
            #
            # # we only proceed if agent_avoid_muggers and if max_mean_exp_rtn <= 0
            # if params.agent_avoid_muggers and max_mean_exp_rtn <= 0:
            #
            #     # find the maximum value of neigh_cp_exp_returns_array
            #     max_cp_exp_rtn = 0.0
            #
            #     for line in neigh_cp_exp_returns_array:
            #         for cell in line:
            #             if len(cell) > 0:
            #                 for el in cell:
            #                     if el > max_cp_exp_rtn:
            #                         max_cp_exp_rtn = el
            #
            #     # if min_mean_exp_rtn < 0 or max_cp_exp_rtn > 0.0:
            #     #     print_fine_dets = 1
            #     #     no_neighs = 1
            #
            #     if print_fine_dets:
            #         # print('\n min_mean_exp_rtn =', min_mean_exp_rtn)
            #         # print(' max_mean_exp_rtn =', max_mean_exp_rtn)
            #         # print('\n\n neigh_exp_returns_array: \n\n', neigh_exp_returns_array)
            #         # print('\n neigh_cp_exp_returns_array: \n')
            #         # for line in neigh_cp_exp_returns_array:
            #         #     print(line)
            #         # print('\n len(squares_w_zero_exp_rtn) =', len(squares_w_zero_exp_rtn))
            #
            #         print('\n agent_avoid_muggers and max_mean_exp_rtn <= 0')
            #         print(' max_cp_exp_rtn', max_cp_exp_rtn)
            #
            #     # in the simpler situation, when min_mean_exp_rtn <= 0 and max_cp_exp_rtn <= 0, the agent will move to a zero square if there is one (it will ignore any agents)
            #     if min_mean_exp_rtn <= 0 and max_cp_exp_rtn <= 0 and len(squares_w_zero_exp_rtn) > 0:
            #
            #         if print_fine_dets:
            #             print('\n min_mean_exp_rtn <= 0 and max_cp_exp_rtn <= 0 and len(squares_w_zero_exp_rtn) > 0')
            #
            #         # here the agent chooses the square closest to its target (if it's not wandering around randomly)
            #         if self.trade_movemnt == 'set':
            #
            #             if print_fine_dets:
            #                 print('\n self.trade_movemnt == set')
            #                 print(' self.grid_trgt', self.grid_trgt)
            #
            #             # if the agent is already at its target - we keep it there
            #             if self.reached_trgt and self.location[0] == self.grid_trgt[0] and self.location[1] == self.grid_trgt[1]:
            #
            #                 max_grid_square = self.grid_trgt
            #                 head_to_target = 1
            #
            #             else:
            #
            #                 # print_fine_dets = 1
            #
            #                 # if print_fine_dets:
            #                 #
            #                 #     print('\n squares_w_zero_exp_rtn:', squares_w_zero_exp_rtn)
            #                 #     print('\n self.location', self.location, 'self.grid_trgt =', self.grid_trgt)
            #
            #                 best_grid_locations_array = []
            #                 min_dist_to_trgt = town_grid.dimen
            #
            #                 for grid_locn in squares_w_zero_exp_rtn:
            #
            #                     dist_to_trgt_2d = abs_dist_on_torus(grid_locn, self.grid_trgt, town_grid.dimen)
            #
            #                     dist_to_trgt = np.max(dist_to_trgt_2d)
            #
            #                     if print_fine_dets:
            #                         print('\n grid_locn', grid_locn)
            #                         print(' dist_to_trgt_2d', dist_to_trgt_2d)
            #                         print(' dist_to_trgt', dist_to_trgt)
            #                         print(' current min_dist_to_trgt', min_dist_to_trgt)
            #
            #                     if dist_to_trgt < min_dist_to_trgt:
            #
            #                         min_dist_to_trgt = dist_to_trgt
            #
            #                         best_grid_locations_array = [grid_locn]
            #
            #                     elif dist_to_trgt == min_dist_to_trgt:
            #
            #                         best_grid_locations_array.append(grid_locn)
            #
            #                     if print_fine_dets:
            #                         print('\n Resulting min_dist_to_trgt =', min_dist_to_trgt)
            #
            #                 max_grid_square = random.choice(best_grid_locations_array)
            #
            #                 if print_fine_dets:
            #                     print('\n best_grid_locations_array: ', best_grid_locations_array)
            #                     print('\n End max_grid_square', max_grid_square)
            #                     # pause()
            #
            #                 head_to_target = 0
            #
            #         else:
            #
            #             max_grid_square = random.choice(squares_w_zero_exp_rtn)  # we do this for when min_mean_exp_rtn < 0 and it gets over-ridden if pot_cp has postive return (agent runs)
            #
            #             head_to_target = 1
            #
            #         if print_fine_dets:
            #             print(' \n min_mean_exp_rtn <= 0 and len(squares_w_zero_exp_rtn) > 0')
            #             print(' max_grid_square =', max_grid_square)
            #
            #     # this is the more complicated situation - the agent needs to work out which square is the least bad to move to
            #     else:
            #
            #         # we start by creating a 3 x 3 matrix with extreme negative values and a variable which tracks the least negative value in the matrix
            #         sum_negs_array = np.full(shape=(3, 3), fill_value=-999.0)
            #         max_neg = -999.0
            #
            #         for i in [0, 1, 2]:
            #             for j in [0, 1, 2]:
            #
            #                 # we are only interested in squares where any counterpart has a positive exp return
            #                 max_cp_value_current_sq = 0.0
            #
            #                 if len(neigh_cp_exp_returns_array[i][j]) > 0:
            #                     max_cp_value_current_sq = np.max(neigh_cp_exp_returns_array[i][j])
            #
            #                 if max_cp_value_current_sq <= 0.0:
            #
            #                     sum_counter = 0.0
            #
            #                     for k in [-1, 0, 1]:
            #                         for l in [-1, 0, 1]:
            #
            #                             if i + k >= 0 and i + k < 3 and j + l >= 0 and j + l < 3:
            #
            #                                 max_cp_value = 0.0
            #
            #                                 if len(neigh_cp_exp_returns_array[i + k][j + l]) > 0:
            #                                     max_cp_value = np.max(neigh_cp_exp_returns_array[i + k][j + l])
            #
            #                                 if max_cp_value > 0.0:
            #                                     sum_counter += neigh_exp_returns_array[i + k][j + l]
            #
            #                     if sum_counter > max_neg:
            #                         max_neg = sum_counter
            #
            #                     sum_negs_array[i][j] = sum_counter
            #
            #         best_locations_array = []
            #
            #         for i in [0, 1, 2]:
            #             for j in [0, 1, 2]:
            #                 if sum_negs_array[i][j] == max_neg:
            #                     best_locations_array.append([i - 1, j - 1])
            #
            #         if print_fine_dets:
            #             print('\n sum_negs_array: \n')
            #             for line in sum_negs_array:
            #                 print('[%5.2f, %5.2f, %5.2f]' % (line[0], line[1], line[2]))
            #             print('\n max_neg', max_neg)
            #             print('\n best_locations_array: \n', best_locations_array)
            #
            #         # here the agent chooses the square closest to its target (if it's not wandering around randomly)
            #         if self.trade_movemnt == 'set':
            #
            #             if print_fine_dets:
            #                 print('\n self.trade_movemnt == set')
            #                 print(' self.grid_trgt', self.grid_trgt)
            #
            #             # if print_fine_dets:
            #             #
            #             #     print('\n best_locations_array:', best_locations_array)
            #             #     print('\n self.location', self.location, 'self.grid_trgt =', self.grid_trgt)
            #
            #             best_grid_locations_array = []
            #             min_dist_to_trgt = town_grid.dimen
            #
            #             for rel_locn in best_locations_array:
            #
            #                 grid_locn = [(self.location[0] + rel_locn[0]) % town_grid.dimen, (self.location[1] + rel_locn[1]) % town_grid.dimen]
            #
            #                 dist_to_trgt_2d = abs_dist_on_torus(grid_locn, self.grid_trgt, town_grid.dimen)
            #
            #                 dist_to_trgt = np.max(dist_to_trgt_2d)
            #
            #                 if print_fine_dets:
            #                     print('\n rel_locn', rel_locn, 'grid_locn', grid_locn)
            #                     print(' dist_to_trgt_2d', dist_to_trgt_2d)
            #                     print(' dist_to_trgt', dist_to_trgt)
            #                     print(' current min_dist_to_trgt', min_dist_to_trgt)
            #
            #                 if dist_to_trgt < min_dist_to_trgt:
            #
            #                     min_dist_to_trgt = dist_to_trgt
            #
            #                     best_grid_locations_array = [grid_locn]
            #
            #                 elif dist_to_trgt == min_dist_to_trgt:
            #
            #                     best_grid_locations_array.append(grid_locn)
            #
            #                 if print_fine_dets:
            #                     print('\n Resulting min_dist_to_trgt =', min_dist_to_trgt)
            #
            #             max_grid_square = random.choice(best_grid_locations_array)
            #
            #             if print_fine_dets:
            #                 print('\n best_grid_locations_array: ', best_grid_locations_array)
            #                 print('\n End max_grid_square', max_grid_square)
            #                 # pause()
            #
            #         else:
            #
            #             best_location_choice = random.choice(best_locations_array)
            #
            #             max_grid_square = [(self.location[0] + best_location_choice[0]) % town_grid.dimen, (self.location[1] + best_location_choice[1]) % town_grid.dimen]
            #
            #         if print_fine_dets:
            #             print('\n self.location =', self.location)
            #             print('\n resulting max_grid_square', max_grid_square)
            #             # pause()
            #
            #         # in this situation, the agent will want to avoid a potentially bad interaction so it will not head toward target
            #         head_to_target = 0
            #
            # if print_fine_dets == 1:
            #     print('\n squares_w_zero_exp_rtn', squares_w_zero_exp_rtn)
            #
            #     if params.track_agent and self == agent_population.tracking_agent:
            #         print('\n checking agent is tracking agent')
            #     else:
            #         print('\n checking agent is NOT tracking agent')
            #
            #     print('\n checking agent res =', self.basket_array)
            #     print(' tracking_agent res =', agent_population.tracking_agent.basket_array)
            #     print(' agent_population.tracking_agent.location', agent_population.tracking_agent.location)
            #     print('\n self.location', self.location)
            #     print(' self.grid_trgt', self.grid_trgt)
            #     print(' self.reached_trgt =', self.reached_trgt)
            #     print('\n max_mean_exp_return', max_mean_exp_return)
            #     print(' max_grid_square', max_grid_square)
            #     print(' number_neighbours', number_neighbours)
            #     print(' move ', move)
            #     print('\n head_to_target =', head_to_target)

        # if (print_fine_dets or print_for_tracking) and tot_neighs_adj_squares > 0:
        #     pause()

        return neigh_exp_returns_array, max_mean_exp_return, town_grid.max_grid_square, number_neighbours, neigh_cp_exp_returns_array, head_to_target


class Agent_Population():

    """This is a class for managing a population of agents."""

    # the class is initiated with a starting population:
    def __init__(self, start_population, trade_prices, min_trans_Q, homes_array, for_strat_parts,
                 black_shoop_exp, stranger_int, corruption_prop_charge, must_update_neighs):

        self.pop = start_population
        self.dead_agent_array = []
        self.trade_prices = trade_prices
        self.min_trans_Q = min_trans_Q
        self.homes_array = homes_array
        self.for_strat_parts = for_strat_parts

        # choose an agent at random from the population so we can track it over its life:
        ag_numb = np.random.randint(0, len(self.pop))
        self.tracking_agent = self.pop[ag_numb]
        self.KI_stiffs = []
        # this variable means agents from different tribes will simply ignore each other
        self.ignore_strangers = 1

        #        if black_shoop_exp:

        self.black_shoop_list = []
        self.black_shoop_seen = 0

        # when not respecting property rights, in one experiment we keep all props the same except for one agent:
        self.change_agent = None

        self.stranger_int = stranger_int

        # variable which corresponds to corruptability of officials imposing any fine
        self.corruption_prop_charge = corruption_prop_charge

        self.must_update_neighs = must_update_neighs

        # variable which tracks the population's mean propensity to steal
        self.mean_ps = 0.0

    def remove_agent(self, agent_num):

        """A method for removing an agent from the population."""

        self.pop = np.delete(self.pop, agent_num)

    def add_agent(self, new_agent):

        """A method for adding a new agent to the population."""

        self.pop.append(new_agent)

    def agents_interact(self, params, fountain_population, agent, cp_agent, day, town_grid, move, dbs, price_mean, force_prices,
                        fixed_price, print_dets, respect_property_rights, adjust_props_r, fight_cost, agent_intn_beta, num_rounds,
                        print_fine_dets, prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, fight_balance,
                        len_reputations_mem, intn_error_std, KO_pop, agent_population, keynesian_ratio, trade_prices,
                        trade_movemnt, trade_when_trgt, track_agent, trgt_sel, trade_moves, granular_mem, wait_at_tgt_moves, ststst,
                        agree_location, formal_inst, prob_fine, fine, print_agents_interact, fight_skill, fix_ps_fb_0, two_tribes_inst,
                        strat_choice, stranger_int, strangers_if_unknown):

        """A method for managing the interaction and potential trading of two agents (designated agent & cp_agent)."""

        if (params.track_agent and params.track_agent <= day) and (agent_population.tracking_agent == agent or agent_population.tracking_agent == cp_agent):

            print_for_tracking = 1

        else:

            print_for_tracking = 0

        # if day > 400 and (agent.prop_steal > 0.0 or cp_agent.prop_steal > 0.0):
        #     print_fine_dets = 1

        # if agent == self.pop[-1] or cp_agent == self.pop[-1]:
        #     print_fine_dets = 1

        # if day > 19:
        #     print_fine_dets = 1

        # if day >= 500:
        #     print_fine_dets = 1
        # print_for_tracking = 1

        # if day > 40 and np.sum(cp_agent.basket_array) > 8 and np.sum(agent.basket_array) == 0:
        #     print_fine_dets = 1
        #     pause_at_end = 1

        # if np.sum(agent.basket_array) > 4.0 and np.sum(cp_agent.basket_array) == 0:
        #
        #     print_fine_dets = 1
        #     pause_at_end = 1

        if print_fine_dets or print_for_tracking:
            print(
                '\n\n\n\n\n\n ********************************************** Agents start interacting **********************************************')

            print('\n day =', day)
            print(' move =', move)

            print('\n agent.home =', agent.home)
            print(' cp_agent.home =', cp_agent.home)

            if agent == agent_population.tracking_agent:
                print('\n agent is tracking agent')

            if cp_agent == agent_population.tracking_agent:
                print('\n cp_agent is tracking agent')

            print('\n agent.grid_trgt =', agent.grid_trgt)
            print(' cp_agent.grid_trgt =', cp_agent.grid_trgt)

            print('\n agent.location =', agent.location)
            print(' cp_agent.location =', cp_agent.location)

            print('\n agent.agent_res_array ', agent.agent_res_array)
            print(' agent.basket_array =', agent.basket_array)

            print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array)
            print(' cp_agent.basket_array =', cp_agent.basket_array)

            print('\n self.stranger_int =', self.stranger_int)

            # print('\n agent.tribe', agent.tribe)
            # print('\n cp_agent.tribe', cp_agent.tribe)

            print('\n agent_population.mean_ps =', agent_population.mean_ps)
            print(' agent_population.corruption_prop_charge =', agent_population.corruption_prop_charge)

            print('\n formal_inst ', formal_inst, 'prob_fine ', prob_fine, 'fine ', fine)

        # When 2 agents interact each agents has to first decide if they want to try to steal from the other, or if they want to trade.  If both want to trade then they simply trade.  If
        # both want to steal then they end up fighting each other.  However, if one wants to steal and the other trade, the agent wishing to trade can then decide to fight back or not once
        # the interaction starts - if they fight back then the two are in a fight; whereas if the agents acquiesces (chooses not to fight) then the fighting agent steal all its resources.

        #        if agent == agent_population.pop[0] or cp_agent == agent_population.pop[0]:
        #            print_fine_dets = 1

        # used for testing:
        #        agent.agent_res_array[0] = [100, 50]
        #        cp_agent.agent_res_array[0] = [50, 100]
        #
        #        agent.basket_array[0] = [1, 1]
        #        cp_agent.basket_array[0] = [1, 1]
        #
        #        print_fine_dets = 1

        ########

        fight_num = None
        transaction = None  # start with this & will be overwritten is they do transact

        ag_exp_overall_rtn = None
        cp_exp_overall_rtn = None

        agent_start_res = copy.copy(agent.agent_res_array[0])
        cp_agent_start_res = copy.copy(cp_agent.agent_res_array[0])

        agent_start_basket = copy.copy(agent.basket_array)
        cp_agent_start_basket = copy.copy(cp_agent.basket_array)

        initiator_start_prop_steal = copy.copy(agent.prop_steal)
        initiator_start_prop_fight_back = copy.copy(agent.prop_fight_back)

        counterpart_start_prop_steal = copy.copy(cp_agent.prop_steal)
        counterpart_start_prop_fight_back = copy.copy(cp_agent.prop_fight_back)

        agents_trade_peacefully = 0  # we assume this unless agents decide otherwise

        if print_fine_dets == 1:
            print_model_2_dets = 1

        else:
            print_model_2_dets = 0

        # record agents' total resources to start
        start_agent_tot_ress = agent.basket_array[0] + agent.agent_res_array[0]
        start_cp_agent_tot_ress = cp_agent.basket_array[0] + cp_agent.agent_res_array[0]

        # and find out which resource most defficient in
        agent_min_res_value = np.min(start_agent_tot_ress)
        cp_agent_min_res_value = np.min(start_cp_agent_tot_ress)

        agent_min_res = 0
        cp_agent_min_res = 0

        for res in range(num_res_founts):

            if start_agent_tot_ress[res] == agent_min_res_value:
                agent_min_res = res

            if start_cp_agent_tot_ress[res] == cp_agent_min_res_value:
                cp_agent_min_res = res

        if respect_property_rights == 0:

            # unpack agent and cp_agent expected returns:
            if params.net_benefit_feedback == 'relative':

                ag_exp_overall_rtn, cp_exp_overall_rtn, cp_exp_cp_overall_rtn = agent.exp_int_gains_dict[str(cp_agent)][2]

            agent_exp_rtns_matrix_copy = copy.copy(agent.exp_rtns_matrix[str(cp_agent)])

            # find exp returns for agent and cp_agent fighting back or acquiescing
            ag_2F_rtn, cp_2F_rtn = agent_exp_rtns_matrix_copy[1]
            ag_2A_rtn, cp_2A_rtn = agent_exp_rtns_matrix_copy[2]

            ag_3F_rtn, cp_3F_rtn = agent_exp_rtns_matrix_copy[3]
            ag_3A_rtn, cp_3A_rtn = agent_exp_rtns_matrix_copy[4]

            if print_fine_dets or print_for_tracking:
                if str(cp_agent) in agent.exp_int_gains_dict:
                    print('\n agent.exp_int_gains_dict[str(cp_agent)] : ', agent.exp_int_gains_dict[str(cp_agent)])
                if str(cp_agent) in agent.exp_rtns_matrix:
                    print('\n agent.exp_rtns_matrix[str(cp_agent)] : ', agent.exp_rtns_matrix[str(cp_agent)])

                print('\n ag_2F_rtn', ag_2F_rtn, 'ag_2A_rtn', ag_2A_rtn)
                print(' cp_2F_rtn', cp_2F_rtn, 'cp_2A_rtn', cp_2A_rtn)
                print(' ag_3F_rtn', ag_3F_rtn, 'ag_3A_rtn', ag_3A_rtn)
                print(' cp_3F_rtn', cp_3F_rtn, 'cp_3A_rtn', cp_3A_rtn)

                print('\n ag_exp_overall_rtn =', ag_exp_overall_rtn)
                print('\n cp_exp_overall_rtn =', cp_exp_overall_rtn)

            if params.limit_props:         # if we limit the agents' propensities within a ceiling and floor, we just need to apply prop_steal and prop_fight_back

                effective_agent_ps = agent.prop_steal
                effective_agent_pfb = agent.prop_fight_back

                effective_cp_ps = cp_agent.prop_steal
                effective_cp_pfb = cp_agent.prop_fight_back

            elif params.limit_props == 0:

                if agent.prop_steal < 0.0:
                    effective_agent_ps = 0.0

                elif agent.prop_steal > 1.0:
                    effective_agent_ps = 1.0

                else:
                    effective_agent_ps = copy.copy(agent.prop_steal)

                if agent.prop_fight_back < 0.0:
                    effective_agent_pfb = 0.0

                elif agent.prop_fight_back > 1.0:
                    effective_agent_pfb = 1.0

                else:
                    effective_agent_pfb = copy.copy(agent.prop_fight_back)

                if cp_agent.prop_steal < 0.0:
                    effective_cp_ps = 0.0

                elif cp_agent.prop_steal > 1.0:
                    effective_cp_ps = 1.0

                else:
                    effective_cp_ps = copy.copy(cp_agent.prop_steal)

                if cp_agent.prop_fight_back < 0.0:
                    effective_cp_pfb = 0.0

                elif cp_agent.prop_fight_back > 1.0:
                    effective_cp_pfb = 1.0

                else:
                    effective_cp_pfb = copy.copy(cp_agent.prop_fight_back)

            if print_fine_dets and params.limit_props == 0:

                print('\n limiting propensities:')
                print('\n agent.prop_steal', agent.prop_steal, '-> effective_agent_ps', effective_agent_ps)
                print(' agent.prop_fight_back', agent.prop_fight_back, '-> effective_agent_pfb', effective_agent_pfb)
                print(' cp_agent.prop_steal', cp_agent.prop_steal, '-> effective_cp_ps', effective_cp_ps)
                print(' cp_agent.prop_fight_back', cp_agent.prop_fight_back, '-> effective_cp_pfb', effective_cp_pfb)

            # pause()

            #           for testing
            #            agent.tribe = 'sharks'
            #            cp_agent.tribe = 'jets'

            #            print('\n agent.tribe =', agent.tribe, 'cp_agent.tribe', cp_agent.tribe)
            #            print(' strat_choice =', strat_choice)
            #            print(' strangers_if_unknown = ', strangers_if_unknown)
            #            print(' agent.agent_knows_cp_dict[str(cp_agent)]', agent.agent_knows_cp_dict[str(cp_agent)])
            #            print(' cp_agent.agent_knows_cp_dict[str(agent)] =', cp_agent.agent_knows_cp_dict[str(agent)])
            #            print(' agent.exp_rtns_matrix[str(cp_agent)]', agent.exp_rtns_matrix[str(cp_agent)])

            # we start by asking each agent if they want to attempt to steal or trade.

            if params.use_NNs:

                if print_for_tracking:
                    print('\n We are using Neural Networks to determine propensities')

                if print_fine_dets:
                    print('\n agent_exp_rtns_matrix_copy[:6] =', agent_exp_rtns_matrix_copy[:6])

                flatten_rtns_matrix_list = [item for sublist in agent_exp_rtns_matrix_copy[:6] for item in sublist]

                if print_fine_dets:
                    print('\n flatten_rtns_matrix_list =', flatten_rtns_matrix_list)
                    print('\n len(flatten_rtns_matrix_list)', len(flatten_rtns_matrix_list))

                # print('\n agent.exp_rtns_matrix[str(cp_agent)]', agent.exp_rtns_matrix[str(cp_agent)])
                # print('\n agent.exp_int_gains_dict[str(cp_agent)]', agent.exp_int_gains_dict[str(cp_agent)])
                #
                # print('\n ag_exp_overall_rtn', ag_exp_overall_rtn, 'cp_exp_overall_rtn', cp_exp_overall_rtn)
                #
                # pause()

                # print('\n agent.reputations_dict[str(cp_agent)]:', agent.reputations_dict[str(cp_agent)])

                cp_ps, cp_pfb, num_ints = find_cp_props(params, agent, cp_agent, day, len_reputations_mem, print_fine_dets=0)

                if print_fine_dets:

                    print('\n cp_ps', cp_ps)
                    print('\n cp_pfb', cp_pfb)

                flatten_rtns_matrix = copy.copy(flatten_rtns_matrix_list)

                flatten_rtns_matrix.append(cp_ps)
                flatten_rtns_matrix.append(cp_pfb)

                flatten_rtns_matrix = np.array([flatten_rtns_matrix]).T

                if print_fine_dets:
                    print('\n new flatten_rtns_matrix =', flatten_rtns_matrix)
                    print('\n len(flatten_rtns_matrix)', len(flatten_rtns_matrix))

                # new_matrix = generate_NN_inputs(params, day, dbs, fountain_population, agent.agent_res_array, agent.basket_array, cp_agent.agent_res_array, cp_agent.basket_array, cp_ps, cp_pfb, use_start_basket=0, print_dets=0, print_fine_dets=0)
                #
                # if print_fine_dets:
                #
                #     print('\n new_matrix =', new_matrix)
                #     print('\n diff: \n', new_matrix - flatten_rtns_matrix)
                #
                #     pause()

                if params.num_NNs == 1:

                    agent.intn_probs, agent.caches = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    agent.prop_steal = agent.intn_probs[0][0]
                    agent.prop_fight_back = agent.intn_probs[1][0]

                    if print_fine_dets:
                        print('\n agent.intn_probs =', agent.intn_probs)
                        # print('\n agent.caches =', agent.caches)

                elif params.num_NNs == 2:

                    if params.NN_inputs == 'game_6':

                        agent.intn_prob_ps, agent.caches_ps = L_model_forward(flatten_rtns_matrix, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        agent.prop_steal = agent.intn_prob_ps[0][0]

                        agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(flatten_rtns_matrix, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        agent.prop_fight_back = agent.intn_prob_pfb[0][0]

                    elif params.NN_inputs == 'mixed':

                        # we have to work out pfb first
                        ag_pfb_inputs = np.array(flatten_rtns_matrix[2:6])

                        if print_fine_dets:
                            print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                            print('\n ag_pfb_inputs \n', ag_pfb_inputs)

                        agent.intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_pfb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        agent.prop_fight_back = agent.intn_prob_pfb[0][0]

                        if print_fine_dets:
                            print('\n agent.prop_fight_back =', agent.prop_fight_back)
                            print('\n cp_pfb =', cp_pfb)

                        ag_ps_inputs = np.zeros(shape=(10, 1))

                        ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                        ag_ps_inputs[2] = (flatten_rtns_matrix[2] * agent.prop_fight_back) + (flatten_rtns_matrix[4] * (1 - agent.prop_fight_back))
                        ag_ps_inputs[3] = (flatten_rtns_matrix[3] * agent.prop_fight_back) + (flatten_rtns_matrix[5] * (1 - agent.prop_fight_back))
                        ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                        ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                        ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                        agent.intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        agent.prop_steal = agent.intn_prob_ps[0][0]

                        if print_fine_dets:
                            print('\n agent.intn_prob_pfb \n', agent.intn_prob_pfb)
                            print('\n ag_ps_inputs = \n', ag_ps_inputs)
                            print('\n agent.prop_steal =', agent.prop_steal)

                    if print_fine_dets:
                        print('\n agent.intn_prob_ps =', agent.intn_prob_ps)
                        print(' agent.intn_prob_pfb =', agent.intn_prob_pfb)
                        # print('\n agent.caches_ps =', agent.caches_ps)
                        # print('\n agent.caches_pfb =', agent.caches_pfb)

                # pause()

                # if print_fine_dets or print_for_tracking:
                #     print('\n agent.intn_probs =', agent.intn_probs)

                if print_fine_dets:
                    print('\n cp_agent:\n')

                flatten_rtns_matrix_list_cp = []

                for i in [1, 0, 7, 6, 9, 8, 3, 2, 5, 4, 11, 10]:
                    flatten_rtns_matrix_list_cp.append(flatten_rtns_matrix_list[i])

                if print_fine_dets:
                    print('\n flatten_rtns_matrix_list_cp =', flatten_rtns_matrix_list_cp)

                ag_ps, ag_pfb, num_ints = find_cp_props(params, cp_agent, agent, day, len_reputations_mem, print_fine_dets=0)

                flatten_rtns_matrix_list_cp.append(ag_ps)
                flatten_rtns_matrix_list_cp.append(ag_pfb)

                flatten_rtns_matrix_cp = np.array([flatten_rtns_matrix_list_cp]).T

                if print_fine_dets:
                    print('\n flatten_rtns_matrix_cp =', flatten_rtns_matrix_cp)
                    print('\n len(flatten_rtns_matrix_cp) =', len(flatten_rtns_matrix_cp))

                if params.num_NNs == 1:

                    cp_agent.intn_probs, cp_agent.caches = L_model_forward(flatten_rtns_matrix_cp, cp_agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                    cp_agent.prop_steal = cp_agent.intn_probs[0][0]
                    cp_agent.prop_fight_back = cp_agent.intn_probs[1][0]

                    if print_fine_dets:
                        print('\n cp_agent.intn_probs =', cp_agent.intn_probs)
                        # print('\n cp_agent.caches =', cp_agent.caches)

                elif params.num_NNs == 2:

                    if params.NN_inputs == 'game_6':

                        cp_agent.intn_prob_ps, cp_agent.caches_ps = L_model_forward(flatten_rtns_matrix, cp_agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        cp_agent.prop_steal = cp_agent.intn_prob_ps[0][0]

                        cp_agent.intn_prob_pfb, cp_agent.caches_pfb = L_model_forward(flatten_rtns_matrix, cp_agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        cp_agent.prop_fight_back = cp_agent.intn_prob_pfb[0][0]

                    elif params.NN_inputs == 'mixed':

                        # we have to work out pfb first
                        cp_pfb_inputs = np.array(flatten_rtns_matrix_cp[2:6])

                        if print_fine_dets:
                            print('\n flatten_rtns_matrix_list_cp \n', flatten_rtns_matrix_cp)
                            print('\n cp_pfb_inputs \n', cp_pfb_inputs)

                        cp_agent.intn_prob_pfb, cp_agent.caches_pfb = L_model_forward(cp_pfb_inputs, cp_agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        cp_agent.prop_fight_back = cp_agent.intn_prob_pfb[0][0]

                        if print_fine_dets:
                            print('\n cp_agent.prop_fight_back =', cp_agent.prop_fight_back)
                            print('\n ag_pfb =', ag_pfb)

                        cp_ps_inputs = np.zeros(shape=(10, 1))

                        cp_ps_inputs[0:2] = flatten_rtns_matrix_cp[0:2]
                        cp_ps_inputs[2] = (flatten_rtns_matrix_cp[2] * cp_agent.prop_fight_back) + (flatten_rtns_matrix_cp[4] * (1 - cp_agent.prop_fight_back))
                        cp_ps_inputs[3] = (flatten_rtns_matrix_cp[3] * cp_agent.prop_fight_back) + (flatten_rtns_matrix_cp[5] * (1 - cp_agent.prop_fight_back))
                        cp_ps_inputs[4] = (flatten_rtns_matrix_cp[6] * ag_pfb) + (flatten_rtns_matrix_cp[8] * (1 - ag_pfb))
                        cp_ps_inputs[5] = (flatten_rtns_matrix_cp[7] * ag_pfb) + (flatten_rtns_matrix_cp[9] * (1 - ag_pfb))
                        cp_ps_inputs[6:] = flatten_rtns_matrix_cp[10:]

                        cp_agent.intn_prob_ps, cp_agent.caches_ps = L_model_forward(cp_ps_inputs, cp_agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        cp_agent.prop_steal = cp_agent.intn_prob_ps[0][0]

                        if print_fine_dets:
                            print('\n cp_agent.intn_prob_pfb \n', cp_agent.intn_prob_pfb)
                            print('\n cp_ps_inputs = \n', cp_ps_inputs)
                            print('\n cp_agent.prop_steal =', cp_agent.prop_steal)

                    if print_fine_dets:
                        print('\n cp_agent.intn_prob_ps =', cp_agent.intn_prob_ps)
                        print(' cp_agent.intn_prob_pfb =', cp_agent.intn_prob_pfb)
                        # print('\n cp_agent.caches_ps =', cp_agent.caches_ps)
                        # print('\n cp_agent.caches_pfb =', cp_agent.caches_pfb)

                    # pause()

                # if print_fine_dets or print_for_tracking:
                #     print('\n cp_agent.intn_probs =', cp_agent.intn_probs)

                # Now apply probabilities:
                agent_ran_num = random.random()

                if agent_ran_num < effective_agent_ps:

                    agent_dec = 'steal'

                else:  # so >= then trade

                    agent_dec = 'trade'

                cp_agent_ran_num = random.random()

                if cp_agent_ran_num < effective_cp_ps:

                    cp_agent_dec = 'steal'

                else:

                    cp_agent_dec = 'trade'

                # if print_fine_dets == 1 or print_model_2_dets == 1:
                #     print('\n agent_ran_num = %1.3f' % (agent_ran_num),
                #           ' agent.intn_probs[0][0] = %1.3f' % (agent.intn_probs[0][0]), 'agent decision:', agent_dec)
                #     print('\n cp_agent_ran_num = %1.3f' % (cp_agent_ran_num),
                #           ' cp_agent.intn_probs[0][0] = %1.3f' % (cp_agent.intn_probs[0][0]), 'cp_agent decision:', cp_agent_dec)

                # pause()

            else:

                if print_for_tracking:
                    print('\n We are NOT using Neural Networks to determine propensities - just conventional approach')

                # Note that if the agents are strangers then by default both their prop steals == 1
                if strat_choice == 'rational' or agent.tribe != cp_agent.tribe or (strat_choice == 'propensities' and strangers_if_unknown and (agent.agent_knows_cp_dict[str(cp_agent)] == 0 or cp_agent.agent_knows_cp_dict[str(agent)] == 0)):
                    #
                    #                print('\n agent.exp_rtns_matrix[str(cp_agent)]', agent.exp_rtns_matrix[str(cp_agent)])
                    #                print(' agent_dec, cp_agent_dec, ag_gain, cp_gain', agent.exp_rtns_matrix[str(cp_agent)][8:])

                    #                use_start_basket = 0
                    #                agent_dec, cp_agent_dec, ag_gain, cp_gain = strangers_interact(self.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, agent_population, fountain_population, print_dets, print_fine_dets,
                    #                                                                               use_start_basket, agent, cp_agent, self.stranger_int, formal_inst, prob_fine, fine, two_tribes_inst, fight_cost)

                    # we can use the data we already have to determine agent and cp_agent's decisions
                    return_data = agent_exp_rtns_matrix_copy

                    agent_dec, cp_agent_dec, ag_gain, cp_gain = return_data[12:16]

                    if print_fine_dets or print_for_tracking:
                        print('\n strangers_interact completed: agent_dec ', agent_dec, ' cp_agent_dec ', cp_agent_dec, ' ag_gain ', ag_gain, ' cp_gain ', cp_gain)

                # if the agents are the same tribe then the interactoin is dictated by the prop steals
                elif agent.tribe == cp_agent.tribe and strat_choice == 'propensities' and (strangers_if_unknown == 0 or (strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and cp_agent.agent_knows_cp_dict[str(agent)])):

                    # print('\n agent.prop_steal =', agent.prop_steal, 'effective_agent_ps', effective_agent_ps)
                    # print(' cp_agent.prop_steal =', cp_agent.prop_steal, 'effective_cp_ps', effective_cp_ps)

                    if params.delib == 'full_delib' or params.delib == 'both':

                        if params.run_habit_timings_exps:
                            start_time = dt.datetime.now()

                        if random.random() < effective_agent_ps:

                            agent_dec = 'steal'

                        else:       # so >= then trade

                            agent_dec = 'trade'

                        if params.run_habit_timings_exps:
                            end_time = dt.datetime.now()

                            if 0.0 < effective_agent_ps < 1.0:

                                time_taken = end_time - start_time

                                dbs.total_time_delib[day] += time_taken.microseconds
                                # dbs.total_trans_delib[day] += 1

                            start_time = dt.datetime.now()

                        if random.random() < effective_cp_ps:

                            cp_agent_dec = 'steal'

                        else:

                            cp_agent_dec = 'trade'

                        if params.run_habit_timings_exps:
                            end_time = dt.datetime.now()

                            if 0.0 < effective_cp_ps < 1.0:

                                time_taken = end_time - start_time

                                dbs.total_time_delib[day] += time_taken.microseconds
                                # dbs.total_trans_delib[day] += 1

                        # if print_fine_dets == 1 or print_model_2_dets == 1 or print_for_tracking:
                        #     print('\n agent_ran_num = %1.3f' % (agent_ran_num),
                        #           ' agent.prop_steal = %1.3f' % (agent.prop_steal), 'agent decision:', agent_dec)
                        #     print('\n cp_agent_ran_num = %1.3f' % (cp_agent_ran_num),
                        #           ' cp_agent.prop_steal = %1.3f' % (cp_agent.prop_steal), 'cp_agent decision:', cp_agent_dec)

                    if params.delib == 'habit' or params.delib == 'both':

                        if params.run_habit_timings_exps:
                            start_time = dt.datetime.now()

                        if effective_agent_ps >= 1:

                            agent_dec = 'steal'

                        elif effective_agent_ps <= 0:

                            agent_dec = 'trade'

                        else:

                            if random.random() < effective_agent_ps:

                                agent_dec = 'steal'
                            else:
                                agent_dec = 'trade'

                        if params.run_habit_timings_exps:
                            end_time = dt.datetime.now()

                            if effective_agent_ps <= 0.0 or effective_agent_ps >= 1.0:

                                time_taken = end_time - start_time

                                dbs.total_time_habit[day] += time_taken.microseconds
                                # dbs.total_trans_habit[day] += 1

                            start_time = dt.datetime.now()

                        if effective_cp_ps >= 1:

                            cp_agent_dec = 'steal'

                        elif effective_cp_ps <= 0:

                            cp_agent_dec = 'trade'

                        else:

                            if random.random() < effective_cp_ps:
                                cp_agent_dec = 'steal'
                            else:
                                cp_agent_dec = 'trade'

                        if params.run_habit_timings_exps:
                            end_time = dt.datetime.now()

                            if effective_cp_ps <= 0.0 or effective_cp_ps >= 1.0:

                                time_taken = end_time - start_time

                                dbs.total_time_habit[day] += time_taken.microseconds
                                # dbs.total_trans_habit[day] += 1

            #            pause()

            # find expected return from quadrants 2 and 3
            if params.strat_choice == 'propensities':

                ag_exp_quad_2_rtn = (ag_2F_rtn * effective_agent_pfb) + (ag_2A_rtn * (1 - effective_agent_pfb))
                cp_exp_quad_2_rtn = (cp_2F_rtn * effective_agent_pfb) + (cp_2A_rtn * (1 - effective_agent_pfb))

                ag_exp_quad_3_rtn = (ag_3F_rtn * effective_cp_pfb) + (ag_3A_rtn * (1 - effective_cp_pfb))
                cp_exp_quad_3_rtn = (cp_3F_rtn * effective_cp_pfb) + (cp_3A_rtn * (1 - effective_cp_pfb))

            # we have to consider what the agents' decisions would be assuming substantive rationality irrespective of params.strat_choice because we want to record what the RCT decisions would have been

            # if print_fine_dets:
            #     print('\n Checking new code :\n')
            #     print(' agent_exp_rtns_matrix_copy =')
            #     for line in agent_exp_rtns_matrix_copy:
            #         print(line)

            if params.strat_choice != 'rational':           # then we have to run strangers_interact() - note this will change agent.exp_rtns_matrix which is why a copy was taken above -> agent_exp_rtns_matrix_copy
                use_start_basket = 0
                ag_rat_dec, cp_dom_strat_rat, ag_gain_rat, cp_gain_rat = strangers_interact(params, params.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, agent_population, fountain_population, print_dets,
                                                                                                    print_fine_dets, use_start_basket, agent, cp_agent, stranger_int, formal_inst, prob_fine, fine, two_tribes_inst, fight_cost, cp_dec=1)
                agent_exp_rtns_matrix_copy.append(agent.exp_rtns_matrix[str(cp_agent)][-1])

                # if print_fine_dets:
                #     print(' new agent.exp_rtns_matrix[str(cp_agent)] =')
                #     for line in agent.exp_rtns_matrix[str(cp_agent)]:
                #         print(line)

            else:           # then we know what the agent will choose
                ag_rat_dec = copy.copy(agent_dec)

            # the function receives various expected returns via agent.exp_rtns_matrix but these are from the instigator's perspective only.  we also need to determine what the counterpart's expected returns - and decision - will be
            use_start_basket = 0
            cp_cp_agent_dom_strat, cp_ag_dom_strat, cp_cp_gain, cp_ag_gain = strangers_interact(params, params.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, agent_population, fountain_population, print_dets, print_fine_dets, use_start_basket, cp_agent, agent,
                                                                                                stranger_int, formal_inst, prob_fine, fine, two_tribes_inst, fight_cost, cp_dec=1)

            cp_rat_dec = copy.copy(cp_cp_agent_dom_strat)

            # if print_fine_dets:
            #     print(' cp_agent.exp_rtns_matrix[str(agent)] =')
            #     for line in cp_agent.exp_rtns_matrix[str(agent)]:
            #         print(line)

            if params.strat_choice == 'rational':

                cp_1_rtn = cp_agent.exp_rtns_matrix[str(agent)][0][0]

                cp_3F_rtn = cp_agent.exp_rtns_matrix[str(agent)][1][0]
                cp_3A_rtn = cp_agent.exp_rtns_matrix[str(agent)][2][0]

                cp_2F_rtn = cp_agent.exp_rtns_matrix[str(agent)][3][0]
                cp_2A_rtn = cp_agent.exp_rtns_matrix[str(agent)][4][0]

                cp_4_rtn = cp_agent.exp_rtns_matrix[str(agent)][5][0]

                # for use later
                if print_fine_dets:
                    ag_tht_cp_would = copy.copy(cp_agent_dec)

                # if agent is choosing via substantive rationality, we set the cp_agent_dec to this:
                cp_agent_dec = copy.copy(cp_cp_agent_dom_strat)

                # the function strangers_interact() will also have set cp_agent.exp_rtns_matrix, which we can use - this essentially gives us the interaction from the cp's point of view.  We need the following data to help us determine the cp's
                # decision in the event its dominant decision is 'none' - we will assume that the cp is allowed to know the agent's decision in this scenario.
                if cp_cp_agent_dom_strat == 'none':

                    if print_fine_dets:
                        print('\n cp_cp_agent_dom_strat == ', cp_cp_agent_dom_strat, '  |  agent thought it would be:', ag_tht_cp_would)
                        print('\n cp_agent.exp_rtns_matrix[str(agent)]:', cp_agent.exp_rtns_matrix[str(agent)])
                        print('\n cp_1_rtn =', cp_1_rtn)
                        print(' cp_2F_rtn =', cp_2F_rtn)
                        print(' cp_2A_rtn =', cp_2A_rtn)
                        print(' cp_3F_rtn =', cp_3F_rtn)
                        print(' cp_3A_rtn =', cp_3A_rtn)
                        print(' cp_4_rtn =', cp_4_rtn)

                    # before moving forward we need to know in principle whether cp would choose acq, fb in Q3
                    # to speed the code up we consider the situation when 2A and 2F returns are equal first
                    if stranger_int == 'full':
                        cp_agent_dec_in_pr = random.choice(('trade', 'fight_back'))
                    elif stranger_int == 'fb':
                        cp_agent_dec_in_pr = 'fight_back'
                    elif stranger_int == 'acq':
                        cp_agent_dec_in_pr = 'trade'

                    if print_fine_dets:
                        print('\n cp_agent_dec_in_pr =', cp_agent_dec_in_pr)

                    # first of all, will cp fight back or acq in Q3?
                    if cp_agent_dec_in_pr == 'fight_back' or (stranger_int == 'full' and cp_3F_rtn > cp_3A_rtn):

                        # need to use this later when updating dictionary
                        cp_dec_Q3 = 'fight_back'
                        cp_2_rtn = cp_2F_rtn
                        cp_3_rtn = cp_3F_rtn

                        if print_fine_dets:
                            print(' cp_2_rtn =', cp_2_rtn)
                            print(' cp_3_rtn =', cp_3_rtn)

                    elif cp_agent_dec_in_pr == 'trade' or (stranger_int == 'full' and cp_3F_rtn < cp_3A_rtn):

                        # need to use this later when updating dictionary
                        cp_dec_Q3 = 'trade'
                        cp_2_rtn = cp_2A_rtn
                        cp_3_rtn = cp_3A_rtn

                        if print_fine_dets:
                            print(' cp_2_rtn =', cp_2_rtn)
                            print(' cp_3_rtn =', cp_3_rtn)

                    # now consider what cp_agent would do in the context of agent's decision:
                    if agent_dec == 'trade':

                        if cp_1_rtn > cp_2_rtn:
                            cp_agent_dec = 'trade'
                        elif cp_1_rtn < cp_2_rtn:
                            cp_agent_dec = 'steal'
                        else:       # then the returns are equal
                            cp_agent_dec = random.choice(('trade', 'steal'))

                        # the agent will change its mind in this situation:
                        if stranger_int == 'fb' and cp_agent_dec == 'steal':
                            agent_dec = 'fight_back'

                    elif agent_dec == 'fight_back':

                        if cp_1_rtn > cp_2_rtn:
                            cp_agent_dec = 'trade'
                        elif cp_1_rtn < cp_2_rtn:
                            cp_agent_dec = 'steal'
                        else:  # then the returns are equal
                            cp_agent_dec = random.choice(('trade', 'steal'))

                    elif agent_dec == 'steal':

                        # will cp fight back or acq in Q3?
                        if stranger_int == 'full':

                            if cp_3F_rtn > cp_3A_rtn or cp_agent_dec_in_pr == 'fight_back':

                                # need to use this later when updating dictionary
                                cp_dec_Q3 = 'fight_back'

                                # if FB, would it prefer this or to steal?
                                if cp_4_rtn > cp_3F_rtn:
                                    cp_agent_dec = 'steal'
                                elif cp_4_rtn < cp_3F_rtn:
                                    cp_agent_dec = 'fight_back'
                                else:  # then the returns are equal
                                    cp_agent_dec = random.choice(('fight_back', 'steal'))

                            elif cp_3F_rtn < cp_3A_rtn or cp_agent_dec_in_pr == 'trade':

                                # need to use this later when updating dictionary
                                cp_dec_Q3 = 'trade'

                                # if acq, would it prefer this or to steal?
                                if cp_4_rtn > cp_3A_rtn:
                                    cp_agent_dec = 'steal'
                                elif cp_4_rtn < cp_3A_rtn:
                                    cp_agent_dec = 'trade'
                                else:  # then the returns are equal
                                    cp_agent_dec = random.choice(('trade', 'steal'))

                        elif stranger_int == 'fb':

                            cp_dec_Q3 = 'fight_back'

                            if cp_4_rtn > cp_3_rtn:
                                cp_agent_dec = 'steal'
                            elif cp_4_rtn < cp_3_rtn:
                                cp_agent_dec = 'fight_back'
                            else:  # then the returns are equal
                                cp_agent_dec = random.choice(('fight_back', 'steal'))

                        elif stranger_int == 'acq':

                            cp_dec_Q3 = 'trade'

                            if cp_4_rtn > cp_3_rtn:
                                cp_agent_dec = 'steal'
                            elif cp_4_rtn < cp_3_rtn:
                                cp_agent_dec = 'trade'
                            else:  # then the returns are equal
                                cp_agent_dec = random.choice(('trade', 'steal'))

                # we have to consider this unusual but possible scenario
                if agent_dec == 'trade' and cp_agent_dec == 'fight_back':

                    # first, would agent fb or acq in Q2?  we know this from...
                    ag_Q2_dec_in_pr = agent_exp_rtns_matrix_copy[-1]

                    # first find out which bit of Q2 we're in, which is determined by the agent
                    if ag_Q2_dec_in_pr == 'fb':
                        cp_2_rtn = cp_2F_rtn
                    else:
                        cp_2_rtn = cp_2A_rtn

                    # then compare Q1 and Q2 returns...
                    if cp_1_rtn > cp_2_rtn:
                        cp_agent_dec = 'trade'
                    elif cp_1_rtn < cp_2_rtn:
                        cp_agent_dec = 'steal'
                    else:
                        cp_agent_dec = random.choice(('trade', 'steal'))

                    if print_fine_dets:
                        print('\n unusual situation: agent_dec == trade and cp_agent_dec == fight_back')
                        print(' agent decision in Q2 is ag_Q2_dec_in_pr =', ag_Q2_dec_in_pr)
                        print('\n cp_1_rtn =', cp_1_rtn, 'cp_2_rtn =', cp_2_rtn)
                        print(' so cp_agent chooses:', cp_agent_dec)

                    # but now we have to give the agent a chance to fb if cp steals!  but we already know what he'd do...
                    if cp_agent_dec == 'steal':

                        if ag_Q2_dec_in_pr == 'fb':
                            agent_dec = 'fight_back'
                        else:
                            agent_dec = 'trade'

                        if print_fine_dets:
                            print('\n now its even more unusual! cp_agent_dec == steal - what would agent do?')
                            print(' resulting agent_dec:', agent_dec)

                            # pause()

                # if agent_dec == 'trade' and cp_agent_dec == 'steal' and :

                if params.stranger_int == 'fb':

                    ag_exp_quad_2_rtn = ag_2F_rtn
                    cp_exp_quad_2_rtn = cp_2F_rtn

                    ag_exp_quad_3_rtn = ag_3F_rtn
                    cp_exp_quad_3_rtn = cp_3F_rtn

                elif params.stranger_int == 'acq':

                    ag_exp_quad_2_rtn = ag_2A_rtn
                    cp_exp_quad_2_rtn = cp_2A_rtn

                    ag_exp_quad_3_rtn = ag_3A_rtn
                    cp_exp_quad_3_rtn = cp_3A_rtn

                elif params.stranger_int == 'full':

                    if ag_2F_rtn > ag_2A_rtn:
                        ag_exp_quad_2_rtn = ag_2F_rtn
                        cp_exp_quad_2_rtn = cp_2F_rtn
                    elif ag_2F_rtn < ag_2A_rtn:
                        ag_exp_quad_2_rtn = ag_2A_rtn
                        cp_exp_quad_2_rtn = cp_2A_rtn
                    else:
                        ag_exp_quad_2_rtn = np.mean([ag_2F_rtn, ag_2A_rtn])
                        cp_exp_quad_2_rtn = np.mean([cp_2F_rtn, cp_2A_rtn])

                    if cp_3F_rtn > cp_3A_rtn:
                        ag_exp_quad_3_rtn = ag_3F_rtn
                        cp_exp_quad_3_rtn = cp_3F_rtn
                    elif cp_3F_rtn < cp_3A_rtn:
                        ag_exp_quad_3_rtn = ag_3A_rtn
                        cp_exp_quad_3_rtn = cp_3A_rtn
                    else:
                        ag_exp_quad_3_rtn = np.mean([ag_3F_rtn, ag_3A_rtn])
                        cp_exp_quad_3_rtn = np.mean([cp_3F_rtn, cp_3A_rtn])

                # if we allow the cp_agent to switch its decision from none to something else, it might be the case that the agent wants to trade and the cp wants to steal, which would
                # automatically mean the agent acquiesces.  But we know that in this scenario, the agent would choose between acq or fb so we apply ag_dec_in_pr:
                if agent_dec == 'trade' and cp_agent_dec == 'steal':

                    ag_dec_in_pr = agent_exp_rtns_matrix_copy[-1]               # this will == 'acq' or 'fb'

                    if ag_dec_in_pr == 'fb':
                        agent_dec = 'fight_back'            #

                    if print_fine_dets:
                        print('\n the lovely agent wanted to trade and the horrible cp decided to steal so the agent re-thought and decided to', agent_dec)

                # similarly it is possible for agent_dec == 'steal' and cp_agent_dec == 'trade' when stranger_int == 'fb' - the cp_agent expects 'trade' 'trade'
                if stranger_int == 'fb' and agent_dec == 'steal' and cp_agent_dec == 'trade':
                    cp_agent_dec = 'fight_back'

            # Now we have agents' decisions, let us record what type of game this is
            if params.track_game_types:

                # print('\n agent_exp_rtns_matrix_copy:', agent_exp_rtns_matrix_copy, 'line by line:\n')
                # for item in agent_exp_rtns_matrix_copy:
                #     print(item)
                #
                if print_fine_dets:
                    print('\n resulting stuff:\n')
                    if params.strat_choice == 'rational':
                        print(' cp_cp_agent_dom_strat == ', cp_cp_agent_dom_strat, '  |  agent thought it would be:', ag_tht_cp_would)
                    print(' agent_dec =', agent_dec)
                    print(' cp_agent_dec =', cp_agent_dec)
                    print('\n ag_rat_dec =', ag_rat_dec)
                    print(' cp_rat_dec =', cp_rat_dec)

                add_game_to_game_dict(params, self, fountain_population, agent, cp_agent, agent_exp_rtns_matrix_copy, cp_agent.exp_rtns_matrix[str(agent)], dbs, day, strat_choice, stranger_int, strangers_if_unknown,
                                      agent_dec, cp_agent_dec, ag_rat_dec, cp_rat_dec, print_fine_dets=0)

                # pause()

                if print_for_tracking:
                    print('\n Game added to game dictionary')

            # print('\n agent.prop_fight_back', agent.prop_fight_back, 'ag_exp_quad_2_rtn ', ag_exp_quad_2_rtn)
            # print('\n cp_agent.prop_fight_back', cp_agent.prop_fight_back, 'cp_exp_quad_3_rtn ', cp_exp_quad_3_rtn)
            #
            # pause()

            fight_winner = None

            if print_fine_dets or print_for_tracking:
                print('\n Initial trading decisions:')
                print('\n agent_dec =', agent_dec)
                print(' cp_agent_dec =', cp_agent_dec)

                # if agent_dec == 'trade' and cp_agent_dec == 'fight_back':
                #     pause()

            # if they both choose to trade then
            if agent_dec == 'trade' and cp_agent_dec == 'trade':

                agents_trade_peacefully = 1  # and we head to the code which organises the trading

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n => agents_trade_peacefully')

            # if one agent wants to fight and the other trade, they trader gets the chance to fight back
            # there are two cases: one where agent tries to steal and vice versa
            if agent_dec == 'steal' and cp_agent_dec == 'trade':

                if strat_choice == 'propensities' and agent.tribe == cp_agent.tribe:

                    fight_back_random_num = random.random()

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n fight_back_random_num: %1.3f' % (fight_back_random_num))
                        print(' cp_agent.prop_fight_back: %1.3f' % (cp_agent.prop_fight_back))

                    if fight_back_random_num < effective_cp_pfb:  # then the cp_agent decides to fight back

                        cp_agent_dec = 'fight_back'

                        if print_fine_dets == 1 or print_model_2_dets == 1 or print_for_tracking:
                            print('\n cp_agent decides to fight')

                # if the agents' choices remain the same then the cp is acquiescing
                if agent_dec == 'steal' and cp_agent_dec == 'trade':

                    agent.basket_array += cp_agent.basket_array
                    cp_agent.basket_array = np.zeros(shape=(1, num_res_founts), dtype=float)

                    if print_fine_dets == 1 or print_model_2_dets == 1 or print_for_tracking:
                        print('\n cp_agent is a wimp - doesnt fight back')

                    fight_winner = agent
                    fight_loser = cp_agent

                    #                    # if the agent has successfully stolen from cp_agent then it will ignore cp_agent from now on (no upside to interaction); and
                    #                    # the cp_agent, being bruised fomr the encounter, will ignore the agent
                    #                    agent.ignore_agents_array.append(cp_agent)
                    #                    cp_agent.ignore_agents_array.append(agent)

                    # if there is a formal institution and policing of fights then we include that here
                    if formal_inst:

                        if print_fine_dets:

                            print('\n formal_inst = ', formal_inst)
                            print(' agent_population.corruption_prop_charge =', agent_population.corruption_prop_charge)
                            print(' agent_population.mean_ps =', agent_population.mean_ps)

                        if random.random() < prob_fine:  # then the fight was detected and the agent is punished (from agent_res_array - agent might not have any res in basket)

                            if random.random() < agent_population.mean_ps:  # then there is corruption and the agent pays a bribe

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n corruption!')
                                    print(' agent pays bribe of fine * agent_population.corruption_prop_charge =',
                                          fine * agent_population.corruption_prop_charge)

                                agent.agent_res_array[0] += np.array([fine * agent_population.corruption_prop_charge,
                                                                      fine * agent_population.corruption_prop_charge])

                                dbs.corruption_array[day] += 1

                            else:  # then there is no corruption

                                agent.agent_res_array[0] += np.array([fine, fine])

                                dbs.non_corruption_array[day] += 1

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n agent fought and was fined by the police')
                                    print(' agent.agent_res_array ', agent.agent_res_array)

                                if formal_inst == 'compensate':
                                    cp_agent.agent_res_array[0] -= np.array([fine, fine])

                                    if print_fine_dets == 1 or print_model_2_dets == 1:
                                        print('\n cp_agent was compensated by ', np.array([fine, fine]) * -1)
                                        print(' cp_agent.agent_res_array ', cp_agent.agent_res_array)

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print(' agent.basket_array ', agent.basket_array)
                    print(' cp_agent.basket_array ', cp_agent.basket_array)

                    # the second case is when the cp_agent tries to steal and the agent wants to trade
            if agent_dec == 'trade' and cp_agent_dec == 'steal':

                if strat_choice == 'propensities' and agent.tribe == cp_agent.tribe:

                    fight_back_random_num = random.random()

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n fight_back_random_num: %1.3f' % (fight_back_random_num))
                        print(' agent.prop_fight_back: %1.3f' % (agent.prop_fight_back))

                    if fight_back_random_num < effective_agent_pfb:  # then the agent decides to fight back

                        agent_dec = 'fight_back'

                        if print_fine_dets == 1 or print_model_2_dets == 1 or print_for_tracking:
                            print('\n agent decides to fight')

                # if the agents' choices remain the same
                if agent_dec == 'trade' and cp_agent_dec == 'steal':

                    cp_agent.basket_array += agent.basket_array
                    agent.basket_array = np.zeros(shape=(1, num_res_founts), dtype=float)

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n agent is a wimp')

                    fight_winner = cp_agent
                    fight_loser = agent

                    #                    # if the agent has successfully stolen from cp_agent then it will ignore cp_agent from now on (no upside to interaction); and
                    #                    # the cp_agent, being bruised fomr the encounter, will ignore the agent
                    #                    agent.ignore_agents_array.append(cp_agent)
                    #                    cp_agent.ignore_agents_array.append(agent)

                    # if there is a formal institution and policing of fights then we include that here
                    if formal_inst:

                        if print_fine_dets:
                            print(' agent_population.mean_ps =', agent_population.mean_ps)

                        if random.random() < prob_fine:  # then the fight was detected and the agent is punished (from agent_res_array - agent might not have any res in basket)

                            if random.random() < agent_population.mean_ps:  # then there is corruption and the cp_agent pays a bribe

                                cp_agent.agent_res_array[0] += np.array([fine * agent_population.corruption_prop_charge,
                                                                         fine * agent_population.corruption_prop_charge])

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n corruption!')
                                    print(' cp_agent pays bribe of fine * agent_population.corruption_prop_charge =',
                                          fine * agent_population.corruption_prop_charge)

                                dbs.corruption_array[day] += 1

                            else:  # then there is no corruption - pays full fine

                                cp_agent.agent_res_array[0] += np.array([fine, fine])

                                dbs.non_corruption_array[day] += 1

                                if formal_inst == 'compensate':
                                    agent.agent_res_array[0] -= np.array([fine, fine])

                                    if print_fine_dets or print_model_2_dets:
                                        print('\n agent was compensated by ', np.array([fine, fine]) * -1)
                                        print(' agent.agent_res_array ', agent.agent_res_array)

                                if print_fine_dets or print_model_2_dets:
                                    print('\n cp_agent fought and was fined by the police')

                                    print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array)

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n agent.basket_array ', agent.basket_array)
                    print(' cp_agent.basket_array ', cp_agent.basket_array)

            # the third case is when the two agents want to steal / fight (this can arise because they both initially decide to fight;
            # or because one oringinally wanted to trade and then decided to fight back):
            if (agent_dec == 'steal' or agent_dec == 'fight_back') and (cp_agent_dec == 'steal' or cp_agent_dec == 'fight_back'):

                if print_fine_dets == 1 or print_model_2_dets == 1 or print_for_tracking:
                    print('\n They fight')

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n y agent.agent_res_array ', agent.agent_res_array)
                    print(' y agent.basket_array ', agent.basket_array)

                    print('\n y cp_agent.agent_res_array ', cp_agent.agent_res_array)
                    print(' y cp_agent.basket_array ', cp_agent.basket_array)

                if fight_skill is not None:

                    sum_skill = agent.fight_skill + cp_agent.fight_skill

                    if sum_skill != 0.0:

                        agent_win_thresh = agent.fight_skill / float(sum_skill)

                    else:

                        agent_win_thresh = 0.5

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n fight based on fight_skills - agent.fight_skill =', agent.fight_skill,
                              'cp_agent.fight_skill =', cp_agent.fight_skill, 'sum_skill =', sum_skill,
                              'agent_win_thresh =', agent_win_thresh)

                elif fight_balance == '50_50':

                    agent_win_thresh = 0.5

                elif fight_balance == 'res_power':

                    agent_mean_res = np.mean(agent.agent_res_array[0])
                    cp_agent_mean_res = np.mean(cp_agent.agent_res_array[0])

                    # this means that if agent has more resources then it will have more chance of winning the fight
                    agent_win_thresh = agent_mean_res / float(agent_mean_res + cp_agent_mean_res)

                    if print_fine_dets == 1:
                        print("\n fight_balance == res_power")
                        print('\n agent_mean_res =', agent_mean_res)
                        print(' cp_agent_mean_res =', cp_agent_mean_res)
                        print('\n agent_win_thresh =', agent_win_thresh)
                        print(' prob_agent_loses_fight =', 1 - agent_win_thresh)

                fight_random_number = random.random()

                if print_fine_dets:

                    print('\n agents fight.. fight_skill =', fight_skill)
                    print(' fight_random_number = ', fight_random_number)
                    print(' agent_win_thresh =', agent_win_thresh)

                if fight_random_number < agent_win_thresh:

                    if print_fine_dets == 1 or print_model_2_dets == 1 or print_for_tracking:
                        print('\n agent wins fight')

                    agent.basket_array += cp_agent.basket_array
                    agent.agent_res_array[0] += np.array([fight_cost, fight_cost])

                    cp_agent.basket_array = np.zeros(shape=(1, num_res_founts), dtype=float)
                    cp_agent.agent_res_array[0] += np.array([fight_cost, fight_cost])

                    fight_winner = agent
                    fight_loser = cp_agent

                else:

                    if print_fine_dets == 1 or print_model_2_dets == 1 or print_for_tracking:
                        print('\n cp_agent wins fight')

                    cp_agent.basket_array += agent.basket_array
                    cp_agent.agent_res_array[0] += np.array([fight_cost, fight_cost])

                    agent.basket_array = np.zeros(shape=(1, num_res_founts), dtype=float)
                    agent.agent_res_array[0] += np.array([fight_cost, fight_cost])

                    fight_winner = cp_agent
                    fight_loser = agent

                #                # if the agent has successfully stolen from cp_agent then it will ignore cp_agent from now on (no upside to interaction); and
                #                # the cp_agent, being bruised fomr the encounter, will ignore the agent
                #                agent.ignore_agents_array.append(cp_agent)
                #                cp_agent.ignore_agents_array.append(agent)

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n x agent.agent_res_array ', agent.agent_res_array)
                    print(' x agent.basket_array ', agent.basket_array)

                    print('\n x cp_agent.agent_res_array ', cp_agent.agent_res_array)
                    print(' x cp_agent.basket_array ', cp_agent.basket_array)

                # if there is a formal institution and policing of fights then we include that here
                if formal_inst:

                    if print_fine_dets:
                        print('\n formal_inst = ', formal_inst)
                        print(' agent_population.corruption_prop_charge =', agent_population.corruption_prop_charge)
                        print(' agent_population.mean_ps =', agent_population.mean_ps)

                    if random.random() < prob_fine:  # then the fight was detected and the agent is punished (from agent_res_array - agent might not have any res in basket)

                        if agent_dec == 'steal':

                            if random.random() < agent_population.mean_ps:  # then there is corruption and the cp_agent pays a bribe (and there is no compensation).  If there is no corruption in model then mean_ps == 0

                                agent.agent_res_array[0] += np.array([fine * agent_population.corruption_prop_charge,
                                                                      fine * agent_population.corruption_prop_charge])

                                dbs.corruption_array[day] += 1

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n corruption!')
                                    print(' agent pays bribe of fine * agent_population.corruption_prop_charge =',
                                          fine * agent_population.corruption_prop_charge)

                            else:  # then there is no corruption - pays full fine

                                agent.agent_res_array[0] += np.array([fine, fine])
                                dbs.non_corruption_array[day] += 1

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n agent fought and was fined by the police')
                                    print(' agent.agent_res_array ', agent.agent_res_array)

                                if cp_agent_dec == 'fight_back' and formal_inst == 'compensate':

                                    cp_agent.agent_res_array[0] -= np.array([fine, fine])

                                    if print_fine_dets == 1 or print_model_2_dets == 1:
                                        print('\n cp_agent was compensated by ', np.array([fine, fine]) * -1)
                                        print(' cp_agent.agent_res_array ', cp_agent.agent_res_array)

                        if cp_agent_dec == 'steal':

                            if random.random() < agent_population.mean_ps:  # then there is corruption and the cp_agent pays a bribe

                                cp_agent.agent_res_array[0] += np.array([fine * agent_population.corruption_prop_charge,
                                                                         fine * agent_population.corruption_prop_charge])

                                dbs.corruption_array[day] += 1

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n corruption!')
                                    print(' cp_agent pays bribe of fine * agent_population.corruption_prop_charge =',
                                          fine * agent_population.corruption_prop_charge)

                            else:  # then there is no corruption - pays full fine

                                cp_agent.agent_res_array[0] += np.array([fine, fine])
                                dbs.non_corruption_array[day] += 1

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n cp_agent fought and was fined by the police')
                                    print(' cp_agent.agent_res_array ', cp_agent.agent_res_array)

                                if agent_dec == 'fight_back' and formal_inst == 'compensate':

                                    agent.agent_res_array[0] -= np.array([fine, fine])

                                    if print_fine_dets == 1 or print_model_2_dets == 1:
                                        print('\n agent was compensated by ', np.array([fine, fine]) * -1)
                                        print(' agent.agent_res_array ', agent.agent_res_array)

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n agent.agent_res_array ', agent.agent_res_array)
                    print(' agent.basket_array ', agent.basket_array)

                    print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array)
                    print(' cp_agent.basket_array ', cp_agent.basket_array)

            # if the agents dont trade then we have to create and return these data anyway
            if agents_trade_peacefully == 0:
                remove_agents = np.array([])
                transactions = 0
                traded_array = []
                trans_numbs_array = []

        #        if print_fine_dets == 1:
        #            pause()

        if print_fine_dets == 1:
            print('\n agent', agent, 'agent.ignore_agents_array', agent.ignore_agents_array)
            print(' cp_agent', cp_agent, 'cp_agent.ignore_agents_array', cp_agent.ignore_agents_array)

        if respect_property_rights or agents_trade_peacefully:

            #            print_fine_dets = 1

            # create variables to record number of transactions (nothing to do with price, it merely counts transactions) gain_pot_cp_low_res_6_prob_weighted
            transactions = 0

            # record all of the transaction numbers in an array
            trans_numbs_array = []

            if print_fine_dets == 1:
                print('\n\n--> Agents start interacting')

                print('\nday =', day)
                print('move =', move)

                print('\nagent.home =', agent.home)
                print('cp_agent.home =', cp_agent.home)

                print('\nagent.grid_trgt =', agent.grid_trgt)
                print('cp_agent.grid_trgt =', cp_agent.grid_trgt)

                print('\nagent.location =', agent.location)
                print('cp_agent.location =', cp_agent.location)

                print('\nagent.trade_loc_rec =\n')

                for move in np.arange(len(agent.trade_loc_rec)):
                    print(agent.trade_loc_rec[move])

                print(agent.location, '<-- agent.location')
                print('\nagent.trgt_loc_rec =\n')

                for move in np.arange(len(agent.trgt_loc_rec)):
                    print(agent.trgt_loc_rec[move])

                print(agent.grid_trgt, '<-- agent.grid_trgt =')

                print('\nINITIAL agent.trading_basket =', agent.trading_basket)
                print('INITIAL cp_agent.trading_basket =', cp_agent.trading_basket)

                print('\nagent.basket_array =', agent.basket_array)
                print('\ncp_agent.basket_array =', cp_agent.basket_array)

            # create arrays to update agents' memory arrays
            rec_array = copy.deepcopy(agent.location)

            # add the round to this array
            rec_array = np.append(rec_array, day)

            # set up an array to record the information corresponding to any transaction
            traded_array = []

            # Create array to record agents we should remove.  Below we also update each agent's sell_array and buy_array
            remove_agents = np.array([])

            if print_dets == 1:
                print('\n rec_array =', rec_array)

            stop_transacting = 0

            iter_loop = 0

            while stop_transacting == 0:

                if print_fine_dets == 1:
                    print('\n\n--> Starting while loop: transactions =', transactions)

                # We have to differentiate between the use of fixed or variable prices to determine trading between agents
                if self.trade_prices == 'variable':

                    use_start_basket = 0
                    agent_res_array = agent.agent_res_array
                    agent_basket_array = agent.basket_array
                    agent_basket_array_start = agent.basket_array_start
                    cp_agent_res_array = cp_agent.agent_res_array
                    cp_agent_basket_array = cp_agent.basket_array
                    cp_agent_basket_array_start = cp_agent.basket_array_start

                    # The function build_tot_cons_surp_array returns the total consumer surplus array and the data for the best transaction
                    if (agent.basket_array[0][0] > 0.0 and cp_agent.basket_array[0][1] > 0.0) or (
                            agent.basket_array[0][1] > 0.0 and cp_agent.basket_array[0][
                        0] > 0):  # then they might trade

                        tot_cons_surp_array, best_trans_data = build_tot_cons_surp_array(params, self.min_trans_Q, price_mean,
                                                                                         force_prices, fixed_price, day,
                                                                                         dbs, fountain_population,
                                                                                         print_dets, print_fine_dets,
                                                                                         use_start_basket,
                                                                                         agent_res_array,
                                                                                         agent_basket_array,
                                                                                         agent_basket_array_start,
                                                                                         cp_agent_res_array,
                                                                                         cp_agent_basket_array,
                                                                                         cp_agent_basket_array_start)

                    else:  # then they won't trade

                        tot_cons_surp_array, best_trans_data = (
                        [[0.0, 0.0], [0.0, 0.0]], [None, None, None, None, None])

                    # find the maximum change in consumer surplus
                    max_cons_surp_ch = np.max(tot_cons_surp_array)

                    if print_fine_dets == 1:
                        print('\n tot_cons_surp_array:\n', tot_cons_surp_array)
                        print('\n max_cons_surp_ch', max_cons_surp_ch)
                        print('\n best_trans_data =', best_trans_data)

                    # We only carry on if max_cons_surp_ch is positive.  It can't be negative but all cells might be zero in which
                    # case there's no advantage to either agent in transacting

                    if max_cons_surp_ch > 0.0:

                        agent_sells, agent_buys, tot_trans_ag_sell, tot_trans_ag_buy, trans_agr_MRS = best_trans_data

                        if print_fine_dets == 1:
                            print('\n\n the agents trade')
                            print(' agent_sells =', agent_sells)
                            print(' agent_buys =', agent_buys)
                            print(' tot_trans_ag_sell =', tot_trans_ag_sell)
                            print(' tot_trans_ag_buy =', tot_trans_ag_buy)
                            print(' trans_agr_MRS =', trans_agr_MRS)

                        # record what traded and how much:
                        trans_receipt = np.array(
                            [agent_sells, agent_buys, tot_trans_ag_sell, tot_trans_ag_buy, trans_agr_MRS])

                        # add this to traded_array
                        traded_array.append(trans_receipt)

                        # update some arrays & variables:
                        if agent_sells is not None:
                            agent.basket_array[0][agent_sells] -= tot_trans_ag_sell
                            cp_agent.basket_array[0][agent_sells] += tot_trans_ag_sell
                            agent.trading_basket[0][agent_sells] -= tot_trans_ag_sell
                            cp_agent.trading_basket[0][agent_sells] += tot_trans_ag_sell

                            # Note that as a default we use the amount sold by the agent as the quantity of the transaction
                            transactions += tot_trans_ag_sell

                            agent.basket_array[0][agent_buys] += tot_trans_ag_buy
                            cp_agent.basket_array[0][agent_buys] -= tot_trans_ag_buy
                            agent.trading_basket[0][agent_buys] += tot_trans_ag_buy
                            cp_agent.trading_basket[0][agent_buys] -= tot_trans_ag_buy

                        # create a transaction instance to record all relevant data
                        transaction = Transaction(copy.copy(agent.for_strat_array), copy.copy(cp_agent.for_strat_array),
                                                  copy.deepcopy(agent.location), day, agent_sells, agent_buys,
                                                  copy.copy(agent.home), copy.copy(cp_agent.home), tot_trans_ag_sell,
                                                  tot_trans_ag_buy, move, copy.deepcopy(agent.grid_trgt),
                                                  copy.deepcopy(cp_agent.grid_trgt),
                                                  copy.deepcopy(agent.trading_basket[0]),
                                                  copy.deepcopy(cp_agent.trading_basket[0]),
                                                  copy.deepcopy(agent.trade_loc_rec),
                                                  copy.deepcopy(cp_agent.trade_loc_rec), copy.deepcopy(agent.MRS_array),
                                                  copy.deepcopy(cp_agent.MRS_array), str(agent), str(cp_agent),
                                                  copy.deepcopy(trans_agr_MRS), agent_a_tribe=copy.copy(agent.tribe),
                                                  agent_b_tribe=copy.copy(cp_agent.tribe))

                        agent.loc_mems_array[day].append(len(dbs.trans_db))
                        cp_agent.loc_mems_array[day].append(len(dbs.trans_db))

                        trans_numbs_array.append(len(dbs.trans_db))
                        dbs.trans_db.append(transaction)

                        if print_fine_dets:
                            print('\n trans_numbs_array =', trans_numbs_array)
                            print('\n agent.loc_mems_array[day] =', agent.loc_mems_array[day])
                            print('\n cp_agent.loc_mems_array[day] =', cp_agent.loc_mems_array[day])

                        if len(dbs.start_end_transs[day]) == 0:  # then this is the first transaction

                            dbs.start_end_transs[day] = [len(dbs.trans_db) - 1, len(dbs.trans_db) - 1]

                        else:

                            dbs.start_end_transs[day][1] = len(dbs.trans_db) - 1

                        # How do we decide if either agent wants to remain on the board or leave?  If the agent can sell (a) good(s) and gain
                        # from this then it stays on the grid

                        # update MRS_arrays
                        for ag in [agent, cp_agent]:
                            ag.update_agent_MRS_array(print_dets, print_fine_dets, self)

                        # pause()

                    # We stop transacting in two scenarios: either there is no gain to the agents in transacting or there they
                    # are attempting to unwind a preious transaction (MRS crossing)
                    #                    elif max_cons_surp_ch == 0:
                    #
                    #                        if print_fine_dets == 1:
                    #                            print('\nmax_cons_surp_ch == 0 : there is no positive consumer surplus to be gained')
                    #
                    #                        stop_transacting = 1
                    #
                    #                        transaction = None

                    # we set the following, which prevents the agents from immediately trading with each other again: if the two agents trade but wanted to trade more and were constrained by
                    # their basket holdings, their MRSs will adjust but if they then got in to another interaction, they might trade again because the agreed price will change from the first
                    # trade - this can cause lots of iterations of trading, which we avoid on reasonableness grounds.
                    # Note these are only set if the agents try to transact - if they try to steal from each other then these are not set.
                    if respect_property_rights or (
                            respect_property_rights == 0 and max_cons_surp_ch > 0):  # i.e. they actually traded some resources

                        agent.agent_last_traded_with = cp_agent
                        cp_agent.agent_last_traded_with = agent

                if print_fine_dets == 1:
                    print('\nagent.agent_res_array =', agent.agent_res_array)
                    print('POST agent.basket_array =', agent.basket_array)
                    print('agent.aggr_res_array =', agent.aggr_res_array)

                    print('\ncp_agent.agent_res_array =', cp_agent.agent_res_array)
                    print('POST cp_agent.basket_array =', cp_agent.basket_array)
                    print('cp_agent.aggr_res_array =', cp_agent.aggr_res_array)

                    print('\nPOST agent.trading_basket =', agent.trading_basket)
                    print('POST cp_agent.trading_basket =', cp_agent.trading_basket)

                    print('\ntransactions =', transactions)

                    print('\nremove_agents =', remove_agents)

                if print_fine_dets == 1:
                    print('\n[remove_agents, transactions, traded_array, trans_numbs_array] =',
                          [remove_agents, transactions, traded_array, trans_numbs_array])

                    # we only continue the iteration loop if num_res_founts > 2
                if num_res_founts == 2:
                    stop_transacting = 1

                # This is the end of the 'while attempt_to_transact == 1' loop

        # we now calculate agent_net_benefit and cp_agent_net_benefit
        if print_fine_dets == 1 or print_model_2_dets == 1 or print_for_tracking:
            print('\n\n -------- interaction: end numbers --------- ')

            print('\n start props:\n')
            print(' agent.prop_steal %1.5f' % (agent.prop_steal),
                  '  agent.prop_fight_back %1.5f' % (agent.prop_fight_back))
            print(' cp_agent.prop_steal %1.5f' % (cp_agent.prop_steal),
                  '  cp_agent.prop_fight_back %1.5f' % (cp_agent.prop_fight_back))

            print('\n agent.agent_res_array ', agent.agent_res_array[0])
            print(' agent_start_basket =', agent_start_basket[0])

            print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array[0])
            print(' cp_agent_start_basket =', cp_agent_start_basket[0])

        start_agent_prop_steal = copy.copy(agent.prop_steal)
        start_agent_prop_fight_back = copy.copy(agent.prop_fight_back)

        start_cp_agent_prop_steal = copy.copy(cp_agent.prop_steal)
        start_cp_agent_prop_fight_back = copy.copy(cp_agent.prop_fight_back)

        end_agent_tot_ress = agent.basket_array[0] + agent.agent_res_array[0]
        end_cp_agent_tot_ress = cp_agent.basket_array[0] + cp_agent.agent_res_array[0]

        agent_ch_ress = end_agent_tot_ress - start_agent_tot_ress
        cp_agent_ch_ress = end_cp_agent_tot_ress - start_cp_agent_tot_ress

        if params.print_PTP_effect and (np.sum(agent_ch_ress) > params.print_PTP_effect or np.sum(cp_agent_ch_ress) > params.print_PTP_effect):
            print_PTP_effect_loc = 1
        else:
            print_PTP_effect_loc = 0

        # if print_fine_dets or print_model_2_dets or print_for_tracking or print_PTP_effect_loc:
        #     print('\n\n day ', day, 'move no. ', move, '\n cp_agent ', cp_agent.home, ' cp_agent_ch_ress', cp_agent_ch_ress)
        #     print(' agent ', agent.home, ' agent_ch_ress', agent_ch_ress)

        # in order to generate a net benefit value for each agent, we find the resource gain (loss) in units of the resource which was its lowest at the start of the interaction.
        # We use the MRS to convert from one resource to another

        # let's start with the agent - the resource which had been its minimum was agent_min_res at the start
        agent_net_benefit = 0

        agent_MRS_array = generate_MRS_array([start_agent_tot_ress], print_fine_dets=0)

        if print_fine_dets == 1 or print_model_2_dets == 1:
            print('\n agent total res_array ', agent.agent_res_array[0] + agent.basket_array[0])
            print('\n agent_MRS_array\n', agent_MRS_array)
            print('\n agent_min_res', agent_min_res)
            print('\n iterate over resources to find agent_net_benefit:')

        for res in range(num_res_founts):

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n res ', res)

            if res == agent_min_res:

                agent_net_benefit += agent_ch_ress[agent_min_res]

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n this is the same resource as min_res so no conversion necessary')
                    print(' agent_ch_ress[agent_min_res] =', agent_ch_ress[agent_min_res])

            else:

                agent_net_benefit += agent_MRS_array[agent_min_res][res] * agent_ch_ress[res]

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n this is a different resource to min_res')
                    print(' agent_MRS_array[agent_min_res][res]', agent_MRS_array[agent_min_res][res])
                    print(' agent_ch_ress[res]', agent_ch_ress[res])
                    print(' agent_MRS_array[agent_min_res][res] * agent_ch_ress[res]',
                          agent_MRS_array[agent_min_res][res] * agent_ch_ress[res])

        # if agent_net_benefit > 20.0 and day > 200:
        #     print_fine_dets = 1

        # if print_fine_dets or print_model_2_dets or print_for_tracking:
        #     print('\n after iterating: agent_net_benefit = ', agent_net_benefit)

        # ch_agent_prop_steal = (adjust_props_r * agent_net_benefit) * agent.prop_steal * (1 - agent.prop_steal)
        # ch_agent_prop_fight_back = (adjust_props_r * agent_net_benefit) * agent.prop_fight_back * (
        #             1 - agent.prop_fight_back)
        #
        # if print_fine_dets == 1 or print_model_2_dets == 1:
        #     print('\n ch_agent_prop_steal =', ch_agent_prop_steal)
        #     print(' ch_agent_prop_fight_back =', ch_agent_prop_fight_back)

        # now the same for the cp_agent:
        cp_agent_net_benefit = 0

        cp_agent_MRS_array = generate_MRS_array([start_cp_agent_tot_ress], print_fine_dets=0)

        if print_fine_dets == 1 or print_model_2_dets == 1:
            print('\n\n\n cp_agent total res_array ', cp_agent.agent_res_array[0] + cp_agent.basket_array[0])
            print('\n cp_agent_MRS_array\n', cp_agent_MRS_array)
            print('\n cp_agent_min_res', cp_agent_min_res)
            print('\n iterate over resources to find cp_agent_net_benefit:')

        for res in range(num_res_founts):

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n res ', res)

            if res == cp_agent_min_res:

                cp_agent_net_benefit += cp_agent_ch_ress[cp_agent_min_res]

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n this is the same resource as min_res so no conversion necessary')
                    print(' cp_agent_ch_ress[cp_agent_min_res] =', cp_agent_ch_ress[cp_agent_min_res])

            else:

                cp_agent_net_benefit += cp_agent_MRS_array[cp_agent_min_res][res] * cp_agent_ch_ress[res]

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n this is a different resource to min_res')
                    print(' cp_agent_MRS_array[cp_agent_min_res][res]', cp_agent_MRS_array[cp_agent_min_res][res])
                    print(' cp_agent_ch_ress[res]', cp_agent_ch_ress[res])
                    print(' cp_agent_MRS_array[cp_agent_min_res][res] * cp_agent_ch_ress[res]',
                          cp_agent_MRS_array[cp_agent_min_res][res] * cp_agent_ch_ress[res])

        # if cp_agent_net_benefit > 20.0 and day > 200:
        #     print_fine_dets = 1

        # if print_fine_dets or print_for_tracking or print_PTP_effect_loc:
        #     print(' after iterating: cp_agent_net_benefit = ', cp_agent_net_benefit)
        #
        # if print_PTP_effect_loc:
        #     print(' after iterating: agent_net_benefit = ', agent_net_benefit)

        # ch_cp_agent_prop_steal = (adjust_props_r * cp_agent_net_benefit) * cp_agent.prop_steal * (
        #             1 - cp_agent.prop_steal)
        # ch_cp_agent_prop_fight_back = (adjust_props_r * cp_agent_net_benefit) * cp_agent.prop_fight_back * (
        #             1 - cp_agent.prop_fight_back)
        #
        # if print_fine_dets == 1 or print_model_2_dets == 1:
        #     print('\n ch_cp_agent_prop_steal =', ch_cp_agent_prop_steal)
        #     print(' ch_cp_agent_prop_fight_back =', ch_cp_agent_prop_fight_back)

        # if we are respecting property rights then we set two of the transaction's attributes:
        if respect_property_rights and max_cons_surp_ch > 0.0:      # latter term means there was a transaction

            if params.target_location_weights == 'crude':

                transaction.agent_a_reduced_value = 1.0
                transaction.agent_b_reduced_value = 1.0

            elif params.target_location_weights == 'reduced_value':

                transaction.agent_a_reduced_value = agent_net_benefit
                transaction.agent_b_reduced_value = cp_agent_net_benefit

        # at the end of the interaction, if the agents are not respecting property rights, we must adjust their propensities to steal and fight back.  We do this
        # by using a logistic equation: the net benefit of the players' strategy determines the change on prop_steal and prop_fight_back
        if respect_property_rights == 0 and agent_dec != 'none' and cp_agent_dec != 'none':

            # defaults:
            agent_record = None
            cp_agent_record = None

            # if params.use_NNs:

                # if params.learning_feedback_scale == '1/2.0':
                #
                #     agent_net_benefit_back_prop = np.sign(agent_net_benefit) * (np.abs(agent_net_benefit)) ** (1 / 2.0)
                #     cp_agent_net_benefit_back_prop = np.sign(cp_agent_net_benefit) * (np.abs(cp_agent_net_benefit)) ** (1 / 2.0)
                #
                # elif params.learning_feedback_scale == '1/3.0':
                #
                #     agent_net_benefit_back_prop = np.sign(agent_net_benefit) * (np.abs(agent_net_benefit)) ** (1 / 3.0)
                #     cp_agent_net_benefit_back_prop = np.sign(cp_agent_net_benefit) * (np.abs(cp_agent_net_benefit)) ** (1 / 3.0)

            # if (strat_choice == 'rational' and stranger_int == 'full') is False:

            # print('params.learning_feedback_scale', params.learning_feedback_scale)

            # find agent_net_benefit_back_prop and cp_agent_net_benefit_back_prop (note we use these data even without NNs)
            if params.learning_feedback_scale == '+/-1':

                agent_net_benefit_back_prop = np.sign(agent_net_benefit)
                cp_agent_net_benefit_back_prop = np.sign(cp_agent_net_benefit)

                if params.net_benefit_feedback == 'relative_fb_only':

                    # Note we have to compare agent and cp's net_benefits with their expectations of returns in quads 2 & 3 differently:
                    if agent_dec != 'steal' and cp_agent_dec == 'steal':            # i.e. Q2

                        agent_net_benefit_back_prop_fb = np.sign(agent_net_benefit - ag_exp_quad_2_rtn)
                        cp_agent_net_benefit_back_prop_fb = np.sign(cp_agent_net_benefit - cp_exp_quad_2_rtn)

                    elif agent_dec == 'steal' and cp_agent_dec != 'steal':          # i.e. Q3

                        agent_net_benefit_back_prop_fb = np.sign(agent_net_benefit - ag_exp_quad_3_rtn)
                        cp_agent_net_benefit_back_prop_fb = np.sign(cp_agent_net_benefit - cp_exp_quad_3_rtn)

                    else:

                        agent_net_benefit_back_prop_fb = 0.0
                        cp_agent_net_benefit_back_prop_fb = 0.0

                    # agent_net_benefit_back_prop_fb = np.sign(agent_net_benefit)
                    # cp_agent_net_benefit_back_prop_fb = np.sign(cp_agent_net_benefit)

            else:

                if params.net_benefit_feedback == 'absolute':

                    agent_net_benefit_back_prop = np.sign(agent_net_benefit) * ((np.abs(agent_net_benefit)) ** (params.learning_feedback_scale))
                    cp_agent_net_benefit_back_prop = np.sign(cp_agent_net_benefit) * ((np.abs(cp_agent_net_benefit)) ** (params.learning_feedback_scale))

                    agent_net_benefit_back_prop_fb = agent_net_benefit_back_prop
                    cp_agent_net_benefit_back_prop_fb = cp_agent_net_benefit_back_prop

                elif params.net_benefit_feedback == 'relative':     #

                    agent_net_benefit_back_prop = np.sign(agent_net_benefit - ag_exp_overall_rtn) * ((np.abs(agent_net_benefit - ag_exp_overall_rtn)) ** (params.learning_feedback_scale))
                    cp_agent_net_benefit_back_prop = np.sign(cp_agent_net_benefit - cp_exp_cp_overall_rtn) * ((np.abs(cp_agent_net_benefit - cp_exp_cp_overall_rtn)) ** (params.learning_feedback_scale))

                    agent_net_benefit_back_prop_fb = np.sign(agent_net_benefit - ag_exp_quad_2_rtn) * ((np.abs(agent_net_benefit - ag_exp_quad_2_rtn)) ** (params.learning_feedback_scale))
                    cp_agent_net_benefit_back_prop_fb = np.sign(cp_agent_net_benefit - cp_exp_quad_3_rtn) * ((np.abs(cp_agent_net_benefit - cp_exp_quad_3_rtn)) ** (params.learning_feedback_scale))

                elif params.net_benefit_feedback == 'relative_fb_only' or params.net_benefit_feedback == 'relative_fb_fight_only':

                    # used for ps's:
                    agent_net_benefit_back_prop = np.sign(agent_net_benefit) * ((np.abs(agent_net_benefit)) ** (params.learning_feedback_scale))
                    cp_agent_net_benefit_back_prop = np.sign(cp_agent_net_benefit) * ((np.abs(cp_agent_net_benefit)) ** (params.learning_feedback_scale))

                    # Now for pfb changes: we have to compare agent and cp's net_benefits with their expectations of returns in quads 2 & 3 differently:
                    if params.net_benefit_feedback == 'relative_fb_only':

                        if agent_dec != 'steal' and cp_agent_dec == 'steal':            # i.e. Q2

                            agent_net_benefit_back_prop_fb = np.sign(agent_net_benefit - ag_exp_quad_2_rtn) * ((np.abs(agent_net_benefit - ag_exp_quad_2_rtn)) ** (params.learning_feedback_scale))
                            cp_agent_net_benefit_back_prop_fb = np.sign(cp_agent_net_benefit - cp_exp_quad_2_rtn) * ((np.abs(cp_agent_net_benefit - cp_exp_quad_2_rtn)) ** (params.learning_feedback_scale))

                        elif agent_dec == 'steal' and cp_agent_dec != 'steal':          # i.e. Q3

                            agent_net_benefit_back_prop_fb = np.sign(agent_net_benefit - ag_exp_quad_3_rtn) * ((np.abs(agent_net_benefit - ag_exp_quad_3_rtn)) ** (params.learning_feedback_scale))
                            cp_agent_net_benefit_back_prop_fb = np.sign(cp_agent_net_benefit - cp_exp_quad_3_rtn) * ((np.abs(cp_agent_net_benefit - cp_exp_quad_3_rtn)) ** (params.learning_feedback_scale))

                        else:

                            agent_net_benefit_back_prop_fb = 0.0
                            cp_agent_net_benefit_back_prop_fb = 0.0

                    elif params.net_benefit_feedback == 'relative_fb_fight_only':

                        if agent_dec != 'steal' and cp_agent_dec == 'steal':            # i.e. Q2

                            if agent_dec == 'fight_back':

                                # here we compare the actual outcome with the expected return for 2F only - not Q2
                                agent_net_benefit_back_prop_fb = np.sign(agent_net_benefit - ag_2F_rtn) * ((np.abs(agent_net_benefit - ag_2F_rtn)) ** (params.learning_feedback_scale))
                                cp_agent_net_benefit_back_prop_fb = np.sign(cp_agent_net_benefit - cp_2F_rtn) * ((np.abs(cp_agent_net_benefit - cp_2F_rtn)) ** (params.learning_feedback_scale))

                            elif agent_dec == 'trade':

                                # we use an absolute change
                                agent_net_benefit_back_prop_fb = agent_net_benefit_back_prop
                                cp_agent_net_benefit_back_prop_fb = cp_agent_net_benefit_back_prop


                        elif agent_dec == 'steal' and cp_agent_dec != 'steal':          # i.e. Q3

                            if cp_agent_dec == 'fight_back':

                                # here we compare the actual outcome with the expected return for 3F only - not Q3
                                agent_net_benefit_back_prop_fb = np.sign(agent_net_benefit - ag_3F_rtn) * ((np.abs(agent_net_benefit - ag_3F_rtn)) ** (params.learning_feedback_scale))
                                cp_agent_net_benefit_back_prop_fb = np.sign(cp_agent_net_benefit - cp_3F_rtn) * ((np.abs(cp_agent_net_benefit - cp_3F_rtn)) ** (params.learning_feedback_scale))

                            elif cp_agent_dec == 'trade':

                                # we use an absolute change
                                agent_net_benefit_back_prop_fb = agent_net_benefit_back_prop
                                cp_agent_net_benefit_back_prop_fb = cp_agent_net_benefit_back_prop

                        else:

                            agent_net_benefit_back_prop_fb = 0.0
                            cp_agent_net_benefit_back_prop_fb = 0.0

                # if (agent.prop_fight_back < -5.0 or cp_agent.prop_fight_back < -5.0) and params.child_prop_std < 0.5:
                #
                #     # print_fine_dets = 1
                #     print('\n PROBLEM: agent.prop_fight_back < -5.0 or cp_agent.prop_fight_back < -5.0')

                # if we are introducing loss aversion then we take the above values (post **) and then add the loss_aversion_degree so +ve is x ** (params.learning_feedback_scale) and
                # -ve is 2 (x ** (params.learning_feedback_scale)).  Note if we do (2x) ** (params.learning_feedback_scale) then loss aversion degree is also scaled by ** (params.learning_feedback_scale)
                if params.loss_aversion_degree:

                    if agent_net_benefit_back_prop < 0:
                        agent_net_benefit_back_prop *= params.loss_aversion_degree

                    if cp_agent_net_benefit_back_prop < 0:
                        cp_agent_net_benefit_back_prop *= params.loss_aversion_degree

                    if agent_net_benefit_back_prop_fb < 0:
                        agent_net_benefit_back_prop_fb *= params.loss_aversion_degree

                    if cp_agent_net_benefit_back_prop_fb < 0:
                        cp_agent_net_benefit_back_prop_fb *= params.loss_aversion_degree

                if print_fine_dets:

                    print('\n\n params.net_benefit_feedback: ', params.net_benefit_feedback)
                    print(' params.adjust_props_r_linear', params.adjust_props_r_linear)
                    print(' agent_intn_beta', agent_intn_beta)

                    print('\n agent_net_benefit =', agent_net_benefit)
                    # print(' ag_exp_overall_rtn =', agent.exp_int_gains_dict[str(cp_agent)][2][0])
                    print(' ag_exp_quad_2_rtn =', ag_exp_quad_2_rtn)
                    print(' ag_exp_quad_3_rtn =', ag_exp_quad_3_rtn)
                    print(' params.learning_feedback_scale =', params.learning_feedback_scale)
                    print(' params.loss_aversion_degree =', params.loss_aversion_degree)
                    print(' agent_net_benefit_back_prop =', agent_net_benefit_back_prop)
                    print(' agent_net_benefit_back_prop_fb =', agent_net_benefit_back_prop_fb)

                    print('\n cp_agent_net_benefit =', cp_agent_net_benefit)
                    # print(' cp_exp_overall_rtn =', agent.exp_int_gains_dict[str(cp_agent)][2][1])
                    print(' cp_exp_quad_2_rtn =', cp_exp_quad_2_rtn)
                    print(' cp_exp_quad_3_rtn =', cp_exp_quad_3_rtn)
                    print(' cp_agent_net_benefit_back_prop =', cp_agent_net_benefit_back_prop)
                    print(' cp_agent_net_benefit_back_prop_fb', cp_agent_net_benefit_back_prop_fb)

                    # pause()

            if print_PTP_effect_loc:

                print('\n cp_agent_net_benefit_back_prop =', cp_agent_net_benefit_back_prop, 'cp_agent_net_benefit_back_prop_fb =', cp_agent_net_benefit_back_prop_fb)
                print(' agent_net_benefit_back_prop =', agent_net_benefit_back_prop, 'agent_net_benefit_back_prop_fb =', agent_net_benefit_back_prop_fb)

            if print_fine_dets or print_for_tracking:

                print('\n agent_dec', agent_dec)
                print(' cp_agent_dec', cp_agent_dec)

                if fight_winner is agent:
                    print('\n fight_winner: agent')
                elif fight_winner is cp_agent:
                    print('\n fight_winner: cp')
                else:
                    print('\n fight_winner: none')

                # print('\n agent_net_benefit =', agent_net_benefit)
                # print(' cp_agent_net_benefit =', cp_agent_net_benefit)

                if params.use_NNs:

                    print('\n agent_net_benefit_back_prop =', agent_net_benefit_back_prop)
                    print(' cp_agent_net_benefit_back_prop =', cp_agent_net_benefit_back_prop)

            # Now we have to adjust the agents' propensities to steal and fight back set_agent_target
            # propensities_change determines the way propensities change - they can be 'linear' or 'logistic'.
            # adjust_props_r_linear is the rate of change when propensities change in a linear way.
            if agent_dec == 'steal' and cp_agent_dec == 'steal':  # straight fight - no fighting back here, both chose to steal

                if fix_ps_fb_0 != 1 and params.use_NNs == 0:

                    if params.change_one_only != 1 and agent.tribe == cp_agent.tribe and strat_choice == 'propensities' and\
                            (strangers_if_unknown == 0 or (strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and cp_agent.agent_knows_cp_dict[str(agent)])):

                        if params.propensities_change == 'logistic' and params.fixed_prop_steal is None:

                            # the gain to the agent uses a logistic equation - it uses the gain (loss) to the agent plus (minus) the gain (loss) to the cp_agent (* some beta fraction)
                            agent.prop_steal += adjust_props_r * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                            cp_agent.prop_steal += adjust_props_r * (cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta)) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                        elif params.propensities_change == 'linear' and params.fixed_prop_steal is None:

                            agent.prop_steal += params.adjust_props_r_linear * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta))
                            cp_agent.prop_steal += params.adjust_props_r_linear * (cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta))

                    # if we're only changing one agent:
                    if params.change_one_only and (agent is agent_population.change_agent or cp_agent is agent_population.change_agent):

                        if params.propensities_change == 'logistic':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += adjust_props_r * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += adjust_props_r * (cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta)) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                        elif params.propensities_change == 'linear':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += params.adjust_props_r_linear * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta))

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += params.adjust_props_r_linear * (cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta))

                if params.use_NNs:

                    agent_net_gain_NNs = np.array([[agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta)], [0.0]])
                    cp_agent_net_gain_NNs = np.array([[cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta)], [0.0]])

                    ag_ch_prop_steal_simple = adjust_props_r * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                    cp_ch_prop_steal_simple = adjust_props_r * (cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta)) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                    ag_ch_prop_fb_simple = 0.0
                    cp_ch_prop_fb_simple = 0.0

                agent_record = [str(cp_agent), 1, 0, 1, 0]  # [1 is whether other agent fought; [2] is whether they fought back; [3] is whether I fought; [4] is whether I fought back]
                cp_agent_record = [str(agent), 1, 0, 1, 0]

            elif agent_dec == 'steal' and cp_agent_dec == 'fight_back':  # then cp_agent fought back - if it won we add to prop_fight_back; if lost, subtract

                if fix_ps_fb_0 != 1 and params.fixed_prop_steal is None and params.use_NNs == 0:

                    if params.change_one_only != 1 and agent.tribe == cp_agent.tribe and strat_choice == 'propensities' and\
                            (strangers_if_unknown == 0 or (strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and cp_agent.agent_knows_cp_dict[str(agent)])):

                        if params.propensities_change == 'logistic':

                            if params.fixed_prop_steal is None:

                                agent.prop_steal += adjust_props_r * (agent_net_benefit_back_prop - (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                                cp_agent.prop_steal += adjust_props_r * ((agent_net_benefit_back_prop * agent_intn_beta) - cp_agent_net_benefit_back_prop) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                            if params.fix_prop_fb is None:

                                agent.prop_fight_back += adjust_props_r * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta) * agent.prop_fight_back * (1 - agent.prop_fight_back)
                                cp_agent.prop_fight_back += adjust_props_r * cp_agent_net_benefit_back_prop_fb * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                        elif params.propensities_change == 'linear':

                            if params.fixed_prop_steal is None:

                                agent.prop_steal += params.adjust_props_r_linear * (agent_net_benefit_back_prop - (cp_agent_net_benefit_back_prop * agent_intn_beta))
                                cp_agent.prop_steal += params.adjust_props_r_linear * ((agent_net_benefit_back_prop * agent_intn_beta) - cp_agent_net_benefit_back_prop)

                            if params.fix_prop_fb is None:

                                agent.prop_fight_back += params.adjust_props_r_linear * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta)
                                cp_agent.prop_fight_back += params.adjust_props_r_linear * cp_agent_net_benefit_back_prop_fb

                    # if we're only changing one agent:
                    if params.change_one_only and (agent is agent_population.change_agent or cp_agent is agent_population.change_agent):

                        if params.propensities_change == 'logistic':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += adjust_props_r * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                                if params.fix_prop_fb != 0:
                                    agent.prop_fight_back += adjust_props_r * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta) * agent.prop_fight_back * (1 - agent.prop_fight_back)

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += adjust_props_r * ((agent_net_benefit_back_prop * agent_intn_beta) + cp_agent_net_benefit_back_prop) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)
                                if params.fix_prop_fb != 0:
                                    cp_agent.prop_fight_back += adjust_props_r * cp_agent_net_benefit_back_prop_fb * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                        elif params.propensities_change == 'linear':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += params.adjust_props_r_linear * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta))
                                if params.fix_prop_fb != 0:
                                    agent.prop_fight_back += params.adjust_props_r_linear * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta)

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += params.adjust_props_r_linear * ((agent_net_benefit_back_prop * agent_intn_beta) + cp_agent_net_benefit_back_prop)
                                if params.fix_prop_fb != 0:
                                    cp_agent.prop_fight_back += params.adjust_props_r_linear * cp_agent_net_benefit_back_prop_fb

                if params.use_NNs:

                    agent_net_gain_NNs = np.array([[agent_net_benefit_back_prop - (cp_agent_net_benefit_back_prop * agent_intn_beta)], [cp_agent_net_benefit_back_prop_fb * agent_intn_beta]])
                    cp_agent_net_gain_NNs = np.array([[(agent_net_benefit_back_prop * agent_intn_beta) - cp_agent_net_benefit_back_prop], [cp_agent_net_benefit_back_prop_fb]])

                    ag_ch_prop_steal_simple = adjust_props_r * (agent_net_benefit_back_prop - (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                    cp_ch_prop_steal_simple = adjust_props_r * ((agent_net_benefit_back_prop * agent_intn_beta) - cp_agent_net_benefit_back_prop) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                    ag_ch_prop_fb_simple = adjust_props_r * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta) * agent.prop_fight_back * (1 - agent.prop_fight_back)
                    cp_ch_prop_fb_simple = adjust_props_r * cp_agent_net_benefit_back_prop_fb * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                agent_record = [str(cp_agent), 0, 1, 1, 0]
                cp_agent_record = [str(agent), 1, 0, 0, 1]

            elif agent_dec == 'fight_back' and cp_agent_dec == 'steal':  # then agent fought back - if it won we add to prop_fight_back; if lost, subtract

                if fix_ps_fb_0 != 1 and params.use_NNs == 0:

                    if params.change_one_only != 1 and agent.tribe == cp_agent.tribe and strat_choice == 'propensities' and\
                            (strangers_if_unknown == 0 or (strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and cp_agent.agent_knows_cp_dict[str(agent)])):

                        if params.propensities_change == 'logistic':

                            if params.fixed_prop_steal is None:

                                agent.prop_steal += adjust_props_r * ((-1 * agent_net_benefit_back_prop) + (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                                cp_agent.prop_steal += adjust_props_r * ((-1 * agent_net_benefit_back_prop * agent_intn_beta) + cp_agent_net_benefit_back_prop) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                            if params.fix_prop_fb is None:

                                agent.prop_fight_back += adjust_props_r * agent_net_benefit_back_prop_fb * agent.prop_fight_back * (1 - agent.prop_fight_back)
                                cp_agent.prop_fight_back += adjust_props_r * (agent_net_benefit_back_prop_fb * agent_intn_beta) * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                        elif params.propensities_change == 'linear':

                            if params.fixed_prop_steal is None:

                                agent.prop_steal += params.adjust_props_r_linear * ((-1 * agent_net_benefit_back_prop) + (cp_agent_net_benefit_back_prop * agent_intn_beta))
                                cp_agent.prop_steal += params.adjust_props_r_linear * ((-1 * agent_net_benefit_back_prop * agent_intn_beta) + cp_agent_net_benefit_back_prop)

                            if params.fix_prop_fb is None:

                                agent.prop_fight_back += params.adjust_props_r_linear * agent_net_benefit_back_prop_fb
                                cp_agent.prop_fight_back += params.adjust_props_r_linear * (agent_net_benefit_back_prop_fb * agent_intn_beta)

                    # if we're only changing one agent:
                    if params.change_one_only and (agent is agent_population.change_agent or cp_agent is agent_population.change_agent):

                        if params.propensities_change == 'logistic':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += adjust_props_r * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                                if params.fix_prop_fb != 0:
                                    agent.prop_fight_back += (adjust_props_r * agent_net_benefit_back_prop_fb) * agent.prop_fight_back * (1 - agent.prop_fight_back)

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += adjust_props_r * ((agent_net_benefit_back_prop * agent_intn_beta) + cp_agent_net_benefit_back_prop) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)
                                if params.fix_prop_fb != 0:
                                    cp_agent.prop_fight_back += adjust_props_r * (agent_net_benefit_back_prop_fb * agent_intn_beta) * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                        elif params.propensities_change == 'linear':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += params.adjust_props_r_linear * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta))
                                if params.fix_prop_fb != 0:
                                    agent.prop_fight_back += (params.adjust_props_r_linear * agent_net_benefit_back_prop_fb)

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += params.adjust_props_r_linear * ((agent_net_benefit_back_prop * agent_intn_beta) + cp_agent_net_benefit_back_prop)
                                if params.fix_prop_fb != 0:
                                    cp_agent.prop_fight_back += params.adjust_props_r_linear * (agent_net_benefit_back_prop_fb * agent_intn_beta)

                if params.use_NNs:

                    agent_net_gain_NNs = np.array([[(-1 * agent_net_benefit_back_prop) + (cp_agent_net_benefit_back_prop * agent_intn_beta)], [agent_net_benefit_back_prop_fb]])
                    cp_agent_net_gain_NNs = np.array([[(-1 * agent_net_benefit_back_prop * agent_intn_beta) + cp_agent_net_benefit_back_prop], [agent_net_benefit_back_prop_fb * agent_intn_beta]])

                    ag_ch_prop_steal_simple = adjust_props_r * ((-1 * agent_net_benefit_back_prop) + (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                    cp_ch_prop_steal_simple = adjust_props_r * ((-1 * agent_net_benefit_back_prop * agent_intn_beta) + cp_agent_net_benefit_back_prop) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                    ag_ch_prop_fb_simple = adjust_props_r * agent_net_benefit_back_prop_fb * agent.prop_fight_back * (1 - agent.prop_fight_back)
                    cp_ch_prop_fb_simple = adjust_props_r * (agent_net_benefit_back_prop_fb * agent_intn_beta) * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                agent_record = [str(cp_agent), 1, 0, 0, 1]
                cp_agent_record = [str(agent), 0, 1, 1, 0]

            elif agent_dec == 'steal' and cp_agent_dec == 'trade':  # then cp_agent wimped out: add agent's ch_agent_prop_steal to prop_steal; and cp_agent will have lost
                # out so we subtract loss to increase prop_fight_back

                if fix_ps_fb_0 != 1 and params.use_NNs == 0:

                    if params.change_one_only != 1 and agent.tribe == cp_agent.tribe and strat_choice == 'propensities' and\
                            (strangers_if_unknown == 0 or (strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and cp_agent.agent_knows_cp_dict[str(agent)])):

                        if params.propensities_change == 'logistic':

                            if params.fixed_prop_steal is None:

                                agent.prop_steal += adjust_props_r * (agent_net_benefit_back_prop - (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                                cp_agent.prop_steal += adjust_props_r * ((agent_net_benefit_back_prop * agent_intn_beta) - cp_agent_net_benefit_back_prop) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                            if params.fix_prop_fb is None:

                                agent.prop_fight_back += adjust_props_r * (-1 * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta)) * agent.prop_fight_back * (1 - agent.prop_fight_back)
                                cp_agent.prop_fight_back += adjust_props_r * (-1 * cp_agent_net_benefit_back_prop_fb) * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                        elif params.propensities_change == 'linear':

                            if params.fixed_prop_steal is None:

                                agent.prop_steal += params.adjust_props_r_linear * (agent_net_benefit_back_prop - (cp_agent_net_benefit_back_prop * agent_intn_beta))
                                cp_agent.prop_steal += params.adjust_props_r_linear * ((agent_net_benefit_back_prop * agent_intn_beta) - cp_agent_net_benefit_back_prop)

                            if params.fix_prop_fb is None:

                                agent.prop_fight_back += params.adjust_props_r_linear * (-1 * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta))
                                cp_agent.prop_fight_back += params.adjust_props_r_linear * (-1 * cp_agent_net_benefit_back_prop_fb)

                    # if we're only changing one agent:
                    if params.change_one_only and (agent is agent_population.change_agent or cp_agent is agent_population.change_agent):

                        if params.propensities_change == 'logistic':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += adjust_props_r * (agent_net_benefit_back_prop - (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                                if params.fix_prop_fb != 0:
                                    agent.prop_fight_back += adjust_props_r * (-1 * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta)) * agent.prop_fight_back * ( 1 - agent.prop_fight_back)

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += adjust_props_r * ((agent_net_benefit_back_prop * agent_intn_beta) - cp_agent_net_benefit_back_prop) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)
                                if params.fix_prop_fb != 0:
                                    cp_agent.prop_fight_back += adjust_props_r * (-1 * cp_agent_net_benefit_back_prop_fb) * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                        elif params.propensities_change == 'linear':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += params.adjust_props_r_linear * (agent_net_benefit_back_prop - (cp_agent_net_benefit_back_prop * agent_intn_beta))
                                if params.fix_prop_fb != 0:
                                    agent.prop_fight_back += params.adjust_props_r_linear * (-1 * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta))

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += params.adjust_props_r_linear * ((agent_net_benefit_back_prop * agent_intn_beta) - cp_agent_net_benefit_back_prop)
                                if params.fix_prop_fb != 0:
                                    cp_agent.prop_fight_back += params.adjust_props_r_linear * (-1 * cp_agent_net_benefit_back_prop_fb)

                if params.use_NNs:

                    agent_net_gain_NNs = np.array([[agent_net_benefit_back_prop - (cp_agent_net_benefit_back_prop * agent_intn_beta)], [-1 * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta)]])
                    cp_agent_net_gain_NNs = np.array([[(agent_net_benefit_back_prop * agent_intn_beta) - cp_agent_net_benefit_back_prop], [-1 * cp_agent_net_benefit_back_prop_fb]])

                    ag_ch_prop_steal_simple = adjust_props_r * (agent_net_benefit_back_prop - (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal)
                    cp_ch_prop_steal_simple = adjust_props_r * ((agent_net_benefit_back_prop * agent_intn_beta) - cp_agent_net_benefit_back_prop) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                    ag_ch_prop_fb_simple = adjust_props_r * (-1 * (cp_agent_net_benefit_back_prop_fb * agent_intn_beta)) * agent.prop_fight_back * (1 - agent.prop_fight_back)
                    cp_ch_prop_fb_simple = adjust_props_r * (-1 * cp_agent_net_benefit_back_prop_fb) * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                agent_record = [str(cp_agent), 0, 0, 1, 0]
                cp_agent_record = [str(agent), 1, 0, 0, 0]

            elif agent_dec == 'trade' and cp_agent_dec == 'steal':  # then agent wimped out

                if fix_ps_fb_0 != 1 and params.use_NNs == 0:

                    if params.change_one_only != 1 and agent.tribe == cp_agent.tribe and strat_choice == 'propensities' and\
                            (strangers_if_unknown == 0 or (strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and cp_agent.agent_knows_cp_dict[str(agent)])):

                        if params.propensities_change == 'logistic':

                            if params.fixed_prop_steal is None:

                                agent.prop_steal += adjust_props_r * ((cp_agent_net_benefit_back_prop * agent_intn_beta) - agent_net_benefit_back_prop) * agent.prop_steal * (1 - agent.prop_steal)
                                cp_agent.prop_steal += adjust_props_r * (cp_agent_net_benefit_back_prop - (agent_net_benefit_back_prop * agent_intn_beta)) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                            if params.fix_prop_fb is None:

                                agent.prop_fight_back += adjust_props_r * (-1 * agent_net_benefit_back_prop_fb) * agent.prop_fight_back * (1 - agent.prop_fight_back)
                                cp_agent.prop_fight_back += adjust_props_r * (-1 * agent_net_benefit_back_prop_fb * agent_intn_beta) * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                        elif params.propensities_change == 'linear':

                            if params.fixed_prop_steal is None:

                                agent.prop_steal += params.adjust_props_r_linear * ((cp_agent_net_benefit_back_prop * agent_intn_beta) - agent_net_benefit_back_prop)
                                cp_agent.prop_steal += params.adjust_props_r_linear * (cp_agent_net_benefit_back_prop - (agent_net_benefit_back_prop * agent_intn_beta))

                            if params.fix_prop_fb is None:

                                agent.prop_fight_back += params.adjust_props_r_linear * (-1 * agent_net_benefit_back_prop_fb)
                                cp_agent.prop_fight_back += params.adjust_props_r_linear * (-1 * agent_net_benefit_back_prop_fb * agent_intn_beta)

                    # if we're only changing one agent:
                    if params.change_one_only and (agent is agent_population.change_agent or cp_agent is agent_population.change_agent):

                        if params.propensities_change == 'logistic':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += adjust_props_r * ((cp_agent_net_benefit_back_prop * agent_intn_beta) - agent_net_benefit_back_prop) * agent.prop_steal * (1 - agent.prop_steal)
                                if params.fix_prop_fb != 0:
                                    agent.prop_fight_back += adjust_props_r * (-1 * agent_net_benefit_back_prop_fb) * agent.prop_fight_back * (1 - agent.prop_fight_back)

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += adjust_props_r * (cp_agent_net_benefit_back_prop - (agent_net_benefit_back_prop * agent_intn_beta)) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)
                                if params.fix_prop_fb != 0:
                                    cp_agent.prop_fight_back += adjust_props_r * (-1 * agent_net_benefit_back_prop_fb * agent_intn_beta) * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                        elif params.propensities_change == 'linear':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += params.adjust_props_r_linear * ((cp_agent_net_benefit_back_prop * agent_intn_beta) - agent_net_benefit_back_prop)
                                if params.fix_prop_fb != 0:
                                    agent.prop_fight_back += params.adjust_props_r_linear * (-1 * agent_net_benefit_back_prop_fb)

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += params.adjust_props_r_linear * (cp_agent_net_benefit_back_prop - (agent_net_benefit_back_prop * agent_intn_beta))
                                if params.fix_prop_fb != 0:
                                    cp_agent.prop_fight_back += params.adjust_props_r_linear * (-1 * agent_net_benefit_back_prop_fb * agent_intn_beta)

                if params.use_NNs:

                    agent_net_gain_NNs = np.array([[(cp_agent_net_benefit_back_prop * agent_intn_beta) - agent_net_benefit_back_prop], [-1 * agent_net_benefit_back_prop_fb]])
                    cp_agent_net_gain_NNs = np.array([[cp_agent_net_benefit_back_prop - (agent_net_benefit_back_prop * agent_intn_beta)], [-1 * agent_net_benefit_back_prop_fb * agent_intn_beta]])

                    ag_ch_prop_steal_simple = adjust_props_r * ((cp_agent_net_benefit_back_prop * agent_intn_beta) - agent_net_benefit_back_prop) * agent.prop_steal * (1 - agent.prop_steal)
                    cp_ch_prop_steal_simple = adjust_props_r * (cp_agent_net_benefit_back_prop - (agent_net_benefit_back_prop * agent_intn_beta)) * cp_agent.prop_steal * (1 - cp_agent.prop_steal)

                    ag_ch_prop_fb_simple = adjust_props_r * (-1 * agent_net_benefit_back_prop_fb) * agent.prop_fight_back * (1 - agent.prop_fight_back)
                    cp_ch_prop_fb_simple = adjust_props_r * (-1 * agent_net_benefit_back_prop_fb * agent_intn_beta) * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                agent_record = [str(cp_agent), 1, 0, 0, 0]
                cp_agent_record = [str(agent), 0, 0, 1, 0]

            elif agents_trade_peacefully:

                if fix_ps_fb_0 != 1 and params.use_NNs == 0:

                    if params.change_one_only != 1 and agent.tribe == cp_agent.tribe and strat_choice == 'propensities' and\
                            (strangers_if_unknown == 0 or (strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and cp_agent.agent_knows_cp_dict[str(agent)])):

                        if params.propensities_change == 'logistic' and params.fixed_prop_steal is None:

                            agent.prop_steal += -1 * (adjust_props_r * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal))
                            cp_agent.prop_steal += -1 * (adjust_props_r * (cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta)) * cp_agent.prop_steal * (1 - cp_agent.prop_steal))

                        elif params.propensities_change == 'linear' and params.fixed_prop_steal is None:

                            agent.prop_steal += -1 * params.adjust_props_r_linear * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta))
                            cp_agent.prop_steal += -1 * params.adjust_props_r_linear * (cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta))

                    # if we're only changing one agent:
                    if params.change_one_only and (agent is agent_population.change_agent or cp_agent is agent_population.change_agent):

                        if params.propensities_change == 'logistic':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += -1 * (adjust_props_r * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal))

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += -1 * (adjust_props_r * (cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta)) * cp_agent.prop_steal * (1 - cp_agent.prop_steal))

                        elif params.propensities_change == 'linear':

                            if agent is agent_population.change_agent:
                                agent.prop_steal += -1 * (params.adjust_props_r_linear * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta)))

                            if cp_agent is agent_population.change_agent:
                                cp_agent.prop_steal += -1 * (params.adjust_props_r_linear * (cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta)))

                if params.use_NNs:

                    agent_net_gain_NNs = np.array([[(-1 * agent_net_benefit_back_prop) - (cp_agent_net_benefit_back_prop * agent_intn_beta)], [0.0]])
                    cp_agent_net_gain_NNs = np.array([[(-1 * cp_agent_net_benefit_back_prop) - (agent_net_benefit_back_prop * agent_intn_beta)], [0.0]])

                    ag_ch_prop_steal_simple = -1 * (adjust_props_r * (agent_net_benefit_back_prop + (cp_agent_net_benefit_back_prop * agent_intn_beta)) * agent.prop_steal * (1 - agent.prop_steal))
                    cp_ch_prop_steal_simple = -1 * (adjust_props_r * (cp_agent_net_benefit_back_prop + (agent_net_benefit_back_prop * agent_intn_beta)) * cp_agent.prop_steal * (1 - cp_agent.prop_steal))

                    ag_ch_prop_fb_simple = 0.0
                    cp_ch_prop_fb_simple = 0.0

                # add to reputations dict's
                if str(cp_agent) not in agent.reputations_dict:  # this is where a new entry in the dict occurs

                    agent.reputations_dict[str(cp_agent)] = [np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int)]

                agent.reputations_dict[str(cp_agent)][1][day] += 1

                # now the cp_agent:
                if str(agent) not in cp_agent.reputations_dict:
                    cp_agent.reputations_dict[str(agent)] = [np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int)]

                cp_agent.reputations_dict[str(agent)][1][day] += 1

                # update this also
                agent.agent_knows_cp_dict[str(cp_agent)] = 1
                cp_agent.agent_knows_cp_dict[str(agent)] = 1

                # we update these arrays, which helps us shortcut some of the coding when agents evaluate each other.  We only record trans in last_intn if they have traded
                if transaction is not None:

                    if transaction.good_a is not None:

                        agent.last_intn = transaction
                        cp_agent.last_intn = transaction

                        # we also update these values - we only update the reputations data when we need to and this is part of that process
                        agent.need_to_update_reps[str(cp_agent)] = 1
                        cp_agent.need_to_update_reps[str(agent)] = 1

                    agent.trades_array.append(transaction)
                    cp_agent.trades_array.append(transaction)

                    # we also add information to the transaction
                    if params.target_location_weights == 'crude':

                        transaction.agent_a_reduced_value = 1.0
                        transaction.agent_b_reduced_value = 1.0

                    elif params.target_location_weights == 'reduced_value':

                        transaction.agent_a_reduced_value = agent_net_benefit_back_prop
                        transaction.agent_b_reduced_value = cp_agent_net_benefit_back_prop

                    if print_fine_dets:
                        print('\n transaction.agent_a_reduced_value =', transaction.agent_a_reduced_value)
                        print(' transaction.agent_b_reduced_value =', transaction.agent_b_reduced_value)

                    if respect_property_rights == 0:

                        # add ps and pfb data to transaction object
                        transaction.initiator_new_prop_steal = copy.copy(agent.prop_steal)
                        transaction.initiator_new_prop_fight_back = copy.copy(agent.prop_fight_back)
                        transaction.counterpart_new_prop_steal = copy.copy(cp_agent.prop_steal)
                        transaction.counterpart_new_prop_fight_back = copy.copy(cp_agent.prop_fight_back)

                        transaction.initiator_start_prop_steal = initiator_start_prop_steal
                        transaction.initiator_start_prop_fight_back = initiator_start_prop_fight_back
                        transaction.counterpart_start_prop_steal = counterpart_start_prop_steal
                        transaction.counterpart_start_prop_fight_back = counterpart_start_prop_fight_back

            # here we want to add any change in prop_steal to two databases - ps_contr_RL_pos and ps_contr_RL_neg
            if params.habit_val_props:

                ch_agent_prop_steal = agent.prop_steal - initiator_start_prop_steal

                if ch_agent_prop_steal > 0.0:
                    agent.ps_contr_RL_pos[day] += ch_agent_prop_steal
                elif ch_agent_prop_steal < 0.0:
                    agent.ps_contr_RL_neg[day] -= ch_agent_prop_steal

                ch_cp_agent_prop_steal = cp_agent.prop_steal - counterpart_start_prop_steal

                if ch_cp_agent_prop_steal > 0.0:
                    cp_agent.ps_contr_RL_pos[day] += ch_cp_agent_prop_steal
                elif ch_cp_agent_prop_steal < 0.0:
                    cp_agent.ps_contr_RL_neg[day] -= ch_cp_agent_prop_steal

            # here we add an habituation variable when params.habit_val_props > 0
            if params.habit_val_props and params.track_agent and params.track_agent > day and (agent_population.tracking_agent == agent or agent_population.tracking_agent == cp_agent):
                print('\n pre-habituation:')
                print(' agent.prop_steal', agent.prop_steal, ' agent.prop_fight_back', agent.prop_fight_back)
                print(' cp_agent.prop_steal', cp_agent.prop_steal, ' cp_agent.prop_fight_back', cp_agent.prop_fight_back)
                print(' agent_dec =', agent_dec)
                print(' cp_agent_dec =', cp_agent_dec)

            if params.habit_val_props:

                # start with props steal:
                if agent_dec == 'trade' or agent_dec == 'fight_back':

                    agent.prop_steal -= params.habit_val_props
                    agent.ps_contr_hab_neg[day] += params.habit_val_props

                elif agent_dec == 'steal':

                    agent.prop_steal += params.habit_val_props
                    agent.ps_contr_hab_pos[day] += params.habit_val_props

                if cp_agent_dec == 'trade' or cp_agent_dec == 'fight_back':

                    cp_agent.prop_steal -= params.habit_val_props
                    cp_agent.ps_contr_hab_neg[day] += params.habit_val_props

                elif cp_agent_dec == 'steal':

                    cp_agent.prop_steal += params.habit_val_props
                    cp_agent.ps_contr_hab_pos[day] += params.habit_val_props

                # now props FB:
                if agent_dec == 'steal' and cp_agent_dec == 'fight_back':   # cp fought back

                    cp_agent.prop_fight_back += params.habit_val_props

                elif agent_dec == 'steal' and cp_agent_dec == 'trade':      # cp wimped out

                    cp_agent.prop_fight_back -= params.habit_val_props

                if agent_dec == 'fight_back' and cp_agent_dec == 'steal':    # agent fought back

                    agent.prop_fight_back += params.habit_val_props

                elif agent_dec == 'trade' and cp_agent_dec == 'steal':      # agent wimped out

                    agent.prop_fight_back -= params.habit_val_props

            if params.habit_val_props and params.track_agent and day >= params.track_agent and (agent_population.tracking_agent == agent or agent_population.tracking_agent == cp_agent):
                print('\n post-habituation:')
                print(' agent.prop_steal', agent.prop_steal, ' agent.prop_fight_back', agent.prop_fight_back)
                print(' cp_agent.prop_steal', cp_agent.prop_steal, ' cp_agent.prop_fight_back', cp_agent.prop_fight_back)
                # pause()

            if params.use_NNs:

                if print_fine_dets:
                    print('\n agent_net_benefit =', agent_net_benefit)
                    print(' agent_net_gain_NNs =\n', agent_net_gain_NNs)

                    print('\n cp_agent_net_benefit =', cp_agent_net_benefit)
                    print(' cp_agent_net_gain_NNs =\n', cp_agent_net_gain_NNs)

                if print_for_tracking:
                    print('\n agents now learn from their experiences - adjust NN coefficients')

                # for agent
                if params.num_NNs == 1:

                    agent.grads = L_model_backward_from_net_gain(agent.caches, agent_net_gain_NNs, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    update_parameters_net_gain(agent.NN_parameters, agent.grads, learning_rate=params.NN_learning_rate, print_fine_dets=0)

                elif params.num_NNs == 2:

                    agent.grads_ps = L_model_backward_from_net_gain(agent.caches_ps, agent_net_gain_NNs[0][0], params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    update_parameters_net_gain(agent.NN_parameters_ps, agent.grads_ps, learning_rate=params.NN_learning_rate, print_fine_dets=0)

                    agent.grads_pfb = L_model_backward_from_net_gain(agent.caches_pfb, agent_net_gain_NNs[1][0], params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    update_parameters_net_gain(agent.NN_parameters_pfb, agent.grads_pfb, learning_rate=params.NN_learning_rate, print_fine_dets=0)

                # for cp_agent
                if params.num_NNs == 1:

                    cp_agent.grads = L_model_backward_from_net_gain(cp_agent.caches, cp_agent_net_gain_NNs, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    update_parameters_net_gain(cp_agent.NN_parameters, cp_agent.grads, learning_rate=params.NN_learning_rate, print_fine_dets=0)

                elif params.num_NNs == 2:

                    cp_agent.grads_ps = L_model_backward_from_net_gain(cp_agent.caches_ps, cp_agent_net_gain_NNs[0][0], params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    update_parameters_net_gain(cp_agent.NN_parameters_ps, cp_agent.grads_ps, learning_rate=params.NN_learning_rate, print_fine_dets=0)

                    cp_agent.grads_pfb = L_model_backward_from_net_gain(cp_agent.caches_pfb, cp_agent_net_gain_NNs[1][0], params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                    update_parameters_net_gain(cp_agent.NN_parameters_pfb, cp_agent.grads_pfb, learning_rate=params.NN_learning_rate, print_fine_dets=0)

                # sense check: compare outcomes with same data
                if print_fine_dets or print_for_tracking or params.track_interactions_detailed:

                    if print_fine_dets or print_for_tracking:
                        print('\n sense check - compare previous probs with new probs given same data')

                    # agent:
                    if params.num_NNs == 1:

                        if print_fine_dets or print_for_tracking:
                            print('\n --> agent: previous agent.intn_probs =', agent.intn_probs[0][0], agent.intn_probs[1][0])

                        new_intn_probs, ignore = L_model_forward(flatten_rtns_matrix, agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        if print_fine_dets or print_for_tracking:
                            print('\n new_intn_probs =', new_intn_probs[0][0], new_intn_probs[1][0])
                            print(' changes: %7.6f, %7.6f' % (new_intn_probs[0][0] - agent.intn_probs[0][0], new_intn_probs[1][0] - agent.intn_probs[1][0]))

                    elif params.num_NNs == 2:

                        if print_fine_dets or print_for_tracking:
                            print('\n previous agent.intn_probs =', agent.intn_prob_ps[0][0], agent.intn_prob_pfb[0][0])

                        if params.NN_inputs == 'game_6':

                            new_intn_prob_ps, ignore = L_model_forward(flatten_rtns_matrix, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                            new_intn_prob_pfb, ignore = L_model_forward(flatten_rtns_matrix, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        elif params.NN_inputs == 'mixed':

                            # we have to work out pfb first
                            ag_pfb_inputs = np.array(flatten_rtns_matrix[2:6])

                            # print('\n flatten_rtns_matrix \n', flatten_rtns_matrix)
                            # print('\n ag_pfb_inputs \n', ag_pfb_inputs)

                            new_intn_prob_pfb, agent.caches_pfb = L_model_forward(ag_pfb_inputs, agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                            agent.prop_fight_back = new_intn_prob_pfb[0][0]

                            # print('\n agent.prop_fight_back =', agent.prop_fight_back)
                            # print('\n cp_pfb =', cp_pfb)

                            ag_ps_inputs = np.zeros(shape=(10, 1))

                            ag_ps_inputs[0:2] = flatten_rtns_matrix[0:2]
                            ag_ps_inputs[2] = (flatten_rtns_matrix[2] * agent.prop_fight_back) + (flatten_rtns_matrix[4] * (1 - agent.prop_fight_back))
                            ag_ps_inputs[3] = (flatten_rtns_matrix[3] * agent.prop_fight_back) + (flatten_rtns_matrix[5] * (1 - agent.prop_fight_back))
                            ag_ps_inputs[4] = (flatten_rtns_matrix[6] * cp_pfb) + (flatten_rtns_matrix[8] * (1 - cp_pfb))
                            ag_ps_inputs[5] = (flatten_rtns_matrix[7] * cp_pfb) + (flatten_rtns_matrix[9] * (1 - cp_pfb))
                            ag_ps_inputs[6:] = flatten_rtns_matrix[10:]

                            new_intn_prob_ps, agent.caches_ps = L_model_forward(ag_ps_inputs, agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                            # print('\n new_intn_prob_pfb \n', new_intn_prob_pfb)
                            # print('\n ag_ps_inputs = \n', ag_ps_inputs)
                            # print('\n agent.prop_steal =', agent.prop_steal)

                        if print_fine_dets or print_for_tracking:
                            print('\n new agent.intn_probs =', new_intn_prob_ps[0][0], new_intn_prob_pfb[0][0])
                            print(' changes: %7.6f, %7.6f' % (new_intn_prob_ps[0][0] - agent.intn_prob_ps[0][0], new_intn_prob_pfb[0][0] - agent.intn_prob_pfb[0][0]))

                    if print_fine_dets or print_for_tracking:
                        print('\n ag_ch_prop_steal_simple =', ag_ch_prop_steal_simple, ' ag_ch_prop_fb_simple =', ag_ch_prop_fb_simple)

                    if ag_ch_prop_steal_simple != 0.0:
                        ag_ps_prop = (new_intn_prob_ps[0][0] - agent.intn_prob_ps[0][0]) / ag_ch_prop_steal_simple
                    else:
                        ag_ps_prop = 0.0

                    if ag_ch_prop_fb_simple != 0.0:
                        ag_pfb_prop = (new_intn_prob_pfb[0][0] - agent.intn_prob_pfb[0][0]) / ag_ch_prop_fb_simple
                    else:
                        ag_pfb_prop = 0.0

                    if print_fine_dets or print_for_tracking:
                        print('\n agent: ratio of NN change in ps / simple =', ag_ps_prop, 'fight_back ratio = ', ag_pfb_prop)

                    # cp_agent:
                    if params.num_NNs == 1:

                        if print_fine_dets or print_for_tracking:
                            print('\n --> cp_agent: previous cp_agent.intn_probs =', cp_agent.intn_probs[0][0], cp_agent.intn_probs[1][0])

                        new_intn_prob_cp, ignore = L_model_forward(flatten_rtns_matrix, cp_agent.NN_parameters, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        if print_fine_dets or print_for_tracking:
                            print('\n new_intn_probs =', new_intn_prob_cp[0][0], new_intn_probs[1][0])
                            print(' changes: %7.6f, %7.6f' % (new_intn_prob_cp[0][0] - cp_agent.intn_probs[0][0], new_intn_prob_cp[1][0] - cp_agent.intn_probs[1][0]))

                    elif params.num_NNs == 2:

                        if print_fine_dets or print_for_tracking:
                            print('\n previous cp_agent.intn_probs =', cp_agent.intn_prob_ps[0][0], cp_agent.intn_prob_pfb[0][0])

                        if params.NN_inputs == 'game_6':

                            new_intn_prob_ps_cp, ignore = L_model_forward(flatten_rtns_matrix, cp_agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)
                            new_intn_prob_pfb_cp, ignore = L_model_forward(flatten_rtns_matrix, cp_agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                        elif params.NN_inputs == 'mixed':

                            # we have to work out pfb first
                            cp_pfb_inputs = np.array(flatten_rtns_matrix_cp[2:6])

                            # print('\n flatten_rtns_matrix_list_cp \n', flatten_rtns_matrix_cp)
                            # print('\n cp_pfb_inputs \n', cp_pfb_inputs)

                            new_intn_prob_pfb_cp, cp_agent.caches_pfb = L_model_forward(cp_pfb_inputs, cp_agent.NN_parameters_pfb, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                            cp_ps_inputs = np.zeros(shape=(10, 1))

                            cp_ps_inputs[0:2] = flatten_rtns_matrix_cp[0:2]
                            cp_ps_inputs[2] = (flatten_rtns_matrix_cp[2] * new_intn_prob_pfb_cp) + (flatten_rtns_matrix_cp[4] * (1 - new_intn_prob_pfb_cp))
                            cp_ps_inputs[3] = (flatten_rtns_matrix_cp[3] * new_intn_prob_pfb_cp) + (flatten_rtns_matrix_cp[5] * (1 - new_intn_prob_pfb_cp))
                            cp_ps_inputs[4] = (flatten_rtns_matrix_cp[6] * ag_pfb) + (flatten_rtns_matrix_cp[8] * (1 - ag_pfb))
                            cp_ps_inputs[5] = (flatten_rtns_matrix_cp[7] * ag_pfb) + (flatten_rtns_matrix_cp[9] * (1 - ag_pfb))
                            cp_ps_inputs[6:] = flatten_rtns_matrix_cp[10:]

                            new_intn_prob_ps_cp, cp_agent.caches_ps = L_model_forward(cp_ps_inputs, cp_agent.NN_parameters_ps, params.NN_mid_activation, params.sigmoid_coefficient, print_fine_dets=0)

                            # print('\n cp_agent.intn_prob_pfb \n', cp_agent.intn_prob_pfb)
                            # print('\n cp_ps_inputs = \n', cp_ps_inputs)

                        if print_fine_dets or print_for_tracking:
                            print('\n new cp_agent.intn_probs =', new_intn_prob_ps_cp[0][0], new_intn_prob_pfb_cp[0][0])
                            print(' changes: %7.6f, %7.6f' % (new_intn_prob_ps_cp[0][0] - cp_agent.intn_prob_ps[0][0], new_intn_prob_pfb_cp[0][0] - cp_agent.intn_prob_pfb[0][0]))

                    if print_fine_dets or print_for_tracking:
                        print('\n cp_ch_prop_steal_simple =', cp_ch_prop_steal_simple, ' cp_ch_prop_fb_simple =', cp_ch_prop_fb_simple)

                    if cp_ch_prop_steal_simple != 0.0:
                        cp_ps_prop = (new_intn_prob_ps_cp[0][0] - cp_agent.intn_prob_ps[0][0]) / cp_ch_prop_steal_simple
                    else:
                        cp_ps_prop = 0.0

                    if cp_ch_prop_fb_simple != 0.0:
                        ag_pfb_prop = (new_intn_prob_pfb_cp[0][0] - cp_agent.intn_prob_pfb[0][0]) / cp_ch_prop_fb_simple
                    else:
                        ag_pfb_prop = 0.0

                    if print_fine_dets or print_for_tracking:
                        print('\n cp: ratio of NN change in ps / simple =', cp_ps_prop, 'fight_back ratio = ', ag_pfb_prop)

            # print('\n params.limit_props =', params.limit_props)
            # pause()

            # set props' floors and ceiling (this means that props cannot get locked in to 1 or 0, which would mean they cannot change)
            if params.use_NNs == 0 and params.adjust_props_r != 0.0 and fix_ps_fb_0 != 1 and agent.tribe == cp_agent.tribe and \
                strat_choice == 'propensities' and (strangers_if_unknown == 0 or (strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and cp_agent.agent_knows_cp_dict[str(agent)])):

                if params.fixed_prop_steal is None:

                    if (params.change_one_only != 1 or (params.change_one_only == 1 and agent == agent_population.change_agent)):

                        # we don't want to limit the props if the agent is a black shoop and if black_shoop_prop_start == 1
                        if (params.black_shoop_prop_start == 1.0 and agent in agent_population.black_shoop_list) == False:

                            if params.limit_props:

                                if agent.prop_steal > prop_steal_ceil:
                                    agent.prop_steal = prop_steal_ceil

                                if agent.prop_steal < prop_steal_floor:
                                    agent.prop_steal = prop_steal_floor

                    if (params.change_one_only != 1 or (params.change_one_only == 1 and cp_agent == agent_population.change_agent)):

                        if (params.black_shoop_prop_start == 1.0 and cp_agent in agent_population.black_shoop_list) == False:

                            if params.limit_props:

                                if cp_agent.prop_steal > prop_steal_ceil:
                                    cp_agent.prop_steal = prop_steal_ceil

                                if cp_agent.prop_steal < prop_steal_floor:
                                    cp_agent.prop_steal = prop_steal_floor

                if params.fix_prop_fb is None:

                    if (params.change_one_only != 1 or (params.change_one_only == 1 and agent == agent_population.change_agent)):

                        if (params.black_shoop_prop_start == 1.0 and agent in agent_population.black_shoop_list) == False:

                            if params.limit_props:

                                if agent.prop_fight_back > prop_fight_back_ceil:
                                    agent.prop_fight_back = prop_fight_back_ceil

                                if agent.prop_fight_back < prop_fight_back_floor:
                                    agent.prop_fight_back = prop_fight_back_floor

                    if (params.change_one_only != 1 or (params.change_one_only == 1 and cp_agent == agent_population.change_agent)):

                        if (params.black_shoop_prop_start == 1.0 and cp_agent in agent_population.black_shoop_list) == False:

                            if params.limit_props:

                                if cp_agent.prop_fight_back > prop_fight_back_ceil:
                                    cp_agent.prop_fight_back = prop_fight_back_ceil

                                if cp_agent.prop_fight_back < prop_fight_back_floor:
                                    cp_agent.prop_fight_back = prop_fight_back_floor

            if print_fine_dets or print_for_tracking or print_model_2_dets:  # or np.abs(cp_agent.prop_steal - start_cp_agent_prop_steal) > 0.25 or np.abs(agent.prop_steal - start_agent_prop_steal) > 0.25) and day > 200:

                # print('\n\n\n\n agent_dec', agent_dec)
                # print('\n cp_agent_dec', cp_agent_dec)

                # print('\n agent benefit:', agent_net_benefit)
                # print(' cp_agent benefit:', cp_agent_net_benefit)

                # print('\n agent.agent_res_array ', agent.agent_res_array)
                # print(' agent_start_basket ', agent_start_basket)
                # print(' ag_exp_overall_rtn =', ag_exp_overall_rtn)
                # print(' agent_net_benefit =', agent_net_benefit)
                # print(' agent_net_benefit - ag_exp_overall_rtn =', agent_net_benefit - ag_exp_overall_rtn)
                # print(' agent_net_benefit_back_prop =', agent_net_benefit_back_prop)
                # print(' agent.prop_steal from %1.5f => %1.5f (ch %1.5f)' % (start_agent_prop_steal, agent.prop_steal, agent.prop_steal - start_agent_prop_steal),
                #       '  agent.prop_fight_back from %1.5f => %1.5f (ch %1.5f)' % (start_agent_prop_fight_back, agent.prop_fight_back, agent.prop_fight_back - start_agent_prop_fight_back))
                #
                # print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array)
                # print(' cp_agent_start_basket ', cp_agent_start_basket)
                # print(' cp_exp_cp_overall_rtn =', cp_exp_cp_overall_rtn)
                # print(' cp_agent_net_benefit =', cp_agent_net_benefit)
                # print(' cp_agent_net_benefit - cp_exp_cp_overall_rtn =', cp_agent_net_benefit - cp_exp_cp_overall_rtn)
                # print(' cp_agent_net_benefit_back_prop =', cp_agent_net_benefit_back_prop)
                # print(' cp_agent.prop_steal from %1.5f => %1.5f (ch %1.5f)' % (start_cp_agent_prop_steal, cp_agent.prop_steal, cp_agent.prop_steal - start_cp_agent_prop_steal),
                #     '  cp_agent.prop_fight_back from %1.5f => %1.5f (ch %1.5f)' % (start_cp_agent_prop_fight_back, cp_agent.prop_fight_back, cp_agent.prop_fight_back - start_cp_agent_prop_fight_back))

                print('\n final props:')
                print('\n agent.prop_steal from %1.5f => %1.5f (ch %1.5f)' % (start_agent_prop_steal, agent.prop_steal, agent.prop_steal - start_agent_prop_steal),
                      '  agent.prop_fight_back from %1.5f => %1.5f (ch %1.5f)' % (start_agent_prop_fight_back, agent.prop_fight_back, agent.prop_fight_back - start_agent_prop_fight_back))
                print(
                    ' cp_agent.prop_steal from %1.5f => %1.5f (ch %1.5f)' % (start_cp_agent_prop_steal, cp_agent.prop_steal, cp_agent.prop_steal - start_cp_agent_prop_steal),
                    '  cp_agent.prop_fight_back from %1.5f => %1.5f (ch %1.5f)' % (start_cp_agent_prop_fight_back, cp_agent.prop_fight_back, cp_agent.prop_fight_back - start_cp_agent_prop_fight_back))

                print('\n day =', day)
                print(' move =', move)

                print('\n agent.home =', agent.home)
                print(' cp_agent.home =', cp_agent.home)

                print('\n agent.grid_trgt =', agent.grid_trgt)
                print(' cp_agent.grid_trgt =', cp_agent.grid_trgt)

                print('\n agent.location =', agent.location)
                print(' cp_agent.location =', cp_agent.location)

                print('\n agent.agent_res_array ', agent.agent_res_array)
                print(' agent.basket_array =', agent.basket_array)

                print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array)
                print(' cp_agent.basket_array =', cp_agent.basket_array)

                print('\n self.stranger_int =', self.stranger_int)

                print('\n agent_dec =\t', agent_dec, 'res change', agent_ch_ress)
                print(' cp_agent_dec =\t', cp_agent_dec, 'res change', cp_agent_ch_ress)

                print('\n agent_net_benefit_back_prop = ', agent_net_benefit_back_prop)
                print(' cp_agent_net_benefit_back_prop = ', cp_agent_net_benefit_back_prop)

                print('\n params.learning_feedback_scale =', params.learning_feedback_scale)

                if agent == agent_population.tracking_agent:
                    print('\n tracking agent is agent \n')

                elif cp_agent == agent_population.tracking_agent:
                    print('\n tracking agent is cp_agent \n')

                # pause()

            if print_PTP_effect_loc:

                print(
                    '\n cp_agent.prop_steal from %1.5f => %1.5f' % (start_cp_agent_prop_steal, cp_agent.prop_steal),
                    '  cp_agent.prop_fight_back from %1.5f => %1.5f' % (
                    start_cp_agent_prop_fight_back, cp_agent.prop_fight_back))
                print(' agent.prop_steal from %1.5f => %1.5f' % (start_agent_prop_steal, agent.prop_steal),
                      '  agent.prop_fight_back from %1.5f => %1.5f' % (
                      start_agent_prop_fight_back, agent.prop_fight_back))

            # here, agents will head home if they currently have in their basket the reduced value of their start basket +2
            if params.agents_can_head_home:

                if print_fine_dets:
                    print('\n\n\n agent.total_res_reduced_value_start_trading =', agent.total_res_reduced_value_start_trading)

                if print_fine_dets:

                    print('\n pre- agent.grid_trgt =', agent.grid_trgt)
                    print(' agent.home =', agent.home)

                ag_total_res_reduced_value = find_total_res_reduced_value(agent, print_fine_dets)

                if agent.heads_home == 0 and ag_total_res_reduced_value >= agent.total_res_reduced_value_start_trading + 2:    # then the agent heads home

                    if print_for_tracking:
                        print('\n ag_total_res_reduced_value =', ag_total_res_reduced_value, 'agent.total_res_reduced_value_start_trading', agent.total_res_reduced_value_start_trading)
                        print('\n agent heads home')

                    agent.heads_home = 1

                    agent.grid_trgt = copy.copy(agent.home)
                    agent.can_trade = 0
                    agent.trade_movemnt = 'set'

                    # print('\n agent heading home : home location is ', agent.home, 'day', day, 'move', move, 'basket:', agent.basket_array[0], 'location', cp_agent.location)

                    # print_fine_dets = 1

                # it's possible that an agent attempted to return home but was then mugged - the agent will then move to a target as before
                elif agent.heads_home == 1 and ag_total_res_reduced_value < agent.total_res_reduced_value_start_trading + 2:

                    if print_fine_dets:
                        print('\n agent was heading home but reverses decision')

                    set_agent_target(params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, respect_property_rights, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt,
                                     trade_when_trgt, dbs, track_agent, agent, day, town_grid, trgt_sel, trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, ststst, retarg=1, move=move, has_acted=1,
                                     print_dets=print_dets, print_fine_dets=0, fight_balance=fight_balance, agree_location=agree_location, adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta,
                                     formal_inst=formal_inst, prob_fine=prob_fine, fine=fine, fight_skill=fight_skill, fix_ps_fb_0=fix_ps_fb_0, strat_choice=strat_choice, stranger_int=stranger_int, two_tribes_inst=two_tribes_inst,
                                     strangers_if_unknown=strangers_if_unknown)

                    agent.heads_home = 0
                    agent.can_trade = 1
                    agent.reached_tgt_on_move = 0
                    agent.reached_trgt = 0

                    if print_fine_dets:
                        print('\n new agent.grid_trgt =', agent.grid_trgt)

                    # pause()

                if print_fine_dets:
                    print('\n post- agent.grid_trgt =', agent.grid_trgt)

                    print('\n agent.heads_home ?', agent.heads_home)

                    print('\n\n\n cp_agent.total_res_reduced_value_start_trading =', cp_agent.total_res_reduced_value_start_trading)

                    print('\n pre- cp_agent.grid_trgt =', cp_agent.grid_trgt)
                    print(' cp_agent.home =', cp_agent.home)

                cp_total_res_reduced_value = find_total_res_reduced_value(cp_agent, print_fine_dets)

                if cp_agent.heads_home == 0 and cp_total_res_reduced_value >= cp_agent.total_res_reduced_value_start_trading + 2:    # then the agent heads home

                    if print_for_tracking:
                        print('\n cp_total_res_reduced_value =', cp_total_res_reduced_value, 'cp_agent.total_res_reduced_value_start_trading', cp_agent.total_res_reduced_value_start_trading)
                        print('\n cp_agent heads home')

                    cp_agent.heads_home = 1

                    cp_agent.grid_trgt = copy.copy(cp_agent.home)
                    cp_agent.can_trade = 0
                    cp_agent.trade_movemnt = 'set'

                    # print('\n cp_agent heading home : home location is ', cp_agent.home, 'day', day, 'move', move, 'basket:', agent.basket_array[0], 'location', cp_agent.location)

                    # print_fine_dets = 1

                # it's possible that an agent attempted to return home but was then mugged - the agent will then move to a target as before
                elif cp_agent.heads_home == 1 and cp_total_res_reduced_value < cp_agent.total_res_reduced_value_start_trading + 2:

                    set_agent_target(params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, respect_property_rights, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt,
                                     trade_when_trgt, dbs, track_agent, cp_agent, day, town_grid, trgt_sel, trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, ststst, retarg=1, move=move, has_acted=1,
                                     print_dets=print_dets, print_fine_dets=0, fight_balance=fight_balance, agree_location=agree_location, adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta,
                                     formal_inst=formal_inst, prob_fine=prob_fine, fine=fine, fight_skill=fight_skill, fix_ps_fb_0=fix_ps_fb_0, strat_choice=strat_choice, stranger_int=stranger_int, two_tribes_inst=two_tribes_inst,
                                     strangers_if_unknown=strangers_if_unknown)

                    cp_agent.heads_home = 0
                    cp_agent.can_trade = 1
                    cp_agent.reached_tgt_on_move = 0
                    cp_agent.reached_trgt = 0

                    if print_fine_dets:
                        print('\n new cp_agent.grid_trgt =', cp_agent.grid_trgt)

                    # pause()

                if print_fine_dets:
                    print('\n cp_agent.heads_home ?', cp_agent.heads_home)
                    print('\n post- cp_agent.grid_trgt =', cp_agent.grid_trgt)

                # if agent.heads_home or cp_agent.heads_home:
                #     pause()

            if agents_trade_peacefully and transaction is not None:

                transaction.initiator_new_prop_steal = copy.copy(agent.prop_steal)
                transaction.initiator_new_prop_fight_back = copy.copy(agent.prop_fight_back)
                transaction.counterpart_new_prop_steal = copy.copy(cp_agent.prop_steal)
                transaction.counterpart_new_prop_fight_back = copy.copy(cp_agent.prop_fight_back)
                transaction.initiator_start_prop_steal = initiator_start_prop_steal
                transaction.initiator_start_prop_fight_back = initiator_start_prop_fight_back
                transaction.counterpart_start_prop_steal = counterpart_start_prop_steal
                transaction.counterpart_start_prop_fight_back = counterpart_start_prop_fight_back

            # now we need to record information about the interaction, if they did not trade - for passing on to others.  Note this includes fights AND muggings.
            if agents_trade_peacefully == 0:

                # if fight_winner is agent:
                #     fight_winner_net_benefit = copy.copy(agent_net_benefit)
                #     fight_loser_net_benefit = copy.copy(cp_agent_net_benefit)
                #
                # elif fight_loser is agent:
                #     fight_winner_net_benefit = copy.copy(cp_agent_net_benefit)
                #     fight_loser_net_benefit = copy.copy(agent_net_benefit)

                # for any of the first 6 scenarions, agents fight - we record this information like so (but not if they trade peacefully)
                fight_num = len(dbs.fights_db)

                fight = Fight_Object(day, fight_num, initiator=str(agent), counterpart=str(cp_agent),
                                     location=copy.copy(agent.location), winner=str(fight_winner),
                                     agent_record=copy.copy(agent_record), cp_agent_record=copy.copy(cp_agent_record),
                                     agent_res_gain=agent_ch_ress, cp_agent_res_gain=cp_agent_ch_ress,
                                     move_num=move, initiator_new_prop_steal=copy.copy(agent.prop_steal),
                                     initiator_new_prop_fight_back=copy.copy(agent.prop_fight_back),
                                     counterpart_new_prop_steal=copy.copy(cp_agent.prop_steal),
                                     counterpart_new_prop_fight_back=copy.copy(cp_agent.prop_fight_back),
                                     initiator_start_prop_steal=initiator_start_prop_steal,
                                     initiator_start_prop_fight_back=initiator_start_prop_fight_back,
                                     counterpart_start_prop_steal=counterpart_start_prop_steal,
                                     counterpart_start_prop_fight_back=counterpart_start_prop_fight_back,
                                     initiator_start_basket=agent_start_basket,
                                     counterpart_start_basket=cp_agent_start_basket, initiator_dec=agent_dec,
                                     counterpart_dec=cp_agent_dec,
                                     initiator_end_basket=copy.copy(agent.basket_array),
                                     counterpart_end_basket=copy.copy(cp_agent.basket_array),
                                     agent_start_res=agent_start_res,
                                     cp_agent_start_res=cp_agent_start_res, agent_a_tribe=agent.tribe,
                                     agent_b_tribe=cp_agent.tribe)

                dbs.fights_db.append(fight)

                if print_fine_dets:
                    print('\n fight_num ', fight_num)
                    print(' fight address', fight)

                # add to the fight object:
                fight.initiator_reduced_value = agent_net_benefit
                fight.counterpart_reduced_value = cp_agent_net_benefit

                agent.loc_fights_array[day].append(fight_num)
                cp_agent.loc_fights_array[day].append(fight_num)

                agent.fights_array.append(agent_record)
                cp_agent.fights_array.append(cp_agent_record)

                if len(dbs.start_end_fights[day]) == 0:  # then this is the first fight of the day

                    dbs.start_end_fights[day] = [fight_num, fight_num]

                else:

                    dbs.start_end_fights[day][1] = fight_num

                # we update these arrays, which helps us shortcut some of the coding when agents evaluate each other
                agent.last_intn = fight
                cp_agent.last_intn = fight

                # the agents also add to their own reputations dictionaries, given their experiences
                # start with agent:
                #                if agent_record == None:

                #                    print('\n agent_dec =', agent_dec, 'cp_agent_dec', cp_agent_dec)

                try:
                    other_agent, fought, fought_back, i_fought, i_fought_back = agent_record
                except Exception as e:
                    print('\n problem: \n')
                    print(' agent_dec = ', agent_dec)
                    print(' cp_agent_dec = ', cp_agent_dec)

                if fought == 0:

                    fought_back_tally = 1  # the other agent wanted to trade; I tried to steal; it could have fought back

                else:

                    fought_back_tally = 0  # vice versa

                if other_agent not in agent.reputations_dict:  # this is where a new entry in the dict occurs

                    agent.reputations_dict[other_agent] = [np.zeros(shape=(num_rounds), dtype=int),
                                                           np.zeros(shape=(num_rounds), dtype=int),
                                                           np.zeros(shape=(num_rounds), dtype=int),
                                                           np.zeros(shape=(num_rounds), dtype=int)]

                agent.reputations_dict[other_agent][0][day] += fought
                agent.reputations_dict[other_agent][1][day] += 1
                agent.reputations_dict[other_agent][2][day] += fought_back
                agent.reputations_dict[other_agent][3][day] += fought_back_tally

                # now the cp_agent:
                other_agent, fought, fought_back, i_fought, i_fought_back = cp_agent_record

                if fought == 0:

                    fought_back_tally = 1  # the other agent wanted to trade; I tried to steal; it could have fought back

                else:

                    fought_back_tally = 0  # vice versa

                if other_agent not in cp_agent.reputations_dict:
                    cp_agent.reputations_dict[other_agent] = [np.zeros(shape=(num_rounds), dtype=int),
                                                              np.zeros(shape=(num_rounds), dtype=int),
                                                              np.zeros(shape=(num_rounds), dtype=int),
                                                              np.zeros(shape=(num_rounds), dtype=int)]

                cp_agent.reputations_dict[other_agent][0][day] += fought
                cp_agent.reputations_dict[other_agent][1][day] += 1
                cp_agent.reputations_dict[other_agent][2][day] += fought_back
                cp_agent.reputations_dict[other_agent][3][day] += fought_back_tally

                # update this also
                agent.agent_knows_cp_dict[str(cp_agent)] = 1
                cp_agent.agent_knows_cp_dict[str(agent)] = 1

                # we also update these values - we only update the reputations data when we need to and this is part of that process
                agent.need_to_update_reps[str(cp_agent)] = 1
                cp_agent.need_to_update_reps[str(agent)] = 1

                # if the agents fought, the fight_winner will re-target when the sum of its resources exceeds the total resources at the start of the round;
                # also, we don't want to run this if there has been no change during the transaction, so we include agent_net_benefit != 0; and we don't want to
                # run this if the agent has retargetted and hasn't reached its designated target, i.e., we don't want to change the target

                # if len(fight_winner.positive_locations_dict) > 1:
                #     print_fine_dets = 1

                if params.allow_retarget:

                    if print_fine_dets == 1:
                        print('\n\n\n\n np.sum(fight_winner.basket_array) =', np.sum(fight_winner.basket_array),
                              'np.sum(fight_winner.basket_array_start) =', np.sum(fight_winner.basket_array_start))

                        print('\n day', day, 'move', move)
                        print('\n fight_winner.home =', fight_winner.home)
                        print('\n fight_winner.trade_loc_rec:\n')
                        for mo in np.arange(len(fight_winner.trade_loc_rec)):
                            print(mo, fight_winner.trade_loc_rec[mo])

                        print(fight_winner.location, '<-- fight_winner.location')
                        print('\n fight_winner.trgt_loc_rec:\n')

                        for mo in np.arange(len(fight_winner.trgt_loc_rec)):
                            print(mo, fight_winner.trgt_loc_rec[mo])

                        print(fight_winner.grid_trgt, '<-- fight_winner.grid_trgt')
                        print('\n fight_winner.home =', fight_winner.home)
                        print(' fight_winner.location =', fight_winner.location)
                        print(' fight_winner.grid_trgt =', fight_winner.grid_trgt)

                        print('\n fight_loser.home =', fight_loser.home)
                        print('\n fight_loser.trade_loc_rec:\n')
                        for mo in np.arange(len(fight_loser.trade_loc_rec)):
                            print(mo, fight_loser.trade_loc_rec[mo])

                        print(fight_loser.location, '<-- fight_loser.location')
                        print('\n fight_loser.trgt_loc_rec:\n')

                        for mo in np.arange(len(fight_loser.trgt_loc_rec)):
                            print(mo, fight_loser.trgt_loc_rec[mo])

                        print(fight_loser.grid_trgt, '<-- fight_loser.grid_trgt')
                        print('\n fight_loser.home =', fight_loser.home)
                        print(' fight_loser.location =', fight_loser.location)
                        print(' fight_loser.grid_trgt =', fight_loser.grid_trgt)

                        print('\n np.sum(fight_winner.basket_array) =', np.sum(fight_winner.basket_array),
                              'np.sum(fight_winner.basket_array_start) =', np.sum(fight_winner.basket_array_start))
                        print(' agent_net_benefit =', agent_net_benefit)
                        print(' fight_winner.reached_trgt =', fight_winner.reached_trgt)
                        print(' len(fight_winner.positive_locations_dict) =', len(fight_winner.positive_locations_dict))

                    if fight_winner.grid_trgt[0] != None:

                        fw_distance_to_trgt = np.max(abs_dist_on_torus(fight_winner.location, fight_winner.grid_trgt, town_grid.dimen))

                    else:

                        fw_distance_to_trgt = 2

                    if fight_loser.grid_trgt[0] != None:

                        fl_distance_to_trgt = np.max(abs_dist_on_torus(fight_loser.location, fight_loser.grid_trgt, town_grid.dimen))

                    else:

                        fl_distance_to_trgt = 2

                    if print_fine_dets == 1:
                        print('\n fw_distance_to_trgt =', fw_distance_to_trgt)

                    # the fight winner will retarget if (1) the agent has already reached its target (or it's within 1 grid square),
                    # and (2) there is at least one other viable target (or it has one target and will switch to random); and (3) it is not heading home
                    if (fight_winner.reached_trgt or (fight_winner.reached_trgt == 0 and fw_distance_to_trgt < 2)) and len(fight_winner.positive_locations_dict) > 0 and fight_winner.heads_home == 0:

                        if print_fine_dets == 1 or print_for_tracking:
                            print('\n the fight winner is re-targeting')
                            print(' pre-retargeting target =', fight_winner.grid_trgt)
                            print(' pre trade_movemnt =', fight_winner.trade_movemnt, '\n')

                        set_agent_target(params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, respect_property_rights, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt,
                                         trade_when_trgt, dbs, track_agent, fight_winner, day, town_grid, trgt_sel, trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, ststst, retarg=1, move=move, has_acted=1,
                                         print_dets=print_dets, print_fine_dets=0, fight_balance=fight_balance, agree_location=agree_location, adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta,
                                         formal_inst=formal_inst, prob_fine=prob_fine, fine=fine, fight_skill=fight_skill, fix_ps_fb_0=fix_ps_fb_0, strat_choice=strat_choice, stranger_int=stranger_int, two_tribes_inst=two_tribes_inst,
                                         strangers_if_unknown=strangers_if_unknown)

                        # can_trade is only 0 after the start of the trading phase and before the agent reaches its target (or is intercepted) so here it is set = 1
                        fight_winner.can_trade = 1
                        fight_winner.reached_tgt_on_move = 0
                        fight_winner.reached_trgt = 0

                        # agent.reached_trgt is 0 when agent is heading to target and 1 after it has reached it, unless moving randomly
                        if fight_winner.trade_movemnt == 'set' and trade_when_trgt == 1 and (fight_winner.grid_trgt[0] == fight_winner.location[0] and fight_winner.grid_trgt[1] == fight_winner.location[1]) == False:

                            fight_winner.reached_trgt = 0

                        else:

                            fight_winner.reached_trgt = 1

                    if print_fine_dets:
                        print('\n fight_loser.reached_trgt =', fight_loser.reached_trgt)
                        print(' len(fight_loser.positive_locations_dict)', len(fight_loser.positive_locations_dict))
                        print('\n fl_distance_to_trgt =', fl_distance_to_trgt)

                    # for the fight loser, we retarget if the agent has already reached its target (or it's within 1 grid square) - note fl_distance_to_trgt = [2, 2] if fight_loser.trade_movemnt = 'random' :
                    if (fight_loser.reached_trgt or (fight_loser.reached_trgt == 0 and fl_distance_to_trgt < 2)) and len(fight_loser.positive_locations_dict) > 0 and fight_loser.heads_home == 0:

                        if print_fine_dets == 1 or print_for_tracking:
                            print('\n the fight loser is re-targeting')

                        set_agent_target(params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, respect_property_rights, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt,
                                         trade_when_trgt, dbs, track_agent, fight_loser, day, town_grid, trgt_sel, trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, ststst, retarg=1, move=move, has_acted=1,
                                         print_dets=print_dets, print_fine_dets=0, fight_balance=fight_balance, agree_location=agree_location, adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta,
                                         formal_inst=formal_inst, prob_fine=prob_fine, fine=fine, fight_skill=fight_skill, fix_ps_fb_0=fix_ps_fb_0, strat_choice=strat_choice, stranger_int=stranger_int, two_tribes_inst=two_tribes_inst,
                                         strangers_if_unknown=strangers_if_unknown)

                        # agent.reached_trgt is 0 when agent is heading to target and 1 after it has reached it, unless moving randomly
                        if fight_loser.trade_movemnt == 'set' and trade_when_trgt == 1 and (fight_loser.grid_trgt[0] == fight_loser.location[0] and fight_loser.grid_trgt[1] == fight_loser.location[1]) == False:

                            fight_loser.reached_trgt = 0

                        else:

                            fight_loser.reached_trgt = 1

                        # can_trade is only 0 after the start of the trading phase and before the agent reaches its target (or is intercepted) so here it is set = 1
                        fight_loser.can_trade = 1
                        fight_loser.reached_tgt_on_move = 0

                    # print data after retargetting:
                    if print_fine_dets or print_for_tracking:

                        print('\n Retargetting details:')

                        print('\n fight_winner.trade_movemnt =', fight_winner.trade_movemnt)
                        print(' fight_winner.grid_trgt =', fight_winner.grid_trgt)
                        print(' fight_winner.can_trade =', fight_winner.can_trade)
                        print(' fight_winner.reached_trgt =', fight_winner.reached_trgt)
                        print(' fight_winner.reached_tgt_on_move =', fight_winner.reached_tgt_on_move)

                        print('\n fight_loser.trade_movemnt =', fight_loser.trade_movemnt)
                        print(' fight_loser.grid_trgt =', fight_loser.grid_trgt)
                        print(' fight_loser.can_trade =', fight_loser.can_trade)
                        print(' fight_loser.reached_trgt =', fight_loser.reached_trgt)
                        print(' fight_loser.reached_tgt_on_move =', fight_loser.reached_tgt_on_move)

            if params.track_interactions_detailed:

                if agents_trade_peacefully:

                    intn_type = 'transaction'
                    intn_num = len(dbs.trans_db) - 1

                else:

                    intn_type = 'fight'
                    intn_num = fight_num

                if params.use_NNs and params.num_NNs == 1:

                    agent_a_ps_start_trans = agent.intn_prob[0][0]
                    agent_b_ps_start_trans = cp_agent.intn_prob[0][0]

                    agent_a_pfb_start_trans = agent.intn_prob[1][0]
                    agent_b_pfb_start_trans = cp_agent.intn_prob[1][0]

                    agent_a_ps_end_trans = new_intn_prob[0][0]
                    agent_b_ps_end_trans = new_intn_prob_cp[0][0]

                    agent_a_pfb_end_trans = new_intn_prob[1][0]
                    agent_b_pfb_end_trans = new_intn_prob_cp[1][0]

                elif params.use_NNs and params.num_NNs == 2:

                    agent_a_ps_start_trans = agent.intn_prob_ps[0][0]
                    agent_b_ps_start_trans = cp_agent.intn_prob_ps[0][0]

                    agent_a_pfb_start_trans = agent.intn_prob_pfb[0][0]
                    agent_b_pfb_start_trans = cp_agent.intn_prob_pfb[0][0]

                    agent_a_ps_end_trans = new_intn_prob_ps[0][0]
                    agent_b_ps_end_trans = new_intn_prob_ps_cp[0][0]

                    agent_a_pfb_end_trans = new_intn_prob_pfb[0][0]
                    agent_b_pfb_end_trans = new_intn_prob_pfb_cp[0][0]

                else:

                    agent_a_ps_start_trans = start_agent_prop_steal
                    agent_b_ps_start_trans = start_cp_agent_prop_steal

                    agent_a_pfb_start_trans = start_agent_prop_fight_back
                    agent_b_pfb_start_trans = start_cp_agent_prop_fight_back

                    agent_a_ps_end_trans = copy.copy(agent.prop_steal)
                    agent_b_ps_end_trans = copy.copy(cp_agent.prop_steal)

                    agent_a_pfb_end_trans = copy.copy(agent.prop_fight_back)
                    agent_b_pfb_end_trans = copy.copy(cp_agent.prop_fight_back)

                    ag_ch_prop_steal_simple = None
                    ag_ch_prop_fb_simple = None
                    cp_ch_prop_steal_simple = None
                    cp_ch_prop_fb_simple = None

                    agent_net_gain_NNs = None
                    cp_agent_net_gain_NNs = None

                interaction = Interaction(day=day, move=move, agent=agent, cp_agent=cp_agent, intn_type=intn_type, intn_num=intn_num, agent_a_dec=agent_dec, agent_b_dec=cp_agent_dec, location=agent.location,
                                          agent_net_benefit=agent_net_benefit, cp_agent_net_benefit=cp_agent_net_benefit, agent_net_benefit_back_prop=agent_net_benefit_back_prop, cp_agent_net_benefit_back_prop=cp_agent_net_benefit_back_prop,
                                          ag_ch_prop_steal_simple=ag_ch_prop_steal_simple, ag_ch_prop_fb_simple=ag_ch_prop_fb_simple, cp_ch_prop_steal_simple=cp_ch_prop_steal_simple, cp_ch_prop_fb_simple=cp_ch_prop_fb_simple,
                                          agent_net_gain_NNs=agent_net_gain_NNs, cp_agent_net_gain_NNs=cp_agent_net_gain_NNs,
                                          ag_exp_overall_rtn=ag_exp_overall_rtn, cp_exp_overall_rtn=cp_exp_overall_rtn, ag_exp_quad_2_rtn=ag_exp_quad_2_rtn, cp_exp_quad_3_rtn=cp_exp_quad_3_rtn,
                                          agent_net_benefit_back_prop_fb=agent_net_benefit_back_prop_fb, cp_agent_net_benefit_back_prop_fb=cp_agent_net_benefit_back_prop_fb,
                                          agent_a_start_day_res=agent.agent_res_array_start[0], agent_b_start_day_res=cp_agent.agent_res_array_start[0], agent_a_start_day_bskt=agent.basket_array_start[0],
                                          agent_b_start_day_bskt=cp_agent.basket_array_start[0],
                                          agent_a_start_trans_res=agent_start_res, agent_b_start_trans_res=cp_agent_start_res, agent_a_start_trans_bskt=agent_start_basket, agent_b_start_trans_bskt=cp_agent_start_basket,
                                          transfer_to_agent_a=agent_ch_ress, transfer_to_agent_b=cp_agent_ch_ress, agent_a_ps_start_trans=agent_a_ps_start_trans, agent_b_ps_start_trans=agent_b_ps_start_trans,
                                          agent_a_pfb_start_trans=agent_a_pfb_start_trans, agent_b_pfb_start_trans=agent_b_pfb_start_trans, agent_a_ps_end_trans=agent_a_ps_end_trans, agent_b_ps_end_trans=agent_b_ps_end_trans,
                                          agent_a_pfb_end_trans=agent_a_pfb_end_trans, agent_b_pfb_end_trans=agent_b_pfb_end_trans)

                dbs.interactions_db[day].append(interaction)

        # if (params.track_agent and params.track_agent <= day) and (agent_population.tracking_agent == agent or agent_population.tracking_agent == cp_agent):
            # print_fine_dets == 1 or print_model_2_dets == 1 or print_for_tracking:

            # pause()
            # print('\n\n\n')

        # when all is done, update dbs.quadrants_tallies_actual
        if params.respect_property_rights == 0:

            if agent_dec == 'trade' and cp_agent_dec == 'trade':
                dbs.quadrants_tallies_actual['1'][day] += 1
            if agent_dec == 'fight_back' and cp_agent_dec == 'steal':
                dbs.quadrants_tallies_actual['2F'][day] += 1
            if agent_dec == 'trade' and cp_agent_dec == 'steal':
                dbs.quadrants_tallies_actual['2A'][day] += 1
            if agent_dec == 'steal' and cp_agent_dec == 'fight_back':
                dbs.quadrants_tallies_actual['3F'][day] += 1
            if agent_dec == 'steal' and cp_agent_dec == 'trade':
                dbs.quadrants_tallies_actual['3A'][day] += 1
            if agent_dec == 'steal' and cp_agent_dec == 'steal':
                dbs.quadrants_tallies_actual['4'][day] += 1

        if print_fine_dets or print_for_tracking:

            print('\n overall:\n\n agent_net_benefit = ', agent_net_benefit, 'ag_exp_overall_rtn =', ag_exp_overall_rtn)
            print(' cp_agent_net_benefit = ', cp_agent_net_benefit, 'cp_exp_overall_rtn =', cp_exp_overall_rtn)

            print('\n ----> End of agent_population.agents_interact \n')

            # if pause_at_end:
            pause()
            # if cp_rat_dec == 'none':

        if (stranger_int == 'fb' and agent_dec == 'trade' and cp_agent_dec == 'steal') or (stranger_int == 'fb' and agent_dec == 'steal' and cp_agent_dec == 'trade') or\
                (stranger_int == 'acq' and agent_dec == 'fight_back' and cp_agent_dec == 'steal') or (stranger_int == 'acq' and agent_dec == 'steal' and cp_agent_dec == 'fight_back'):
            print('\n PROBLEM in agents_interact: stranger_int =', stranger_int, 'agent_dec =', agent_dec, 'cp_agent_dec =', cp_agent_dec)
            pause()

        return [remove_agents, transactions, traded_array, trans_numbs_array, fight_num]


class TownGrid():

    """A grid representing a town around which agents search for other agents with whom they might trade."""

    def __init__(self, rounds, dimen, trade_moves, print_dets):

        self.dimen = dimen
        self.all_trans_array = np.zeros(shape=(rounds, dimen, dimen))
        self.agents_seen_db = []
        self.unsucc_trans_db = []
        self.trade_moves = trade_moves
        self.grid_accup = np.zeros(shape=(dimen, dimen))
        self.max_grid_square = np.array([0, 0], dtype=int)
        self.item_loc = np.array([0, 0], dtype=int)

        # this create a grid on which we can place the agents
        self.grid_agents = []
        row = []
        for k in np.arange(self.dimen):
            row.append([])
        for l in np.arange(self.dimen):
            self.grid_agents.append(copy.deepcopy(row))

        if print_dets == 1:
            print('\n** creating an instance of TownGrid **')
            print('\ntowngrid dimension =', dimen, 'x', dimen)
            print('\n** instance of TownGrid has been created **\n')

    def locate_agents(self, agent_population, fountain_population, dbs, print_dets, trade_loc):

        """A method for asigning locations to those agents which attempt to trade."""

#        print_dets = 1

        if print_dets == 1:
            print('\n * asign random locations to agents if trade_loc != 1, and asign home location if trade_loc == 1 *')
            print('trade_loc =', trade_loc)

        for agent in dbs.agent_list:

            if trade_loc == 'random':

                x_coord = np.random.randint(0, self.dimen)
                y_coord = np.random.randint(0, self.dimen)

                agent.location = np.array([x_coord, y_coord])

            elif trade_loc == 'home':

                agent.location = copy.copy(agent.home)

            elif trade_loc == 'fountain':

                at_fountain_num = agent.for_strat_array[0][-1]

                if print_dets == 1:
                    print('\n at_fountain_num', at_fountain_num)

                fountain = fountain_population.pop[at_fountain_num]

                if print_dets == 1:
                    print('fountain', fountain)

                agent.location = copy.copy(fountain.location)

                if print_dets == 1:
                    print('fountain.location', fountain.location)
                    print('agent.location', agent.location)

        if print_dets == 1:
            print('\nlocate_agents is finished')

            input("Press Enter to continue...")


class Databases():

    def __init__(self, params, rounds, dimen, for_strat_parts, trade_moves, data_folder, init_res_level, print_MRS_std_charts, constitutional_voting, num_experiments, two_tribes, black_shoop_exp, agree_location):

        # self.check_fights = []
        # self.check_trans = []

        self.num_rounds = rounds

        # create dictionary which converts str of agent address to agent itself
        self.str_ag_to_ag_dict = {}

        # create a database to record initial reserve levels of all fountains: this will vary when famine is explored
        if two_tribes == 0:

            self.init_res_levels = np.zeros(shape=(rounds, num_res_founts))

        elif two_tribes == 1:

            self.init_res_levels = np.zeros(shape=(rounds, 4))

        # this database records most of the main data
        self.main_db = np.zeros(shape=(4 + num_res_founts, rounds))
        self.main_db[0] = np.arange(rounds)

        # create database to record number of agents at each fountain in each time slot
        self.founts_db = np.zeros(shape=((for_strat_parts * num_res_founts) + 1, rounds))
        self.founts_db[0] = np.arange(rounds)

        # create database to record key trading data.  Note: [0] is rounds, [1] is proportion of grid squares with transaction.
        self.key_trading_db = np.zeros(shape=(2, rounds))
        self.key_trading_db[0] = np.arange(rounds)

        # if agents trade, set up a database to record the number of successful trades and number of agents attempting to trade:
        # [0] records number of agents in play; [1] records number of agents attempting to trade in the round; [2] is the
        # number of successful trades in that round; [3] records the proportion of successful trades per person i.e. [2]
        # divided by [1].
        self.trading_db = np.zeros(shape=(7, rounds))

        # create database to record min resource levels of agents
        self.min_res_levels_db = np.zeros(shape=(rounds, dimen, dimen))

        #        # create a clustering database: [0] = rounds, [1] = clustering coeff, [2] = x_coord of cluster centre, [3] = y_coord
        #        self.clustering_db = np.zeros(shape=(2, rounds))
        #        self.clustering_db[0] = np.arange(rounds)
        #
        #        # create cluster centre db
        #        self.cluster_centre_db = np.zeros(shape=(3, rounds))
        #        self.cluster_centre_db[0] = np.arange(rounds)

        # create a database to record agents' average age
        self.ag_age_db = np.zeros(shape=(2, rounds), dtype=int)
        self.ag_age_db[0] = np.arange(rounds)

        # create database with this number of arrays plus one more to record the average & one to include rounds
        self.for_spec_db = np.zeros(shape=(for_strat_parts + 3, rounds))
        self.for_spec_db[0] = np.arange(rounds)

        # create arrays which records the resource levels of each fountain at the beginning and end of each time slot
        if two_tribes == 0:

            self.res_level_array = np.zeros(shape=(for_strat_parts, num_res_founts))
            self.res_level_array_ends = np.zeros(shape=(for_strat_parts, num_res_founts))

        elif two_tribes == 1:

            self.res_level_array = np.zeros(shape=(for_strat_parts, 4))
            self.res_level_array_ends = np.zeros(shape=(for_strat_parts, 4))

            self.pop_sharks = np.zeros(shape=rounds)
            self.pop_jets = np.zeros(shape=rounds)

            self.res_founts_sharks = np.zeros(shape=(num_res_founts, rounds))
            self.res_founts_jets = np.zeros(shape=(num_res_founts, rounds))

        # create a list which tracks which agents want to trade after foraging
        self.agent_list = []

        # create a variable to track the total number of goods on sale in each round
        self.total_on_sale = 0

        # Create a transactions database to record all transactions
        self.trans_db = []

        # Create a database which records transactions in each day
        self.transs_daily_db = [[] for i in range(rounds)]

        # Create a similar database for fights
        self.fights_daily_db = [[] for i in range(rounds)]

        # this array is used to record the names of the dead agents in each round :-)
        self.davy_jones_locker = []

        #        net_transs_db = []
        #        twod_array = []
        #        row = []
        #        for k in np.arange(num_res_founts):
        #            row.append(np.array([0.0, 0.0]))
        #        for l in np.arange(num_res_founts):
        #            twod_array.append(copy.deepcopy(row))
        #        for j in np.arange(rounds):
        #            net_transs_db.append(copy.deepcopy(twod_array))
        #
        #        self.net_transs_db = net_transs_db

        self.SD_equilibrium_data_1d = np.zeros(shape=(rounds, num_res_founts, num_res_founts, 2))

        self.net_net_transs_db = np.zeros(shape=(rounds, num_res_founts))

        if two_tribes:
            self.net_net_transs_db_sharks = np.zeros(shape=(rounds, num_res_founts))
            self.net_net_transs_db_jets = np.zeros(shape=(rounds, num_res_founts))

        self.net_trans_MRSs = np.zeros(shape=(rounds, num_res_founts, num_res_founts))

        #        self.all_transs_array = [[] for i in range(num_res_founts)]

        #        self.all_transs_array_1_res = [[[] for i in range(num_res_founts)] for j in range(num_res_founts)]

        self.tot_trans = np.zeros(shape=(rounds, num_res_founts))

        self.tot_trans_1_res = np.zeros(shape=(rounds, num_res_founts, num_res_founts))

        # This database records foraging strategy array data - one list for each round
        self.for_strat_db = [[] for i in range(rounds)]

        if two_tribes:
            self.for_strat_db_sharks = [[] for i in range(rounds)]
            self.for_strat_db_jets = [[] for i in range(rounds)]

        # Create a database to record all the mean price history (working prices not chart prices)
        self.mean_price_history = np.zeros(shape=(num_res_founts, num_res_founts, rounds))
        self.price_history_std = np.zeros(shape=(num_res_founts, num_res_founts, rounds))

        if two_tribes:
            self.mean_price_history_sharks = np.zeros(shape=(num_res_founts, num_res_founts, rounds))
            self.price_history_std_sharks = np.zeros(shape=(num_res_founts, num_res_founts, rounds))

            self.mean_price_history_jets = np.zeros(shape=(num_res_founts, num_res_founts, rounds))
            self.price_history_std_jets = np.zeros(shape=(num_res_founts, num_res_founts, rounds))

        # Creat an array to record optimal basket turnover (from constrained optimization technique)
        self.optimal_bskt_turnover = np.zeros(shape=(rounds, num_res_founts))

        if two_tribes:
            self.optimal_bskt_turnover_sharks = np.zeros(shape=(rounds, num_res_founts))
            self.optimal_bskt_turnover_jets = np.zeros(shape=(rounds, num_res_founts))

        # Create an array to record the errors in the optimal basket turnover calcs (measure of accuracy)
        self.optimal_bskt_errors = np.zeros(shape=(rounds, num_res_founts))

        # And create an array to record the number of iterations gone through in order to find optimal basket turnover (measure of accuracy)
        self.optimal_bskt_iters = np.zeros(shape=(rounds))

        # Creat an array to record optimal price array (from constrained optimization technique) - we record these as chart prices
        self.optimal_price_array = np.zeros(shape=(rounds, num_res_founts, num_res_founts))

        if two_tribes:
            self.optimal_price_array_sharks = np.zeros(shape=(rounds, num_res_founts, num_res_founts))
            self.optimal_price_array_jets = np.zeros(shape=(rounds, num_res_founts, num_res_founts))

        # Create an array to record the proportion of net_net_transs_db / optimal_bskt_turnover
        self.net_turnover_prop = np.zeros(shape=(rounds, num_res_founts))

        if two_tribes:
            self.net_turnover_prop_sharks = np.zeros(shape=(rounds, num_res_founts))
            self.net_turnover_prop_jets = np.zeros(shape=(rounds, num_res_founts))

        # Create an array to record agent MRSs over all moves
        # self.MRS_moves_array = [[[[] for move in np.arange(trade_moves)] for res_1 in np.arange(num_res_founts)] for
        #                         res_2 in np.arange(num_res_founts)]

        # we only want this database if we're printing specific charts
        if print_MRS_std_charts == 1:
            self.MRS_STDs_array = np.zeros(shape=(num_res_founts, num_res_founts, 2, rounds))

        self.live_agents = [[] for i in np.arange(rounds)]

        self.copy_ags_max_det_probs = [[] for i in np.arange(rounds)]
        self.copy_ags_res_arrays = [[] for i in np.arange(rounds)]

        self.transactions_record = np.zeros(shape=(dimen, dimen, rounds))

        self.three_d_SD_data = np.array([])

        self.aggr_three_d_data = np.array([])

        self.abs_three_d_data = np.array([])

        self.min_3d_array = np.array([])

        self.best_prices_array = np.array([])

        self.prices_array_0_2 = np.array([])
        self.prices_array_1_2 = np.array([])

        self.prices_array_0_2_prev = np.array([])
        self.prices_array_1_2_prev = np.array([])

        # create max and min boundaries for prices
        self.bound_p02_min = 0.0
        self.bound_p02_max = 5.0
        self.bound_p12_min = 0.0
        self.bound_p12_max = 5.0

        # This is an array which counts the home locations of dead agents
        self.dead_ags_grid_counter = np.zeros(shape=(dimen, dimen), dtype=int)

        self.proposed_KI_loc = [int(0), int(0)]

        # This is a text file for making any notes
        self.notes_file = '%s/00_notes_file.txt' % (data_folder)

        # This is a file for making any notes about the creation of a Keynesian Institution
        if params.allow_Keynes_Inst:

            self.KI_notes_file = '%s/00_KI_notes_file.txt' % (data_folder)

            with open(self.KI_notes_file, 'a') as myfile:
                myfile.write(
                    "This text file is for recording notes concerning the proposal of any Keynesian Institutions\n")

        self.agent_summary_notes_file = '%s/00_ag_sum_notes_file.txt' % (data_folder)

        with open(self.agent_summary_notes_file, 'a') as myfile:
            myfile.write("This text file records data about agents\n")

        # self.sign_locs_notes_file = '%s/00_sign_locs_notes_file.txt' % (data_folder)
        self.sign_locs_notes_file = '%s/00_sign_locs_notes_file.html' % (data_folder)

        with open(self.sign_locs_notes_file, 'a') as myfile:
            myfile.write("<h1>This text file records data about significant market locations, i.e., where transactions occurred</h1><body>")

        if params.write_detailed_S_D_data:

            self.daily_S_D_data = '%s/00_daily_S_D_data.txt' % (data_folder)

            with open(self.daily_S_D_data, 'a') as myfile:
                myfile.write(
                    "This text file records data corresponding to the Supply / Demand charts\n\n")

        # if we fix prices, we create a list so we can append S&D curves at different times in order to track the evolution of the curves
        self.saved_SD_curves = []

        self.serviced_locations = np.zeros(shape=(rounds))

        # This database records all market locations (defined as locations where > 2 agents have transacted)
        self.sign_mkt_locs = [[] for i in range(rounds)]
        # This record all sign locations - whether transactions or fights
        self.sign_locs = [[] for i in range(rounds)]

        # for the purposes of recording iterations in the optimization technique, and also time - delete when evaluation done
        self.opt_iters_record = np.zeros(shape=(rounds))
        self.opt_time_record = np.zeros(shape=(rounds))

        # create two arrays - to record each agents' x_1 and x_2 in the optimization process
        self.agent_x_1_grid = np.array([])
        self.agent_x_2_grid = np.array([])
        self.agent_obj_vals = np.array([])

        # copies of relevant arrays
        self.agent_x_1_grid_copy = np.array([])
        self.agent_x_2_grid_copy = np.array([])

        # as above but records previous round's data
        self.agent_x_1_grid_prev = np.array([])
        self.agent_x_2_grid_prev = np.array([])
        self.agent_obj_vals_prev = np.array([])

        # create two arrays - to record each agents' x_1 and x_2 in the optimization process - old process
        self.agent_x_1_grid_old = np.array([])
        self.agent_x_2_grid_old = np.array([])
        self.agent_obj_vals_old = np.array([])

        self.agents_x_min_max = np.zeros(shape=(16, 4), dtype=float)

        self.problem_agents = np.array([16], dtype=int)
        self.problem_grids = []
        self.max_diffs = []

        self.i_corner_min_prev = np.array([])
        self.i_corner_max_prev = np.array([])
        self.j_corner_min_prev = np.array([])
        self.j_corner_max_prev = np.array([])

        # we create an array with 3 elements: the round in which a (10 round MA) turnover ratio of 90%, 95% and 99% were hit
        self.mkt_emerged_round = np.zeros(shape=3, dtype=int)

        self.foutain_levels = np.zeros(shape=(num_res_founts, rounds))

        # we need to record the initial values of foutains - we assume all at init_res_level - this will get changed if there is a famine
        self.fountains_init_levels_hist = np.full((num_res_founts, rounds), init_res_level, dtype=int)

        self.last_round_trans_data = np.zeros(shape=(dimen, dimen), dtype=float)

        self.num_perfect_specs = np.zeros(shape=(4, rounds))
        self.num_perfect_specs[0] = np.arange(rounds)

        if constitutional_voting == 1:
            self.constitutional_agents = [[] for i in range(num_experiments + 1)]
            self.constitutional_min_ress = [[] for i in range(num_experiments + 1)]

        self.trades_array_ags = [[[] for j in range(dimen)] for i in range(dimen)]
        self.fights_array_ags = [[[] for j in range(dimen)] for i in range(dimen)]

        self.fights_db = []

        # self.mean_prop_steal_hist = np.arange(rounds)
        # self.mean_prop_fight_back_hist = np.arange(rounds)

        # this records, for each round, the first and last transaction number
        self.start_end_transs = [[] for i in range(rounds)]

        self.latest_trans = None

        # now the same with fights
        self.start_end_fights = [[] for i in range(rounds)]

        self.latest_fights = None

        self.prop_steal_db = [[] for i in range(rounds)]
        self.prop_fight_back_db = [[] for i in range(rounds)]

        self.prop_steal_mean_db = [[] for i in range(rounds)]
        self.prop_fb_mean_db = [[] for i in range(rounds)]

        if two_tribes:
            self.prop_steal_mean_db_sharks = [[] for i in range(rounds)]
            self.prop_fb_mean_db_sharks = [[] for i in range(rounds)]

            self.prop_steal_mean_db_jets = [[] for i in range(rounds)]
            self.prop_fb_mean_db_jets = [[] for i in range(rounds)]

        self.prop_steal_std_db = [[] for i in range(rounds)]
        self.prop_fb_std_db = [[] for i in range(rounds)]

        if two_tribes:
            self.prop_steal_std_db_sharks = [[] for i in range(rounds)]
            self.prop_fb_std_db_sharks = [[] for i in range(rounds)]

            self.prop_steal_std_db_jets = [[] for i in range(rounds)]
            self.prop_fb_std_db_jets = [[] for i in range(rounds)]

        self.prop_steal_mean_above_50_db = [[] for i in range(rounds)]
        self.prop_fb_mean_above_50_db = [[] for i in range(rounds)]
        self.prop_steal_mean_below_50_db = [[] for i in range(rounds)]
        self.prop_fb_mean_below_50_db = [[] for i in range(rounds)]

        self.num_ints_each_round = np.zeros(
            shape=(7, rounds))  # for 6 scenarios but we align scenarios with indices so [0] always zero
        self.num_fight_each_round = np.zeros(shape=rounds)

        if two_tribes:
            self.num_ints_each_round_sharks = np.zeros(
                shape=(7, rounds))  # for 6 scenarios but we align scenarios with indices so [0] always zero
            self.num_fight_each_round_sharks = np.zeros(shape=rounds)

            self.num_ints_each_round_jets = np.zeros(
                shape=(7, rounds))  # for 6 scenarios but we align scenarios with indices so [0] always zero
            self.num_fight_each_round_jets = np.zeros(shape=rounds)

            self.num_ints_each_round_inter = np.zeros(
                shape=(7, rounds))  # for 6 scenarios but we align scenarios with indices so [0] always zero
            self.num_fight_each_round_inter = np.zeros(shape=rounds)

        # for some plotly charts we record the urls
        self.agents_prop_steal_url = ''
        self.agents_prop_fb_url = ''
        self.prop_steal_above_below_50_url = ''
        self.prop_fb_above_below_50_url = ''
        self.props_means_url = ''
        self.trans_and_fights_url = ''
        self.fight_types_url = ''
        self.fight_skill_url = ''

        self.trans_and_fights_url_sharks = ''
        self.fight_types_url_sharks = ''
        self.fight_skill_url_sharks = ''

        self.trans_and_fights_url_jets = ''
        self.fight_types_url_jets = ''
        self.fight_skill_url_jets = ''

        self.trans_and_fights_url_inter = ''
        self.fight_types_url_inter = ''
        self.fight_skill_url_inter = ''

        if agree_location:
            self.agreed_locs = [[] for i in range(rounds)]

        self.games_type_considered_dict = dict()
        self.games_type_considered_dict_RCT = dict()
        self.games_type_dict = dict()
        self.games_type_dict_RCT = dict()
        self.games_type_dict_2 = dict()
        self.games_type_dict_3 = dict()
        self.classic_games_considered = dict()
        self.classic_games_considered_RCT = dict()
        self.classic_games_seen = dict()
        self.classic_games_seen_RCT = dict()

        self.agents_reached_home = []

        if params.track_interactions_detailed:

            self.interactions_db = [[] for i in range(rounds)]

        # dictionary to record rational choice decisions in interactions
        self.games_RCT_dict = dict()

        self.num_RE_games = 0
        self.num_known_outcome_games = 0

        self.quadrants_tallies_RCT = dict()

        self.quadrants_tallies_RCT['1'] = np.zeros(shape=rounds, dtype=int)
        self.quadrants_tallies_RCT['2F'] = np.zeros(shape=rounds, dtype=int)
        self.quadrants_tallies_RCT['2A'] = np.zeros(shape=rounds, dtype=int)
        self.quadrants_tallies_RCT['3F'] = np.zeros(shape=rounds, dtype=int)
        self.quadrants_tallies_RCT['3A'] = np.zeros(shape=rounds, dtype=int)
        self.quadrants_tallies_RCT['4'] = np.zeros(shape=rounds, dtype=int)

        self.quadrants_tallies_actual = dict()

        self.quadrants_tallies_actual['1'] = np.zeros(shape=rounds, dtype=int)
        self.quadrants_tallies_actual['2F'] = np.zeros(shape=rounds, dtype=int)
        self.quadrants_tallies_actual['2A'] = np.zeros(shape=rounds, dtype=int)
        self.quadrants_tallies_actual['3F'] = np.zeros(shape=rounds, dtype=int)
        self.quadrants_tallies_actual['3A'] = np.zeros(shape=rounds, dtype=int)
        self.quadrants_tallies_actual['4'] = np.zeros(shape=rounds, dtype=int)

        self.ps_net_contr_by_scen = dict()

        self.ps_net_contr_by_scen['1'] = np.zeros(shape=rounds, dtype=float)
        self.ps_net_contr_by_scen['2F'] = np.zeros(shape=rounds, dtype=float)
        self.ps_net_contr_by_scen['2A'] = np.zeros(shape=rounds, dtype=float)
        self.ps_net_contr_by_scen['3F'] = np.zeros(shape=rounds, dtype=float)
        self.ps_net_contr_by_scen['3A'] = np.zeros(shape=rounds, dtype=float)
        self.ps_net_contr_by_scen['4'] = np.zeros(shape=rounds, dtype=float)

        self.pfb_net_contr_by_scen = dict()

        self.pfb_net_contr_by_scen['1'] = np.zeros(shape=rounds, dtype=float)
        self.pfb_net_contr_by_scen['2F'] = np.zeros(shape=rounds, dtype=float)
        self.pfb_net_contr_by_scen['2A'] = np.zeros(shape=rounds, dtype=float)
        self.pfb_net_contr_by_scen['3F'] = np.zeros(shape=rounds, dtype=float)
        self.pfb_net_contr_by_scen['3A'] = np.zeros(shape=rounds, dtype=float)
        self.pfb_net_contr_by_scen['4'] = np.zeros(shape=rounds, dtype=float)

        self.ps_net_contr_by_scen_pos = dict()

        self.ps_net_contr_by_scen_pos['1'] = np.zeros(shape=rounds, dtype=float)
        self.ps_net_contr_by_scen_pos['2F'] = np.zeros(shape=rounds, dtype=float)
        self.ps_net_contr_by_scen_pos['2A'] = np.zeros(shape=rounds, dtype=float)
        self.ps_net_contr_by_scen_pos['3F'] = np.zeros(shape=rounds, dtype=float)
        self.ps_net_contr_by_scen_pos['3A'] = np.zeros(shape=rounds, dtype=float)
        self.ps_net_contr_by_scen_pos['4'] = np.zeros(shape=rounds, dtype=float)

        # add this to look at relative impact of 2F (-ve) and 3F (+ve)
        self.ps_net_contr_by_scen_pos['3F + 2F'] = np.zeros(shape=rounds, dtype=float)

        self.target_locations = {}
        self.transaction_locations = {}

        self.target_locations['none'] = np.zeros(rounds, dtype=int)

        # this records number of specialists (number of slots taken up by a specific resourcfe AND its detection probability exceeds 0.95)
        # [0] is resource 0 / A specialists, [1] is resource 1 / B specialists, and [2] is other.
        self.num_specialists = np.zeros(shape=(3, rounds), dtype=int)

        self.num_specialists_tot = np.zeros(shape=(3, rounds), dtype=int)

        self.res_conc_gini_starts = np.zeros(shape=rounds, dtype=float)
        self.res_conc_gini = np.zeros(shape=rounds, dtype=float)

        # if params.corruption_prop_charge != 1.0:
        self.corruption_array = np.zeros(shape=rounds, dtype=int)
        self.non_corruption_array = np.zeros(shape=rounds, dtype=int)
        self.medians_ts = np.zeros(rounds)
        self.medians_actual_ts = [None for i in range(rounds)]

        self.total_time_delib = np.zeros(shape=rounds, dtype=int)
        self.total_trans_delib = np.zeros(shape=rounds, dtype=int)

        self.total_time_habit = np.zeros(shape=rounds, dtype=int)
        self.total_trans_habit = np.zeros(shape=rounds, dtype=int)

        self.num_doves = np.zeros(shape=rounds, dtype=int)
        self.num_PA = np.zeros(shape=rounds, dtype=int)
        self.num_hawks = np.zeros(shape=rounds, dtype=int)

    def update_net_transs_db(self, params, day, print_dets, print_fine_dets, fountain_population, agent_population, town_grid, daily_succ_trans, two_tribes, respect_property_rights):

        """This method updates the class's net_transs_db, which occurs at the end of trading."""

        # if day > 100:
        #     print_fine_dets = 1

        # Here I find the net sales of the resources by the agents - record in self.net_net_transs_db[day][resource]
        if params.respect_property_rights:

            for agent in self.agent_list:

                if print_fine_dets == 1:
                    print('\n agent =', agent)

                for res in np.arange(num_res_founts):

                    if print_fine_dets == 1:
                        print(' res =', res)
                        print(' agent.basket_array_start_hist[day][res]', agent.basket_array_start_hist[day][res])
                        print(' agent.basket_array[0][res]', agent.basket_array[0][res])

                    agent_sale = agent.basket_array_start_hist[day][res] - agent.basket_array[0][res]

                    if agent_sale > 0:

                        self.net_net_transs_db[day][res] += agent_sale

                        if two_tribes:

                            if agent.tribe == 'sharks':

                                self.net_net_transs_db_sharks[day][res] += agent_sale

                            elif agent.tribe == 'jets':

                                self.net_net_transs_db_jets[day][res] += agent_sale

            if print_fine_dets == 1:
                print('\n self.net_net_transs_db[day]', self.net_net_transs_db[day])
            #            print(' self.net_net_transs_db_sharks[day][res]', self.net_net_transs_db_sharks[day][res])
            #            print(' self.net_net_transs_db_jets[day][res]', self.net_net_transs_db_jets[day][res])

        # In order to find the weighted mean prices we simply need to find the total sales of two resources and divide one by the other:
        # price of res_0 = sales of good 1 / sales of good 0 (this is the chart price of res_0: the number of res_1 units requird to buy one unit of res_0)
        #        total_gross_sales_numerator = np.zeros(shape=(num_res_founts, num_res_founts), dtype=float)
        #        total_gross_sales_denominator = np.zeros(shape=(num_res_founts, num_res_founts), dtype=float)

        # calculate the number of successful transactions (i.e., where the agents exchanged resources)
        num_succ_trans = 0

        for trans_num in daily_succ_trans:

            transaction = self.trans_db[trans_num]

            if transaction.good_a is not None:

                num_succ_trans += 1

        # create matrix to record all transaction price data for the day
        all_trans_prices = np.zeros(shape=(num_res_founts, num_res_founts, num_succ_trans), dtype=float)

        #        print('\n daily_succ_trans', daily_succ_trans)

        if two_tribes:

            daily_succ_trans_sharks = []
            daily_succ_trans_jets = []

            for trans_num in daily_succ_trans:

                transaction = self.trans_db[trans_num]

                if transaction.good_a is not None:

                    if transaction.agent_a_tribe == 'sharks' and transaction.agent_b_tribe == 'sharks':

                        daily_succ_trans_sharks.append(trans_num)

                    elif transaction.agent_a_tribe == 'jets' and transaction.agent_b_tribe == 'jets':

                        daily_succ_trans_jets.append(trans_num)

            all_trans_prices_sharks = np.zeros(shape=(
            num_res_founts, num_res_founts, len(daily_succ_trans_sharks)),
                                               dtype=float)

            all_trans_prices_jets = np.zeros(shape=(
            num_res_founts, num_res_founts, len(daily_succ_trans_jets)),
                                             dtype=float)

            if print_fine_dets == 1:
                print('\n daily_succ_trans', daily_succ_trans)
                print('\n daily_succ_trans_sharks', daily_succ_trans_sharks)
                print('\n daily_succ_trans_jets', daily_succ_trans_jets)

        #        row = []
        #        for k in np.arange(num_res_founts):
        #            row.append([])
        #        for l in np.arange(num_res_founts):
        #            all_trans_prices.append(copy.deepcopy(row))

        #        num_check = np.zeros(shape=(num_res_founts, num_res_founts, len(daily_succ_trans)), dtype=float)
        #        row = []
        #        for k in np.arange(num_res_founts):
        #            row.append([])
        #        for l in np.arange(num_res_founts):
        #            num_check.append(copy.deepcopy(row))

        #        denom_check = np.zeros(shape=(num_res_founts, num_res_founts, len(daily_succ_trans)), dtype=float)
        #        row = []
        #        for k in np.arange(num_res_founts):
        #            row.append([])
        #        for l in np.arange(num_res_founts):
        #            denom_check.append(copy.deepcopy(row))

        trans_counter = 0

        for trans_num in daily_succ_trans:

            transaction = self.trans_db[trans_num]

            #            print_fine_dets = 1

            if print_fine_dets == 1:
                print('\n trans_num =', trans_num)
                print(' transaction.good_a =', transaction.good_a)
                print(' transaction.good_b =', transaction.good_b)
                print(' transaction.tot_trans_ag_sell =', transaction.tot_trans_ag_sell)
                print(' transaction.tot_trans_ag_buy =', transaction.tot_trans_ag_buy)

                print('\n transaction.good_a is not None: ', transaction.good_a is not None)

                # pause()

            #            total_gross_sales_numerator[transaction.good_a][transaction.good_b] += transaction.tot_trans_ag_sell
            #            total_gross_sales_denominator[transaction.good_b][transaction.good_a] += transaction.tot_trans_ag_sell
            #
            #            total_gross_sales_numerator[transaction.good_b][transaction.good_a] += transaction.tot_trans_ag_buy
            #            total_gross_sales_denominator[transaction.good_a][transaction.good_b] += transaction.tot_trans_ag_buy
            #
            #            num_check[transaction.good_a][transaction.good_b][trans_counter] = transaction.tot_trans_ag_sell
            #            num_check[transaction.good_b][transaction.good_a][trans_counter] = transaction.tot_trans_ag_buy
            #
            #            denom_check[transaction.good_b][transaction.good_a][trans_counter] = transaction.tot_trans_ag_sell
            #            denom_check[transaction.good_a][transaction.good_b][trans_counter] = transaction.tot_trans_ag_buy

            if transaction.good_a is not None:
                all_trans_prices[transaction.good_a][transaction.good_b][trans_counter] = transaction.tot_trans_ag_sell / float(transaction.tot_trans_ag_buy)
                all_trans_prices[transaction.good_b][transaction.good_a][trans_counter] = transaction.tot_trans_ag_buy / float(transaction.tot_trans_ag_sell)

                trans_counter += 1

        # we repeat this process if we have two tribes...
        if two_tribes:

            trans_counter = 0

            for trans_num in daily_succ_trans_sharks:

                transaction = self.trans_db[trans_num]

                if transaction.good_a is not None:
                    all_trans_prices_sharks[transaction.good_a][transaction.good_b][
                        trans_counter] = transaction.tot_trans_ag_sell / float(transaction.tot_trans_ag_buy)
                    all_trans_prices_sharks[transaction.good_b][transaction.good_a][
                        trans_counter] = transaction.tot_trans_ag_buy / float(transaction.tot_trans_ag_sell)

                trans_counter += 1

            trans_counter = 0

            for trans_num in daily_succ_trans_jets:

                transaction = self.trans_db[trans_num]

                if transaction.good_a is not None:
                    all_trans_prices_jets[transaction.good_a][transaction.good_b][
                        trans_counter] = transaction.tot_trans_ag_sell / float(transaction.tot_trans_ag_buy)
                    all_trans_prices_jets[transaction.good_b][transaction.good_a][
                        trans_counter] = transaction.tot_trans_ag_buy / float(transaction.tot_trans_ag_sell)

                trans_counter += 1

            if print_fine_dets == 1:
                print('\n all_trans_prices', all_trans_prices)
                print('\n all_trans_prices_sharks', all_trans_prices_sharks)
                print('\n all_trans_prices_jets', all_trans_prices_jets)

        if print_fine_dets == 1:
            #            print('\n num_check =', num_check)
            #            print('\n denom_check =', denom_check)
            #            print('\n\n total_gross_sales_numerator =', total_gross_sales_numerator)
            #            print('\n total_gross_sales_denominator =', total_gross_sales_denominator)
            #            print('\n num_check / denom_check :', num_check / denom_check)
            print('\n all_trans_prices =', all_trans_prices)

        # we use this data to generated the mean weighted prices, which is
        #        mean_prices_array = np.zeros(shape=(num_res_founts, num_res_founts))
        # print('\n all_trans_prices:', all_trans_prices)

        for res_1 in np.arange(num_res_founts):

            for res_2 in np.arange(num_res_founts):

                if res_1 != res_2 and len(all_trans_prices[res_1][res_2]) > 0 and np.max(all_trans_prices[res_1][res_2]) > 0.0:  # ie there are some transactions

                    # print('\n all_trans_prices[res_1][res_2]:', all_trans_prices[res_1][res_2])

                    working_prices_array = copy.copy(all_trans_prices[res_1][res_2])

                    # print('\n 1 / working_prices_array :', 1 / working_prices_array)

                    chart_prices_array = 1 / working_prices_array

                    chart_price_mean = np.mean(chart_prices_array)
                    chart_price_std = np.std(chart_prices_array)

                    # We record the price as a working price
                    self.mean_price_history[res_1][res_2][day] = chart_price_mean
                    self.price_history_std[res_1][res_2][day] = chart_price_std

                    if print_fine_dets == 1:
                        print('\n\n\n res_1', res_1, 'res_2', res_2, 'chart_price_mean =', chart_price_mean, 'std',
                              chart_price_std)

                    if print_fine_dets == 1:
                        print('\n chart_price_mean', chart_price_mean, 'chart_price_std', chart_price_std)

                else:

                    self.mean_price_history[res_1][res_2][day] = 1000

        # pause()

        # repeat the above process is we have 2 tribes
        if two_tribes:

            for res_1 in np.arange(num_res_founts):

                for res_2 in np.arange(num_res_founts):

                    if res_1 != res_2 and len(all_trans_prices_sharks[res_1][res_2]) > 0 and np.max(
                            all_trans_prices_sharks[res_1][res_2]) > 0.0:  # ie there are some transactions

                        working_prices_array_sharks = copy.copy(all_trans_prices_sharks[res_1][res_2])

                        chart_prices_array_sharks = 1 / working_prices_array_sharks

                        chart_price_mean_sharks = np.mean(chart_prices_array_sharks)
                        chart_price_std_sharks = np.std(chart_prices_array_sharks)

                        # We record the price as a working price
                        self.mean_price_history_sharks[res_1][res_2][day] = chart_price_mean_sharks
                        self.price_history_std_sharks[res_1][res_2][day] = chart_price_std_sharks

                        if print_fine_dets == 1:
                            print('\n chart_price_mean_sharks', chart_price_mean_sharks, 'chart_price_std_sharks',
                                  chart_price_std_sharks)

                    else:

                        self.mean_price_history_sharks[res_1][res_2][day] = 1000

            for res_1 in np.arange(num_res_founts):

                for res_2 in np.arange(num_res_founts):

                    if res_1 != res_2 and len(all_trans_prices_jets[res_1][res_2]) > 0 and np.max(
                            all_trans_prices_jets[res_1][res_2]) > 0.0:  # ie there are some transactions

                        working_prices_array_jets = copy.copy(all_trans_prices_jets[res_1][res_2])

                        chart_prices_array_jets = 1 / working_prices_array_jets

                        chart_price_mean_jets = np.mean(chart_prices_array_jets)
                        chart_price_std_jets = np.std(chart_prices_array_jets)

                        # We record the price as a working price
                        self.mean_price_history_jets[res_1][res_2][day] = chart_price_mean_jets
                        self.price_history_std_jets[res_1][res_2][day] = chart_price_std_jets

                        if print_fine_dets == 1:
                            print('\n chart_price_mean_jets', chart_price_mean_jets, 'chart_price_std_jets',
                                  chart_price_std_jets)

                    else:

                        self.mean_price_history_jets[res_1][res_2][day] = 1000

        # Now we update self.net_turnover_prop
        for res in np.arange(num_res_founts):

            # print('\n self.net_net_transs_db[day][res] =', self.net_net_transs_db[day][res], 'self.optimal_bskt_turnover[day][res]', self.optimal_bskt_turnover[day][res])

            self.net_turnover_prop[day][res] = self.net_net_transs_db[day][res] / self.optimal_bskt_turnover[day][res]

            if two_tribes:
                self.net_turnover_prop_sharks[day][res] = self.net_net_transs_db_sharks[day][res] / self.optimal_bskt_turnover_sharks[day][res]
                self.net_turnover_prop_jets[day][res] = self.net_net_transs_db_jets[day][res] / self.optimal_bskt_turnover_jets[day][res]

        # if print_fine_dets == 1 or day > 0 and day % 50 == 0:
        #     print('\n self.net_net_transs_db[day][res] =', self.net_net_transs_db[day][res])
        #     print(' self.optimal_bskt_turnover[day][res] =', self.optimal_bskt_turnover[day][res])
        #     print(' self.net_turnover_prop[day][res] =', self.net_turnover_prop[day][res])

        #            input("Press Enter to continue...")

        # Create array to record net transactions
        #        net_transs = []
        #        row = []
        #        for k in np.arange(num_res_founts):
        #            row.append(np.array([0.0, 0.0]))
        #        for l in np.arange(num_res_founts):
        #            net_transs.append(copy.deepcopy(row))

        # blank the array which record all transactions:
        #        self.all_transs_array = [[] for i in range(num_res_founts)]
        # and blank the array which records the granular transactions:
        #        self.all_transs_array_1_res = [[[] for i in range(num_res_founts)] for j in range(num_res_founts)]
        #        # Create an array to record which transactions we've already recorded, to prevent double counting
        #        all_trans_register = []

        #        # Unpack from self.transs_daily_db[day], which will have all of the day's transactions - all this section does is add to self.all_transs_array_1_res
        #        for trans_num in self.transs_daily_db[day]:
        #
        #            if print_fine_dets == 1:
        #                print('\ntrans_num =', trans_num)
        #
        #            trans = self.trans_db[trans_num]
        #
        #            # Add the amount sold to self.tot_trans_1_res
        #            self.tot_trans_1_res[day][trans.good_a][trans.good_b] += trans.tot_trans_ag_sell        # internal
        #            # Find the chart price
        #            chart_price = trans.tot_trans_ag_buy / float(trans.tot_trans_ag_sell)       # internal
        #            # Unpack Location
        #            locn = trans.location       # internal
        #
        #            self.all_transs_array_1_res[trans.good_a][trans.good_b].append([chart_price, self.tot_trans_1_res[day][trans.good_a][trans.good_b], trans.tot_trans_ag_sell, locn])
        #
        #            # For the database with data for one res versus all others:
        #            self.tot_trans[day][trans.good_a] += trans.tot_trans_ag_sell       # internal
        #            self.all_transs_array[trans.good_a].append([chart_price, self.tot_trans[day][trans.good_a]])       # internal
        #
        #            # We record the bilateral transaction data the other way round too:
        #            # Add the amount sold to self.tot_trans_1_res
        #            self.tot_trans_1_res[day][trans.good_b][trans.good_a] += trans.tot_trans_ag_buy       # internal
        #            # Find the chart price
        #            chart_price = trans.tot_trans_ag_sell / trans.tot_trans_ag_buy       # internal
        #
        #            self.all_transs_array_1_res[trans.good_b][trans.good_a].append([chart_price, self.tot_trans_1_res[day][trans.good_b][trans.good_a], trans.tot_trans_ag_buy, locn])

        # This is the end of the iteration over agents

        #        # Now we update self.all_chart_transs_1_res_adj and self.mean_price_history:
        #        self.all_chart_transs_1_res_adj = [[[] for i in range(num_res_founts)] for j in range(num_res_founts)]
        #
        #        for res_1 in np.arange(num_res_founts):
        #
        #            for res_2 in np.arange(num_res_founts):
        #
        #                if res_1 != res_2:
        #
        #                    all_chart_transs_1_res = self.all_transs_array_1_res[res_1][res_2]       # internal
        #
        #                    if print_fine_dets == 1:
        #                        print('\nxx all_chart_transs_1_res =\n', all_chart_transs_1_res)
        #
        #                    # If we want to show weighted average prices we have to adjust all_chart_transs_1_res:
        #
        #                    mean_chart_price = 0       # internal
        #
        #                    for index in np.arange(len(all_chart_transs_1_res)):
        #
        #                        mean_chart_price = 0
        #                        denom = all_chart_transs_1_res[index][1]       # internal
        #                        cumul_weight = 0       # internal
        #                        if print_fine_dets == 1:
        #                            print('\nindex =', index)
        #                            print('all_chart_transs_1_res[index] =', all_chart_transs_1_res[index])
        #                            print('denom =', denom)
        #
        #                        for ind in np.arange(index + 1):
        #
        #                            if print_fine_dets == 1:
        #                                print('ind =', ind)
        #
        #                            weight = all_chart_transs_1_res[ind][2] / float(denom)
        #                            mean_chart_price += weight * all_chart_transs_1_res[ind][0]
        #                            cumul_weight += weight
        #
        #                            if print_fine_dets == 1:
        #                                print('all_chart_transs_1_res[ind][2] =', all_chart_transs_1_res[ind][2])
        #                                print('weight =', weight)
        #                                print('cumul_weight =', cumul_weight)
        #                                print('mean_chart_price =', mean_chart_price)
        #
        #                        self.all_chart_transs_1_res_adj[res_1][res_2].append([mean_chart_price, all_chart_transs_1_res[index][1]])

        # if day > 0 and day % 50 == 0:
        #     print_fine_dets = 1

        # Now we update the agents' personal arrays: total_actual_agent_sales, total_optimal_agent_sales, personal_turnover_ratio
        for agent in self.agent_list:

            # if print_fine_dets == 1:
            #     print('\n\n\n agent =', agent)

            total_optimal_agent_sales = 0

            for res in np.arange(num_res_founts):

                res_opt_trans = agent.optimal_transs_systemic[day][res]

                if res_opt_trans > 0:
                    total_optimal_agent_sales += res_opt_trans

            agent.total_optimal_agent_sales[day] = total_optimal_agent_sales

            # if (params.track_agent and params.track_agent <= day) and agent_population.tracking_agent == agent:

            # we take different approaches, depending on respect for property rights
            if respect_property_rights == 0:

                if print_fine_dets:

                    print('\n agent.agent_res_array =', agent.agent_res_array)
                    print('\n agent.basket_array_start: ', agent.basket_array_start[0])
                    print(' agent.basket_array: ', agent.basket_array[0])
                    print(' total_optimal_agent_sales =', total_optimal_agent_sales)

                # there are 9 scenarios to consider for the two resources (up, down, equal to X up, down, equal to)
                # here, the agent must have been (net) mugged or it didn't see a change in its basket (not trans, no fights where it gained) - covers 4 of the 9 scenarios
                if agent.basket_array[0][0] <= agent.basket_array_start[0][0] and agent.basket_array[0][1] <= agent.basket_array_start[0][1]:

                    if print_fine_dets:
                        print('\n it looks like the agent has been (net) mugged - agent.total_actual_agent_sales[day] = 0.0')

                    agent.total_actual_agent_sales[day] = 0.0
                    agent.personal_turnover_ratio[day] = 0.0

                # here the agent has net mugged (an)other(s) - we treat this 'as if' the agent sold everything it wanted to - covers 3 of the 9 scenarios
                elif (agent.basket_array[0][0] > agent.basket_array_start[0][0] and agent.basket_array[0][1] > agent.basket_array_start[0][1]) or \
                        (agent.basket_array[0][0] > agent.basket_array_start[0][0] and agent.basket_array[0][1] == agent.basket_array_start[0][1]) or \
                        (agent.basket_array[0][0] == agent.basket_array_start[0][0] and agent.basket_array[0][1] > agent.basket_array_start[0][1]):

                    if print_fine_dets:
                        print('\n it looks like the agent has been a bit naughty and has (net) mugged other agents - agent.total_actual_agent_sales[day] = total_optimal_agent_sales = ', total_optimal_agent_sales)

                    agent.total_actual_agent_sales[day] = total_optimal_agent_sales
                    agent.personal_turnover_ratio[day] = 1.0

                else:

                    # there are 7 of the total 9 scenarios above - else covers the remaining two where one resource went up and the other down.
                    # here we copy the conventional approach by measuring the total 'sales' and comparing it to the optimal.  Note this is a conservative stratgy
                    # because if the changes are the reverse of the optimal then we get turnover ratio of 0; but if they are the same way round then we treat the whole thing
                    # 'as if' they sold, i.e., if anything this approach understates the turnover ratio

                    if print_fine_dets:
                        print('\n it looks like the agent has seen one resource increase and the other decrease \n')

                    # Create a variable to record net sales of goods (we will ignore purchases)
                    total_actual_agent_sales = 0

                    for res in np.arange(num_res_founts):

                        # the net transactions for this resource =
                        res_trans = agent.basket_array_start[0][res] - agent.basket_array[0][res]

                        if res_trans > 0:  # then the agent sold this resource

                            total_actual_agent_sales += res_trans

                        if print_fine_dets:
                            print(' res_trans = agent.basket_array_start[0][res] - agent.basket_array[0][res] =', res_trans)

                    agent.total_actual_agent_sales[day] = total_actual_agent_sales

                    if print_fine_dets:
                        print('\n agent.total_actual_agent_sales[day] = total_actual_agent_sales =', total_actual_agent_sales)

                    # note to self: for sims with 2 resources, the ratio of sales and demands will not be the same because trans prices will differ from the mkt clearing price
                    if total_optimal_agent_sales > 0:  # We can get / zero (note default value is zero):

                        agent.personal_turnover_ratio[day] = total_actual_agent_sales / float(total_optimal_agent_sales)

            #                if print_fine_dets == 1:

            #                if day > 10:
            #
            #                    print('\n self.optimal_price_array[day][0][1] =', self.optimal_price_array[day][0][1])
            #                    print('\n agent.agent_res_array[0] =', agent.agent_res_array[0])
            #                    print('\n agent.basket_array_start[0] =', agent.basket_array_start[0])
            #                    print(' agent.basket_array[0] =', agent.basket_array[0])
            #                    print('\n agent.total_optimal_agent_sales[day] =', agent.total_optimal_agent_sales[day])
            #                    print(' agent.total_actual_agent_sales[day] =', agent.total_actual_agent_sales[day])
            #                    print(' agent.personal_turnover_ratio[day] =', agent.personal_turnover_ratio[day])
            #
            #                    pause()

            else:

                # Create a variable to record net sales of goods (we will ignore purchases)
                total_actual_agent_sales = 0

                for res in np.arange(num_res_founts):

                    if print_fine_dets == 1:
                        print('\n\n res =', res)
                        print('\n agent.basket_array_start[0] =', agent.basket_array_start[0])
                        print('\n agent.basket_array[0] =', agent.basket_array[0])
                        print('\n agent.basket_array_start[0][res] =', agent.basket_array_start[0][res])
                        print('\n agent.basket_array[0][res] =', agent.basket_array[0][res])

                    # the net transactions for this resource =
                    res_trans = agent.basket_array_start[0][res] - agent.basket_array[0][res]

                    if print_fine_dets == 1:
                        print('\n res_trans =', res_trans)

                    if res_trans > 0:  # then the agent sold this resource

                        total_actual_agent_sales += res_trans

                agent.total_actual_agent_sales[day] = total_actual_agent_sales

                if print_fine_dets == 1:
                    print('\n\n total_actual_agent_sales =', total_actual_agent_sales)

                # note to self: for sims with 2 resources, the ratio of sales and demands will not be the same because trans prices will differ from the mkt clearing price
                if total_optimal_agent_sales > 0:  # We can get / zero (note default value is zero):

                    agent.personal_turnover_ratio[day] = total_actual_agent_sales / float(total_optimal_agent_sales)

                # if print_fine_dets:
                #     print('\n agent.personal_turnover_ratio[day] =', agent.personal_turnover_ratio[day])

            # Note we limit each agent's personal_turnover_ratio[day] to 1
            agent.personal_turnover_ratio[day] = np.min([agent.personal_turnover_ratio[day], 1.0])

        # if we're respecting property rights, we record the agents' turnover ratio by taking an average of all the agents' personal turnover ratios:
        if params.respect_property_rights == 0:

            total_personal_turnover_values = 0

            for agent in agent_population.pop:
                total_personal_turnover_values += agent.personal_turnover_ratio[day]

            mean_personal_turnover_values = total_personal_turnover_values / float(len(agent_population.pop))

            # add this to the database which generates charts
            self.net_turnover_prop[day][0] = mean_personal_turnover_values
            self.net_turnover_prop[day][1] = mean_personal_turnover_values

            # we also find the implied net transactions for all agents
            self.net_net_transs_db[day][0] = self.optimal_bskt_turnover[day][0] * mean_personal_turnover_values
            self.net_net_transs_db[day][1] = self.optimal_bskt_turnover[day][1] * mean_personal_turnover_values

            # if mean_personal_turnover_values > 4.0:
            #     print_fine_dets = 1

            if print_fine_dets:

                print('\n Turnover ratios data:')
                for agent in agent_population.pop:
                    print('\n agent.agent_res_array:', agent.agent_res_array)
                    print(' agent.basket_array_start:', agent.basket_array_start[0])
                    print(' agent.basket_array end:', agent.basket_array[0])
                    print(' agent.total_actual_agent_sales[day]:', agent.total_actual_agent_sales[day])
                    print(' agent.total_optimal_agent_sales[day]:', agent.total_optimal_agent_sales[day])
                    print(' agent.personal_turnover_ratio[day] = ', agent.personal_turnover_ratio[day])
                print('\n implied self.net_net_transs_db[day] =', self.net_net_transs_db[day])
                print(' self.optimal_bskt_turnover[day] =', self.optimal_bskt_turnover[day])
                print(' self.net_turnover_prop[day] from mean of agents personal_turnover_ratios =', self.net_turnover_prop[day])

        # if print_fine_dets == 1:
        #     pause()


class Transaction():

    """This is a class for recording a transaction between agents."""

    # the class is initiated with a starting population:
    def __init__(self, ag_for_strat_array, cp_for_strat_array, location, day, good_a, good_b, agent_a_home, agent_b_home, tot_trans_ag_sell, tot_trans_ag_buy, move_num, agent_a_trgt, agent_b_trgt,
                 a_tb, b_tb, a_loc_rec, b_loc_rec, a_MRS_array, b_MRS_array, agent_a, agent_b, trans_agr_MRS, agent_a_tribe, agent_b_tribe):

        self.location = location
        self.day = day
        self.good_a = good_a        # this is what agent_a is selling
        self.good_b = good_b        # this is what agent_a is buying
        self.agent_a_home = agent_a_home
        self.agent_b_home = agent_b_home
        self.tot_trans_ag_sell = tot_trans_ag_sell      # total number of goods to have passed hands (agent sells)
        self.tot_trans_ag_buy = tot_trans_ag_buy      # total number of goods to have passed hands (agent buys)
        self.move_num = move_num
        self.agent_a_trgt = agent_a_trgt
        self.agent_b_trgt = agent_b_trgt
        self.a_tb = a_tb                # agent a's trading basket
        self.b_tb = b_tb                # agent b's trading basket
        self.a_loc_rec = a_loc_rec
        self.b_loc_rec = b_loc_rec
        self.a_MRS_array = a_MRS_array
        self.b_MRS_array = b_MRS_array
        self.trans_agr_MRS = trans_agr_MRS
        self.ag_for_strat_array = ag_for_strat_array
        self.cp_for_strat_array = cp_for_strat_array
        self.agent_a = agent_a
        self.agent_b = agent_b
        self.agent_a_tribe = agent_a_tribe
        self.agent_b_tribe = agent_b_tribe

        self.initiator_new_prop_steal = 0.0
        self.initiator_new_prop_fight_back = 0.0
        self.counterpart_new_prop_steal = 0.0
        self.counterpart_new_prop_fight_back = 0.0
        self.initiator_start_prop_steal = 0.0
        self.initiator_start_prop_fight_back = 0.0
        self.counterpart_start_prop_steal = 0.0
        self.counterpart_start_prop_fight_back = 0.0


class Fight_Object():

    def __init__(self, day, fight_num, initiator, counterpart, location, winner, agent_record, cp_agent_record, agent_res_gain, cp_agent_res_gain, move_num,
                 initiator_new_prop_steal, initiator_new_prop_fight_back, counterpart_new_prop_steal, counterpart_new_prop_fight_back,
                 initiator_start_prop_steal, initiator_start_prop_fight_back, counterpart_start_prop_steal, counterpart_start_prop_fight_back,
                 initiator_start_basket, counterpart_start_basket, initiator_dec, counterpart_dec, initiator_end_basket, counterpart_end_basket,
                 agent_start_res, cp_agent_start_res, agent_a_tribe, agent_b_tribe):

        self.day = day
        self.fight_num = fight_num
        self.initiator = initiator
        self.counterpart = counterpart
        self.location = location
        self.winner = winner
        self.agent_record = agent_record
        self.cp_agent_record = cp_agent_record
        self.agent_res_gain = agent_res_gain
        self.cp_agent_res_gain = cp_agent_res_gain
        self.move_num = move_num
        self.initiator_new_prop_steal = initiator_new_prop_steal
        self.initiator_new_prop_fight_back = initiator_new_prop_fight_back
        self.counterpart_new_prop_steal = counterpart_new_prop_steal
        self.counterpart_new_prop_fight_back = counterpart_new_prop_fight_back
        self.initiator_start_prop_steal = initiator_start_prop_steal
        self.initiator_start_prop_fight_back = initiator_start_prop_fight_back
        self.counterpart_start_prop_steal = counterpart_start_prop_steal
        self.counterpart_start_prop_fight_back = counterpart_start_prop_fight_back
        self.initiator_start_basket = initiator_start_basket
        self.counterpart_start_basket = counterpart_start_basket
        self.initiator_dec = initiator_dec
        self.counterpart_dec = counterpart_dec
        self.initiator_end_basket = initiator_end_basket
        self.counterpart_end_basket = counterpart_end_basket
        self.agent_start_res = agent_start_res
        self.cp_agent_start_res = cp_agent_start_res
        self.agent_a_tribe = agent_a_tribe
        self.agent_b_tribe = agent_b_tribe


class Interaction():

    def __init__(self, day, move, agent, cp_agent, intn_type, intn_num, agent_a_dec, agent_b_dec, location, agent_net_benefit, cp_agent_net_benefit, agent_net_benefit_back_prop, cp_agent_net_benefit_back_prop,
                 ag_ch_prop_steal_simple, cp_ch_prop_steal_simple, ag_ch_prop_fb_simple, cp_ch_prop_fb_simple, agent_net_gain_NNs, cp_agent_net_gain_NNs, ag_exp_overall_rtn, cp_exp_overall_rtn, ag_exp_quad_2_rtn,
                 cp_exp_quad_3_rtn, agent_net_benefit_back_prop_fb, cp_agent_net_benefit_back_prop_fb,
                 agent_a_start_day_res, agent_b_start_day_res, agent_a_start_day_bskt, agent_b_start_day_bskt, agent_a_start_trans_res, agent_b_start_trans_res, agent_a_start_trans_bskt,
                 agent_b_start_trans_bskt, transfer_to_agent_a, transfer_to_agent_b, agent_a_ps_start_trans, agent_b_ps_start_trans, agent_a_pfb_start_trans, agent_b_pfb_start_trans, agent_a_ps_end_trans,
                 agent_b_ps_end_trans, agent_a_pfb_end_trans, agent_b_pfb_end_trans):

        self.day = day
        self.move = move
        self.agent = agent
        self.cp_agent = cp_agent
        self.intn_type = intn_type
        self.intn_num = intn_num
        self.agent_a_dec = agent_a_dec
        self.agent_b_dec = agent_b_dec
        self.location = location
        self.agent_net_benefit = agent_net_benefit
        self.cp_agent_net_benefit = cp_agent_net_benefit
        self.agent_net_benefit_back_prop = agent_net_benefit_back_prop
        self.cp_agent_net_benefit_back_prop = cp_agent_net_benefit_back_prop
        self.ag_ch_prop_steal_simple = ag_ch_prop_steal_simple
        self.ag_ch_prop_fb_simple = ag_ch_prop_fb_simple
        self.cp_ch_prop_steal_simple = cp_ch_prop_steal_simple
        self.cp_ch_prop_fb_simple = cp_ch_prop_fb_simple
        self.agent_net_gain_NNs = agent_net_gain_NNs
        self.cp_agent_net_gain_NNs = cp_agent_net_gain_NNs
        self.ag_exp_overall_rtn = ag_exp_overall_rtn
        self.cp_exp_overall_rtn = cp_exp_overall_rtn
        self.ag_exp_quad_2_rtn = ag_exp_quad_2_rtn
        self.cp_exp_quad_3_rtn = cp_exp_quad_3_rtn
        self.agent_net_benefit_back_prop_fb = agent_net_benefit_back_prop_fb
        self.cp_agent_net_benefit_back_prop_fb = cp_agent_net_benefit_back_prop_fb
        self.agent_a_start_day_res = agent_a_start_day_res
        self.agent_b_start_day_res = agent_b_start_day_res
        self.agent_a_start_day_bskt = agent_a_start_day_bskt
        self.agent_b_start_day_bskt = agent_b_start_day_bskt
        self.agent_a_start_trans_res = agent_a_start_trans_res
        self.agent_b_start_trans_res = agent_b_start_trans_res
        self.agent_a_start_trans_bskt = agent_a_start_trans_bskt
        self.agent_b_start_trans_bskt = agent_b_start_trans_bskt
        self.transfer_to_agent_a = transfer_to_agent_a
        self.transfer_to_agent_b = transfer_to_agent_b
        self.agent_a_ps_start_trans = agent_a_ps_start_trans
        self.agent_b_ps_start_trans = agent_b_ps_start_trans
        self.agent_a_pfb_start_trans = agent_a_pfb_start_trans
        self.agent_b_pfb_start_trans = agent_b_pfb_start_trans
        self.agent_a_ps_end_trans = agent_a_ps_end_trans
        self.agent_b_ps_end_trans = agent_b_ps_end_trans
        self.agent_a_pfb_end_trans = agent_a_pfb_end_trans
        self.agent_b_pfb_end_trans = agent_b_pfb_end_trans


class Fountain():

    """A class for instantiating a resource fountain."""

    def __init__(self, init_res_level, dimen, trade_loc, rounds, tribe):

        self.init_res_level = init_res_level
        self.res_level = init_res_level    # resource level of the foutain
        self.highest_prices = np.zeros(shape=(rounds))      # measure is working price

        if trade_loc == 'fountain':

            self.location = [random.randint(0, dimen - 1), random.randint(0, dimen - 1)]

        self.tribe = tribe


class Resource_Fountain_Population():

    """This is a class for managing a population of resource fountains."""

    # the class is initiated with a starting population:
    def __init__(self, start_population, two_tribes):

        self.pop = start_population

        if two_tribes == 1:

            self.pop_0 = [start_population[0], start_population[1]]         # these will have tags for 'sharks'
            self.pop_1 = [start_population[2], start_population[3]]         # these will have 'jets' tags


class Keynesian_Object_Population():

    def __init__(self):

        self.pop = []
        self.KI_stiffs = []


class Keynesian_Object():

    def __init__(self, day_created, loc, folder, notes_file, pre_dead_ags_grid, post_dead_ags_grid, target_agents, trgt_locations):

        self.day_created = day_created
        self.loc = loc
        self.folder = folder
        self.notes_file = notes_file
        self.pre_dead_ags_grid = pre_dead_ags_grid
        self.post_dead_ags_grid = post_dead_ags_grid
        self.target_agents = target_agents
        self.trgt_locations = trgt_locations

    def write_to_notes(self, text):

        with open(self.notes_file, 'a') as myfile:
            myfile.write(text)

        myfile.close()

    def add_initial_text(self, fountain_population, trade_prices, granular_mem, print_fine_dets, print_dets, dbs,
                         town_grid, day, wait_at_tgt_moves):

        # print('\n self.target_agents:', self.target_agents)

        has_acted = 0
        move = 0

        text = '\n\n\nTarget Live Agents - Home, Foraging Strategies, Starting Res Arrays and Current Grid Target:\n'

        self.write_to_notes(text)

        for ag in self.target_agents:

            if ag.age > 0:          # an error occurs if the agent was born on the same day the KI was formed

                text = '\nagent home [%2.0f, %2.0f]  |  for. array %s  |  res [%2.4s, %2.4s]  |  curr trgt %s' % (ag.home[0], ag.home[1], ag.for_strat_array[0], ag.agent_res_array[0][0], ag.agent_res_array[0][1], ag.start_trgt_loc_rec[day][0])

            # except Exception as e:
            #
            #     print('\n couldnt write text')
            #     print(' Exception is', e)
            #     print('\n ag.home', ag.home)
            #     print('\n ag.for_strat_array', ag.for_strat_array)
            #     print('\n ag.agent_res_array', ag.agent_res_array)
            #     print('\n ag.start_trgt_loc_rec', ag.start_trgt_loc_rec)
            #     pause()

                self.write_to_notes(text)

        text = '\n\n\nHistory of grid square wrt transactions to date at the KI location\n'
        self.write_to_notes(text)

        there_is_hist = 0

        for trans in dbs.trans_db:

            if trans.tot_trans_ag_sell is not None and trans.location[0] == self.loc[0] and trans.location[1] == \
                    self.loc[1]:
                text = '\nday = %s  |  move_num = %s  |  agent A sold %s  |  agent B sold %s' % (
                trans.day, trans.move_num, trans.tot_trans_ag_sell, trans.tot_trans_ag_buy)

                there_is_hist = 1

        if there_is_hist == 0:
            text = '\n-----> There have been no transactions at this square\n'
            self.write_to_notes(text)

        text = '\n\n\nTransaction Information at the KI Location after it was proposed\n'
        self.write_to_notes(text)

        # pause()

# if __name__ == "__main__":
#     run_sim_suite()