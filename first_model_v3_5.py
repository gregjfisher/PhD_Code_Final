# -*- coding: utf-8 -*-
"""
Created on Sunday 8 March 2015 17.25

This file sets up a simple economic system, including resources which are 'collected'
by agents who forage.  These agents then trade the resources, which they also
'consume' for survival.  Agents also adjust their foraging and trading strategies
through simulated cognitive processes.

@author: Greg Fisher (gjf1g13@soton.ac.uk)
"""


import numpy as np
#from pandas.DataFrame import rolling_mean as pd_rolling_mean
import random
import matplotlib.pyplot as plt
import DateTime as dt
import copy
import math
import statsmodels.api as sm
#import itertools
import os
from mpl_toolkits.mplot3d.axes3d import Axes3D
import operator
import scipy.optimize as optimize
import builtins

from operator import itemgetter

from matplotlib import cm
from matplotlib.ticker import LinearLocator, FormatStrFormatter

#import plotly.plotly as py
import plotly

import chart_studio.plotly as py
from plotly.graph_objs import Surface
import plotly.graph_objs as go

import time

# from playsound import playsound

import smtplib

from urllib.error import HTTPError

from gjf_lib_v1_0_old_version_copy import print_chart as print_chart, print_SD_chart as print_SD_chart, print_chart_cc as print_chart_cc, print_chart_prices as print_chart_prices, send_mail as send_mail, pause as pause, length_of_time as length_of_time,\
generate_MA_array as generate_MA_array, plot_scatter_2d as plot_scatter_2d, gini as gini, print_turnover_breakdown_charts as print_turnover_breakdown_charts, print_turnover_charts as print_turnover_charts,\
print_prices_charts as print_prices_charts, find_location_furthest_away as find_location_furthest_away, abs_dist_on_torus as abs_dist_on_torus, within_striking_dist as within_striking_dist, print_3d_histogram as print_3d_histogram,\
create_heat_map_double_plotly as create_heat_map_double_plotly, create_heat_map_double as create_heat_map_double, create_heat_map as create_heat_map, print_3d_SD_planes as print_3d_SD_planes,\
plot_single_plane_plotly as plot_single_plane_plotly, plot_3d_SD_planes_plotly as plot_3d_SD_planes_plotly, find_best_box as find_best_box, print_histogram as print_histogram, print_scatter_1d as print_scatter_1d,\
print_scatter_1d_MRS_moves as print_scatter_1d_MRS_moves, plot_non_policy_lines_and_errors as plot_non_policy_lines_and_errors, plot_policy_lines_and_errors as plot_policy_lines_and_errors,\
create_supply_demand_charts as create_supply_demand_charts

from gjf_lib_v1_0 import print_contributions_to_tot_2_axes as print_contributions_to_tot_2_axes

# Global Variables

# Core structural parameters
num_res_founts = 2

# Agent
num_agents = 25

# Foraging
prob_res_detection = 0.5
max_prob_det = 1.0
min_prob_det = 0.2

wait_at_target_til_end = 1

# This is the directory in which any output is placed
directory = '/Users/Greg/PhD/Simulations/simulation_runs/'
#directory = '/Users/user/Documents/SugarSync_Shared_Folders/ICSS_research/Research/Simulations/results/'

system_folder = "%ssim_sets/" % (directory)   # "%ssim_sets/z_holiday_sims/"


def run_sim_suite(rounds=2000, num_runs=20, readme_notes='none', heatmap_days_show=250, SD_charts_freq=250):

    """This function runs a suite of simulations where parameters vary over the suite. Each simulation set has fixed
    parameters. Each simulation has a number of runs ('num_runs') and each run is given a certain number of rounds ('rounds')."""

#    # iteration loop for each sim set:
#    for scenario in ['null', 'two', 'three', 'default']:      # ['null', 'two', 'three', 'default']
#
#        # record data returned from 'run_sim()' function
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, scenario=scenario, readme_notes=scenario)
#
#    for mem in [1]:
#
#        readme_notes = 'adjust_mem_length_mem_%s' % (mem)
#
#        multi_sims(num_runs=num_runs, rounds=rounds, agent_mem_length=mem, readme_notes=readme_notes)

#    for density in [1]:      # [4, 5, 6, 7, 8, 9]
#
##        wait_at_tgt_moves = 400
##        trade_moves = 800
#
#        wait_at_tgt_moves = np.max([density * 2, 8])
#        trade_moves = (density * 2) + wait_at_tgt_moves
#
#        readme_notes = 'change_dim_density_%s_wait_%s' % (density, wait_at_tgt_moves)
#
##        print('sim_suite: wait_at_tgt_moves =', wait_at_tgt_moves, 'trade_moves =', trade_moves)
#
#        # record data returned from 'run_sim()' function
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, dimen_density=density, trade_moves=trade_moves, wait_at_tgt_moves=wait_at_tgt_moves, readme_notes=readme_notes, scenario='adjust_travel_dist')

#    readme_notes = 'no_comms_rounds_1000'
#
#    # record data returned from 'run_sim()' function
#    multi_sims(num_runs=num_runs, rounds=1000, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, agents_comm_prob=0.0, readme_notes=readme_notes)   

#    mem = 0
#
#    for density in [1, 2, 4, 12, 20]:   # 1, 2, 4, 12, 20
#
#        wait_at_tgt_moves = np.max([density * 2, 8])
#        trade_moves = (density * 2) + wait_at_tgt_moves
#
#        for comms_prob in [0.0]:       # [0.0, 0.0025, 0.005, 0.0075, 0.01]
#
#            readme_notes = 'ch_mem_%d_den_%d_comms_%1.4f_random' % (mem, density, comms_prob)
#
#            # record data returned from 'run_sim()' function
#            multi_sims(num_runs=num_runs, rounds=5000, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, agent_mem_length=mem, dimen_density=density, trade_moves=trade_moves, wait_at_tgt_moves=wait_at_tgt_moves, agents_comm_prob=comms_prob, scenario='adjust_travel_dist', readme_notes=readme_notes, trade_movemnt='random')

#    for mem in [1]:
#
#        for density in [40]:   # 1, 2, 4, 12, 20
#
#            wait_at_tgt_moves = np.max([density * 2, 8])
#            trade_moves = (density * 2) + wait_at_tgt_moves
#
#            for comms_prob in [0.0, 0.0025, 0.005, 0.0075, 0.01]:       # [0.0, 0.0025, 0.005, 0.0075, 0.01]
#
#                readme_notes = 'ch_mem_%d_den_%d_comms_%f' % (mem, density, comms_prob)
#
#                # record data returned from 'run_sim()' function
#                multi_sims(num_runs=num_runs, rounds=5000, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, agent_mem_length=mem, dimen_density=density, trade_moves=trade_moves, wait_at_tgt_moves=wait_at_tgt_moves, agents_comm_prob=comms_prob, scenario='adjust_travel_dist', readme_notes=readme_notes)
#
#    for wait in range(11):
#
#        readme_notes = 'wait_at_trgt_%d' % (wait)
#
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, trade_moves=20+wait, wait_at_tgt_moves=wait, scenario='adjust_travel_dist', readme_notes=readme_notes, wait_at_target_til_end=0)

#    readme_notes = 'transact_otw_tgt'
#
#    multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, trade_when_trgt=0, readme_notes=readme_notes)
#
#    # iteration loop for each sim set:
#    for r in [0.0025, 0.005, 0.0075, 0.01, 0.0125, 0.015, 0.0175, 0.02]:      # [4, 5, 6, 7, 8, 9]
#
#        readme_notes = 'r_speed_of_skill_ch_%s' % (r)
#
#        # record data returned from 'run_sim()' function
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, for_skill_r=r, readme_notes=readme_notes)
#
#    readme_notes = 'randomize_home_locs'
#
#    multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, agent_homes='random', readme_notes=readme_notes)

#    for density in [60]:
#
#        readme_notes = 'randomize_home_locs_ch_den_%s' % (density)
#    
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, agent_homes='random', dimen_density=density, readme_notes=readme_notes)

#    readme_notes = 'pop_variation'
#
#    multi_sims(num_runs=num_runs, readme_notes=readme_notes, popn_ch='vary', rounds=1000, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, )

#    for intel in [0.75]:   # [0.0, 0.5, 1.0, 1.5, 2.0, 100.0]
#
#        readme_notes = 'intelligence_change_%s' % (intel)
#
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, cognition_factor=intel, readme_notes=readme_notes)

#    for weight in [0.001]:     # 0.25, 0.75, 1.0, 1.25, 1.50
#
#        readme_notes = 'other_agent_trans_weight_%s' % (weight)
#
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, readme_notes=readme_notes, cp_trans_weight=weight)

#   serviced_grids

#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18]
#
#        rounds = 100000
#        readme_notes = 'travel_dist_change_%s_rounds_%d' % (dist, rounds)
#
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=50, SD_charts_freq=50, readme_notes=readme_notes, wait_at_tgt_moves=8, trade_moves=(dist + 8), scenario='adjust_travel_dist', homes_spacing='square')

#    readme_notes = 'WTA'
#
#    multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, readme_notes=readme_notes, trgt_sel=readme_notes)

#    readme_notes = 'force_prices_power'
#
#    multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=heatmap_days_show, readme_notes=readme_notes, force_prices='power')

#    readme_notes = 'initial_res_std_%s' % (0.0)
#
#    multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, readme_notes=readme_notes, agent_res_init_std=0.0)

#    readme_notes = 'fountain_home_locs'
#
#    multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, trade_loc='fountain', readme_notes=readme_notes)        #, trgt_sel='WTA', trade_when_trgt=0)

#    readme_notes = 'fountain_home_locs_otw'
#
#    multi_sims(num_runs=num_runs, rounds=5000, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, trade_loc='fountain', readme_notes=readme_notes, trade_when_trgt=0, SD_charts_freq=20)        #agents_comm_prob=0.0, trgt_sel='WTA', trade_when_trgt=0)

#    for ag_mean in [1.3, 1.4, 1.2]:
#
#        readme_notes = 'fountain_res_per_agent_%s' % (ag_mean)
#    
#        multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, readme_notes=readme_notes, init_res_lev_per_agent=ag_mean)

#    KI_round = 500
#    num_runs = 100
#
#    for ratio in [0.625]:               # [0.25, 0.5, 0.75, 1.0, 1.25, 1.50, 2.0, 2.5, 3.0, 4.0, 5.0, 7.5, 1000000000.0]
#
#        for num_agents in [16]:         # 4, 8, 12, 16
#
#            readme_notes = 'Keynes_Inst_500_Kratio_%s_num_%d' % (ratio, num_agents)
#
#            multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, readme_notes=readme_notes, allow_Keynes_Inst='total', Keynes_round=KI_round, keynesian_ratio=ratio, num_KI_agents=num_agents, print_end_of_round_charts=0)

#    rounds = 3000
#    start_famine = 1000
#    famine_duration = 1000
#
#    for fam_ress in [[0], [0, 1]]:
#
#        readme_notes = 'famine_%d_res_st_%d_end_%d' % (len(fam_ress), start_famine, start_famine + famine_duration)
#    
#        multi_sims(readme_notes=readme_notes, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, res_depletion=start_famine, tot_rounds_depl=famine_duration, fount_dep=fam_ress, fount_depl_ratio=0.5, popn_ch='vary')

    # here we try to engineer local market

    # default:
#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [4]:    # 4, 20
#
#            for res in [50]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.01
#                allow_Keynes_Inst = 'none' # 'sparse'
#                chart_freq = 500
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=chart_freq, SD_charts_freq=chart_freq, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)

    # default with policy intervention
#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [4]:    # 4, 20
#
#            for res in [50]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.01
#                allow_Keynes_Inst = 'sparse' # 'sparse'
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=500, SD_charts_freq=500, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)
#

#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [20]:    # 4, 20
#
#            for res in [50]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.01
#                allow_Keynes_Inst = 'none' # 'sparse'
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=500, SD_charts_freq=500, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)

#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [4]:    # 4, 20
#
#            for res in [50]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.5
#                allow_Keynes_Inst = 'none' # 'sparse'
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=500, SD_charts_freq=500, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)

#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [4]:    # 4, 20
#
#            for res in [200]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.01
#                allow_Keynes_Inst = 'none' # 'sparse'
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=500, SD_charts_freq=500, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)

#    for dist in [6]:     # [6, 8, 10, 12, 14, 16, 18] serviced_grids prob Important set_agent_target
#
#        for mem in [20]:    # 4, 20
#
#            for res in [200]:    # 50, 200 dist Important
#
#                rounds = 40000
#                agents_comm_prob = 0.5
#                allow_Keynes_Inst = 'none' # 'sparse'
#
#                readme_notes = 'engineer_local_mkts_dist_%s_mem_%s_res_%s_rounds_%s_ags_%d_comms_%s_KI_%s' % (dist, mem, res, rounds, agents_comm_prob, allow_Keynes_Inst)
#
#                multi_sims(num_runs=20, rounds=rounds, heatmap_days_show=500, SD_charts_freq=500, readme_notes=readme_notes, agent_mem_length=mem, agent_res_init=res, wait_at_tgt_moves=10, trade_moves=(dist + 10),
#                           scenario='adjust_travel_dist', keynesian_ratio=1.0, allow_Keynes_Inst=allow_Keynes_Inst, loc_mkt='avoid_interference', restrict_by_district=0, homes_spacing='square', agents_comm_prob=agents_comm_prob, print_local_policy_data=1)

#    # here we fix prices - note this is the chart price of resource 0  
#    for price in [10.0]:
#
#        readme_notes = 'fixed_price_at_%s' % (price)
#
#        multi_sims(readme_notes=readme_notes, force_prices='fixed', fixed_price=price, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, print_end_of_round_charts=1)

#    for const_exp in range(4):

#    mating_thresh = 100
#    applied_constitutions = [3, 1]         # [1, 2, 3, 4, 5]
#
#    num_experiments = len(applied_constitutions)
#
#    start_const_proces = 2000
#    const_proc_test_period = 500
#    rounds = int(start_const_proces + (const_proc_test_period * num_experiments))
#
#    readme_notes = 'constitution_test_start_%d_periods_%d_%s' % (start_const_proces, const_proc_test_period, applied_constitutions)
##    readme_notes = 'constitution_test_null_rounds_%d' % (rounds)
#
#    multi_sims(num_runs=100, rounds=rounds, print_voting_only=1, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, readme_notes=readme_notes, constitutional_voting=1, applied_constitutions=applied_constitutions,
#               start_const_proces=start_const_proces, const_proc_test_period=const_proc_test_period, num_experiments=num_experiments, ststst=[1, 22, [1.0, 0.2], [20, 20], 'even'],
#               popn_ch='vary', mating_thresh=mating_thresh, cognition_factor=0.1)        #agent_res_init_std=5, const_mkt_opens = 20) #, force_prices = 'optimal')

#     # in this experiment we vary the population and the agents walk around randomly
#    readme_notes = 'pop_variation_random_walk_moves_100'
#
#    multi_sims(num_runs=20, rounds=10000, readme_notes=readme_notes, popn_ch='vary', agent_homes='random', trade_movemnt='random', dimen_density=8, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq, trade_moves=100)

#    readme_notes = 'test_steady_state_start'
#
#    multi_sims(rounds=5000, num_runs=5, ststst=[1, 22, [1.0, 0.2], [20, 20]], popn_ch='vary', readme_notes=readme_notes)

#    send_mail(send_from='gregfisherhome@gmail.com', send_to='greg.fisher@synthesisips.net',
#              subject='Testing email', text='test', files=[], server='smtp.gmail.com',
#              port=587, username='gregfisherhome@gmail.com', password='NewW0rld)rdergmail', isTls=True)  


# HOLIDAY CODE strangers_interact

    # Null models
#    readme_notes = 'no_prop_rights_null_ps_0.0_p_fb_0.0_no_error'
#
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, fix_ps_fb_0=1)

#    readme_notes = 'no_prop_rights_null_ps_1.0'
#
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, fixed_prop_steal=1.0)
#
#    readme_notes = 'no_prop_rights_null_fix_0.5'
#    
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, adjust_props_r=0.0, start_prop_steal_mean=0.5, start_prop_steal_std=0.0, start_prop_fight_back_mean=0.5, start_prop_fight_back_std=0.0, child_prop_std=0.0)

    # readme_notes = 'no_prop_rights_null_rational_fb'
    #
    # multi_sims(respect_property_rights=0, readme_notes=readme_notes, strat_choice='rational', stranger_int='fb')

    # readme_notes = 'no_prop_rights_null_rational_acq'
    #
    # multi_sims(respect_property_rights=0, readme_notes=readme_notes, strat_choice='rational', stranger_int='acq')

    # default
    # readme_notes = 'no_prop_rights_default_res_125'
    #
    # multi_sims(respect_property_rights=0, readme_notes=readme_notes, PR_res_init=125, PR_mating_threshold=125, rounds=1000)

     # props ceiling and floors
#    readme_notes = 'no_prop_props_ceil_and_floors_0.01_0.99'
#    
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, prop_steal_ceil=0.99, prop_steal_floor=0.01, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01)

#    # start props at different high and low levels
#    readme_notes = 'no_prop_rights_starts_ps_0.9_pf_0.1'
#
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, start_prop_steal_mean=0.9, start_prop_fight_back_mean=0.1)
#
#    readme_notes = 'no_prop_rights_starts_ps_0.9_pf_0.1_res_250'
#
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, start_prop_steal_mean=0.9, start_prop_fight_back_mean=0.1, PR_res_init=250)
#
#    readme_notes = 'no_prop_rights_starts_ps_0.1_pf_0.9'
#
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, start_prop_steal_mean=0.1, start_prop_fight_back_mean=0.9)
#
#    readme_notes = 'no_prop_rights_starts_ps_0.9_pf_0.9'
#
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, start_prop_steal_mean=0.9, start_prop_fight_back_mean=0.9)
#
#    readme_notes = 'no_prop_rights_starts_ps_0.1_pf_0.1'
#
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, start_prop_steal_mean=0.1, start_prop_fight_back_mean=0.1)

    # fight costs
#    test_array = [-0.50]      # running [0.0, -0.03, -0.04, -0.15, -0.2]
#
#    for fight_cost in test_array:
#    
#        readme_notes = 'no_prop_rights_fight_cost_%1.3f' % fight_cost
#
#        multi_sims(respect_property_rights=0, readme_notes=readme_notes, fight_cost=fight_cost)

    # adjust_props_r
#    test_array = [0.02]     # 0.05 was the floor
#
#    for r in test_array:
#
#        readme_notes = 'no_prop_rights_adjust_props_r_%1.2f' % r
#        
#        multi_sims(respect_property_rights=0, readme_notes=readme_notes, adjust_props_r=r)

#    # agent_intn_beta
#    test_array = [0.3]  # 0.0, 1.0
#
#    for beta in test_array:
#
#        readme_notes = 'no_prop_rights_agent_intn_beta_%1.2f' % (beta)
#        
#        multi_sims(respect_property_rights=0, readme_notes=readme_notes, agent_intn_beta=beta)      # prop_steal_ceil=0.99, prop_steal_floor=0.01, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01

#    # intn_error_std
#    test_array = [0.5, 1.0, 2.0, 1000.0]
#
#    for error in test_array:
#
#        readme_notes = 'no_prop_rights_intn_error_std_%1.2f' % (error)
#        
#        multi_sims(respect_property_rights=0, readme_notes=readme_notes, intn_error_std=error)

#    # child_prop_std = 1.0
#    for child_prop_std in [0.0, 0.5, 1000.0]:
#
#        readme_notes = 'no_prop_rights_child_prop_std_%1.2f' % (child_prop_std)
#        
#        multi_sims(respect_property_rights=0, readme_notes=readme_notes, child_prop_std=child_prop_std)



    # EXPERIMENTS

#    # 1 Change one agent only
#    for props in [(0.0, 0.0), (0.0, 1.0), (1.0, 1.0)]:       # [(0.0, 0.0), (0.0, 1.0), (1.0, 1.0)]
#
#        start_ps, start_fb = props
#
#        for beta in [0.0, 0.5]:
#
#            readme_notes = 'no_prop_rights_change_one_ag_ps_%1.2f_pfb_%1.2f_beta_%1.1f' % (start_ps, start_fb, beta)
#        
#            multi_sims(rounds=2000, respect_property_rights=0, readme_notes=readme_notes, change_one_only=1, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5, agent_intn_beta=beta,
#                       child_prop_std=0.0, start_prop_steal_mean=start_ps, start_prop_steal_std=0.0, start_prop_fight_back_mean=start_fb, start_prop_fight_back_std=0.0, adjust_props_r=0.0)

#    # 2 Yellow Agents
#    readme_notes = 'no_prop_rights_prop_fb_0'
#    
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, fix_prop_fb=0)

#    # 3 Black Shoops
#    # single shoop early on and near full pop:
#    for pop in [0]:
#
#        readme_notes = 'no_prop_rights_black_shoop_1_pop_%d_prop_1.00' % (pop)
#        
#        multi_sims(rounds=1000, respect_property_rights=0, readme_notes=readme_notes, black_shoop_exp=1, black_shoop_pop=pop, black_shoop_prop_start=1.00)
#
#    # single black shoop born with ps = pfb = 0.99 and ceiling and floor of 0.01 and 0.99
#    for pop in [0]:
#
#        readme_notes = 'no_prop_rights_black_shoop_1_pop_%d_prob_0.99' % (pop)
#        
#        multi_sims(respect_property_rights=0, readme_notes=readme_notes, black_shoop_exp=1, black_shoop_pop=pop, black_shoop_prop_start=0.99,\
#                   prop_steal_ceil=0.99, prop_steal_floor=0.01, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01)
#
#    # all chidren black shoops from start with prob = 1.00
#    readme_notes = 'no_prop_rights_black_shoop_all_prob_1.00'
#    
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, black_shoop_exp='all', black_shoop_pop=0, black_shoop_prop_start=1.00)
#
#    # all chidren black shoops from start with prob = 0.99
#    readme_notes = 'no_prop_rights_black_shoop_all_prob_0.99'
#    
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, black_shoop_exp='all', black_shoop_pop=0, black_shoop_prop_start=0.99,\
#               prop_steal_ceil=0.99, prop_steal_floor=0.01, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01)

    # 4 Fight Balance
#    for res in [125]:         # [125, 200, 300]
#
#        readme_notes = 'no_prop_rights_fight_bal_res_power_res_%d' % res
#    
#        multi_sims(rounds=2000, respect_property_rights=0, readme_notes=readme_notes, fight_balance='res_power', PR_res_init=res, PR_mating_threshold=10000,
#                   prop_steal_ceil=0.99, prop_steal_floor=0.01, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01)

#    # rich agent
#    for res in [400, 500, 600, 700]:
#    
#        readme_notes = 'no_prop_rights_fight_bal_res_power_rich_agent_res_%d' % res
#
#        multi_sims(respect_property_rights=0, readme_notes=readme_notes, fight_balance='res_power', PR_res_init=res, PR_mating_threshold=10000,
#                   prop_steal_ceil=0.99, prop_steal_floor=0.01, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01, start_1_rich_agent=1)

#    # fighting skills
#
#    r = 0.02
#    p_s = 0.5
#    p_fb = 0.5
#    fs = 10
#    
#    readme_notes = 'no_prop_rights_fight_skill_0_fsr_%1.2f_res_400_ps_%1.2f_pfb_%1.2f_fs_%3d' % (r, p_s, p_fb, fs)
#
#    multi_sims(rounds=3000, respect_property_rights=0, readme_notes=readme_notes, fight_skill=fs, fight_skill_r=r, PR_res_init=400, PR_res_init_std=5, PR_mating_threshold=1000,
#               start_prop_steal_mean=p_s, start_prop_fight_back_mean=p_fb, prop_steal_ceil=0.99, prop_steal_floor=0.01, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01)      # agent_intn_beta=0.0

#    # 5 Agreed Location is none, strong or super_strong (with bullies emerging)
#
#    # apply to default:
#    
#    readme_notes = 'no_prop_rights_org_technique_strong_default'
#
#    multi_sims(respect_property_rights=0, readme_notes=readme_notes, agree_location='strong')
#
#    r = 0.02
#    p_s = 0.5
#    p_fb = 0.5
#    fs = 10
#    error = 0.1
#    ps_floor = 0.01
#
#    for org_technique in ['none', 'weak', 'strong', 'super_strong']:
#
#        for commun_prob in [1.0]:
#        
#            readme_notes = 'no_prop_rights_fight_skill_bully_avoidance_%s_error_%1.1f_psf_%1.2f_comm_prob_%1.2f' % (org_technique, error, ps_floor, commun_prob)       # Q: do good agents outlast bad agents and then all ok?  need to test higher starting res
#        
#            multi_sims(respect_property_rights=0, readme_notes=readme_notes, fight_skill=fs, fight_skill_r=r, PR_res_init=400, PR_mating_threshold=1000,
#                       start_prop_steal_mean=p_s, start_prop_fight_back_mean=p_fb, prop_steal_ceil=0.99, prop_steal_floor=ps_floor, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01,
#                       agree_location=org_technique, intn_error_std=error, agents_comm_prob=commun_prob)


#    # 6 Leviathan
#    
    # fight cost 0
#    for inst_type in ['fine_only']:         # 'compensate'
#
#        for data in [(1.0, -1.0)]:       # (0.5, -0.10), (1.0, -0.10), (0.5, -0.05), (1.0, -0.05)
#
#            prob_fine, fine = data
#
#            # zero fight cost
#            readme_notes = 'no_prop_rights_formal_inst_%s_fight_cost_0_prob_%1.2f_fine_%1.3f' % (inst_type, prob_fine, fine)
# 
#            multi_sims(rounds=1000, respect_property_rights=0, readme_notes=readme_notes, fight_cost=0.0, formal_inst=inst_type, prob_fine=prob_fine, fine=fine)        # corruption_prop_charge=1.0

    # low speed of adjustment (r = 0.035)
#    for inst_type in ['fine_only']:         # 'compensate'
#
#        for prob_fine in [1.0]:
#
#            for fine in [-0.1, -0.5, -1.0, -2.0, -4.0]:
#
#                readme_notes = 'no_prop_rights_formal_inst_%s_r_0.02_prob_%1.2f_fine_%1.3f' % (inst_type, prob_fine, fine)
#     
#                multi_sims(num_runs=4, rounds=1000, respect_property_rights=0, readme_notes=readme_notes, adjust_props_r=0.02, formal_inst=inst_type, prob_fine=prob_fine, fine=fine)

    # beta = 0
#    for inst_type in ['fine_only']:         # 'compensate'
#
#        for prob_fine in [1.0]:
#
#            for fine in [-0.8, -0.7, -0.6]:
#
#                 readme_notes = 'no_prop_rights_formal_inst_%s_beta_0_prob_%1.2f_fine_%1.2f' % (inst_type, prob_fine, fine)
#             
#                 multi_sims(rounds=1000, respect_property_rights=0, readme_notes=readme_notes, agent_intn_beta=0.0, formal_inst=inst_type, prob_fine=prob_fine, fine=fine)

    # Yellow Agents
#    for inst_type in ['compensate']:         # 'compensate'
#
#        for prob_fine in [1.0]:
#
#            for fine in [-4.0]:
#
#                readme_notes = 'no_prop_rights_formal_inst_%s_yellow_prob_%1.2f_fine_%1.2f' % (inst_type, prob_fine, fine)
#     
#                multi_sims(rounds=1000, respect_property_rights=0, readme_notes=readme_notes, fix_prop_fb=0, formal_inst=inst_type, prob_fine=prob_fine, fine=fine)

    # Doveish Agents
#    for inst_type in ['fine_only']:         # 'compensate'
#
#        for prob_fine in [1.0]:
#
#            for fine in [-0.5, -1.0, -2.0]:
#
#                if (inst_type is 'fine_only' and prob_fine == 0.5 and fine == -0.25) is False:         # I've completed the first
#
#                    readme_notes = 'no_prop_rights_formal_inst_%s_angels_prob_%1.2f_fine_%1.2f' % (inst_type, prob_fine, fine)
#
#                    multi_sims(num_runs=4, rounds=1000, respect_property_rights=0, readme_notes=readme_notes, change_one_only=1, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5,
#                               child_prop_std=0.0, start_prop_steal_mean=0.0, start_prop_steal_std=0.0, start_prop_fight_back_mean=0.0, start_prop_fight_back_std=0.0, adjust_props_r=0.0,
#                               formal_inst=inst_type, prob_fine=prob_fine, fine=fine)

#    for inst_type in ['compensate']:         # 'compensate'
#
#        for prob_fine in [1.0]:
#
#            for fine in [-1.25]:             # -0.5, -0.75, -1.0, -1.25, -1.5
#
#                readme_notes = 'no_prop_rights_formal_inst_%s_angels_prob_%1.2f_fine_%1.2f' % (inst_type, prob_fine, fine)
#
#                multi_sims(num_runs=3, rounds=1000, respect_property_rights=0, readme_notes=readme_notes, change_one_only=1, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5,
#                           child_prop_std=0.0, start_prop_steal_mean=0.0, start_prop_steal_std=0.0, start_prop_fight_back_mean=0.0, start_prop_fight_back_std=0.0, adjust_props_r=0.0,
#                           formal_inst=inst_type, prob_fine=prob_fine, fine=fine)

    # rich agent
#    for inst_type in ['compensate']:         # 'compensate'
#
#        for prob_fine in [1.0]:
#
#            for fine in [-0.4, -0.5]:
#
#                readme_notes = 'no_prop_rights_formal_inst_%s_rich_agent_prob_%1.2f_fine_%1.3f' % (inst_type, prob_fine, fine)
#            
#                multi_sims(num_runs=20, respect_property_rights=0, readme_notes=readme_notes, fight_balance='res_power', PR_res_init=125, PR_mating_threshold=10000,
#                           prop_steal_ceil=0.99, prop_steal_floor=0.01, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01, start_1_rich_agent=1, formal_inst=inst_type, prob_fine=prob_fine, fine=fine)
    # bullies
#    r = 0.02
#    p_s = 0.5
#    p_fb = 0.5
#    fs = 10
#    error = 0.1
#    ps_floor = 0.01    
#    inst_type = 'fine_only'
#    prob_fine = 1.0
#
#    for fine in [-0.1, -0.125, -0.15]:
#
#        readme_notes = 'no_prop_rights_formal_inst_%s_bullies_error_%1.1f_psf_%1.2f_probf_%1.1f_fine_%1.3f' % (inst_type, error, ps_floor, prob_fine, fine)
#    
#        multi_sims(num_runs=4, rounds=3000, respect_property_rights=0, readme_notes=readme_notes, fight_skill=fs, fight_skill_r=r, PR_res_init=400, PR_res_init_std=5, PR_mating_threshold=1000,
#                   start_prop_steal_mean=p_s, start_prop_fight_back_mean=p_fb, prop_steal_ceil=0.99, prop_steal_floor=ps_floor, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01,
#                   intn_error_std=error, formal_inst=inst_type, prob_fine=prob_fine, fine=fine)      # agent_intn_beta=0.0


    # 7 Two Tribes
    
    # nulls
#    for str_int in ['acq', 'fb']:
#    
#        readme_notes = 'no_prop_rights_two_tribes_null_str_int_%s' % (str_int)
#    
#        multi_sims(respect_property_rights=0, readme_notes=readme_notes, two_tribes=1, rounds=1000, new_mkt_round=500, agents_die_old_age=1000,
#                   keynesian_ratio=10.0, num_runs=1, SD_charts_freq=100,
#                   start_prop_steal_mean=0.1, start_prop_steal_std=0.0, start_prop_fight_back_mean=0.9, start_prop_fight_back_std=0.0, print_agents_interact=0, stranger_int=str_int)

#    for prob in [1.0]:
#
#        for fine in [-2.0, -4.0]:
#            
#            for str_int in ['acq', 'fb']:
#
#                for inst in ['fine_only', 'compensate']:
#                
#                    readme_notes = 'no_prop_rights_two_tribes_prob_%1.1f_fine_%1.1f_oldage_adv_start_strang_int_%s_instit_%s' % (prob, fine, str_int, inst)
#
#                    multi_sims(respect_property_rights=0, readme_notes=readme_notes, two_tribes=1, rounds=1000, new_mkt_round=500, agents_die_old_age=1000,
#                               keynesian_ratio=10.0, num_runs=1, two_tribes_inst=inst, prob_fine=prob, fine=fine, SD_charts_freq=100,
#                               start_prop_steal_mean=0.1, start_prop_steal_std=0.0, start_prop_fight_back_mean=0.9, start_prop_fight_back_std=0.0, print_agents_interact=0, stranger_int=str_int)

#    Corruption

    # fight cost 0
#    for charge in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:            # 0.1, 0.2, 0.3, 0.4
#
#        for inst_type in ['fine_only']:         # 'compensate'
#    
#            for data in [(1.0, -0.05)]:       # (0.5, -0.10), (1.0, -0.10), (0.5, -0.05), (1.0, -0.05)
#    
#                prob_fine, fine = data
#    
#                # zero fight cost
#                readme_notes = 'no_prop_rights_corruption_charge_%s_fight_cost_0_fine_%1.3f' % (charge, fine)
#     
#                multi_sims(num_runs=10, rounds=1000, respect_property_rights=0, readme_notes=readme_notes, fight_cost=0.0, formal_inst=inst_type, prob_fine=prob_fine, fine=fine, corruption_prop_charge=charge)        # corruption_prop_charge=1.0


#    for charge in [0.5, 0.6, 0.7, 0.8, 0.9]:            # 0.1, 0.2, 0.3, 0.4
#
#        for inst_type in ['compensate']:         # 'compensate'
#    
#            for prob_fine in [1.0]:
#    
#                for fine in [-0.75]:
#    
#                    readme_notes = 'no_prop_rights_corruption_charge_%s_rich_agent_fine_%1.3f' % (charge, fine)
#                
#                    multi_sims(num_runs=4, respect_property_rights=0, readme_notes=readme_notes, fight_balance='res_power', PR_res_init=125, PR_mating_threshold=10000, corruption_prop_charge=charge,
#                               prop_steal_ceil=0.99, prop_steal_floor=0.01, prop_fight_back_ceil=0.99, prop_fight_back_floor=0.01, start_1_rich_agent=1, formal_inst=inst_type, prob_fine=prob_fine, fine=fine)

    # memory_decay_rate = 0.2
    # readme_notes = 'first_model_mem_dec_%2.1f_2k_rnds' % memory_decay_rate

    # habit_val = 55.0
    # rounds=2000
    # readme_notes = 'first_model_habit_val_%2.1f_5k' % habit_val
    #
    # multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq,
    #            target_location_weights='crude', habit_val=habit_val, readme_notes=readme_notes)

    # multi_sims(num_runs=20, rounds=1000, readme_notes='default_first_model')

    memory_decay_rate = 0.2
    habit_val = 100.0
    habit_deteriorates = 1
    num_runs = 20
    rounds = 1000
    readme_notes = 'first_model_mem_dec_%2.1f_det_%d_habit_val_%2.1f' % (memory_decay_rate, habit_deteriorates, habit_val)

    multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq,
               memory_decay_rate=memory_decay_rate, target_location_weights='crude', habit_val=habit_val,
               readme_notes=readme_notes, habit_deteriorates=habit_deteriorates)

    # multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq,
    #            scenario='default', readme_notes='first_model_crude_params_2k_rnds', target_location_weights='crude')

    # multi_sims(rounds=2000, scenario='first_model_default_params_2k_rnds')

    # multi_sims(num_runs=num_runs, rounds=rounds, heatmap_days_show=heatmap_days_show, SD_charts_freq=SD_charts_freq,
    #            scenario='habit_exp', readme_notes='first_model_habit_val_2k_rnds')


def multi_sims(num_runs=20, rounds=1000, scenario='default', mov_av_days_threshold_chart=10, cognition_factor=0.1, agents_comm_prob = 0.01, dimen_density=10, readme_notes='default', for_skill_r=0.01,
               agent_homes='even', trade_when_trgt=1, mating_thresh=125, popn_ch='vary', min_trans_Q=0.01, agent_res_init=50, agent_res_init_std=5, vision_len=1,
               cp_trans_weight=0.5, res_depletion=0, tot_rounds_depl=200, fount_dep=[0, 1], fount_depl_ratio=0.5, wait_at_target_til_end=1, wait_at_tgt_moves=25, trade_moves=50, force_prices='float', fixed_price=1.0,
               trgt_sel='roulette', allow_Keynes_Inst=0, Keynes_round=200, keynesian_ratio=0.5, heatmap_days_show=100, trade_movemnt='mixed', trade_loc='home', init_res_lev_per_agent=2,
               constitutional_voting=0, applied_constitutions=[1, 2, 3, 4, 5], constitutional_exp=0, start_const_proces=1000, const_proc_test_period=1000, num_experiments=5, SD_charts_freq=100, num_KI_agents=16, print_end_of_round_charts=1, Walrasian_Trading=0,
               ststst=[0, 24, [1.0, 0.2], [20, 20]], const_mkt_opens=0, print_voting_only=0, loc_mkt='avoid_interference', restrict_by_district=0,
               homes_spacing='hex', print_local_policy_data=0, for_strat_parts=5, price_mean='geometric',  print_fine_dets=0, printed_segment_size=100, gen_equ_wh_lps=100,
               respect_property_rights=1, fight_cost=-0.15, file_type='html', black_shoop_exp=0, black_shoop_pop='low', black_shoop_prop_start=1.0, adjust_props_r=0.08, agent_intn_beta=0.5, intn_error_std=0.1, agent_avoid_muggers=1,
               child_prop_std=0.1, prop_steal_ceil=0.999, prop_steal_floor=0.001, prop_fight_back_ceil=0.999, prop_fight_back_floor=0.001, start_prop_steal_mean=0.5, start_prop_steal_std=0.10, start_prop_fight_back_mean=0.5, start_prop_fight_back_std=0.10,
               formal_inst=0, prob_fine=0.5, fine=-0.5, agree_location='none', fight_balance='50_50', new_mkt_round=1000, two_tribes=0, two_tribes_inst=0, fight_skill=None, agents_die_old_age=None, fix_prop_fb=None, fixed_prop_steal=None,
               fix_ps_fb_0=None, start_child_births=50, plotly_online=0, change_one_only=0, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5, PR_mating_threshold=150, PR_res_init=125, fight_skill_r=0.01, PR_res_init_std=5, start_1_rich_agent=0,
               clear_of_fights_radius=5, print_agents_interact=0, stranger_int='fb', corruption_prop_charge=1.0, strat_choice='heuristics', strangers_if_unknown=0, track_agent=None, local_fight='none', limit_agent_interaction=5,
               track_game_types=1, calc_timings=0, target_location_weights='crude', agent_mem_length=4, habit_deteriorates=0, habit_val=0.0, memory_decay_rate=0.2):

    """This function organises a single set of simulations, which will have a
    single set of parameters.  Individual simulation data is generated by
    calling the function 'run_sim()'.  These data are compiled in to a
    database."""

    if respect_property_rights == 0:

        agents_comm_prob = 0.25

        if agree_location == 'super_strong':
            
            agents_comm_prob = 1.0

        agent_res_init = 100
        mating_thresh = 125
        printed_segment_size = 20

    SSO = Sim_Suite_Object(allow_Keynes_Inst, print_voting_only, print_local_policy_data, num_experiments, applied_constitutions, popn_ch, num_runs, track_game_types)

    sim_set_folder = "%s%s_%d_%d_%d_%d_%d_%d_%d" % (system_folder, readme_notes,
                                                 dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(),
                                                 dt.DateTime().hour(), dt.DateTime().minute(), dt.DateTime().second(),
                                                 dt.DateTime().millis() / 100000)

    if scenario == 'null':

        for_skill_r = 0.0          # 0.01 by default
        # agent_mem_length = 0        # 2 by default (1 is a bit fragile - agents lose memory is they don't transact and communicate)
        trade_movemnt = 'random'

    if scenario == 'two':

        for_skill_r = 0.0          # 0.01 by default

    if scenario == 'three':

        # agent_mem_length = 0        # 2 by default (1 is a bit fragile - agents lose memory is they don't transact and communicate)
        trade_movemnt = 'random'

    if SSO.numb_of_sims == 0:

        SSO.add_sub_folder(sim_set_folder)
        SSO.add_segment_size(printed_segment_size)
        os.makedirs(SSO.sub_folder)

    total_runs = num_runs - SSO.numb_of_sims

    # place all of the paramters in to a dictionary, which helps when we record these in data files:
    param_dict = locals()

    # straight away we write a read_me file to record parameters in a single file (this is done at the beginning in case
    # of errors in the code - having this data might help us find bugs)
    write_text_file_readme(SSO.sub_folder, param_dict, scenario, readme_notes)

    monthDict={1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'June', 7:'July', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}

    for i in range(num_runs - SSO.numb_of_sims):

        if i == 0:

            start_time = dt.DateTime()
            run_end_time = start_time

        single_sim_data = run_sim(track_agent=track_agent, rounds=rounds, agents_comm_prob=agents_comm_prob,
                                   trade_movemnt=trade_movemnt, for_skill_r=for_skill_r,
                                   dimen_density=dimen_density, price_mean=price_mean, SD_charts_freq=SD_charts_freq,
                                   trade_when_trgt=trade_when_trgt, sim_no=i, total_runs=total_runs, init_res_lev_per_agent=init_res_lev_per_agent,
                                   min_trans_Q=min_trans_Q, cp_trans_weight=cp_trans_weight, trade_loc=trade_loc,
                                   vision_len=vision_len, agent_mem_length=agent_mem_length, gen_equ_wh_lps=gen_equ_wh_lps,
                                   res_depletion=res_depletion, tot_rounds_depl=tot_rounds_depl, fount_dep=fount_dep,
                                   fount_depl_ratio=fount_depl_ratio, allow_Keynes_Inst=allow_Keynes_Inst, Keynes_round=Keynes_round,
                                   keynesian_ratio=keynesian_ratio, homes_spacing=homes_spacing, agent_homes=agent_homes,
                                   popn_ch=popn_ch, mating_thresh=mating_thresh,
                                   cognition_factor=cognition_factor, save_folder=SSO.sub_folder, for_strat_parts=for_strat_parts,
                                   printed_segment_size=printed_segment_size, mov_av_days_threshold_chart=mov_av_days_threshold_chart,
                                   scenario=scenario, readme_notes=readme_notes, agent_res_init=agent_res_init, agent_res_init_std=agent_res_init_std,
                                   wait_at_target_til_end=wait_at_target_til_end, wait_at_tgt_moves=wait_at_tgt_moves, trade_moves=trade_moves,
                                   force_prices=force_prices, fixed_price=fixed_price, trgt_sel=trgt_sel, heatmap_days_show=heatmap_days_show,
                                   constitutional_voting=constitutional_voting, applied_constitutions=applied_constitutions, start_const_proces=start_const_proces,
                                   const_proc_test_period=const_proc_test_period, num_experiments=num_experiments,
                                   num_KI_agents=num_KI_agents, print_end_of_round_charts=print_end_of_round_charts, constitutional_exp=constitutional_exp,
                                   Walrasian_Trading=Walrasian_Trading, target_location_weights=target_location_weights,
                                   ststst=ststst, const_mkt_opens=const_mkt_opens, loc_mkt=loc_mkt, restrict_by_district=restrict_by_district,
                                   respect_property_rights=respect_property_rights, fight_cost=fight_cost, black_shoop_exp=black_shoop_exp,
                                   black_shoop_pop=black_shoop_pop, adjust_props_r=adjust_props_r,
                                   agent_intn_beta=agent_intn_beta, intn_error_std=intn_error_std, agent_avoid_muggers=agent_avoid_muggers,
                                   child_prop_std=child_prop_std, print_agents_interact=print_agents_interact, prop_steal_ceil=prop_steal_ceil, prop_steal_floor=prop_steal_floor,
                                   prop_fight_back_ceil=prop_fight_back_ceil, prop_fight_back_floor=prop_fight_back_floor,
                                   start_prop_steal_mean=start_prop_steal_mean, start_prop_fight_back_mean=start_prop_fight_back_mean,
                                   black_shoop_prop_start=black_shoop_prop_start, formal_inst=formal_inst, prob_fine=prob_fine, fine=fine,
                                   agree_location=agree_location, fight_balance=fight_balance, two_tribes_inst=two_tribes_inst, two_tribes=two_tribes,
                                   new_mkt_round=new_mkt_round, fight_skill=fight_skill, agents_die_old_age=agents_die_old_age, fix_prop_fb=fix_prop_fb,
                                   fixed_prop_steal=fixed_prop_steal, fix_ps_fb_0=fix_ps_fb_0, start_prop_steal_std=start_prop_steal_std,
                                   start_prop_fight_back_std=start_prop_fight_back_std, start_child_births=start_child_births, plotly_online=plotly_online,
                                   change_one_only=change_one_only, ch_ag_prop_steal=ch_ag_prop_steal, ch_ag_prop_fb=ch_ag_prop_fb, PR_mating_threshold=PR_mating_threshold,
                                   PR_res_init=PR_res_init, fight_skill_r=fight_skill_r, PR_res_init_std=PR_res_init_std, start_1_rich_agent=start_1_rich_agent,
                                   clear_of_fights_radius=clear_of_fights_radius, stranger_int=stranger_int, corruption_prop_charge=corruption_prop_charge,
                                   strat_choice=strat_choice, strangers_if_unknown=strangers_if_unknown, local_fight=local_fight, limit_agent_interaction=limit_agent_interaction,
                                   track_game_types=track_game_types, calc_timings=calc_timings, habit_deteriorates=habit_deteriorates, habit_val=habit_val,
                                   memory_decay_rate=memory_decay_rate
                                   )

        # This method updates the various databases
        SSO.add_to_dbs(single_sim_data)
        SSO.numb_of_sims += 1

        if print_fine_dets == 1:
            print('\n\nsingle_sim_data =\n', single_sim_data)

#        print('\n SSO.population_data[-1][-1] =', SSO.population_data[-1][-1])

        if (SSO.numb_of_sims % 1 == 0 or SSO.numb_of_sims == num_runs) or print_voting_only == 1:   #  and SSO.population_data[-1][-1] > 0

            SSO.save_sim_set_data(sim_set_folder, rounds, for_strat_parts, constitutional_voting, start_const_proces, const_proc_test_period, constitutional_exp,
                                  respect_property_rights, file_type, black_shoop_exp, two_tribes, fight_skill, plotly_online=0, print_fine_dets=0)

        # email data
    #
    #     if SSO.numb_of_sims % 5 == 0:
    #
    #         single_run_time = dt.DateTime() - run_end_time
    #
    #         run_end_time = dt.DateTime()
    #
    #         average_time_delta = (dt.DateTime() - start_time) / float(i + 1)
    #
    #         num_sims_remaining = num_runs - i - 1
    #
    #         time_remaining = num_sims_remaining * average_time_delta
    #
    #         exp_end_point = dt.DateTime() + time_remaining
    #
    #         subject = 'Sim Completed - %s' % (readme_notes)
    #
    # #        print('\n single_run_time.microseconds', single_run_time.microseconds)
    # #        print('\n single_run_time.microseconds/10000.0', single_run_time.microseconds/100.0)
    #
    #         if i < num_runs - 1:
    #
    #             text_content = 'sim completed (%d of %d) - latest results attached.\n\nLast run time = %d day(s), %d hour(s), %d minute(s), %d.%02d second(s).\n\nMean run time = %d day(s), %d hour(s), %d minute(s), %d.%02d second(s).\n\nTime remaining = %d day(s), %d hour(s), %d minute(s), %d.%02d second(s),\n\nExpected completion: %d %s %d at %02d:%02d:%02d.'\
    #                             % (i + 1, num_runs, single_run_time.days, single_run_time.seconds//3600, single_run_time.seconds%3600//60, single_run_time.seconds%3600%60, single_run_time.microseconds/10000.0,\
    #                                average_time_delta.days, average_time_delta.seconds//3600, average_time_delta.seconds%3600//60, average_time_delta.seconds%3600%60, average_time_delta.microseconds/10000.0,\
    #                                time_remaining.days, time_remaining.seconds//3600, time_remaining.seconds%3600//60, time_remaining.seconds%3600%60, time_remaining.microseconds/10000.0,\
    #                                exp_end_point.day, monthDict[exp_end_point.month], exp_end_point.year, exp_end_point.hour, exp_end_point.minute, exp_end_point.second)
    #
    #         elif i == num_runs - 1:
    #
    #             text_content = 'Final sim completed (%d of %d) - final results attached' % (i + 1, num_runs)
    #
    #         file_to_send = SSO.results_to_email
    #
    #         try:
    #
    #             send_mail(send_from='gregfisherhome@gmail.com', send_to='gjf1g13@soton.ac.uk',
    #                       subject=subject, text=text_content, files=[file_to_send], server='smtp.gmail.com',
    #                       port=587, username='gregfisherhome@gmail.com', password='NewW0rld)rdergmail', isTls=True)
    #
    #         except Exception as e:
    #
    #             print('\n email didnt work')


def run_sim(
            # Core structural parameters
            rounds=1000, dimen_density=10, agent_homes='even', homes_spacing='hex', popn_ch='vary', mating_thresh=125, agents_die_old_age=None,
            # - agents
            agent_res_init=50, agent_res_init_std=5, local_net_rad=11, agents_comm_prob=0.01, cognition_factor=0.1, for_strat_parts=5, start_child_births=100,
            # - foraging
            init_res_lev_per_agent=2, for_skill_r=0.01,
            # - searching & trading
            trade_moves=50, agents_trade=1, wait_at_target_til_end=1, wait_at_tgt_moves=20, trade_prob_mem=5, vision_len=1,
            trade_loc='home', cp_trans_weight=0.5,
            trade_prices='variable', trgt_sel='roulette', trade_when_trgt=1, trade_movemnt='mixed', min_trans_Q=0.01, must_update_neighs=1,

            # Pricing & General Equilibrium Issues
            price_mean='geometric', force_prices='float', fixed_price=1.0, find_gen_equ_PQ=1, gen_equ_wh_lps=100, gen_equ_thresh=0.01, Walrasian_Trading=0, agent_mem_length=4,

            # Parallelism
            use_parallel_code=0, price_grid_dimen=10, test_par_code=1,

            # Famine            
            res_depletion=0, tot_rounds_depl=200, fount_dep=[0, 1], fount_depl_ratio=0.5,

            # Keynesian Institution
            allow_Keynes_Inst=0, Keynes_round=200, keynesian_ratio=0.5, num_KI_agents=16, loc_mkt='avoid_interference', restrict_by_district=0,

            # Constitutional Issues
            constitutional_voting=0, applied_constitutions=[1, 2, 3, 4, 5], constitutional_exp=0, start_const_proces=1000, const_proc_test_period=1000, num_experiments=5, const_mkt_opens=0,

            # Respecting Property Rights Params
            respect_property_rights=1, fight_cost=-0.15, adjust_props_r=0.08, start_props='set', start_prop_steal_mean=0.5, start_prop_steal_std=0.1, start_prop_fight_back_mean=0.5,
            start_prop_fight_back_std=0.10, agent_intn_beta=0.5, len_reputations_mem=20, intn_error_std=0.1, agent_avoid_muggers=1,
            children_props='mean_props_and_dev', child_prop_std=0.1, prop_steal_ceil=0.999, prop_steal_floor=0.001, prop_fight_back_ceil=0.999, prop_fight_back_floor=0.001,
            agree_location='none', trade_at_trgt_precise=1, fight_balance='50_50', use_original_model_struct=0, proportion_in_plotly_charts=1.0, two_tribes=0, new_mkt_round=1000,
            initial_fount_stock_high=72, black_shoop_exp=0, black_shoop_pop='low', black_shoop_prop_start=1.0, formal_inst=0, prob_fine=0.5, fine=-0.5, fight_skill=None, fight_skill_r=0.01,
            single_tribe=0, two_tribes_inst=0, fix_prop_fb=None, fixed_prop_steal=None, fix_ps_fb_0=None, change_one_only=0, ch_ag_prop_steal=0.5, ch_ag_prop_fb=0.5, PR_mating_threshold=150,
            PR_res_init=125, PR_res_init_std=5, start_1_rich_agent=0, clear_of_fights_radius=5, stranger_int='fb', corruption_prop_charge=1.0, strat_choice='heuristics', strangers_if_unknown=0,
            local_fight='none', target_location_weights='crude', limit_agent_interaction=5, memory_decay_rate=0.2,

            # Habituation
            habit_deteriorates=0, habit_val=0.0,

            # Steady state starts
            ststst=[0, 25, [1.0, 0.2], [20, 20]],

            # Admin
            suite_no=0, num_sim_sets=0, sim_no=0, total_runs=1, create_dir=1, record_dead_agents=1, save_folder="%ssingle_runs" % (directory), scenario='default', readme_notes='default',
            calc_timings=0, run_code_tests=0, track_game_types=1,

            # Printing & charts
            track_agent=None, heatmap_days_show=100, print_dets=0, print_fine_dets=0, print_charts=1, print_histo=1, print_3d_histo=0, print_heat_map=1, heatmap_story=1,
            heatmap_story_segs=20, random_rounds_start=0, cluster_lag=5, print_round_trans=0,
            print_move_heat_maps=0, SD_charts_freq=100, end_of_round_rpt=0, print_plotly_charts=1, plotly_online=0, printed_segment_size=100, mov_av_days_threshold_chart=10,
            print_MRS_std_charts=0, print_end_of_round_charts=1, sign_mkt_thresh=2, plotly_sharing='private', file_type='html', print_for=0, print_agents_interact=0, print_serviced_locations=0,
            granular_mem=0, print_sim_breaking_charts=1
            ):

    """This function controls a single run - it is the main function in the whole file.  Important variables: 

    - num_agents is the number of starting agents: note that if agents_home == 'even' then the square root of this number
    must be an integer e.g. 144 => 12.
    - dimen_density controls the dimensions of the grid: the grid's x and y dimensions = sqrt(num_agents) * dimen_density.
    This number controls the overall density of the agents on the grid.
    - for_strat_parts is the number of parts in agents' foraging strategies.  This is also the number of time slots in a day.
    - agent_res_init is the mean initial level of reserves of each of the resources given to all agents.
    = agent_res_init_std is the standard deviation of the initial level of reserves (mean and std are combined to form a
    normal distribution from which each agent's reserve level for each resource is chosen).
    - num_res_founts.  The number of resources in the environment (i.e. number of fountains).
    - init_res_level is the initial level given to each resource fountain.
    - prob_res_detection. Agents' skill at detecting the resources is given by a probability of detection. In the first
    simulation, I start with a fixed probability for all fountains (e.g. prob = 0.3).
    - min_prob_det gives a floor to the prob of detection: the idea is that agents do not become totally useless at foraging
    for a particular resource - there is a minimum level of detection.
    - max_prob_det gives a ceiling to the prob of detection: agents' cognition is limited to this maximum skill level.
    - dimen denoted the dimensions of the town_grid (dimen x dimen).
    - vision_len is the distance an agent can see in the town_grid (when trying to look for agents with which to trade).
    - trade_moves is the number of rounds in which agents attempting to trade get to move around the town_grid.
    - trade_movemnt == 'random' means the agents don't set a target, they just move randomly; and 'set' means they move to a
    set target.  'mixed' means they initally have random then they switch to set after 'random_rounds_start' rounds.
    - agents_trade is a variable which controls whether the agents trade or not (0 = they don't, 1 = they do).
    - wait_at_tgt_moves is the number of moves an agent will wait at its target location before moving away.
    - for_skill_r is used as a parameter in the logistic equation associated with changes in skill levels (see below).
    - track_agent == 1 means we track a randomly chosen agent during its 'life'.
    - print_histo == 1 means a histogram of trading data (locations) will be printed.
    - print_3d_histo == 1 means a 3d histogram is printed showing trades in each town grid cell.
    - print_heat_map == 1 means a 2d heat map is printed showing trades in each town grid cell.
    - trade_loc concerns the starting location of agent who are trading: if == 'home' then they start from their home
    location; if == 'random' then they start from a random location in each round; if 'fountain' they start from the last fountain visited.
    - result_main_fold is the main folder where data is kept - we use sub-folders below to organise further.
    - local_net_rad determines the radius of an agent's local network, from which they judge the likelihood of trading. They
    take an average of transactions / goods being sold from their 'neighbour' agents over the past [5] rounds.
    - print_dets = 1 means the higher level details are printed.
    - print_fine_dets = 1 means a finer level of detail of output is printed.
    - trade_prob_mem is the length of memory (in rounds) over which an agent assesses the likelihood of trading.
    - create_dir = 1 creates a directory for saving data & charts.
    - agent_homes='even' means agents' homes are distributed evenly across the grid and also the population is kept constant.
    If agent_homes='random' then homes locations are randomly distributed on the grid.
    - trgt_sel is about target selection: = 'WTA' is winner takes all (the location with the most trades is selected); and
    == 'roulette' is a 'roulette wheel' (weighted random) selection of location from a relevant array.
    - end_of_round_rpt prints the end of round report corresponding to the tracking_agent.
    - trade_when_trgt == 1 means the agent only trades when it gets to its target location on the grid; otherwise it moves to
    the target. wait_at_tgt_moves still applies.
    - cluster_lag is the number of periods over which the cluster data are averaged i.e. the lag.
    - print_round_trans allows us to print transactions data in each round (= frequency of printing e.g. 10) or not (= 0).
    - popn_ch is a parameter which deides if the population can vary or not. = 'fixed' or 'vary'.
    - agent_mem_length was originally used as the number of rounds the agent can remember, for when setting a lcoation target to head toward
    when trading. It is no longer used for this but it is used by the agents as a time horizon for updating the prices they're aware of.
    - cp_trans_weight is used when setting the target location ahead of trading: it is the weight attached to transaction
    locations the agent has heard about from others, with the weight of transactions it was involved in getting weight = 1.
    - agents_comm_likld is the number of agents any agent is expected to communicate with in order to exchange information
    about transaction locations.
    - print_move_heat_maps = 1 means we print off move-by-move heatmaps.
    - trade_prices determines whether the agents trade at a fixed price ('fixed') or at a variable price ('variable').
    - min_trans_Q is the minimum quantity of resources which must be traded by agents (stops infintesimally small amounts
    being traded).
    - gen_equ_thresh is 'general equilibrium threshold', which is a measure of accuracy for the market clearing quantities
    in the function which estimates these via a while loop.  The smaller the number, the more accurate but the longer the
    will take.  Default = 0.01.
    - gen_equ_wh_lps is the number of while loops in the function which finds general equilibrium prices.
    - find_gen_equ_PQ controls whether we bother to find the gen equ prices and quantities.
    - res_depletion is a number corresponding to the round when fountain resources become depleted i.e. famine. If the
    number == 0 then we don't have any sort of resource depletion; if > 0 then this corresponds to the round a depletion
    starts.
    - tot_rounds_depl is the number of rounds the fountain(s) will be depleted for.
    - fount_dep corresponds to which resources are depleted - this is an array of numbers.
    - fount_depl_ratio is the rate of depletion of the Fountain resource i.e. new starting reserve level is 
    initial level * fount_depl_ratio.
    - allow_Keynes_Inst creates a Keynesian Instition (unless == 0). 'sparse' means a KI is created in areas which agents
    who cannot get to a market can get to; and 'total' means we try to shift a pre-existing instititon for all agents.
    - homes_spacing is about the spacing of agents on the grid: this can be 'square' or 'hex'.
    - use_parallel_code switches parallel code on or off.  Off means the code will run slower.
    - price_grid_dimen is the size of the price grid dimension used for the optimization process.
    - test_par_code = 1 means we deploy lots of testing aparatus for the parallel proces (= 0 we do not).
    - note that to print a chart with high graphic density, go to the function call and set dpi = 'high'.
    - force_prices determines whether the agents use the market clearing prices in transactions), if forced_prices == 'optimal' then
    any value of price_mean is ignored.
    - fixed_price: if force_prices == 'fixed' then we use this value to fix the price.
    - constitutional_voting means agents go through a process of evaluating 4 different constitutions and then vote on their preference.
    - Walrasian_Trading == 1 means the trading process is ignored in place of a Walrasian auctioneer approach, i.e., the price is market
    clearing and the volume transacted is determined by the agents' ideal trades at that price.
    - ststst is about a steady state start: if ststst[0] == 1 then we force specific start conditions on the agents; ststst[1] is the 
    number of agents; ststst[2] is max and min detection probs; the ststst[3] starting market location, which is a grid location; and
    [4] is about the resource distribution of agents: if == 'even' then the population start off with a uniform distribution.
    - respect_property_rights: if == 1 then the agents only trade; they don't fight; however, if == 0 they might try to steal from each other.
    - adjust_props_r is the 'malthus r' for adjusting the prop_steal and prop_fight_back values of each agent via a logistic equation.
    - start_props determines of the agents' prop_steal and prop_fight_back values are instantiated: 'random' or 'set'.
    - if start_props == 'set' then start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std are used to 
    create initial values of prop_steal and prop_fight_back via a normal distribution with relevant mean and std.
    - fight_cost is the gross deduction in both resources to the agents' agent_res_array when they fight.
    - agent_intn_beta is 'agent interaction beta': when updating their prop_steal and prop_fight_back, agents don't just learn from their own benefit
    or cost of the interaction - they also observe their counterparty's benefit or cost.  This is incorporated in to the agent's learning but with
    a weight of agent_intn_beta (relative to the weight given to the agent's direct benefit / cost.
    - len_reputations_mem: we restrict the agents' memories v-a-v recalling the reputation of other agents.  len_reputations_mem is the number
    of rounds which covers the agents' memories (i.e. memories start at day - len_reputations_mem).
    - intn_error_std: when the agents don't respect property rights they must form expectations about about the expected benefit of interacting
    with other agents.  They use a variety of information about themselves and agent - intn_error is an error term added to any expectation
    formed (using a normal distribution with this as standard deviation).
    - record_dead_agents = 1 means we record all the dead agents - turn this off when we are running v long sims (e.g. > 20k rounds).
    - agent_avoid_muggers = 1: if an agent believes their expected gain from an interaction with a counterpart is negative and that counterpart's
    expected gain is positive then they will actively avoid that agent, i.e., move away from it.
    - agree_location can be 'weak', 'strong', 'super_strong', or 'none': if 'strong', two agents who communicate (they are known to each other and their expected gains / loss
    from transacting are both positive) will exchange trans location and then agree up front to meet somewhere in the next round.  If they transacted
    in the previous round, this location will be at the same location; else it will be randomly chosen.  If 'weak' then 2 agents exchange trans and
    fight information and they will select a location to meet at randomly (if neither have any + fight locations) or they will select a location furthest away
    from any known (-) fight locations.  If 'super_strong' then the agents run a sophisticated self-organisation process at the end of each round.  If 'none'
    then the agent reverts to the original approach to choosing a target location ie no incorpration of fight information.
    - trade_at_trgt_precise: if the agent is heading to a target location, if this == 0 then the agent can trade on the move before getting to the target; if
    == 1 then it can only trade at target.
    - fight_balance: if two agents fight, this dictates the balance of power in the fight.  if == '50_50' then agents have an equal chance, whereas if
    == res_power then the advantage is with the agent with the most resources.
    - use_original_model_struct == 1 means we use the original model structure while not respecting property rights, which is to replicate that approach at key points.
    - sign_mkt_thresh is the threshold number of agents for any location to be printed out, e.g., if sign_mkt_thresh == 3 then any location which saw more than or
    equal to 3 agents trade will be recorded as significant.
    - proportion_in_plotly_charts helps to make the plotly charts showing prop_steal and prop_fight_back less busy.  We will include only this proportion (e.g. 0.3)
    of the total number of agents.
    - two_tribes: if == 1 then the population is split in to 2 communities, each in diagonally opposite quadrants of the grid.  This is to experiment with
    formal property rights enabling trade between strangers.  The communities are called the 'sharks' and the 'jets'.
    - initial_fount_stock_high: when we have 2 tribes, each forages for 2 resources but 'sharks' have more of res 0 and 'jets' have more of res 1 (twice as much as the other).
    This variable sets the stock for each fountain.
    - black_shoop_exp is where two parents give birth to a black shoop (singular of sheep!) child, which has prop_steal and prop_fight_back = 1.  The question is whether it can survive: this
    is the equivalent to the invading defector in the iterated prisoners' dilemma game.  == 1 means only one shoop is born.  == 'all' means all children are black shoops.
    - black_shoop_pop defines the conditions under which a black shoop is born: == 0 means the black shoop will be the first child born in a sim (the
    easiest conditions); whereas == 54 means it will be born when the population is that size and a new baby is then born (54 is close to max when fountain
    stocks = 72).
    - formal_inst == 0 means no formal institution; == 'fine_only' means the offender is fined with no compenation to the damaged party; and == 'compensate' means
    the offender is fined and the damaged party compensated.
    - fight_skill is about whether we allow agents to be skilled (or not) at fighting, which can be used in interactions when respect_property_rights == 0.
    if fight_skill == None then we don't use it; otherwise we use a number (like 0.5, as a starting skill).
    - single_tribe is for testing what happens to one tribe when its resources are imbalanced.
    - agents_die_old_age = int means the agents die of old age at this age.
    - fix_prop_fb helps us fix prop_fb at zero, making the agents' interaction a simpler 2-strategy affair.  If == None then we ignore this, if == 0 then we fix prop_fb at zero.
    - fixed_prop_steal helps us fixed the propensity to steal at 1.0 for all agents at instantiation and any children.  If == None this is ignored, if == 1.0 then this
    fixes prop_steal at 1.0 with 0 std.
    - fix_ps_fb_0 allows us to set ps and p_fb = 0; if == 1 then this is done, if None it is ignored.
    - change_one_only allows us to change the propensities of one agent only, to test 'social construction' in the model.
    - ch_ag_prop_steal and ch_ag_prop_fb are the change agent's starting props.
    - PR_mating_threshold allows us to change the mating threshold when the agents don't respect property rights.
    - PR_res_init allows us to change initial res endownments when agents dont respect property rights.
    - start_1_rich_agent = 1 allows us to explore fight power issues: we allow one agent 1,000 resources.
    - clear_of_fights_radius: if we use super_strong agreed_location then agents will avoid any location and squares around it (determined by this radius).
    - corruption_prop_charge is used when formal institutions are in effect: if == 1.0 then there is no corruption; otherwise, when a fine is being levvied, the propbability of
    corruption in the process is taken as the mean prop to steal in the population, and corruption_prop_charge is multipled by the fine to arrive at the bribe.
    - strat_choice is 'strategic choice' in game interactions: 'heuristics' means use propensities; and 'rational' means use rational choice approach.
    - start_child_births is the minimum age of agents to be parents.
    - local_fight concerns agents' targetting: if 'zeroed' then agents will ignore grid squares around any location where they have a negative score; and if 'minus_one' then they
    will reduce the scores in nearby scquares by 1.
    - target_location_weights is used when agents are setting weights in their locations_dicts: == 'crude' means +1 for transactions where goods changed hands, cp_trans_weight
    for transactions heard about (and where goods changed hands), -1 for fights lost, +1 for fights won, -1 * cp_trans_weight for fights heard about.  If == 'reduced_value' then
    the agents use the reduced values of fights / transactions.
    - must_update_neighs: we only call update_neighbours if we have to, i.e., when there have been new agents born.
    - habit_val: this is about habituation.  If habit_val > 0.0, this value gets added to the weight of the agent's target location at the end of each round, regardless of transactions.
    - granular_mem represents 'granular memory' and is now onlu used to print data in Keynesian Object experiment.
    """

    if calc_timings:

        start_time = dt.DateTime()

    # if this is true, we change these default parameters:
    if respect_property_rights == 0:

        agents_comm_prob = 0.25

        if agree_location == 'super_strong':
            
            agents_comm_prob = 1.0

        # agent_mem_length = 20
        agent_res_init = PR_res_init
        agent_res_init_std = PR_res_init_std
        mating_thresh = PR_mating_threshold
        popn_ch = 'vary'
        dimen = int(math.sqrt(num_agents) * dimen_density)
        init_res_level = init_res_lev_per_agent * num_agents

        if two_tribes == 1:
            
            # note: must change num_agents manually
            dimen = int(math.sqrt(num_agents / 2.0) * dimen_density * 2)
            
            init_res_level = init_res_lev_per_agent * num_agents / 2.0
            initial_fount_stock_high = init_res_level * 2

        if single_tribe == 1:
            
            init_res_level = init_res_lev_per_agent * num_agents / 2.0
            initial_fount_stock_high = init_res_level * 2

    if respect_property_rights == 1:
        dimen = int(math.sqrt(num_agents) * dimen_density)
        init_res_level = init_res_lev_per_agent * num_agents

    if scenario != 'adjust_travel_dist' and two_tribes == 0:

        wait_at_tgt_moves = int((dimen_density * (num_agents ** 0.5)) / 2.0)    # this ensures the first agents to arrive at a market wait for the last agent
        trade_moves = wait_at_tgt_moves * 2

    if two_tribes:

        wait_at_tgt_moves = int(dimen_density * (num_agents ** 0.5))        
        trade_moves = wait_at_tgt_moves * 2

    local_net_rad = dimen_density + 1

    # if ststst[0] == 1:
    #
    #     num_agents = ststst[1]

    # place all of the paramters in to a dictionary, which helps when we record these in data files:
    params_dict = locals()

    # print('\n params_dict', params_dict)

    # pause()

    # create an object which saves all starting parameters
    params = Parameters_Object(params_dict, ststst, fount_dep, applied_constitutions)

    # we start by creating folders in a directory in whcih we save charts and data (we create 'blank' variables first as they
    # will be passed to functions below):
#    data_folder = ""
    df_daily = ""

    if create_dir == 1:

        # designate a folder which is the variable 'result_main_fold' plus a date/time stamp:
        run_folder = "%s/%d_%d_%d_%d_%d_%d_%d" % (save_folder,
                                                 dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(),
                                                 dt.DateTime().hour(), dt.DateTime().minute(), dt.DateTime().second(),
                                                 dt.DateTime().millis() / 100000)

        # this line creates the directory
        if os.path.exists(run_folder) == False:
            os.makedirs(run_folder)

        # if we want to store charts printed every round then we create a sub-directory in this data_folder:
        if print_round_trans != 0 or print_move_heat_maps != 0 or track_agent:

            df_daily = "%s/daily_data" % (run_folder)

            os.makedirs(df_daily)

    # straight away we write a read_me file to record parameters in a single file (this is done at the beginning in case
    # of errors in the code - having this data might help us find bugs)
    write_text_file_readme(run_folder, params_dict, scenario, readme_notes)

    # for chart colours, use this
    colors = ['black', 'blue', 'red', 'green', 'aqua', 'teal', 'navy', 'fuchsia', 'purple', 'yellow', 'brown', 'maroon', 'firebrick', 'salmon', 'gold']

    # for parallelism: here in these two lines we copy num_agents to a constant variable in the c code
#    num_agents_ptr, num_agents_const_size = mod.get_global("num_agents")
#    driver.memcpy_htod(num_agents_ptr, int(num_agents))

    ################################################################################################################
    ############################################ Instantiation #####################################################

    # Here we set up 5 objects: a population of databases, an agent population, a population of fountains, a town_grid and a Keynesian_Object_Population

    # First we set up an object which contains all of the databases we will use:
    dbs = Databases(rounds, dimen, for_strat_parts, trade_moves, run_folder, init_res_level, print_MRS_std_charts, constitutional_voting, num_experiments,
                    two_tribes, black_shoop_exp, agree_location)

    # Second, we set up a population of agents (this returns an object):
    agent_population = create_agents(dbs, print_dets, for_strat_parts, agent_res_init, agent_res_init_std,
                                     vision_len, dimen, print_fine_dets,
                                     rounds, trade_moves, trade_when_trgt, agent_homes, agent_mem_length, homes_spacing,
                                     cp_trans_weight, wait_at_tgt_moves, trade_prices, min_trans_Q, cognition_factor, trade_movemnt,
                                     start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                                     prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, two_tribes, black_shoop_exp, fight_skill,
                                     agents_die_old_age, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, stranger_int, corruption_prop_charge, popn_ch, must_update_neighs)

    if start_1_rich_agent == 1:
        
        agent_population.pop[-1].agent_res_array[0] = np.array([[1000.0, 1000.0]], dtype=float)

    # if we want to change the propensities of one agent only, to test social construction, we do this
    if change_one_only:
        
        agent_population.change_agent = agent_population.pop[-1]
        
        agent_population.change_agent.prop_steal = ch_ag_prop_steal
        agent_population.change_agent.prop_fight_back = ch_ag_prop_fb
        
        agent_population.black_shoop_list.append(agent_population.change_agent)

        # create a data file to record change agent data
        black_shoop_file = '%s/change_agent_file.txt' % (run_folder)       

        with open(black_shoop_file, 'a') as myfile:
            myfile.write("This text file is for recording notes concerning a change_agent \n")

        agent_population.change_agent.black_shoop_file = black_shoop_file

        # this is a switch so we don't create any more black shoops after the first
#            agent_population.black_shoop_seen = 1

        print('\n A change_agent was born!!!! - dum dum duuuuum')

        text = '\n\nThe change agent was born on day 0  |  home = %s\n' % (agent_population.change_agent.home)
        with open(agent_population.change_agent.black_shoop_file, 'a') as myfile:
            myfile.write(text)

#    for agent in agent_population.pop:
#        
#        print('\n agent.agent_res_array =', agent.agent_res_array[0])


#    input("Press Enter to continue...")

    # show this agent's home if we are tracking this agent during the simulation
    if track_agent:
        print('\n agent_population.tracking_agent.home =', agent_population.tracking_agent.home, '\n')

    # if we want to force a steady state start, we apply the agents' detection prob conditions here
    if ststst[0] == 1:

        if ststst[4] == 'even':

            pop_res_distr = np.linspace(10, mating_thresh - 10, num_agents)

        for agent_num in range(num_agents):

            agent = agent_population.pop[agent_num]
    
            if agent_num == 0 or agent_num % 2 == 0:

                agent.detect_skills_array[0][0] = ststst[2][0]
                agent.detect_skills_array[0][1] = ststst[2][1]

                for res in range(for_strat_parts):

                    agent.for_strat_array[0][res] = 0

            else:      
    
                agent.detect_skills_array[0][1] = ststst[2][0]
                agent.detect_skills_array[0][0] = ststst[2][1]      

                for res in range(for_strat_parts):

                    agent.for_strat_array[0][res] = 1

            if agent_num == 0:

                agent.home = np.array([5, 5])

            else:

                agent.home = np.array([None, None])

            if ststst[4] == 'even':

                agent.agent_res_array[0][0] = pop_res_distr[agent_num]
                agent.agent_res_array[0][1] = pop_res_distr[agent_num]

            print('agent_num =', agent_num, 'detect_skills_array =', agent.detect_skills_array, 'for_strat_array =', agent.for_strat_array, 'home =', agent.home, 'agent.agent_res_array =', agent.agent_res_array, 'age', agent.age)

    # Third we set up a population of resource fountains:
    fountain_population = create_fountains(agent_population, print_dets, init_res_level, rounds, dimen, trade_loc, two_tribes, initial_fount_stock_high, single_tribe)

    # Fourth, create a class to manage a town in around which agents look for other agents with whom they might trade:
    town_grid = TownGrid(rounds, dimen, trade_moves, print_dets)

    # if we are forcing a steady state start we must locate the agents in the following way:
    if ststst[0] == 1 and agent_homes == 'even':

        for agent_num in range(num_agents):

#            print('agent_num ', agent_num, 'of', num_agents)

            # the first agent's location has already been declared as 5, 5
            if agent_num > 0:

                agent = agent_population.pop[agent_num]

                agent.home = place_agent_in_best_spot(agent_population, town_grid, two_tribes)
        
    # now illustrate homes_array via a heatmap if we're printing charts
    if print_charts == 1:

        # now we look at the home locations of the agents and plot these on a heatmap
        # create an array to record the locations
        homes_array = np.zeros(shape=(dimen, dimen))
    
        for agent in agent_population.pop:
    
            x_coord = int(agent.home[0])
            y_coord = int(agent.home[1])
    
            homes_array[x_coord][y_coord] += 1

        create_heat_map(dimen, homes_array, run_folder, 'Greys', '', "agent_homes_start", dpi='high')

    KO_pop = Keynesian_Object_Population()

    # before starting the iteration loop we create a new variable in order to change the variable trade_movemnt if it was
    # mixed to start
    if trade_movemnt == 'mixed':

        trade_movemnt_start = 'mixed'

    else:

        trade_movemnt_start = copy.copy(trade_movemnt)

    # Create a counter so we propose a KI for 10 days only
    KI_before = 0

#    print 'before iteration starts: trade_movemnt =', trade_movemnt
#    print 'before iteration starts: trade_movemnt_start =', trade_movemnt_start

    if constitutional_voting == 1:

        constitution_counter = 0

    # create a dict for str(agent) -> home locations
    str_agent_to_home_dict = dict()

    for agent in agent_population.pop:

        str_agent_to_home_dict[str(agent)] = agent.home

    if calc_timings:

        dbs.timings_dict = dict()

        overheads_time = dt.DateTime() - start_time

        dbs.timings_dict['overheads'] = overheads_time
        dbs.timings_dict['foraging'] = []
        dbs.timings_dict['trading'] = []
        dbs.timings_dict['three_updates'] = []
        dbs.timings_dict['comms'] = []
        dbs.timings_dict['for_strats'] = []
        dbs.timings_dict['new_births'] = []

        dbs.timings_dict['trading_overhead'] = []

        dbs.timings_dict['trading_move_overhead'] = []
        dbs.timings_dict['trading_move_agent_mtt'] = []
        dbs.timings_dict['trading_move_agent_eval_own_grid_sq'] = []
        dbs.timings_dict['trading_move_agent_eval_exp_gains_own_square'] = []
        dbs.timings_dict['trading_move_agent_agents_interact'] = []
        dbs.timings_dict['trading_move_agent_eval_all_grid_sqs'] = []
        dbs.timings_dict['trading_move_agent_retargetting'] = []
        dbs.timings_dict['trading_move_agent_bilat_eval'] = []

    ################################################################################################################
    ######################################## start iteration loop ##################################################
    ################################################################################################################

    for round in np.arange(rounds, dtype=int):

        # if round >= 50:
        #
        #     track_agent = params.track_agent = 1
        #
        # else:
        #
        #     track_agent = params.track_agent = None

        # find the population's mean propensity to steal if there is corruption
        if agent_population.corruption_prop_charge != 1.0:
        
            # summation variable
            total_ps = 0
            
            for agent in agent_population.pop:
                
                total_ps += agent.prop_steal
            
            agent_population.mean_ps = total_ps / float(len(agent_population.pop))

        # if we are allowing the agents to test and choose a constitution:
        if constitutional_voting == 1:

            if round == start_const_proces + (const_proc_test_period * constitution_counter):        # we create arrays to record agents' resources and we record the agent alive and their min level of resource

                experiment = applied_constitutions[constitution_counter]

                if experiment == 1:

                    force_prices = 'float'
                    const_mkt_opens = 0

                if experiment == 2:

                    force_prices = 'float'
                    const_mkt_opens = 20

                if experiment == 3:

                    force_prices = 'optimal'
                    const_mkt_opens = 0

                if experiment == 4:

                    force_prices = 'optimal'
                    const_mkt_opens = 20

                if experiment == 5:

                    Walrasian_Trading = 1

                print('\n round =', round, 'constitution_counter', constitution_counter, 'applied_constitutions', applied_constitutions, 'experiment', experiment, 'force_prices', force_prices, 'const_mkt_opens', const_mkt_opens, 'Walrasian_Trading', Walrasian_Trading)

                constitution_counter += 1

        # here we need to adjust the parameter trade_movemnt if == 'mixed', which is when agents move around randomly
        # for some rounds and then move to set locations subsequently.
        if trade_movemnt_start == 'mixed':

            if round < random_rounds_start:
                trade_movemnt = 'random'

            else:
                trade_movemnt = 'set'

        # print basic information so sim is tracked neatly daily_succ_trans
        if round % 10 == 0:     # prints every 10 rounds

            if round == 0:
                last_time_stamp = dt.DateTime()
                time_passed = 0
            else:
                time_passed = dt.DateTime() - last_time_stamp
                last_time_stamp = dt.DateTime()

            print('sim_suite:', readme_notes, ' |  sim set = ', sim_no + 1, ' of ', total_runs, ' | dimen_density =', dimen_density, ' |  res_depletion =', res_depletion,\
                  '  |  round ', round, '\tof', rounds, '  adjust_props_r', adjust_props_r, '  fight_cost', fight_cost, '  time passed:', time_passed, '  popn', len(agent_population.pop))

        if round % heatmap_days_show == 0:

            print('\n Little props report:\n')
            aggr_prop_steal = 0
            aggr_prop_fb = 0
            aggr_res_0 = 0
            aggr_res_1 = 0
            aggr_det_max = 0
            aggr_det_min = 0

            def colour_text(value, equal_width=7):
                
                if value > 0.0:
                    
                    return '\x1b[1;31;47m +%6.3f \x1b[0m' % value
                    
                elif value < 0.0:
                    
                    return '\x1b[1;34;47m -%6.3f \x1b[0m' % np.abs(value)
                    
                else:
                    
                    equal_text = ' ' * int(equal_width / 2)
                    equal_text += '='
                    equal_text += ' ' * (equal_width - int(equal_width / 2))
                    
                    return equal_text
     
            for alive_agent in agent_population.pop:

                aggr_prop_steal += alive_agent.prop_steal
                aggr_prop_fb += alive_agent.prop_fight_back
                aggr_res_0 += alive_agent.agent_res_array[0][0]
                aggr_res_1 += alive_agent.agent_res_array[0][1] 
                aggr_det_max += np.max(alive_agent.detect_skills_array)
                aggr_det_min += np.min(alive_agent.detect_skills_array)

                if round == 0:

                    prop_steal_change = ' = '
                    prop_fb_change = ' = '
                    res_0_change = ' = '
                    res_1_change = ' = '
                    det_0_change = ' = '
                    det_1_change = ' = '

                if round > 0:
                    
                    prop_steal_change = alive_agent.prop_steal - alive_agent.prop_steal_record
                    prop_steal_change = colour_text(prop_steal_change, equal_width=8)
    
                    prop_fb_change = alive_agent.prop_fight_back - alive_agent.prop_fight_back_record
                    prop_fb_change = colour_text(prop_fb_change, equal_width=8)
    
                    res_0_change = alive_agent.agent_res_array[0][0] - alive_agent.agent_res_array_record[0][0]
                    res_0_change = colour_text(res_0_change, equal_width=8)
    
                    res_1_change = alive_agent.agent_res_array[0][1] - alive_agent.agent_res_array_record[0][1]
                    res_1_change = colour_text(res_1_change, equal_width=8)
    
                    det_0_change = alive_agent.detect_skills_array[0][0] - alive_agent.detect_skills_array_record[0][0]
                    det_0_change = colour_text(det_0_change, equal_width=9)

                    det_1_change = alive_agent.detect_skills_array[0][1] - alive_agent.detect_skills_array_record[0][1]
                    det_1_change = colour_text(det_1_change, equal_width=9)

                alive_agent.prop_steal_record = copy.copy(alive_agent.prop_steal)
                alive_agent.prop_fight_back_record = copy.copy(alive_agent.prop_fight_back )  
                alive_agent.agent_res_array_record = copy.copy(alive_agent.agent_res_array)
                alive_agent.detect_skills_array_record = copy.copy(alive_agent.detect_skills_array)

                print('ag home [%3.0d, %3.0d]' % (alive_agent.home[0], alive_agent.home[1]), 'tribe ', alive_agent.tribe, ' prop_steal  %1.3f ' % alive_agent.prop_steal, prop_steal_change, ' prop_fight_back  %1.3f' % alive_agent.prop_fight_back, prop_fb_change,
                      'res [%6.2f, %6.2f]' % (alive_agent.agent_res_array[0][0], alive_agent.agent_res_array[0][1]), '[', res_0_change, res_1_change, ']', ' det skills [%5.3f %5.3f]' % (alive_agent.detect_skills_array[0][0], alive_agent.detect_skills_array[0][1]),
                      '[', det_0_change, det_1_change, ']', 'fight_skill ', alive_agent.fight_skill, ' age', alive_agent.age)

            mean_prop_steal = aggr_prop_steal / float(len(agent_population.pop))
            mean_prop_fb = aggr_prop_fb / float(len(agent_population.pop))
            mean_res_0 = aggr_res_0 / float(len(agent_population.pop))
            mean_res_1 = aggr_res_1 / float(len(agent_population.pop))
            mean_det_min = aggr_det_min / float(len(agent_population.pop))
            mean_det_max = aggr_det_max / float(len(agent_population.pop))

            if round == 0:

                mean_prop_steal_change = '  =   '
                mean_prop_fb_change = '  =   '
                mean_res_0_change = '  =   '
                mean_res_1_change = '  =   '
                mean_det_min_change = '  =   '
                mean_det_max_change = '  =   '

            else:

                mean_prop_steal_change = mean_prop_steal - dbs.mean_prop_steal_record
                mean_prop_fb_change = mean_prop_fb - dbs.mean_prop_fb_record
                mean_res_0_change = mean_res_0 - dbs.mean_res_0_record
                mean_res_1_change = mean_res_1 - dbs.mean_res_1_record
                mean_det_min_change = mean_det_min - dbs.mean_det_min_record
                mean_det_max_change = mean_det_max - dbs.mean_det_max_record

                mean_prop_steal_change = colour_text(mean_prop_steal_change, equal_width=6)
                mean_prop_fb_change = colour_text(mean_prop_fb_change, equal_width=6)
                mean_res_0_change = colour_text(mean_res_0_change, equal_width=6)
                mean_res_1_change = colour_text(mean_res_1_change, equal_width=6)
                mean_det_min_change = colour_text(mean_det_min_change, equal_width=6)
                mean_det_max_change = colour_text(mean_det_max_change, equal_width=6)

            dbs.mean_prop_steal_record = copy.copy(mean_prop_steal)
            dbs.mean_prop_fb_record = copy.copy(mean_prop_fb)
            dbs.mean_res_0_record = copy.copy(mean_res_0)
            dbs.mean_res_1_record = copy.copy(mean_res_1)
            dbs.mean_det_min_record = copy.copy(mean_det_min)
            dbs.mean_det_max_record = copy.copy(mean_det_max)

#            print('\n dbs.mean_prop_steal_record', dbs.mean_prop_steal_record)
#            print('\n dbs.mean_prop_fb_record', dbs.mean_prop_fb_record)
#            print('\n dbs.mean_res_0_record', dbs.mean_res_0_record)
#            print('\n dbs.mean_res_1_record', dbs.mean_res_1_record)
#            print('\n dbs.mean_det_min_record', dbs.mean_det_min_record)
#            print('\n dbs.mean_det_max_record', dbs.mean_det_max_record)

            if len(agent_population.pop) > 0:
                print('\n mean prop_steal = %1.3f' % mean_prop_steal, mean_prop_steal_change, 'mean prop_fb = %1.3f' % mean_prop_fb, mean_prop_fb_change, '  mean res: [%4.2f, %4.2f]' % (mean_res_0, mean_res_1), '[', mean_res_0_change, mean_res_1_change, ']',
                      '   det skills min, max: [%1.3f, %1.3f]' % (mean_det_min, mean_det_max), '[', mean_det_min_change, mean_det_max_change, ']')
                print('\n')

            if len(dbs.games_type_considered_dict) > 0:
                    
                print(' game type scenarios:\n')
                
                counter = 0
                
                for scenario_name in dbs.games_type_considered_dict:
                    
                    counter += sum(dbs.games_type_considered_dict[scenario_name])
                    
                    print(' scenario name: ', scenario_name, 'num interactions =', sum(dbs.games_type_considered_dict[scenario_name]))

                print('\n total =', counter)

                print('\n')

            if len(dbs.games_type_dict) > 0:

                counter = 0
                
                for scenario_name in dbs.games_type_dict:
                    
                    counter += sum(dbs.games_type_dict[scenario_name])
                    print(' scenario name: ', scenario_name, 'num interactions =', sum(dbs.games_type_dict[scenario_name]))

                print('\n total =', counter)

                print('\n')

            if agent_population.change_agent is not None and len(agent_population.pop) > 1:

                print(' change_agent journey that day:', agent_population.change_agent.trade_loc_rec)
                print('\n change_agent targets that day:', agent_population.change_agent.trgt_loc_rec)
#                print('\n')
                
                print('\n first agent journey:', agent_population.pop[0].trade_loc_rec)
                print('\n first agent targets:', agent_population.pop[0].trgt_loc_rec)

                print('\n 2nd agent journey:', agent_population.pop[1].trade_loc_rec)
                print('\n 2nd agent targets:', agent_population.pop[1].trgt_loc_rec)

#        pause()

        # wipe the following two arrays, which record foraging data:
        if two_tribes == 0:

            dbs.res_level_array = np.zeros(shape=(for_strat_parts, num_res_founts))
            dbs.res_level_array_ends = np.zeros(shape=(for_strat_parts, num_res_founts))

        elif two_tribes == 1:
            
            dbs.res_level_array = np.zeros(shape=(for_strat_parts, 4))
            dbs.res_level_array_ends = np.zeros(shape=(for_strat_parts, 4))

        # update each living agent's list of neighbours
        if agent_population.must_update_neighs:

            update_neighbours(town_grid, agent_population, local_net_rad, print_dets, print_fine_dets, dimen, agent_population.tracking_agent, track_agent)

            agent_population.must_update_neighs = 0

        # at the start of every day we set equal to zero each agent's baskets, and their sell_array and buy_array:
        for agent in agent_population.pop:
            for fount in np.arange(num_res_founts):
                agent.basket_array[0][fount] = 0
            agent.sell_array = []
            agent.buy_array = []
            agent.fights_array = []
            agent.trades_array = []
            agent.trans_known_about = []

        # Now set the foutain resource levels back to fully stocked unless...
        # We change the Fountain Resource levels if res_depletion > 0
        if res_depletion > 0 and res_depletion <= round < res_depletion + tot_rounds_depl:

            for resource in np.arange(num_res_founts):

                if resource in fount_dep:

                    fountain_population.pop[resource].res_level = init_res_level * fount_depl_ratio

#                    if round % 10 == 0:
#                        print('\n fountain_population.pop[%d].res_level' % (resource), fountain_population.pop[resource].res_level)

                    # Record the fountains' initial levels
                    dbs.init_res_levels[round][resource] = init_res_level * fount_depl_ratio
                    dbs.fountains_init_levels_hist[resource][round] = init_res_level * fount_depl_ratio

                else:

                    fountain_population.pop[resource].res_level = init_res_level

                    # Record the fountains' initial levels
                    dbs.init_res_levels[round][resource] = init_res_level

        else:

            if two_tribes == 0:

                for res in np.arange(num_res_founts):
    
                    fountain_population.pop[res].res_level = init_res_level

                    # Record the fountains' initial levels
                    dbs.init_res_levels[round][res] = init_res_level
                    
                if single_tribe == 1:
                    
                    fountain_population.pop[0].res_level = init_res_level
                    fountain_population.pop[1].res_level = initial_fount_stock_high

            elif two_tribes == 1:

                # the foutains are set like this where 0 and 3 have higher stocks than 1 and 2
                fountain_population.pop[0].res_level = initial_fount_stock_high
                fountain_population.pop[1].res_level = init_res_level
                fountain_population.pop[2].res_level = init_res_level
                fountain_population.pop[3].res_level = initial_fount_stock_high                

                # Record the fountains' initial levels
                dbs.init_res_levels[round][0] = initial_fount_stock_high
                dbs.init_res_levels[round][1] = init_res_level
                dbs.init_res_levels[round][2] = init_res_level
                dbs.init_res_levels[round][3] = initial_fount_stock_high

        if calc_timings:
            foraging_start_time = dt.DateTime()

        # FORAGING: the following line calls the function which manages the foraging process
        if two_tribes == 0:

            agents_forage(round, for_strat_parts, print_dets, print_fine_dets, agent_population,
                          fountain_population.pop, dbs, print_for, two_tribes, tribe='none')

        elif two_tribes == 1:

            agents_forage(round, for_strat_parts, print_dets, print_fine_dets, agent_population,
                          fountain_population.pop_0, dbs, print_for, two_tribes, tribe='sharks')

            agents_forage(round, for_strat_parts, print_dets, print_fine_dets, agent_population,
                          fountain_population.pop_1, dbs, print_for, two_tribes, tribe='jets')

        if track_agent:
            print('\n day', round, ' - post-foraging agent_population.tracking_agent.basket_array', agent_population.tracking_agent.basket_array, 'skills:', agent_population.tracking_agent.detect_skills_array, 'foraging:', agent_population.tracking_agent.for_strat_array, '\n')
            pause()

        if calc_timings:
            dbs.timings_dict['foraging'].append(dt.DateTime() - foraging_start_time)

        # TRADING: whether the agents trade or not is a parameter of the simulation (agents_trade)

        # before trading (or not), we need to set trade_prob = 0.  This is used later to update foraging strategies - the default
        # should be 0, which can change if there is trading (this is done in the code below)
        trade_prob = 0

        if agents_trade == 1:

            if print_dets == 1:
                print('\n\n**** agents now trade ****\n\n')

            # tidy this up idc - there used to be a function here: agent_trading_decision, which has been removed.  now all agents trade.
            dbs.agent_list = list(copy.copy(agent_population.pop))

            if print_dets == 1:
                print('\nagent_list ahead of trading =', dbs.agent_list)
                print('number of trading agents =', len(dbs.agent_list))

            # Record the agents' foraging strategies in dbs.for_strat_db - these will be used later to unpack & process the
            # data; and record the agent's own strategy in its own for_strat_hist
            for agent in agent_population.pop:

                dbs.for_strat_db[round].append(copy.copy(agent.for_strat_array[0]))
                agent.for_strat_hist[round] = copy.copy(agent.for_strat_array[0])
                agent.basket_array_start = copy.copy(agent.basket_array)
                agent.basket_array_start_hist[round] = copy.copy(agent.basket_array[0])

                if two_tribes:
                    
                    if agent.tribe == 'sharks':
                        
                        dbs.for_strat_db_sharks[round].append(copy.copy(agent.for_strat_array[0]))

                    if agent.tribe == 'jets':
                        
                        dbs.for_strat_db_jets[round].append(copy.copy(agent.for_strat_array[0]))

            # use a seperate function to manage agents trading - note it returns the total number of trades
            if len(agent_population.pop) > 1:

#                # this is reuired below: test whether any agent MRS is > 4 before trading occurs
#                high_MRS = 0
#
#                for agent in agent_population.pop:
#
#                    agent.update_agent_MRS_array(print_dets, print_fine_dets, agent_population)
#
#                    for res_1 in range(num_res_founts):
#                        for res_2 in range(num_res_founts):
#
#                            if agent.MRS_array[res_1][res_2] > 4.0:
#
#                                high_MRS = 1
#
#                if high_MRS == 1 and round < 9000:
#
#                    # Here we create an alternative reality trading scenario - we copy all agent data and databases and use these in an alternative trading approach
#                    new_agent_population = copy.deepcopy(agent_population)
#                    new_fountain_population = copy.deepcopy(fountain_population)
#                    new_dbs = copy.deepcopy(dbs)
#                    new_town_grid = copy.deepcopy(town_grid)
#                    new_run_folder = '%s/alt' % (run_folder)
#    
#                    # this line creates the directory
#                    if os.path.exists(new_run_folder) == False:
#                        os.makedirs(new_run_folder)

                if Walrasian_Trading == 1:

                    gen_equ_thresh = 0.0001

                    agents_trading_Walras_Style(KO_pop, town_grid, agent_population, print_dets, trade_moves, trade_movemnt,
                                   vision_len, round, trade_loc, print_fine_dets, agent_population.tracking_agent,
                                   wait_at_target_til_end, wait_at_tgt_moves, track_agent, trgt_sel, dimen, trade_when_trgt,
                                   run_folder, print_round_trans, df_daily, dbs, granular_mem,
                                   fountain_population, print_move_heat_maps, trade_prices, rounds,
                                   gen_equ_thresh, gen_equ_wh_lps, SD_charts_freq, price_mean, force_prices, fixed_price,
                                   keynesian_ratio, find_gen_equ_PQ, use_parallel_code, price_grid_dimen, test_par_code,
                                   print_plotly_charts, print_MRS_std_charts, const_mkt_opens)

                else:

                    if calc_timings:
                        start_trading_time = dt.DateTime()

                    agents_trading(params, KO_pop, town_grid, agent_population, print_dets, trade_moves, trade_movemnt,
                                   vision_len, round, trade_loc, print_fine_dets, agent_population.tracking_agent,
                                   wait_at_target_til_end, wait_at_tgt_moves, track_agent, trgt_sel, dimen, trade_when_trgt,
                                   run_folder, print_round_trans, df_daily, dbs, granular_mem,
                                   fountain_population, print_move_heat_maps, trade_prices, rounds,
                                   gen_equ_thresh, gen_equ_wh_lps, SD_charts_freq, price_mean, force_prices, fixed_price,
                                   keynesian_ratio, find_gen_equ_PQ, use_parallel_code, price_grid_dimen, test_par_code,
                                   print_plotly_charts, print_MRS_std_charts, const_mkt_opens, ststst, respect_property_rights,
                                   adjust_props_r, fight_cost, agent_intn_beta, rounds, len_reputations_mem, intn_error_std, agent_avoid_muggers,
                                   prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, trade_at_trgt_precise,
                                   fight_balance, agree_location, use_original_model_struct, two_tribes, formal_inst, prob_fine, fine,
                                   print_agents_interact, fight_skill, fix_ps_fb_0, stranger_int, two_tribes_inst, strat_choice, strangers_if_unknown)

                    if calc_timings:
                        dbs.timings_dict['trading'].append(dt.DateTime() - start_trading_time)

#                # here we test a theory that new agents get better prices when Gen Equ used, when they are close to death and their MRSs are v high / v low
#                if high_MRS == 1 and round < 9000:
#
#                    gen_equ_thresh = 0.0000000001
#
#                    # this is our alt reality trading:
#                    agents_trading_Walras_Style(KO_pop, new_town_grid, new_agent_population, print_dets, trade_moves, trade_movemnt,
#                                   vision_len, round, pause, trade_loc, print_fine_dets, agent_population.tracking_agent,
#                                   wait_at_target_til_end, wait_at_tgt_moves, track_agent, trgt_sel, dimen, trade_when_trgt,
#                                   new_run_folder, print_round_trans, df_daily, new_dbs, granular_mem,
#                                   new_fountain_population, print_move_heat_maps, trade_prices, rounds,
#                                   gen_equ_thresh, gen_equ_wh_lps, SD_charts_freq, price_mean, force_prices, fixed_price,
#                                   keynesian_ratio, find_gen_equ_PQ, use_parallel_code, price_grid_dimen, test_par_code,
#                                   print_plotly_charts, print_MRS_std_charts, const_mkt_opens)
#
#                    res_0_diff = 0.0
#                    res_1_diff = 0.0
#
#                    for ag_num in range(len(agent_population.pop)):
#
#                        real_agent = agent_population.pop[ag_num]
#                        alt_agent = new_agent_population.pop[ag_num]
#
#                        print('home', real_agent.home, 'res', real_agent.agent_res_array[0], 'start basket', real_agent.basket_array_start, 'real_basket = ', real_agent.basket_array[0], 'alt_agent basket', alt_agent.basket_array[0], 'diff (real - alt):', real_agent.basket_array - alt_agent.basket_array)
#
#                        res_0_diff += real_agent.basket_array[0][0] - alt_agent.basket_array[0][0]
#                        res_1_diff += real_agent.basket_array[0][1] - alt_agent.basket_array[0][1]
#
##                        print('\n aggreg res_0_diff = %1.15f' % (res_0_diff))
##                        print(' aggreg res_1_diff = %1.15f' % (res_1_diff))
#
#                    input("Press Enter to continue...")

            # Update each agent's basket_array_hist
            for agent in agent_population.pop:
                agent.basket_array_hist[round] = copy.copy(agent.basket_array[0])

            # here we update the database trading_db with various data

            # we would like to add the total_on_sale to trading_db[2]:
            dbs.trading_db[4][round] = dbs.total_on_sale

            # update trading_db with the number of agents attempting to trade
            dbs.trading_db[1][round] = len(dbs.agent_list)

            # add population size to the trading_db
            dbs.trading_db[0][round] = len(agent_population.pop)

            # find the average trade proportion over the past 5 preiods
            if round < trade_prob_mem:
                trade_prob = np.mean(dbs.trading_db[6][:(round + 1)])
            else:
                trade_prob = np.mean(dbs.trading_db[6][(round - 5) : (round + 1)])

        #*************************************************************************************************************
        #******* after trading (or not), the agents then consume their baskets and forfeit the cost of living ********

        if print_dets == 1:
            print('\n\n---------------------------- END OF DAY ADJUSTMENTS ----------------------------------\n')

        # add one to each agent's age
        for agent in agent_population.pop:
            
            agent.age += 1

        if calc_timings:
            start_three_updates = dt.DateTime()

        # now we must also update each agent's subjective perceived trade_proby, which is taken from their neighbours
        update_trade_probys(agent_population, trade_prob_mem, round, print_dets, print_fine_dets, rounds, track_agent, trade_prices, Walrasian_Trading, ststst, fight_skill, fight_skill_r, dbs)

        # this function organises end-of-day consumption and metabolism, and also removes dead agents from the population
        end_of_day_cons_metab(track_agent, KO_pop, agent_population, print_fine_dets, dbs, round, allow_Keynes_Inst, respect_property_rights, record_dead_agents, black_shoop_exp, agents_die_old_age)

        # Now we update forraging skills before updating the population with new births
        update_foraging_skills(for_strat_parts, print_dets, print_fine_dets, agent_population.tracking_agent, track_agent, for_skill_r, agent_population, round)

        if calc_timings:
            dbs.timings_dict['three_updates'].append(dt.DateTime() - start_three_updates)

        here = 0

        update_locations_dicts(params, respect_property_rights, town_grid, dbs, agent_population, round, wait_at_target_til_end, wait_at_tgt_moves)

        if len(agent_population.pop) > 1 and Walrasian_Trading != 1:

            if calc_timings:
                start_comms = dt.DateTime()

            agents_communicate(params, agent_population, fountain_population, dbs, agents_comm_prob, round, town_grid, print_dets, print_fine_dets, respect_property_rights,
                               rounds, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, agree_location, agent_mem_length, prop_steal_floor,
                               fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0, clear_of_fights_radius, rounds, stranger_int,
                               strat_choice, two_tribes_inst, strangers_if_unknown, track_agent)

            if calc_timings:
                dbs.timings_dict['comms'].append(dt.DateTime() - start_comms)

        if calc_timings:
            start_update_for_strat = dt.DateTime()

        # now we need to update agents' foraging strategies.  we do this by randomly selecting one element in the agent's
        # strategy and asking if they ought to change this to a different resource fountain.
        update_for_strats(fountain_population, for_strat_parts, agent_population, print_dets,
                          agent_population.tracking_agent, trade_prob, track_agent, print_fine_dets, trade_loc, round, dbs,
                          trade_prices, Walrasian_Trading, two_tribes)

        if calc_timings:
            dbs.timings_dict['for_strats'].append(dt.DateTime() - start_update_for_strat)

        if calc_timings:
            start_new_births = dt.DateTime()

        # update the population given agent deaths and possible increase of whole population
        new_births(params, agent_population, print_dets, print_fine_dets, agent_homes, init_res_level, dbs, round,
                   for_strat_parts, agent_res_init,
                   vision_len, dimen, rounds, trade_moves, trade_when_trgt, popn_ch, agent_mem_length,
                   cp_trans_weight, wait_at_tgt_moves, trade_prices, agent_res_init_std, mating_thresh,
                   cognition_factor, town_grid, run_folder, trade_movemnt, agents_comm_prob, respect_property_rights,
                   start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                   children_props, child_prop_std, prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor,
                   adjust_props_r, agent_intn_beta, two_tribes, black_shoop_exp, black_shoop_pop, fight_skill, agents_die_old_age,
                   black_shoop_prop_start, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, start_child_births, price_mean, force_prices,
                   fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
                   fight_balance, formal_inst, prob_fine, fine, clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst,
                   track_agent, strangers_if_unknown)

        if calc_timings:
            dbs.timings_dict['new_births'].append(dt.DateTime() - start_new_births)

        # update this dict:
        for agent in agent_population.pop:

            if str(agent) not in str_agent_to_home_dict:

                str_agent_to_home_dict[str(agent)] = agent.home

        # here we do some data manipulation to generate trading data

        # extract the 2d array from town_grid's all_trans_array
        this_round_trans_grid = town_grid.all_trans_array[round]

        # create a blank array to work out gini coefficient
        oned_trans_grid = np.array([])

        mean_transs = np.mean(this_round_trans_grid)

        std_transs = np.std(this_round_trans_grid)

        mean_plus_5stds = mean_transs + (5 * std_transs)

        mean_plus_10stds = mean_transs + (5 * std_transs)

        # count the number of squares with transactions
        trans_sq_tot = 0
        over_5stds = 0
        over_10stds = 0

        # we want to record peak locations (where transs > mean_plus_10stds)
        peak_locs_array = []
#        print '\nthis_round_trans_grid =\n\n'
        for row in np.arange(dimen):
#            print this_round_trans_grid[row]
            for col in np.arange(dimen):
                if this_round_trans_grid[row][col] > 0:
                    trans_sq_tot += 1
                if this_round_trans_grid[row][col] > mean_plus_5stds:
                    over_5stds += 1
                if this_round_trans_grid[row][col] > mean_plus_10stds:
                    over_10stds += 1
                    peak_locs_array.append([row, col])
                if this_round_trans_grid[row][col] > 0:
                    oned_trans_grid = np.append(oned_trans_grid, this_round_trans_grid[row][col])

        # update various key_trading_db cells
        dbs.key_trading_db[1][round] = trans_sq_tot

        if print_dets == 1:
            print('oned_trans_grid =', oned_trans_grid)
            print('dbs.key_trading_db =', dbs.key_trading_db)

        # print chart of individual round trans's
        if print_round_trans != 0 and round % print_round_trans == 0:

            create_heat_map(dimen, this_round_trans_grid, df_daily, 'Blues', 'Trans round %s' % (round), 'daily_chart_%s' % (round), dpi='low')

            write_key_agent_data_round(dbs, agent_population, df_daily, vision_len, round, peak_locs_array, town_grid)

        # now we update for_spec_db, which records the degrees of specialisation among agents
        if len(agent_population.pop) > 0:

            num_agens = len(agent_population.pop)
    
            max_for_counter = 0
            for agen in agent_population.pop:
                track_ress_array = np.zeros(shape=(num_res_founts), dtype=int)
                for i in np.arange(for_strat_parts):
                    for j in np.arange(num_res_founts):
                        if agen.for_strat_array[0][i] == j:
                            track_ress_array[j] += 1

                # find highest number of resources being foraged, add to for_spec_db and add to the counter:
                max_for = np.max(track_ress_array)
                dbs.for_spec_db[max_for + 1][round] += 1

#                print('\n agent', agen, 'agen.for_strat_array', agen.for_strat_array, 'track_ress_array', track_ress_array, 'max_for', max_for)

                max_for_counter += max_for

            # record the average number of max foraging strat
            dbs.for_spec_db[for_strat_parts + 2][round] = max_for_counter / float(num_agens)

        # now we update min_res_levels_db with the min res levels of each agent
        for agent in agent_population.pop:
            x_coord = int(agent.home[0])
            y_coord = int(agent.home[1])
            min_res_lev = np.min(agent.agent_res_array)

            agent.agent_res_array_hist[round] = copy.copy(agent.agent_res_array)

            dbs.min_res_levels_db[round][x_coord][y_coord] = min_res_lev

        # now we update the database counting the number of perfect specialists (skill > 0.99)
        for agent in agent_population.pop:

            if np.any(agent.detect_skills_array[0] > 0.95):

                dbs.num_perfect_specs[1][round] += 1

            if np.any(agent.detect_skills_array[0] > 0.99):

                dbs.num_perfect_specs[2][round] += 1

            if np.any(agent.detect_skills_array[0] >= 0.999):

                dbs.num_perfect_specs[3][round] += 1

        # update dbs.clustering_db and dbs.cluster_centre_db:

#        if round > cluster_lag - 2:
#
#            last_5_days_trades = np.zeros(shape=(dimen, dimen))
#
#            for i in np.arange(5):
#                for j in np.arange(dimen):
#                    for l in np.arange(dimen):
#                        last_5_days_trades[j][l] += town_grid.all_trans_array[round - i][j][l]
#    
#            cluster_data = clustering_coefficient(last_5_days_trades, dimen, print_dets)
#
#            dbs.clustering_db[1][round] = cluster_data[0]
#            dbs.cluster_centre_db[1][round] = cluster_data[1][0]
#            dbs.cluster_centre_db[2][round] = cluster_data[1][1]

        # record agents' average age

        if len(agent_population.pop) > 0:

            tot_age = 0
            for agent in agent_population.pop:
                ag_age = round - agent.birth_date + 1       # we add 1 as this is the end of the round so the agent has lived a whole round, in effect
                tot_age += ag_age

                dbs.ag_age_db[1][round] = tot_age / float(len(agent_population.pop))

        # Update detect_skills_array_hist
        for agent in agent_population.pop:
            agent.detect_skills_array_hist[round] = copy.copy(agent.detect_skills_array[0])

        # Update two bits of agent data at the end of the round
#        dbs.live_agents[round] = agent_population.pop

        max_det_probs_array = []
        agents_res_array = np.zeros(shape=(len(agent_population.pop), num_res_founts))

#        print('\n agent_population.pop =', agent_population.pop)
#        print('\n agents_res_array =', agents_res_array)

        agent_num = 0

        for agent in agent_population.pop:

            max_det_prob = np.max(agent.detect_skills_array)
            max_det_probs_array.append(max_det_prob)

            agents_res_array[agent_num] = agent.agent_res_array[0]

            agent_num += 1

        dbs.copy_ags_max_det_probs[round] = max_det_probs_array

        dbs.copy_ags_res_arrays[round] = agents_res_array

        # Here we update dbs.serviced_locations
        # start by evaluating the trading on the town grid:
        trades_array_vis_seg = np.zeros(shape=(dimen, dimen), dtype=float)
        # this is for evaluating fights:
        fights_array_grid = np.zeros(shape=(dimen, dimen), dtype=int)

        # This array counts the number of agents that have transacted on the grid square
        dbs.trades_array_ags = [[[] for j in range(dimen)] for i in range(dimen)]
        # This is the same but for the fights in the locations
        dbs.fights_array_ags = [[[] for j in range(dimen)] for i in range(dimen)]

        start_round = np.max([0, round - agent_mem_length + 1])     # inclusive counting eg if mem length is 4 and round = 10 then we want 7, 8, 9, 10

        days_transs = []
        days_fights = []

        for day in np.arange(start_round, round + 1):

#            print('\n round =', round, 'day', day, 'dbs.transs_daily_db[day]', dbs.transs_daily_db[day])

            for trans in dbs.transs_daily_db[day]:

                days_transs.append(trans)

            for fight in dbs.fights_daily_db[day]:

                days_fights.append(fight)

#        print('\n days_transs', days_transs)

#        days_transs = dbs.transs_daily_db[round]

        for trans_num in days_transs:

            trans = dbs.trans_db[trans_num]

            if trans.tot_trans_ag_sell is not None:
    
                x_coord = trans.location[0]
                y_coord = trans.location[1]
                trades_array_vis_seg[x_coord][y_coord] += ((trans.tot_trans_ag_sell + trans.tot_trans_ag_buy) / 2.0)
    
                for agent in agent_population.pop:
    
                    if agent.home[0] == trans.agent_a_home[0] and agent.home[1] == trans.agent_a_home[1] and agent not in dbs.trades_array_ags[x_coord][y_coord]:
    
                        dbs.trades_array_ags[x_coord][y_coord].append(agent)
    
                    if agent.home[0] == trans.agent_b_home[0] and agent.home[1] == trans.agent_b_home[1] and agent not in dbs.trades_array_ags[x_coord][y_coord]:
    
                        dbs.trades_array_ags[x_coord][y_coord].append(agent)

        tot_grid_trans = np.sum(trades_array_vis_seg)

        for fight_num in days_fights:

            fight = dbs.fights_db[fight_num]
            
            x_coord = fight.location[0]
            y_coord = fight.location[1]
            
            fights_array_grid[x_coord][y_coord] += 1
            
            if fight.initiator not in dbs.fights_array_ags[x_coord][y_coord]:

                dbs.fights_array_ags[x_coord][y_coord].append(fight.initiator)

            if fight.counterpart not in dbs.fights_array_ags[x_coord][y_coord]:

                dbs.fights_array_ags[x_coord][y_coord].append(fight.counterpart)
                
#        print('\n dbs.trades_array_ags =\n', dbs.trades_array_ags)

        # We consider a market significant if >= 2 agents transact at a particular location
#        sign_mkt_thresh = 2

        for x_coord in np.arange(dimen):
            for y_coord in np.arange(dimen):

                if len(dbs.trades_array_ags[x_coord][y_coord]) >= sign_mkt_thresh:
                    dbs.sign_mkt_locs[round].append([x_coord, y_coord])

                if len(dbs.trades_array_ags[x_coord][y_coord]) >= sign_mkt_thresh or len(dbs.fights_array_ags[x_coord][y_coord]) >= sign_mkt_thresh:
                    dbs.sign_locs[round].append([x_coord, y_coord])

#        print '\n dbs.sign_mkt_locs[round] =', dbs.sign_mkt_locs[round]

        serviced_grid = np.zeros(shape=(dimen, dimen), dtype=int)
        for x_coord in np.arange(dimen):
            for y_coord in np.arange(dimen):

                for sign_mkt_loc in dbs.sign_mkt_locs[round]:

                    if within_striking_dist(wait_at_target_til_end, town_grid, [x_coord, y_coord], wait_at_tgt_moves, vision_len, sign_mkt_loc, move=0, has_acted=0, print_dets=0):

                        serviced_grid[x_coord][y_coord] += 1

#        print '\n serviced_grid =\n', serviced_grid
        if len(agent_population.pop) > 0:

            serviced_agents_counter = 0
            for agent in agent_population.pop:
    
                x_coord = agent.home[0]
                y_coord = agent.home[1]
    
                if serviced_grid[x_coord][y_coord] > 0:
    
                    serviced_agents_counter += 1
    
    #        print '\n serviced_agents_counter =', serviced_agents_counter
    
            ratio_serviced_agents = serviced_agents_counter / float(len(agent_population.pop))
    
            dbs.serviced_locations[round] = ratio_serviced_agents

#        raw_input("Press Enter to continue...")

        # Here we update the Keynesian Institutions Data, if there are any, but only if there are agents with resources < 100 and for the first 200 rounds of the KI's life
        min_res_value = 1000

        for agent in agent_population.pop:
        
            if np.min(agent.agent_res_array) < min_res_value:

                min_res_value = np.min(agent.agent_res_array)

        if min_res_value < 100:

            for KI in KO_pop.pop:

#                if round - KI.day_created <= 200:

                text = '\n\nDay = %d\n' % (round)
                KI.write_to_notes(text)
    
                todays_transs = dbs.transs_daily_db[round]
    
                tot_trans_today = 0
    
                for trans_num in todays_transs:
    
                    trans = dbs.trans_db[trans_num]

                    if trans.good_a is not None:
    
                        if trans.location[0] == KI.loc[0] and trans.location[1] == KI.loc[1]:
        
                            text = '\ntransaction number = %d:' % (trans_num)
                            KI.write_to_notes(text)
        
                            text = ' move_num = %s  |  agent A (home = %s tribe %s) sold %s of Res %d |  agent B (home = %s tribe %s) sold %s of Res %d' % (trans.move_num, trans.agent_a_home, trans.agent_a_tribe, trans.tot_trans_ag_sell, trans.good_a, trans.agent_b_home, trans.agent_b_tribe, trans.tot_trans_ag_buy, trans.good_b)
                            KI.write_to_notes(text)
        
                            tot_trans_today += 1
        
                if tot_trans_today == 0:
    
                    text = '\nThere were no transactions today.'
                    KI.write_to_notes(text)
    
                text = '\n\n'
                KI.write_to_notes(text)
    
                for agent in KI.target_agents:
    
                    if agent.birth_date < round and agent.death_date > round:
    
                        if len(agent.trade_loc_rec) == 0:
    
                            agent.trade_loc_rec = np.array([[1000, 1000], [1000, 1000]])
    
    #                        input("Press Enter to continue...")
    
                        text = 'agent = %s (home %s tribe %s) start basket [%d, %d] optimal trans [%2.2f %2.2f] end basket [%1.2f %1.2f] res array = [%3.2f %3.2f] skills = [%1.2f %1.2f] | journey on grid start [%d %d] end [%d %d] \n' % (agent, agent.home, agent.tribe, agent.basket_array_start[0][0], agent.basket_array_start[0][1], agent.optimal_transs_systemic[round][0], agent.optimal_transs_systemic[round][1], agent.basket_array[0][0], agent.basket_array[0][1], agent.agent_res_array[0][0], agent.agent_res_array[0][1], agent.detect_skills_array[0][0], agent.detect_skills_array[0][1], agent.trade_loc_rec[0][0], agent.trade_loc_rec[0][1], agent.trade_loc_rec[-1][0], agent.trade_loc_rec[-1][1])
                        KI.write_to_notes(text)
    
                    else:
    
                        text = 'agent = %s (home %s tribe %s) is dead (death date = %s)\n' % (agent, agent.home, agent.tribe, agent.death_date)
                        KI.write_to_notes(text)

#                    if round == KI.day_created + 200:
#    
#                        text = '\n\nThis institution is now 200 rounds old so the reporting will now stop'
#                        KI.write_to_notes(text)
                
        # put Keynesian institution here: there are two cases - 'total' where we try to move a single market and 'sparse'
        # where we create a new market for agents in repeatedly dying location
        if (allow_Keynes_Inst == 'total' and round == Keynes_round) or (two_tribes == 1 and round == new_mkt_round):

#            formal_inst = two_tribes_inst
            agent_population.ignore_strangers = 0

            if two_tribes == 0:

                # We take the first location in dbs.sign_mkt_locs and find the furthest point from this
                x_coord_mkt = dbs.sign_mkt_locs[round][0][0]
                y_coord_mkt = dbs.sign_mkt_locs[round][0][1]

                # the furthest point will be this
                KI_x = int((x_coord_mkt + town_grid.dimen / 2.0) % town_grid.dimen)
                KI_y = int((y_coord_mkt + town_grid.dimen / 2.0) % town_grid.dimen)

                new_keynesian_location = np.array([KI_x, KI_y], dtype=int)

            elif two_tribes == 1:

                new_keynesian_location = np.array([60, 60], dtype=int)

            new_ko_folder = '%s/KI_day_%s' % (run_folder, round)
        
            ko_notes_file = '%s/00_notes_file.txt' % (new_ko_folder)

            # this line creates the directory
            os.makedirs(new_ko_folder)

            dead_ags_copy = copy.copy(dbs.dead_ags_grid_counter)

            influenced_agents = []

            KIagents = []
            trgt_locations = []
            dead_ags_at_trgt_locs = []

            if two_tribes:
                
                KIagents = copy.copy(agent_population.pop)

            else:

                # ony some of the agents will be subject to the KI - we add them to an array like so, which becomes part of the KI bject
                for agent_num in range(num_KI_agents):

                    KIagents.append(agent_population.pop[agent_num])

            for agent in agent_population.pop:

                trgt_locations.append(agent.home)
                dead_ags_at_trgt_locs.append(agent)

            # Create a new Keynesian Object
            new_ko = Keynesian_Object(round, copy.copy(new_keynesian_location), new_ko_folder, ko_notes_file, dead_ags_copy, copy.copy(dbs.dead_ags_grid_counter),
                                      copy.copy(KIagents), trgt_locations)

            KO_pop.pop.append(new_ko)
        
            # Append new_ko text_file
            add_text = "This is a Notes File pertaining to a proposed Keynesian Institution.\n\nThe Institution was proposed on day %s at location %s" % (round, new_keynesian_location)
        
            new_ko.write_to_notes(add_text)
        
            new_ko.add_initial_text(fountain_population, trade_prices, granular_mem, print_fine_dets, print_dets, dbs, town_grid, round, wait_at_tgt_moves)

        # Here we propose a Keynesian institution if on any grid square more than two agents have died, which is an indicator of poverty at that location
        # the condition that len([cell for line in dbs.dead_ags_grid_counter for cell in line if cell > 0]) >= 2 means there must be more than one location for the dead agents
        # the condition len([cell for line in dbs.dead_ags_grid_counter for cell in line if cell > 0]) > 1 means there is more than one location
        if allow_Keynes_Inst == 'sparse':

            if np.max(dbs.dead_ags_grid_counter) >= 2:  # and len([cell for line in dbs.dead_ags_grid_counter for cell in line if cell > 0]) > 1:

                if min_res_value < 60:

                    propose_keynesian_inst(KO_pop, dbs, agent_population, dbs.min_res_levels_db, round, agent_res_init, town_grid,
                                           print_fine_dets, print_dets, run_folder, trade_moves, wait_at_tgt_moves,
                                           vision_len, fountain_population, trade_prices, granular_mem, loc_mkt, restrict_by_district)           

        # Print some charts to track the progress of the run
    
        # We create a 'heatmap story' by looking at heatmaps created during successive periods over all rounds
        if heatmap_story == 1 and (round + 1) % heatmap_days_show == 0:          # then we show a chart
    
            segment_size = heatmap_days_show
            start_round = round - heatmap_days_show + 1
            end_round = round
    
            # evaluate trading on the town grid:
            trades_array_vis_seg = np.zeros(shape=(dimen, dimen), dtype=float)

            # this is for evaluating fights:
            fights_array_grid = np.zeros(shape=(dimen, dimen), dtype=int)

            for b in np.arange(start_round, end_round + 1):

                days_transs = dbs.transs_daily_db[b]

                for trans_num in days_transs:
    
                    trans = dbs.trans_db[trans_num]

                    if trans.tot_trans_ag_sell is not None:

                        x_coord = trans.location[0]
                        y_coord = trans.location[1]
                        trades_array_vis_seg[x_coord][y_coord] += ((trans.tot_trans_ag_sell + trans.tot_trans_ag_buy) / 2.0)

                days_fights = dbs.fights_daily_db[b]

                for fight_num in days_fights:
                    
                    fight = dbs.fights_db[fight_num]
                    
                    x_coord = fight.location[0]
                    y_coord = fight.location[1]
                    fights_array_grid[x_coord][y_coord] += 1

            # print transactions on last day only
            if round == rounds - 1:

                b = round - round - 1
                
                last_day_transs = dbs.transs_daily_db[b]

                trades_array_last_day = np.zeros(shape=(dimen, dimen), dtype=float)

                for trans_num in days_transs:
    
                    trans = dbs.trans_db[trans_num]

                    if trans.tot_trans_ag_sell is not None:

                        x_coord = trans.location[0]
                        y_coord = trans.location[1]
                        trades_array_last_day[x_coord][y_coord] += ((trans.tot_trans_ag_sell + trans.tot_trans_ag_buy) / 2.0)

            # transactions heatmap:
            title = 'Total Transactions : Rounds %s to %s' % (start_round, end_round)

#            create_heat_map(dimen, trades_array_vis_seg, run_folder, 'Blues', '', 'trading_segmented %s_to_%s' % (start_round, end_round), dpi='high')

            # Record the data for the last round: 

            if round == rounds - 1:

                dbs.last_round_trans_data = trades_array_vis_seg

                create_heat_map(dimen, trades_array_vis_seg, run_folder, 'Blues', '', 'trading_segmented', dpi='high')
                create_heat_map(dimen, trades_array_last_day, run_folder, 'Blues', '', 'trading_segmented_last_day', dpi='high')

            else:

                create_heat_map(dimen, trades_array_vis_seg, run_folder, 'Blues', title, 'trading_segmented', dpi='low')

            title_2 = 'Agent Min Res Levels: Round %s' % (end_round)
            create_heat_map(dimen, dbs.min_res_levels_db[end_round - 1], run_folder, 'Reds', title_2, 'min_res_levs', dpi='low')

            # Fights heatmap
            title = 'Total Fights : Rounds %s to %s' % (start_round, end_round)

            if round == rounds - 1:

                create_heat_map(dimen, fights_array_grid, run_folder, 'Reds', '', 'fights_heatmap', dpi='high')

            else:

                create_heat_map(dimen, fights_array_grid, run_folder, 'Reds', title, 'fights_heatmap', dpi='low')

             # Now we create a heatmap to show dead agents
#            if np.max(dbs.dead_ags_grid_counter) > 0:
#                title = 'Dead Agents Heatmap - Day %s' % (round)
#                create_heat_map(dimen, dbs.dead_ags_grid_counter, run_folder, 'Greens', title, 'dead_ags', dpi='low')

            # Now we create a heatmap to show which areas of the grid are serviced by markets and which are not.  Here we
            # consider a market significant if >= 2 agents have transacted at a particular location
#            sign_mkt_thresh = 2

#            if print_serviced_locations:

            sign_mkt_locs = []
            sign_fights_locs = []
            sign_locs = []
            num_agents_at_sign_locs = []

            for x_coord in np.arange(dimen):
                for y_coord in np.arange(dimen):

                    if len(dbs.trades_array_ags[x_coord][y_coord]) >= sign_mkt_thresh:
                        sign_mkt_locs.append([x_coord, y_coord])

                        # we need to count the number of agents transacting at each sign loc
                        num_agents_at_sign_locs.append(len(dbs.trades_array_ags[x_coord][y_coord]))

                    if len(dbs.fights_array_ags[x_coord][y_coord]) >= sign_mkt_thresh:
                        sign_fights_locs.append([x_coord, y_coord])

                    if len(dbs.trades_array_ags[x_coord][y_coord]) >= sign_mkt_thresh or len(dbs.fights_array_ags[x_coord][y_coord]) >= sign_mkt_thresh:
                        sign_locs.append([x_coord, y_coord])

            serviced_grid = np.zeros(shape=(dimen, dimen), dtype=int)
            for x_coord in np.arange(dimen):
                for y_coord in np.arange(dimen):

                    for sign_mkt_loc in sign_mkt_locs:

                        if within_striking_dist(wait_at_target_til_end, town_grid, [x_coord, y_coord], wait_at_tgt_moves, vision_len, sign_mkt_loc, move=0, has_acted=0, print_dets=0):

                            serviced_grid[x_coord][y_coord] += 1

            name = 'serviced_grids %s_to_%s' % (start_round, end_round)

#            create_heat_map_double(dimen, serviced_grid, homes_array, run_folder, 'Greens', 'Purples', '', name, dpi='high')

#            title = 'Locations Serviced by Markets: Rounds %s - %s' % (start_round, end_round)
#            create_heat_map_double(dimen, serviced_grid, homes_array, run_folder, 'Greens', 'Purples', 'Serviced Locations', name, dpi='low')

            # Update dbs.agent_summary_notes_file with agent foraging data
            total_forag_slots_array = np.zeros(shape=(num_res_founts))

            for for_strat_array in dbs.for_strat_db[round]:
                for strat in for_strat_array:
                    total_forag_slots_array[strat] += 1

            text = '\n\n\nday %s - total time slots devoted to foraging for resources:\n\n' % (round)
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            for res in np.arange(num_res_founts):

                text = 'resource %s = %3.0f\t' % (res, total_forag_slots_array[res])
                with open(dbs.agent_summary_notes_file, 'a') as myfile:
                    myfile.write(text)

            text = '\ttotal = %3.0f\t' % (np.sum(total_forag_slots_array))
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            num_ags_full_spec = np.zeros(shape=(num_res_founts))
            num_ags_max_det_prob = np.zeros(shape=(num_res_founts))

            for agent in agent_population.pop:

                tally_array = np.zeros(shape=(num_res_founts))

                for res in np.arange(num_res_founts):

                    if builtins.all(x == res for x in agent.for_strat_array[0]) == True:

                        num_ags_full_spec[res] += 1

                for slot in np.arange(for_strat_parts):

#                    print('\n slot =', slot, 'agent.for_strat_array ', agent.for_strat_array)

                    fount = agent.for_strat_array[0][slot]

                    tally_array[fount] += 1

                max_tally = np.max(tally_array)

#                print('tally_array', tally_array)
#                print('max_tally', max_tally)

                max_res = 0

                for res in np.arange(num_res_founts):

                    if tally_array[res] == max_tally:

                        max_res = res

#                print('max_res', max_res)
#                print('agent.detect_skills_array[0]', agent.detect_skills_array[0])

                if agent.detect_skills_array[0][max_res] > 0.99:

                    num_ags_max_det_prob[max_res] += 1

            text = '\n\n---> number of agents with maxed out foraging strats (all time slots devoted to one resource):\n\n' % (round)
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            for res in np.arange(num_res_founts):

                text = 'resource %s: %3.0f agents\t' % (res, num_ags_full_spec[res])
                with open(dbs.agent_summary_notes_file, 'a') as myfile:
                    myfile.write(text)

            text = '\ttotal = %3.0f of %3.0f agents (= %3.1fpct)\t' % (np.sum(num_ags_full_spec), len(agent_population.pop), (np.sum(num_ags_full_spec) * 100 / len(agent_population.pop)))
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            text = '\n\n---> number of agents with max detection probs > 99.9pct by resource:\n\n' % (round)
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            for res in np.arange(num_res_founts):

                text = 'resource %s: %3.0f agents\t' % (res, num_ags_max_det_prob[res])
                with open(dbs.agent_summary_notes_file, 'a') as myfile:
                    myfile.write(text)

            text = '\ttotal = %3.0f of %3.0f agents (= %3.1fpct)\t' % (np.sum(num_ags_max_det_prob), len(agent_population.pop), (np.sum(num_ags_max_det_prob) * 100 / len(agent_population.pop)))
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            # We add a note regarding significant market locations: number of agents transacting and fighting on each
            text = '\n\nSignificant Market Locations:\n'
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            for loc_num in range(len(sign_mkt_locs)):

                loc = sign_mkt_locs[loc_num]

                text = '\nLocation = %s  |  Num of traders = %d' % (loc, num_agents_at_sign_locs[loc_num])
                with open(dbs.agent_summary_notes_file, 'a') as myfile:
                    myfile.write(text)

            text = '\n\nTotal Number of Traders = %d' % (np.sum(num_agents_at_sign_locs))
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            text = '\n\n---------------------------------------------------------------------------------------------------------------'
            with open(dbs.agent_summary_notes_file, 'a') as myfile:
                myfile.write(text)

            # now write to dbs.sign_locs_notes_file Transaction
            for day in range(start_round, end_round):

#                print('\n\n\n day', day)
                if (black_shoop_exp == 1 or agent_population.change_agent is not None) and len(agent_population.black_shoop_list) > 0:
                    
                    for black_shoop in agent_population.black_shoop_list:

                        black_shoop.trans = []
                        black_shoop.fights = []
                        black_shoop.move_nums = []

                text = '\n\n\n\nDay = %d' % (day)
                with open(dbs.sign_locs_notes_file, 'a') as myfile:
                    myfile.write(text)
    
                # find move numbers in which agents fought or traded
                move_nums = []
    
                todays_transs = dbs.transs_daily_db[day]
                todays_fights = dbs.fights_daily_db[day]

                for trans_num in todays_transs:

                    trans = dbs.trans_db[trans_num]

                    if trans.move_num not in move_nums:

                        move_nums.append(trans.move_num)

                    if (black_shoop_exp == 1 or agent_population.change_agent is not None) and len(agent_population.black_shoop_list) > 0:

                        for black_shoop in agent_population.black_shoop_list:
                        
                            if trans.agent_a == str(black_shoop) or trans.agent_b == str(black_shoop):

                                black_shoop.trans.append(trans_num)
        
                                if trans.move_num not in black_shoop.move_nums:
                                    
                                    black_shoop.move_nums.append(trans.move_num)

                for fight_num in todays_fights:

                    fight = dbs.fights_db[fight_num]

                    if fight.move_num not in move_nums:

                        move_nums.append(fight.move_num)

                    if (black_shoop_exp == 1 or agent_population.change_agent is not None) and len(agent_population.black_shoop_list) > 0:
                        
                        for black_shoop in agent_population.black_shoop_list:
                                                    
                            if fight.initiator == str(black_shoop) or fight.counterpart == str(black_shoop):

                                black_shoop.fights.append(fight_num)
        
                                if fight.move_num not in black_shoop.move_nums:
                                    
                                    black_shoop.move_nums.append(fight.move_num)

#                print('\n black_shoop.trans', black_shoop.trans)
#                print('\n black_shoop.fights', black_shoop.fights)

                # place them in order
                move_nums.sort()
    
#                print('\n move_nums =', move_nums)
#                print('\n sign_locs_day =', sign_locs_day)
#                print('\n todays_transs =', todays_transs)
#                print('\n todays_fights =', todays_fights)
    
                for move in move_nums:

                    sign_locs_day = []

                    trans_grid = np.zeros(shape=(town_grid.dimen, town_grid.dimen))
                    fights_grid = np.zeros(shape=(town_grid.dimen, town_grid.dimen))

                    for trans_num in todays_transs:
        
                        trans = dbs.trans_db[trans_num]

                        if trans.move_num == move:

                            x_coord = trans.location[0]
                            y_coord = trans.location[1]
        
                            trans_grid[x_coord][y_coord] += 1
        
                    for fight_num in todays_fights:
    
                        fight = dbs.fights_db[fight_num]

                        if fight.move_num == move:

                            x_coord = fight.location[0]
                            y_coord = fight.location[1]
        
                            fights_grid[x_coord][y_coord] += 1
    
                    for x_coord in range(town_grid.dimen):
                        for y_coord in range(town_grid.dimen):
    
                            if trans_grid[x_coord][y_coord] > 0 or fights_grid[x_coord][y_coord] > 0:
    
                                sign_locs_day.append([x_coord, y_coord])

#                    print('\n move =', move)
    
                    text = '\n\n---> Move Number = %d:\n' % (move)
                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                        myfile.write(text)
    
                    tot_trans_move = 0
                    tot_fights_move = 0
    
                    for loc in sign_locs_day:

#                        print('\n loc', loc)
                        
                        fight_at_loc = 0
                        trans_at_loc = 0
                        fight_or_trans_at_loc = 0
    
                        # work out if there was a fight and / or transaction at this location
                        for trans_num in todays_transs:
    
                            trans = dbs.trans_db[trans_num]
    
                            if trans.move_num == move:
    
                                trans_at_loc = 1
                                fight_or_trans_at_loc = 1
    
                        for fight_num in todays_fights:
    
                            fight = dbs.fights_db[fight_num]
    
                            if fight.move_num == move:
    
                                fight_at_loc = 1
                                fight_or_trans_at_loc = 1
    
#                        print(' fight_at_loc =', fight_at_loc)
#                        print(' trans_at_loc =', trans_at_loc)
#                        print(' fight_or_trans_at_loc =', fight_or_trans_at_loc)
    
                        if fight_or_trans_at_loc:
    
                            text = '\nLocation = %s:\n' % (loc)
                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                myfile.write(text) 
    
                        if trans_at_loc:
    
                            for trans_num in todays_transs:
        
                                trans = dbs.trans_db[trans_num]

                                if trans.good_a is not None:
    
                                    if move == trans.move_num and trans.location[0] == loc[0] and trans.location[1] == loc[1]:
        
                                        text = '\ntrans num = %d:' % (trans_num)
                                        with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                            myfile.write(text)
                    
                                        text = ' day = %d  |  move_num = %s  |  agent A (home = %s) sold %1.3f of Res %d |  agent B (home = %s) sold %1.3f of Res %d' % (trans.day, trans.move_num, trans.agent_a_home, trans.tot_trans_ag_sell, trans.good_a, trans.agent_b_home, trans.tot_trans_ag_buy, trans.good_b)
                                        with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                            myfile.write(text)                

                            text = '\n'
                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                myfile.write(text)  

                        if fight_at_loc:
    
                            for fight_num in todays_fights:
    
#                                print('\n fight_num', fight_num)
    
                                fight = dbs.fights_db[fight_num]
    
#                                print(' fight.location =', fight.location, 'loc', loc)
    
                                if move == fight.move_num and fight.location[0] == loc[0] and fight.location[1] == loc[1]:      # Fight
    
#                                    print(' fight.location[0] == loc[0] and fight.location[1] == loc[1]')
    
                                    text = '\nfight num = %d:' % (fight_num)
                                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                        myfile.write(text)

                                    text = ' transfer to intiator (home %s) %s  |  initr res %s  |  cp res %s  |  new prop_steal = %1.4f  |  new prop_fight_back = %1.4f  |  cp home = %s  |  new cp prop_steal = %1.4f  |  new cp prop_fight_back = %1.4f ' % (str_agent_to_home_dict[fight.initiator], fight.agent_res_gain, fight.initiator_start_basket, fight.counterpart_start_basket, fight.initiator_new_prop_steal, fight.initiator_new_prop_fight_back, str_agent_to_home_dict[fight.counterpart], fight.counterpart_new_prop_steal, fight.counterpart_new_prop_fight_back)
                                    with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                        myfile.write(text)
#                                    Fight_Object initiator_new_prop_steal, initiator_new_prop_fight_back, counterpart_new_prop_steal, counterpart_new_prop_fight_back
                            text = '\n'
                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
                                myfile.write(text)

                # record the equivalent data for the black shoop, if it's alive
                if (black_shoop_exp == 1 or agent_population.change_agent is not None) and len(agent_population.black_shoop_list) > 0:

                    for black_shoop in agent_population.black_shoop_list:

                        # place them in order
                        black_shoop.move_nums.sort()
                        
    #                    print('\n black_shoop_move_nums =', black_shoop_move_nums)
    #                    print(' black_shoop_trans =', black_shoop_trans)
    #                    print(' black_shoop_fights =', black_shoop_fights)
    
                        for move_num in black_shoop.move_nums:
    
                            sign_locs_day = []
        
                            trans_grid = np.zeros(shape=(town_grid.dimen, town_grid.dimen))
                            fights_grid = np.zeros(shape=(town_grid.dimen, town_grid.dimen))
        
                            for trans_num in black_shoop.trans:
                
                                trans = dbs.trans_db[trans_num]
        
                                if trans.move_num == move_num:
        
                                    x_coord = trans.location[0]
                                    y_coord = trans.location[1]
                
                                    trans_grid[x_coord][y_coord] += 1
                
                            for fight_num in black_shoop.fights:
            
                                fight = dbs.fights_db[fight_num]
        
                                if fight.move_num == move_num:
        
                                    x_coord = fight.location[0]
                                    y_coord = fight.location[1]
                
                                    fights_grid[x_coord][y_coord] += 1
            
                            for x_coord in range(town_grid.dimen):
                                for y_coord in range(town_grid.dimen):
            
                                    if trans_grid[x_coord][y_coord] > 0 or fights_grid[x_coord][y_coord] > 0:
            
                                        sign_locs_day.append([x_coord, y_coord])
        
        #                    print('\n move =', move)
            
                            text = '\n\n---> Day %d Move Number = %d:\n' % (day, move_num)
                            with open(black_shoop.black_shoop_file, 'a') as myfile:
                                myfile.write(text)
            
                            tot_trans_move = 0
                            tot_fights_move = 0
            
                            for loc in sign_locs_day:
        
        #                        print('\n loc', loc)
                                
                                fight_at_loc = 0
                                trans_at_loc = 0
                                fight_or_trans_at_loc = 0
            
                                # work out if there was a fight and / or transaction at this location
                                for trans_num in black_shoop.trans:
            
                                    trans = dbs.trans_db[trans_num]
            
                                    if trans.move_num == move_num:
            
                                        trans_at_loc = 1
                                        fight_or_trans_at_loc = 1
            
                                for fight_num in black_shoop.fights:
            
                                    fight = dbs.fights_db[fight_num]
            
                                    if fight.move_num == move_num:
            
                                        fight_at_loc = 1
                                        fight_or_trans_at_loc = 1
            
        #                        print(' fight_at_loc =', fight_at_loc)
        #                        print(' trans_at_loc =', trans_at_loc)
        #                        print(' fight_or_trans_at_loc =', fight_or_trans_at_loc)
            
                                if fight_or_trans_at_loc:
            
                                    text = '\nLocation = %s:\n' % (loc)
                                    with open(black_shoop.black_shoop_file, 'a') as myfile:
                                        myfile.write(text) 
            
                                if trans_at_loc:
            
                                    for trans_num in black_shoop.trans:
                
                                        trans = dbs.trans_db[trans_num]
            
                                        if trans.tot_trans_ag_sell is not None:
            
                                            if move_num == trans.move_num and trans.location[0] == loc[0] and trans.location[1] == loc[1]:
                
                                                text = '\ntrans num = %d:' % (trans_num)
                                                with open(black_shoop.black_shoop_file, 'a') as myfile:
                                                    myfile.write(text)
                            
                                                text = ' day = %d  |  move_num = %s  |  agent A (home = %s) sold %1.3f of Res %d |  agent B (home = %s) sold %1.3f of Res %d' % (trans.day, trans.move_num, trans.agent_a_home, trans.tot_trans_ag_sell, trans.good_a, trans.agent_b_home, trans.tot_trans_ag_buy, trans.good_b)
                                                with open(black_shoop.black_shoop_file, 'a') as myfile:
                                                    myfile.write(text)                
        
                                    text = '\n'
                                    with open(black_shoop.black_shoop_file, 'a') as myfile:
                                        myfile.write(text)  
        
                                if fight_at_loc:
            
                                    for fight_num in black_shoop.fights:
            
        #                                print('\n fight_num', fight_num)
            
                                        fight = dbs.fights_db[fight_num]
            
        #                                print(' fight.location =', fight.location, 'loc', loc)
            
                                        if move_num == fight.move_num and fight.location[0] == loc[0] and fight.location[1] == loc[1]:
            
        #                                    print(' fight.location[0] == loc[0] and fight.location[1] == loc[1]')
            
                                            text = '\nfight num = %d:' % (fight_num)
                                            with open(black_shoop.black_shoop_file, 'a') as myfile:
                                                myfile.write(text)
            
                                            text = ' transfer to intiator (home %s) %s  |  new prop_steal = %1.4f  |  new prop_fight_back = %1.4f  |  cp home = %s  |  new cp prop_steal = %1.4f  |  new cp prop_fight_back = %1.4f ' % (str_agent_to_home_dict[fight.initiator], fight.agent_res_gain, fight.initiator_new_prop_steal, fight.initiator_new_prop_fight_back, str_agent_to_home_dict[fight.counterpart], fight.counterpart_new_prop_steal, fight.counterpart_new_prop_fight_back)
                                            with open(black_shoop.black_shoop_file, 'a') as myfile:
                                                myfile.write(text)
        #                                    Fight_Object initiator_new_prop_steal, initiator_new_prop_fight_back, counterpart_new_prop_steal, counterpart_new_prop_fight_back
                                    text = '\n'
                                    with open(black_shoop.black_shoop_file, 'a') as myfile:
                                        myfile.write(text)

#                        elif fight_at_loc == 0:
#            
#                            text = '\nThere were no fights here today.'
#                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
#                                myfile.write(text)
    
    
    #                    pause()
    
#                    for agent in dbs.trades_array_ags[loc[0]][loc[1]]:
#        
#                        if agent.birth_date < day and agent.death_date > day:
#    
#    #                        print('\n agent', agent, 'home', agent.home, 'loc_hit', agent.hist_trade_loc_rec[round])
#    
#                            if len(agent.hist_trade_loc_rec[day]) > 0:
#        
#                                text = '\nagent = %s (home %s) start basket [%d, %d] optimal trans [%2.2f %2.2f] end basket [%1.2f %1.2f] res array = [%3.2f %3.2f] skills = [%1.2f %1.2f] | journey on grid start %s end %s' % (agent, agent.home, agent.basket_array_start[0][0], agent.basket_array_start[0][1], agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1], agent.basket_array[0][0], agent.basket_array[0][1], agent.agent_res_array[0][0], agent.agent_res_array[0][1], agent.detect_skills_array[0][0], agent.detect_skills_array[0][1], agent.hist_trade_loc_rec[day][0], agent.hist_trade_loc_rec[day][-1])
#    
#                            else:
#        
#                                text = '\nagent = %s (home %s) start basket [%d, %d] optimal trans [%2.2f %2.2f] end basket [%1.2f %1.2f] res array = [%3.2f %3.2f] skills = [%1.2f %1.2f] | journey on grid start None end None' % (agent, agent.home, agent.basket_array_start[0][0], agent.basket_array_start[0][1], agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1], agent.basket_array[0][0], agent.basket_array[0][1], agent.agent_res_array[0][0], agent.agent_res_array[0][1], agent.detect_skills_array[0][0], agent.detect_skills_array[0][1])
#    
#                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
#                                myfile.write(text)
#    
#                        else:
#    
#                            text = '\nagent = %s (home %s) is dead (death date = %s)\n' % (agent, agent.home, agent.death_date)
#                            with open(dbs.sign_locs_notes_file, 'a') as myfile:
#                                myfile.write(text)

            # Here we create a daily report relating to the market locations nTarget
#            write_daily_market_report(run_folder, dbs, fountain_population, round, start_round, end_round, print_fine_dets)

#            create_heat_map_double_plotly(dimen, serviced_grid, homes_array, data_folder, 'Greens', 'Purples', title, 'serviced_grids', round, agent_population)

#            raw_input("Press Enter to continue...")

#        for sell_res in range(num_res_founts):
#            for buy_res in range(num_res_founts):
#
#                if sell_res < buy_res:
#
#                    print '\n dbs.latest_prices[sell_res][buy_res] =', dbs.latest_prices[sell_res][buy_res], '\n'
#                
#                    for agent in agent_population.pop:
#                        print 'agent', agent, 'wkg_prices_memory[sell_res][buy_res] =', agent.wkg_prices_memory[sell_res][buy_res]
    
#        raw_input("Press Enter to continue...")

#        # and create a text file showing agents' key data, including foraging strategies
#        if round > 100:
#
#            # write successful transactions data
#            write_succ_trans_data(dbs, round, town_grid, print_dets, run_folder, daily=0, daily_db=[])
#
#            write_key_agent_data(dbs, agent_population, fountain_population, run_folder, vision_len, town_grid, rounds)

        if constitutional_voting == 1:      # here we record all the consitutional voting data: we do this at the end of the round before the constitution is changed

            if (round - start_const_proces + 1) % const_proc_test_period == 0 and (round - start_const_proces + 1) / float(const_proc_test_period) >= 0:        # we create arrays to record agents' resources and we record the agent alive and their min level of resource

                experiment = int((round - start_const_proces + 1) / float(const_proc_test_period))

                print('\n round = ', round, 'experiment', experiment, '\n')
    
                # record resource levels
                for agent in agent_population.pop:

                    # note that we use pop variation in this exercise so we must account for the agent's resources lost through having children
                    agent_min_res = np.mean(agent.agent_res_array[0]) + np.mean(agent.resources_to_children)

                    print('agent', agent, 'res', agent.agent_res_array[0], 'agent.resources_to_children', agent.resources_to_children, 'add mean', np.mean(agent.resources_to_children))
    
                    dbs.constitutional_agents[experiment].append(agent)
                    dbs.constitutional_min_ress[experiment].append(agent_min_res)
    
                print('\n dbs.constitutional_agents:\n', dbs.constitutional_agents)
                print('\n dbs.constitutional_min_ress:\n', dbs.constitutional_min_ress)   

        if respect_property_rights == 0:

            daily_prop_steal = []
            daily_prop_fight_back = []

            prop_steal_round_aggr = 0
            prop_fb_round_aggr = 0

            if two_tribes:

                daily_prop_steal_sharks = []
                daily_prop_fight_back_sharks = []
                
                daily_prop_steal_jets = []
                daily_prop_fight_back_jets = []
                
                prop_steal_round_aggr_sharks = 0
                prop_fb_round_aggr_sharks = 0
                
                prop_steal_round_aggr_jets = 0
                prop_fb_round_aggr_jets = 0

            num_above_50_steal = 0
            num_above_50_fb = 0
            
            num_below_50_steal = 0
            num_below_50_fb = 0

            prop_steal_round_aggr_above_50 = 0
            prop_fb_round_aggr_above_50 = 0
            
            prop_steal_round_aggr_below_50 = 0
            prop_fb_round_aggr_below_50 = 0

            if two_tribes:
                
                num_sharks = 0
                num_jets = 0

            # record historical prop_steal and prop_fight_back
            for agent in agent_population.pop:

                mean_prop_steal = 0
                mean_prop_fight_back = 0
                
                agent.prop_steal_history[round] = copy.copy(agent.prop_steal)
                agent.prop_fight_back_history[round] = copy.copy(agent.prop_fight_back)

                if fight_skill is not None:
                    
                    agent.fight_skill_history[round] = copy.copy(agent.fight_skill)

                # record all the agents' props
                daily_prop_steal.append(agent.prop_steal)
                daily_prop_fight_back.append(agent.prop_fight_back)

                prop_steal_round_aggr += agent.prop_steal
                prop_fb_round_aggr += agent.prop_fight_back

                if agent.tribe == 'sharks':
                    
                    num_sharks += 1
                    prop_steal_round_aggr_sharks += agent.prop_steal
                    prop_fb_round_aggr_sharks += agent.prop_fight_back

                    daily_prop_steal_sharks.append(agent.prop_steal)
                    daily_prop_fight_back_sharks.append(agent.prop_fight_back)

                if agent.tribe == 'jets':
                    
                    num_jets += 1
                    prop_steal_round_aggr_jets += agent.prop_steal
                    prop_fb_round_aggr_jets += agent.prop_fight_back

                    daily_prop_steal_jets.append(agent.prop_steal)
                    daily_prop_fight_back_jets.append(agent.prop_fight_back)

#                if agent.prop_steal >= 0.5:
#
#                    prop_steal_round_aggr_above_50 += agent.prop_steal
#                    num_above_50_steal += 1
#
#                else:
#
#                    prop_steal_round_aggr_below_50 += agent.prop_steal
#                    num_below_50_steal += 1
#
#                if agent.prop_fight_back >= 0.5:
#
#                    prop_fb_round_aggr_above_50 += agent.prop_fight_back
#                    num_above_50_fb += 1
#
#                else:
#                    
#                    prop_fb_round_aggr_below_50 += agent.prop_fight_back
#                    num_below_50_fb += 1

            dbs.prop_steal_db[round] = daily_prop_steal
            dbs.prop_fight_back_db[round] = daily_prop_fight_back

#            if two_tribes:
#                
#                dbs.prop_steal_db_sharks[round] = daily_prop_steal_sharks
#                dbs.prop_fight_back_db_sharks[round] = daily_prop_fight_back_sharks
#    
#                dbs.prop_steal_db_jets[round] = daily_prop_steal_jets
#                dbs.prop_fight_back_db_jets[round] = daily_prop_fight_back_jets

            if len(daily_prop_steal) > 0:

                dbs.prop_steal_std_db[round] = np.std(daily_prop_steal)

            else:

                dbs.prop_steal_std_db[round] = None

            if len(daily_prop_fight_back) > 0:

                dbs.prop_fb_std_db[round] = np.std(daily_prop_fight_back)

            else:

                dbs.prop_fb_std_db[round] = None

            if two_tribes:
                
                # sharks
                if len(daily_prop_steal_sharks) > 0:
    
                    dbs.prop_steal_std_db_sharks[round] = np.std(daily_prop_steal_sharks)
    
                else:
    
                    dbs.prop_steal_std_db_sharks[round] = None
    
                if len(daily_prop_fight_back_sharks) > 0:
    
                    dbs.prop_fb_std_db_sharks[round] = np.std(daily_prop_fight_back_sharks)
    
                else:
    
                    dbs.prop_fb_std_db_sharks[round] = None

                # jets
                if len(daily_prop_steal_jets) > 0:
    
                    dbs.prop_steal_std_db_jets[round] = np.std(daily_prop_steal_jets)
    
                else:
    
                    dbs.prop_steal_std_db_jets[round] = None
    
                if len(daily_prop_fight_back_jets) > 0:
    
                    dbs.prop_fb_std_db_jets[round] = np.std(daily_prop_fight_back_jets)
    
                else:
    
                    dbs.prop_fb_std_db_jets[round] = None

            # when appointing these values to databases, we need to be careful the denominators are not zero (if they are => None)
            if len(agent_population.pop) > 0:

                dbs.prop_steal_mean_db[round] = prop_steal_round_aggr / float(len(agent_population.pop))
                dbs.prop_fb_mean_db[round] = prop_fb_round_aggr / float(len(agent_population.pop))

            else:
                
                dbs.prop_steal_mean_db[round] = None
                dbs.prop_fb_mean_db[round] = None

            if two_tribes:

                if num_sharks > 0:
                    
                    dbs.prop_steal_mean_db_sharks[round] = prop_steal_round_aggr_sharks / float(num_sharks)
                    dbs.prop_fb_mean_db_sharks[round] = prop_fb_round_aggr_sharks / float(num_sharks)

                else:
                    
                    dbs.prop_steal_mean_db_sharks[round] = None
                    dbs.prop_fb_mean_db_sharks[round] = None

                if num_jets > 0:
                    
                    dbs.prop_steal_mean_db_jets[round] = prop_steal_round_aggr_jets / float(num_jets)
                    dbs.prop_fb_mean_db_jets[round] = prop_fb_round_aggr_jets / float(num_jets)

                else:
                    
                    dbs.prop_steal_mean_db_jets[round] = None
                    dbs.prop_fb_mean_db_jets[round] = None

#            if num_above_50_steal > 0:
#
#                dbs.prop_steal_mean_above_50_db[round] = prop_steal_round_aggr_above_50 / float(num_above_50_steal)
#
#            else:
#
#                dbs.prop_steal_mean_above_50_db[round] = None
#
#            if num_above_50_fb > 0:
#
#                dbs.prop_fb_mean_above_50_db[round] = prop_fb_round_aggr_above_50 / float(num_above_50_fb)
#
#            else:
#                
#                dbs.prop_fb_mean_above_50_db[round] = None
#
#            if num_below_50_steal > 0:
#
#                dbs.prop_steal_mean_below_50_db[round] = prop_steal_round_aggr_below_50 / float(num_below_50_steal)
#                
#            else:
#                
#                dbs.prop_steal_mean_below_50_db[round] = None
#
#            if num_below_50_fb > 0:
#                
#                dbs.prop_fb_mean_below_50_db[round] = prop_fb_round_aggr_below_50 / float(num_below_50_fb)
#                
#            else:
#                
#                dbs.prop_fb_mean_below_50_db[round] = None

#                mean_prop_steal += agent.prop_steal / float(len(agent_population.pop))
#                mean_prop_fight_back += agent.prop_fight_back / float(len(agent_population.pop))
#
#                dbs.mean_prop_steal_hist[round] = mean_prop_steal
#                dbs.mean_prop_fight_back_hist[round] = mean_prop_fight_back

        # here we print charts showing symmetry breaking - the number of agents visiting different locations over time
        #print_chart(database, labels_array, title, y_axis_label, line_width, colors, data_folder, filename, data_type, dpi)
        if round in [50, 100, 200, 500, 800, 1000, rounds - 1] or (round > 0 and round % 500 == 0):

            this_day = round

            trgt_dict_keys = list(dbs.grid_trgt_hist_dict.keys())        # these are the grid location

            # print('\n trgt_dict_keys:', trgt_dict_keys)
            # pause()

            # data for whole sim:
            trgt_loc_db = [list(np.arange(this_day))]

            for loc in dbs.grid_trgt_hist_dict:
                trgt_loc_db.append(list(dbs.grid_trgt_hist_dict[loc][:this_day]))

                # print('\n loc', loc)
                # print(' array =', dbs.grid_trgt_hist_dict[loc])

            # print('\n trgt_loc_db:', trgt_loc_db, '\n\n\n')

            print_chart(database=trgt_loc_db, labels_array=trgt_dict_keys, title='', y_axis_label='Number of Agents',
                        line_width=2, colors=colors, data_folder=run_folder, filename='locs_visited_%d' % this_day, data_type='-',
                        dpi='high')

    #-->>
    #-->> This marks the end of the round iterations - everything below is data processing after all the round iterations <<--#
    #-->>

    print('\n dbs.round_all_ags_one_trgt =', dbs.round_all_ags_one_trgt)
    # pause()

    if respect_property_rights == 0:

        if agree_location == 'super_strong' or agree_location == 'strong':
            
            write_agreed_locs(dbs, run_folder, rounds)
        
        # start with prop_steal and prop_fight_back
    #    prop_steal_array = np.zeros(shape=(2, rounds), dtype=np.float64)
#        prop_steal_array = [np.arange(rounds)]

        data_prop_steal = []
        data_prop_fight_back = []

        if fight_skill is not None:
            
            data_fight_skill = []

        for agent in agent_population.pop:

            for day in range(rounds):
            
                if day < agent.birth_date or day >= agent.death_date:

                    agent.prop_steal_history[day] = None
                    agent.prop_fight_back_history[day] = None

                    if fight_skill is not None:
                        agent.fight_skill_history[day] = None

            if random.random() < proportion_in_plotly_charts:

                trace_prop_steal = go.Scatter(x=np.arange(rounds), y=agent.prop_steal_history, connectgaps=False, name='Agent born %d' % agent.birth_date)
                trace_prop_fight_back = go.Scatter(x=np.arange(rounds), y=agent.prop_fight_back_history, connectgaps=False, name='Agent born %d' % agent.birth_date)
                trace_fight_skill = go.Scatter(x=np.arange(rounds), y=agent.fight_skill_history, connectgaps=False, name='Agent born %d' % agent.birth_date)

                data_prop_steal.append(trace_prop_steal)
                data_prop_fight_back.append(trace_prop_fight_back)

                if fight_skill is not None:
                    
                    data_fight_skill.append(trace_fight_skill)

        for dead_agent in agent_population.dead_agent_array:

            for day in range(rounds):
            
                if day < dead_agent.birth_date or day >= dead_agent.death_date:

                    dead_agent.prop_steal_history[day] = None
                    dead_agent.prop_fight_back_history[day] = None

                    if fight_skill is not None:
                        dead_agent.fight_skill_history[day] = None

            if random.random() < proportion_in_plotly_charts:

                trace_prop_steal = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_steal_history, connectgaps=False, name='Agent born %d' % agent.birth_date)
                trace_prop_fight_back = go.Scatter(x=np.arange(rounds), y=dead_agent.prop_fight_back_history, connectgaps=False, name='Agent born %d' % agent.birth_date)
                trace_fight_skill = go.Scatter(x=np.arange(rounds), y=dead_agent.fight_skill_history, connectgaps=False, name='Agent born %d' % agent.birth_date)

                data_prop_steal.append(trace_prop_steal)
                data_prop_fight_back.append(trace_prop_fight_back)

                if fight_skill is not None:
                    
                    data_fight_skill.append(trace_fight_skill)

        fig_prop_steal = dict(data=data_prop_steal)
        fig_prop_fight_back = dict(data=data_prop_fight_back)

        if fight_skill is not None:
            
            fig_fight_skill = dict(data=data_fight_skill)

        if print_plotly_charts == 1:

            filename_prop_steal = '%s/prop_steal_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
            filename_prop_fight_back = '%s/prop_fight_back_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())               

            # generate and save charts
            dbs.agents_prop_steal_url = plotly.offline.plot(fig_prop_steal, filename=filename_prop_steal, auto_open=False)
            dbs.agents_prop_fb_url = plotly.offline.plot(fig_prop_fight_back, filename=filename_prop_fight_back, auto_open=False)

            if fight_skill is not None:

                filename_fight_skill = '%s/fight_skill_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())   

                dbs.fight_skill_url = plotly.offline.plot(fig_fight_skill, filename=filename_fight_skill, auto_open=False)

            if plotly_online:
            
                filename_prop_steal = '%s/prop_steal_%d-%d-%d-%d-%d.txt' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
                filename_prop_fight_back = '%s/prop_fight_back_%d-%d-%d-%d-%d.txt' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())

                if fight_skill is not None:

                    filename_fight_skill = '%s/fight_skill_%d-%d-%d-%d-%d.txt' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())     
            
                try:
                        
                    dbs.agents_prop_steal_url = py.plot(fig_prop_steal, filename=filename_prop_steal, auto_open=False, sharing=plotly_sharing)

                except Exception as e:
        
                    print('\n error:\n\n', e)
                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')
                
                try:
    
                    dbs.agents_prop_fb_url = py.plot(fig_prop_fight_back, filename=filename_prop_fight_back, auto_open=False, sharing=plotly_sharing)
        
                except:
        
                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

                if fight_skill is not None:
    
                    try:
                                
                        dbs.fight_skill_url = py.plot(fig_fight_skill, filename=filename_fight_skill, auto_open=False, sharing=plotly_sharing)
    
                    except:
            
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

        # now work on the mean prop_steal and prop_fight_back data
        prop_steal_means_above_50 = []
        prop_steal_means_below_50 = []
        prop_fight_back_means_above_50 = []
        prop_fight_back_means_below_50 = [] 

#        prop_steal_means[0] = np.arange(rounds)
#        prop_fight_back_means[0] = np.arange(rounds)

        for one_day in range(rounds):

            prop_steal_above_50_pct = []
            prop_steal_below_50_pct = []

            if len(dbs.prop_steal_db[one_day]) > 0:

                for ag_prop in dbs.prop_steal_db[one_day]:

                    if ag_prop >= 0.5:

                        prop_steal_above_50_pct.append(ag_prop)

                    elif ag_prop < 0.5:

                        prop_steal_below_50_pct.append(ag_prop)

                if len(prop_steal_above_50_pct) > 0:

                    mean_above_50 = np.mean(prop_steal_above_50_pct)

                else:

                    mean_above_50 = None

                if len(prop_steal_below_50_pct) > 0:

                    mean_below_50 = np.mean(prop_steal_below_50_pct)

                else:

                    mean_below_50 = None

                prop_steal_means_above_50.append(mean_above_50)
                prop_steal_means_below_50.append(mean_below_50)

            elif len(dbs.prop_steal_db[one_day]) == 0:

                prop_steal_means_above_50.append(None)
                prop_steal_means_below_50.append(None)

            prop_fight_back_above_50_pct = []
            prop_fight_back_below_50_pct = []
            
            if len(dbs.prop_fight_back_db[one_day]) > 0:

                for ag_prop in dbs.prop_fight_back_db[one_day]:

                    if ag_prop >= 0.5:

                        prop_fight_back_above_50_pct.append(ag_prop)

                    elif ag_prop < 0.5:

                        prop_fight_back_below_50_pct.append(ag_prop)

                if len(prop_fight_back_above_50_pct) > 0:

                    mean_above_50 = np.mean(prop_fight_back_above_50_pct)

                else:

                    mean_above_50 = None

                if len(prop_fight_back_below_50_pct) > 0:

                    mean_below_50 = np.mean(prop_fight_back_below_50_pct)

                else:

                    mean_below_50 = None

                prop_fight_back_means_above_50.append(mean_above_50)
                prop_fight_back_means_below_50.append(mean_below_50)

            elif len(dbs.prop_steal_db[one_day]) == 0:

                prop_fight_back_means_above_50.append(None)
                prop_fight_back_means_below_50.append(None)

        data_prop_steal = []

        data_prop_steal.append(go.Scatter(x=np.arange(rounds), y=prop_steal_means_above_50, connectgaps=False, name='Steal Mean >= 0.5'))
        data_prop_steal.append(go.Scatter(x=np.arange(rounds), y=prop_steal_means_below_50, connectgaps=False, name='Steal Mean < 0.5'))

        data_prop_fight_back = []

        data_prop_fight_back.append(go.Scatter(x=np.arange(rounds), y=prop_fight_back_means_above_50, connectgaps=False, name='Fight Back Mean >= 0.5'))
        data_prop_fight_back.append(go.Scatter(x=np.arange(rounds), y=prop_fight_back_means_below_50, connectgaps=False, name='Fight Back Mean < 0.5'))

        fig_prop_steal = dict(data=data_prop_steal)
        fig_prop_fight_back = dict(data=data_prop_fight_back)

        if print_plotly_charts == 1:

            filename_prop_steal = '%s/prop_steal_means_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
            filename_prop_fight_back = '%s/prop_fight_back_means_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
            
            dbs.prop_steal_above_below_50_url = plotly.offline.plot(fig_prop_steal, filename=filename_prop_steal, auto_open=False)
            dbs.prop_fb_above_below_50_url = plotly.offline.plot(fig_prop_fight_back, filename=filename_prop_fight_back, auto_open=False)

            if plotly_online:
                
                filename_prop_steal = '%s/prop_steal_means_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())                
                filename_prop_fight_back = '%s/prop_fight_back_means_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())

                try:
    
                    dbs.prop_steal_above_below_50_url = py.plot(fig_prop_steal, filename=filename_prop_steal, auto_open=False, sharing=plotly_sharing)
           
                except:
        
                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')
    
                try:
    
                    dbs.prop_fb_above_below_50_url = py.plot(fig_prop_fight_back, filename=filename_prop_fight_back, auto_open=False, sharing=plotly_sharing)
    
                except:
        
                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

        # now do the means of prop_steal and prop_fight_back
        data_prop_means = []

        data_prop_means.append(go.Scatter(x=np.arange(rounds), y=dbs.prop_steal_mean_db, connectgaps=False, name='Mean Propensity to Steal'))
        data_prop_means.append(go.Scatter(x=np.arange(rounds), y=dbs.prop_fb_mean_db, connectgaps=False, name='Mean Propensity to Fight Back'))

        if print_plotly_charts == 1:

            filename_prop_means = '%s/prop_means_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
    
            dbs.props_means_url = plotly.offline.plot(data_prop_means, filename=filename_prop_means, auto_open=False)
            
            filename_prop_means = '%s/prop_means_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
                
            try:
                
                dbs.props_means_url = py.plot(data_prop_means, filename=filename_prop_means, auto_open=False, sharing=plotly_sharing)                 

            except:
    
                print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

        # Now we record the number of transactions and fights in each round by updating num_ints_each_round which has 7 arrays (1 for each scenario),
        # Note, however, we also add total number of fights to dbs.num_fight_each_round and that scearios 2 & 3 and 4 & 5 are lumped together in to indices 2 and 4 respectively
        for trans in dbs.trans_db:

            # note indices of num_ints_each_round aligned with my scneario numbers
            dbs.num_ints_each_round[6][trans.day] += 1

            if two_tribes:
                
                if trans.agent_a_tribe == 'sharks' and trans.agent_b_tribe == 'sharks':
                    
                    dbs.num_ints_each_round_sharks[6][trans.day] += 1

                elif trans.agent_a_tribe == 'jets' and trans.agent_b_tribe == 'jets':
                    
                    dbs.num_ints_each_round_jets[6][trans.day] += 1

                else:               # must be inter-tribe transaction
                    
                    dbs.num_ints_each_round_inter[6][trans.day] += 1

        for fight in dbs.fights_db:

            # note: agent_record = [str(cp_agent), 1, 0, 1, 0]  - [1] is whether cp_agent fought; [2] is whether cp_agent fought back; [3] is whether agent fought; [4] is whether agent fought back]
            
            if fight.agent_record[1] == 1 and fight.agent_record[3] == 1:       # then both tried to steal - scenario 1 only
            
                dbs.num_ints_each_round[1][fight.day] += 1
                dbs.num_fight_each_round[fight.day] += 1

                if two_tribes:
    
                    if fight.agent_a_tribe == 'sharks' and fight.agent_b_tribe == 'sharks':
                        
                        dbs.num_ints_each_round_sharks[1][fight.day] += 1
                        dbs.num_fight_each_round_sharks[fight.day] += 1
    
                    elif fight.agent_a_tribe == 'jets' and fight.agent_b_tribe == 'jets':
                        
                        dbs.num_ints_each_round_jets[1][fight.day] += 1
                        dbs.num_fight_each_round_jets[fight.day] += 1
    
                    else:               # must be inter-tribe transaction
                        
                        dbs.num_ints_each_round_inter[1][fight.day] += 1
                        dbs.num_fight_each_round_inter[fight.day] += 1

            elif (fight.agent_record[1] == 1 and fight.agent_record[3] == 0 and fight.agent_record[4] == 1) or \
                  fight.agent_record[1] == 0 and fight.agent_record[3] == 1 and fight.agent_record[2] == 1:      # then one agent tried to steal and the other fought back (scenarios 2 and 3)

                dbs.num_ints_each_round[2][fight.day] += 1
                dbs.num_fight_each_round[fight.day] += 1

                if two_tribes:
    
                    if fight.agent_a_tribe == 'sharks' and fight.agent_b_tribe == 'sharks':
                        
                        dbs.num_ints_each_round_sharks[2][fight.day] += 1
                        dbs.num_fight_each_round_sharks[fight.day] += 1
    
                    elif fight.agent_a_tribe == 'jets' and fight.agent_b_tribe == 'jets':
                        
                        dbs.num_ints_each_round_jets[2][fight.day] += 1
                        dbs.num_fight_each_round_jets[fight.day] += 1
    
                    else:               # must be inter-tribe transaction
                        
                        dbs.num_ints_each_round_inter[2][fight.day] += 1
                        dbs.num_fight_each_round_inter[fight.day] += 1

            elif (fight.agent_record[1] == 1 and fight.agent_record[3] == 0 and fight.agent_record[4] == 0) or \
                  fight.agent_record[1] == 0 and fight.agent_record[3] == 1 and fight.agent_record[2] == 0:     # one agent steals, the other acquieses (scenarios 4 and 5)

                dbs.num_ints_each_round[4][fight.day] += 1
                dbs.num_fight_each_round[fight.day] += 1

                if two_tribes:
    
                    if fight.agent_a_tribe == 'sharks' and fight.agent_b_tribe == 'sharks':
                        
                        dbs.num_ints_each_round_sharks[4][fight.day] += 1
                        dbs.num_fight_each_round_sharks[fight.day] += 1
    
                    elif fight.agent_a_tribe == 'jets' and fight.agent_b_tribe == 'jets':
                        
                        dbs.num_ints_each_round_jets[4][fight.day] += 1
                        dbs.num_fight_each_round_jets[fight.day] += 1
    
                    else:               # must be inter-tribe transaction
                        
                        dbs.num_ints_each_round_inter[4][fight.day] += 1
                        dbs.num_fight_each_round_inter[fight.day] += 1

        # now chart these trans and fight data - two charts: one with total fights and trans, and second with breakdown of fights by type (1, 2 & 3, and 4 & 5)
        total_trans_and_fights = []
    
        total_trans_and_fights.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round[6], connectgaps=False, name='Transactions'))
        total_trans_and_fights.append(go.Scatter(x=np.arange(rounds), y=dbs.num_fight_each_round, connectgaps=False, name='Fights'))

        fig_trans_and_fights = dict(data=total_trans_and_fights)

        if print_plotly_charts == 1:

            filename_trans_and_fights = '%s/trans_and_fights_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
    
            dbs.trans_and_fights_url = plotly.offline.plot(fig_trans_and_fights, filename=filename_trans_and_fights, auto_open=False)
            
            if plotly_online:

                filename_trans_and_fights = '%s/trans_and_fights_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())

                try:
    
                    dbs.trans_and_fights_url = py.plot(fig_trans_and_fights, filename=filename_trans_and_fights, auto_open=False, sharing=plotly_sharing)                  
                            
                except:
        
                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

        # if we are counting the number of game types, we plot these data also.  We do two charts - one fine detailed, the other is an aggregation of these finer data
        if len(dbs.games_type_dict) > 0:
            
            filename_game_types = '%s/game_types_gross_num_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
            
            game_types_data = []
            
            print('\n number of games =', len(dbs.games_type_dict))
            
#            game_name_conversion_dict = dict()
#            
#            
            
            for game_type in dbs.games_type_dict:
                                
                MA_time_series = generate_MA_array(dbs.games_type_dict[game_type], 10)
                
                print('\n game ', game_type, 'sum', np.sum(dbs.games_type_dict[game_type]))

                game_types_data.append(go.Scatter(x=np.arange(rounds), y=MA_time_series, connectgaps=False, name=game_type))
            
            dbs.trans_and_fights_url = plotly.offline.plot(game_types_data, filename=filename_game_types, auto_open=False)

            # now for the interesting type chart
            filename_game_types_2 = '%s/game_types_net_value_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
            
            game_types_data = []

            for game_type in dbs.games_type_dict_2:
                
                print('\n game ', game_type, 'sum', np.sum(dbs.games_type_dict_2[game_type]))
                
                MA_time_series = generate_MA_array(dbs.games_type_dict_2[game_type], 10)

                game_types_data.append(go.Scatter(x=np.arange(rounds), y=MA_time_series, connectgaps=False, name=game_type))

            dbs.trans_and_fights_url = plotly.offline.plot(game_types_data, filename=filename_game_types_2, auto_open=False)

            # third chart
            filename_game_types_3 = '%s/game_types_net_value_3_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())

            game_types_data = []

            for game_type in dbs.games_type_dict_3:
                                
                MA_time_series = generate_MA_array(dbs.games_type_dict_3[game_type], 10)

                print('\n game ', game_type, 'sum', np.sum(dbs.games_type_dict_3[game_type]))

                game_types_data.append(go.Scatter(x=np.arange(rounds), y=MA_time_series, connectgaps=False, name=game_type))
            
            dbs.trans_and_fights_url = plotly.offline.plot(game_types_data, filename=filename_game_types_3, auto_open=False)

        if two_tribes:

            # sharks
            total_trans_and_fights_sharks = []
        
            total_trans_and_fights_sharks.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_sharks[6], connectgaps=False, name='Transactions'))
            total_trans_and_fights_sharks.append(go.Scatter(x=np.arange(rounds), y=dbs.num_fight_each_round_sharks, connectgaps=False, name='Fights'))
        
            fig_trans_and_fights_sharks = dict(data=total_trans_and_fights_sharks)
            
            if print_plotly_charts == 1:
    
                filename_trans_and_fights_sharks = '%s/trans_and_fights_sharks_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
                
                dbs.trans_and_fights_url_sharks = plotly.offline.plot(fig_trans_and_fights_sharks, filename=filename_trans_and_fights_sharks, auto_open=False)
                
                if plotly_online:
    
                    filename_trans_and_fights_sharks = '%s/trans_and_fights_sharks_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())                   

                    try:
                        
                        dbs.trans_and_fights_url_sharks = py.plot(fig_trans_and_fights_sharks, filename=filename_trans_and_fights_sharks, auto_open=False, sharing=plotly_sharing)
     
                    except:
            
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

            # jets
            total_trans_and_fights_jets = []
        
            total_trans_and_fights_jets.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_jets[6], connectgaps=False, name='Transactions'))
            total_trans_and_fights_jets.append(go.Scatter(x=np.arange(rounds), y=dbs.num_fight_each_round_jets, connectgaps=False, name='Fights'))
        
            fig_trans_and_fights_jets = dict(data=total_trans_and_fights_jets)
            
            if print_plotly_charts == 1:

                filename_trans_and_fights_jets = '%s/trans_and_fights_jets_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
                
                dbs.trans_and_fights_url_jets = plotly.offline.plot(fig_trans_and_fights_jets, filename=filename_trans_and_fights_jets, auto_open=False)
                
                if plotly_online:
    
                    filename_trans_and_fights_jets = '%s/trans_and_fights_jets_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())

                    try:
        
                        dbs.trans_and_fights_url_jets = py.plot(fig_trans_and_fights_jets, filename=filename_trans_and_fights_jets, auto_open=False, sharing=plotly_sharing)
    
                    except:
            
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

            # inter
            total_trans_and_fights_inter = []
        
            total_trans_and_fights_inter.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_inter[6], connectgaps=False, name='Transactions'))
            total_trans_and_fights_inter.append(go.Scatter(x=np.arange(rounds), y=dbs.num_fight_each_round_inter, connectgaps=False, name='Fights'))
        
            fig_trans_and_fights_inter = dict(data=total_trans_and_fights_inter)
            
            if print_plotly_charts == 1:
    
                filename_trans_and_fights_inter = '%s/trans_and_fights_inter_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
                
                dbs.trans_and_fights_url_inter = plotly.offline.plot(fig_trans_and_fights_inter, filename=filename_trans_and_fights_inter, auto_open=False)
                
                if plotly_online:
    
                    filename_trans_and_fights_inter = '%s/trans_and_fights_inter_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())

                    try:
        
                        dbs.trans_and_fights_url_inter = py.plot(fig_trans_and_fights_inter, filename=filename_trans_and_fights_inter, auto_open=False, sharing=plotly_sharing)
    
                    except:
            
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

        # now chart breakdown of fights by type
        fight_types = []

        # average-ify the data
        
        dbs.num_ints_each_round[1] = generate_MA_array(dbs.num_ints_each_round[1], 10)
        dbs.num_ints_each_round[2] = generate_MA_array(dbs.num_ints_each_round[2], 10)
        dbs.num_ints_each_round[4] = generate_MA_array(dbs.num_ints_each_round[4], 10)
        dbs.num_ints_each_round[6] = generate_MA_array(dbs.num_ints_each_round[6], 10)

        ints_1 = np.zeros(shape=rounds)
        ints_2 = np.zeros(shape=rounds)
        ints_4 = np.zeros(shape=rounds)
        ints_6 = np.zeros(shape=rounds)        

        for r in range(rounds):

            total_ints = dbs.num_ints_each_round[1][r] + dbs.num_ints_each_round[2][r] + dbs.num_ints_each_round[4][r] + dbs.num_ints_each_round[6][r]

            if total_ints > 0:

                ints_1[r] = dbs.num_ints_each_round[1][r] / total_ints
                ints_2[r] = dbs.num_ints_each_round[2][r] / total_ints
                ints_4[r] = dbs.num_ints_each_round[4][r] / total_ints
                ints_6[r] = dbs.num_ints_each_round[6][r] / total_ints

            else:
                
                ints_1[r] = None
                ints_2[r] = None
                ints_4[r] = None
                ints_6[r] = None

#        print('\n dbs.num_ints_each_round[1][r] =\n\n', dbs.num_ints_each_round[1][r])
#        print('\n ints_1 =\n\n', ints_1)

        fight_types.append(go.Scatter(x=np.arange(rounds), y=ints_1, connectgaps=False, name='Both Steal'))
        fight_types.append(go.Scatter(x=np.arange(rounds), y=ints_2, connectgaps=False, name='One Steals, Other Fights Back'))
        fight_types.append(go.Scatter(x=np.arange(rounds), y=ints_4, connectgaps=False, name='One Steals, Other Acquiesces'))
        fight_types.append(go.Scatter(x=np.arange(rounds), y=ints_6, connectgaps=False, name='Transactions'))

        fig_fight_types = dict(data=fight_types)

        if print_plotly_charts == 1:

            filename_fight_types = '%s/fight_types_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
            
            dbs.fight_types_url = plotly.offline.plot(fight_types, filename=filename_fight_types, auto_open=False)
            
            if plotly_online:
                
                filename_fight_types = '%s/fight_types_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())

                try:
    
                    dbs.fight_types_url = py.plot(fight_types, filename=filename_fight_types, auto_open=False, sharing=plotly_sharing)
        
                except:
            
                    print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

        if two_tribes:

            # sharks
            fight_types_sharks = []
    
            fight_types_sharks.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_sharks[1], connectgaps=False, name='Both Steal'))
            fight_types_sharks.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_sharks[2], connectgaps=False, name='One Steals, Other Fights Back'))
            fight_types_sharks.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_sharks[4], connectgaps=False, name='One Steals, Other Acquiesces'))
        
            fig_fight_types_sharks = dict(data=fight_types_sharks)
    
            if print_plotly_charts == 1:
    
                filename_fight_types_sharks = '%s/fight_types_sharks_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
                
                dbs.fight_types_url_sharks = plotly.offline.plot(fight_types_sharks, filename=filename_fight_types_sharks, auto_open=False)
                
                if plotly_online:
                    
                    filename_fight_types_sharks = '%s/fight_types_sharks_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
    
                    try:
        
                        dbs.fight_types_url_sharks = py.plot(fight_types_sharks, filename=filename_fight_types_sharks, auto_open=False, sharing=plotly_sharing)
    
                    except:
                
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

            # jets
            fight_types_jets = []
    
            fight_types_jets.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_jets[1], connectgaps=False, name='Both Steal'))
            fight_types_jets.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_jets[2], connectgaps=False, name='One Steals, Other Fights Back'))
            fight_types_jets.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_jets[4], connectgaps=False, name='One Steals, Other Acquiesces'))
        
            fig_fight_types_jets = dict(data=fight_types_jets)
    
            if print_plotly_charts == 1:
    
                filename_fight_types_jets = '%s/fight_types_jets_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
                
                dbs.fight_types_url_jets= plotly.offline.plot(fight_types_jets, filename=filename_fight_types_jets, auto_open=False)
                
                if plotly_online:
                    
                    filename_fight_types_jets = '%s/fight_types_jets_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
    
                    try:
        
                        dbs.fight_types_url_jets = py.plot(fight_types_jets, filename=filename_fight_types_jets, auto_open=False, sharing=plotly_sharing)
    
                    except:
                
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

            # inter
            fight_types_inter = []
    
            fight_types_inter.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_inter[1], connectgaps=False, name='Both Steal'))
            fight_types_inter.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_inter[2], connectgaps=False, name='One Steals, Other Fights Back'))
            fight_types_inter.append(go.Scatter(x=np.arange(rounds), y=dbs.num_ints_each_round_inter[4], connectgaps=False, name='One Steals, Other Acquiesces'))
        
            fig_fight_types_inter = dict(data=fight_types_inter)
    
            if print_plotly_charts == 1:
    
                filename_fight_types_inter = '%s/fight_types_inter_%d-%d-%d-%d-%d.html' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
                
                dbs.fight_types_url_inter = plotly.offline.plot(fight_types_inter, filename=filename_fight_types_inter, auto_open=False)
                
                if plotly_online:
                    
                    filename_fight_types_inter = '%s/fight_types_inter_%d-%d-%d-%d-%d' % (run_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute())
    
                    try:
        
                        dbs.fight_types_url_inter = py.plot(fight_types_inter, filename=filename_fight_types_inter, auto_open=False, sharing=plotly_sharing)
    
                    except:
                
                        print('\n *** There was a problem connecting to plotly so we ignore this and carry on ***\n')

        # now we create a data file to write all sim data for when respect_property_rights == 0
    
        filepath = run_folder
        filename = "text_no_property_rights"

        print('\n---> printing text_no_property_rights')

        fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (run_folder, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
        fileHandle.write("Data Relevant for Agents Not Respecting Property Rights\n\n\n")

        fileHandle.write("Day\tmean_ps\t\tstd\t\tmean_ps_>_50\tmean_ps_<_50\tmean_fb\t\tstd\t\tmean_fb_>_50\tmean_fb_<_50\tnum trans\tnum fights\ttype 1\t\t2 & 3\t\t4 & 5\n\n")

        for day in range(rounds):

            mean_steal = dbs.prop_steal_mean_db[day]

            if mean_steal == None:
                
                mean_steal = 'none'

            else:
                
                mean_steal = '%1.4f' % mean_steal

            std_steal = dbs.prop_steal_std_db[day]

            if std_steal == None:
                
                std_steal = 'none'

            else:
                
                std_steal = '%1.4f' % std_steal

            mean_above_50_steal = prop_steal_means_above_50[day]

            if mean_above_50_steal == None:
                
                mean_above_50_steal = 'none'

            else:
                
                mean_above_50_steal = '%1.4f' % mean_above_50_steal

            mean_below_50_steal = prop_steal_means_below_50[day]

            if mean_below_50_steal == None:
                
                mean_below_50_steal = 'none'

            else:
                
                mean_below_50_steal = '%1.4f' % mean_below_50_steal

            mean_fb = dbs.prop_fb_mean_db[day]

            if mean_fb == None:
                
                mean_fb = 'none'

            else:
                
                mean_fb = '%1.4f' % mean_fb

            std_fb = dbs.prop_fb_std_db[day]

            if std_fb == None:
                
                std_fb = 'none'

            else:
                
                std_fb = '%1.4f' % std_fb

            mean_above_50_fb = prop_fight_back_means_above_50[day]

            if mean_above_50_fb == None:
                
                mean_above_50_fb = 'none'

            else:
                
                mean_above_50_fb = '%1.4f' % mean_above_50_fb

            mean_below_50_fb = prop_fight_back_means_below_50[day]

            if mean_below_50_fb == None:
                
                mean_below_50_fb = 'none'

            else:
                
                mean_below_50_fb = '%1.4f' % mean_below_50_fb

            fileHandle.write("\n%4.0d\t%s\t\t%s\t\t%s\t\t%s\t\t%s\t\t%s\t\t%s\t\t%s\t\t%3d\t\t%3d\t\t%3d\t\t%3d\t\t%3d" % (day, mean_steal, std_steal, mean_above_50_steal, mean_below_50_steal, mean_fb, std_steal, mean_above_50_fb, mean_below_50_fb, dbs.num_ints_each_round[6][day], dbs.num_fight_each_round[day], dbs.num_ints_each_round[1][day], dbs.num_ints_each_round[2][day], dbs.num_ints_each_round[4][day]))

        fileHandle.close()

    # create a chart to show number of perfect specialists
    print_chart(dbs.num_perfect_specs, ['95 pct', '99 pct', '99.9 pct'], 'Number of Specialistss', 'Num Agents', 2, ['green', 'red', 'black'], run_folder, "num_specialists", data_type='-', dpi='low')

    # write successful transactions data
#    write_succ_trans_data(dbs, round, town_grid, print_dets, run_folder, daily=0, daily_db=[])

    write_for_strat_data(print_dets, print_fine_dets, dbs, fountain_population, agent_population, run_folder, rounds, two_tribes)

    # create a chart to show av age of the agents
    print_chart(dbs.ag_age_db, [''], 'Average Age of Agents', 'Av Age', 2, ['black'], run_folder, "agent_age", data_type='-', dpi='low')

    write_ag_age_data(dbs, run_folder)

    # Create a chart to show dbs.serviced_locations
    serv_loc_db = [list(range(rounds))]
    serv_loc_db.append(dbs.serviced_locations)
    print_chart(serv_loc_db, [''], 'Proportion of Agent Homes within Market Catchment Area', 'Ratio', 2, ['black'], run_folder, "serviced_locs", data_type='-', dpi='low')

    # create chart to track the clustering coefficient
#    cropped_clustering_db = []
#    cropped_clustering_db.append(dbs.clustering_db[0][cluster_lag - 1:])
#    cropped_clustering_db.append(dbs.clustering_db[1][cluster_lag - 1:])
#
#    print_chart(cropped_clustering_db, ['coeff'], 'Clustering Coefficient', 'Coefficient', 2, ['blue'], run_folder, "cluster_coeff", data_type='-', dpi='low')

    # create chart to show cluster centre journey

#    cluster_centre_db_copy = copy.deepcopy(dbs.cluster_centre_db)
#    cluster_centre_db_copy = np.delete(cluster_centre_db_copy, 0, 0)
#
#    print_chart_cc(cluster_centre_db_copy, 'Journey of Cluster Centre', 1, 'blue', run_folder, "clust_centre_journ", dimen, cluster_lag)

    # now create a chart to show how specialised agents were in their trading strategies - this will take the maximum prob in
    # each agent's trading strategy and then take an average of this across all agents

    # create chart to track the distribution of foraging strategies (we find the maximum number of times an agent forages for
    # any of the resources)

    min_max_spec = int(for_strat_parts / float(num_res_founts))

#    print('min_max_spec', min_max_spec)

    for_spec_db1 = []
    for_spec_chart = []

    for_spec_chart.append(dbs.for_spec_db[0])

    for spec in np.arange(for_strat_parts + 1, dtype=int):

        for_spec_db1.append(dbs.for_spec_db[spec + 1])

    for spec in np.arange(min_max_spec + 1, for_strat_parts + 2, dtype=int):

        for_spec_chart.append(dbs.for_spec_db[spec])

    # add the mean spec data
    for_spec_means = dbs.for_spec_db[for_strat_parts + 2]

#    print('\n for_spec_db1', for_spec_db1)

    max_for_cols = ['black', 'blue', 'red', 'green', 'navy', 'purple', 'aqua', 'fuchsia', 'teal', 'black', 'blue',
                    'red', 'green', 'aqua', 'teal', 'navy', 'fuchsia', 'purple', 'black', 'blue', 'red', 'green', 'aqua', 'teal',
                    'navy', 'fuchsia', 'purple', 'black', 'blue', 'red', 'green', 'aqua', 'teal', 'navy', 'fuchsia', 'purple']

    if print_end_of_round_charts == 1:

        print_chart(for_spec_chart, np.arange(min_max_spec, for_strat_parts + 2, dtype=int), 'Numbers of maximum foraging values', 'Num Agents', 2, max_for_cols, run_folder, "num_max_for", data_type='-', dpi='low')

    # create chart which takes each agent's maximum foraging value and takes an average of this
    for_spec_db2 = []
    for_spec_db2.append(dbs.for_spec_db[0])
    for_spec_db2.append(dbs.for_spec_db[-1])

    if print_end_of_round_charts == 1:

        print_chart(for_spec_db2, [''], '', 'Mean Max Specialisation Value', 3, ['black'], run_folder, "num_max_for_av", data_type='-', dpi='high')       # 'Average maximum specialisation values'

    # manipulate data to generate some average & sd numbers
    av_last_50_births = np.mean(dbs.main_db[1][-50:])
    av_last_50_deaths = np.mean(dbs.main_db[2][-50:])
    av_last_50_popn = np.mean(dbs.main_db[3][-50:])

    std_last_50_births = np.std(dbs.main_db[1][-50:])
    std_last_50_deaths = np.std(dbs.main_db[2][-50:])
    std_last_50_popn = np.std(dbs.main_db[3][-50:])

    # if we're printing details, show these data:
    if print_dets == 1:

        print('final population size =', len(agent_population.pop))
        print('\nmain_db =\n', dbs.main_db)    

        print('\nav_last_50_births =', av_last_50_births, '(', std_last_50_births, ')')
        print('av_last_50_deaths =', av_last_50_deaths, '(', std_last_50_deaths, ')')
        print('av_last_50_popn =', av_last_50_popn, '(', std_last_50_popn, ')')

        for d in np.arange(num_res_founts):

            print('foutain', d, ': average level last 50 periods =', np.mean(dbs.main_db[4 + d][-50:]), '(', np.std(dbs.main_db[4 + d][-50:]), ')')

        print('\n')

    # manipulate founts_db to extract average numbers for agent's foraging strategies i.e. %age by foutain
    agent_strat_db = np.zeros(shape=(1 + num_res_founts, rounds))
    agent_strat_db[0] = np.arange(rounds)

    for g in np.arange(rounds):
        for h in np.arange(num_res_founts):

            ag_counter = 0
            for i in np.arange(for_strat_parts):

                ag_counter = ag_counter + dbs.founts_db[1 + (i * num_res_founts) + h][g]

            agent_strat_db[1 + h][g] = ag_counter / (float(dbs.main_db[3][g]) * for_strat_parts)

    if agents_trade == 1:

        # create chart which plots the % of squares with transactions in them (any number) in each round
        pct_sq_tr_db = []
        pct_sq_tr_db.append(dbs.key_trading_db[0])
        pct_sq_tr_db.append(dbs.key_trading_db[1])
    
        if print_end_of_round_charts == 1:

            print_chart(pct_sq_tr_db, [''], 'Number of Squares with Transactions', 'No.', 2, ['black'], run_folder, "num_sqrs_transactions", data_type='-', dpi='low')

#        # create chart Goods On Sale & Sold
#        trades_n_goods_db = []
#        trades_n_goods_db.append(np.arange(rounds))
#        trades_n_goods_db.append(dbs.trading_db[4])
#        trades_n_goods_db.append(dbs.trading_db[5])
#
#        print_chart(trades_n_goods_db, ['On Sale', 'Sold'], 'Goods On Sale & Sold', 'Total', 2, ['black', 'blue'], run_folder, "goods", data_type='-', dpi='low')
#
#        # create chrt showing % of goods on sale which were sold
#        trades_n_goods_db_pct = []
#        trades_n_goods_db_pct.append(np.arange(rounds))
#        trades_n_goods_db_pct.append(dbs.trading_db[6])
#
#        print_chart(trades_n_goods_db_pct, ['Percent Sold'], 'Goods Sold / On Sale', 'Percent', 2, ['black'], run_folder, "goods_pct_sold", data_type='-', dpi='low')
    
        # here we convert trading_db data in to text file
#        write_trading_array_to_text(dbs.trading_db, run_folder)

    # print a chart showing births, deaths & population
    line_width = 2

    labels_array = ['births', 'deaths', 'population']
    title = 'Births, Deaths & Population'
    y_axis_label = 'total number'

    if print_end_of_round_charts == 1:

        print_chart(dbs.main_db[:4], labels_array, title, y_axis_label, line_width, colors, run_folder, "agent_population", data_type='-', dpi='low')

        print_chart(dbs.main_db[:4], labels_array, '', 'Total Number', line_width, ['blue', 'red', 'black'], run_folder, "agent_population_paper", data_type='-', dpi='high')

        if two_tribes:

            pops_data = []
            pops_data.append(range(rounds))
            pops_data.append(dbs.pop_sharks)
            pops_data.append(dbs.pop_jets)
            
            print_chart(pops_data, ['Sharks', 'Jets'], '', 'Total Number', line_width, ['blue', 'red'], run_folder, "agent_population_paper_tribes", data_type='-', dpi='high')

        print_turnover_breakdown_charts(num_res_founts, print_dets, print_fine_dets, dbs, rounds, fountain_population, run_folder, gen_equ_thresh)
    
        print_turnover_charts(num_res_founts, print_dets, print_fine_dets, dbs, rounds, fountain_population, run_folder, gen_equ_thresh, constitutional_voting, start_const_proces, const_proc_test_period)
    
        write_turnover_acc_report(run_folder, rounds, dbs, gen_equ_thresh)
    
        print_prices_charts(num_res_founts, print_dets, print_fine_dets, dbs, rounds, fountain_population, run_folder, Walrasian_Trading, two_tribes)

    # now we put the raw data in to a txt file
    write_popn_data_to_txt(dbs.main_db[:4], run_folder, num_agents)

    if print_end_of_round_charts == 1:

        # and create a text file showing agents' key data, including foraging strategies
        write_key_agent_data(dbs, agent_population, fountain_population, run_folder, vision_len, town_grid, rounds)

        # do the same with dead agents
        write_key_dead_agent_data(dbs, agent_population, fountain_population, run_folder, vision_len, town_grid, rounds)

    # create new database to print fountain data chart
    if two_tribes == 0:

        for i in np.arange(num_res_founts):
    
            colors = ['black', 'blue', 'red', 'green', 'aqua', 'teal', 'navy', 'fuchsia', 'purple']
            database2 = np.zeros(shape=(2, rounds))
            database2[0] = np.arange(rounds)
            database2[1] = dbs.foutain_levels[i]
    
            database2b = np.zeros(shape=(2, rounds))
            database2b[0] = np.arange(rounds)
            mov_av_days = 5
    
            database2b[1] = generate_MA_array(database2[1], mov_av_days)
    
            labels_array2 = [i]
            y_axis_label2 = 'Total Number'
            line_width = 1
    
            if trade_loc == 'fountain':
    
                title2 = 'Fountain Yields (loc [%s, %s])' % (fountain_population.pop[i].location[0], fountain_population.pop[i].location[1])
    
            else:
    
                title2 = 'Fountain Yields'
    
            Title = "fountains_yield"
    
            if print_end_of_round_charts == 1:
        
                print_chart(database2, labels_array2, title2, y_axis_label2, line_width, colors, run_folder, Title, data_type='-', dpi='low')
        
                print_chart(database2b, [''], '', y_axis_label2, 2, colors, run_folder, "fountains_yield_paper", data_type='-', dpi='high')

    elif two_tribes:

        # sharks res 0
        database = np.zeros(shape=(2, rounds))
        database[0] = np.arange(rounds)
        database[1] = np.zeros(shape=rounds)

        for day in range(rounds):

            database[1][day] = dbs.init_res_levels[day][0] - dbs.res_founts_sharks[0][day]

        MA_array = generate_MA_array(database[1], 5)
        
        database[1] = MA_array

        print_chart(database, [''], '', 'Total Number', 2, ['black'], run_folder, "fountains_yield_sharks_res_0", data_type='-', dpi='high')

        # sharks res 1
        for day in range(rounds):

            database[1][day] = dbs.init_res_levels[day][1] - dbs.res_founts_sharks[1][day]

        MA_array = generate_MA_array(database[1], 5)
        
        database[1] = MA_array

        print_chart(database, [''], '', 'Total Number', 2, ['blue'], run_folder, "fountains_yield_sharks_res_1", data_type='-', dpi='high')

        # jets res 0
        for day in range(rounds):

            database[1][day] = dbs.init_res_levels[day][2] - dbs.res_founts_jets[0][day]

        MA_array = generate_MA_array(database[1], 5)
        
        database[1] = MA_array

        print_chart(database, [''], '', 'Total Number', 2, ['red'], run_folder, "fountains_yield_jets_res_0", data_type='-', dpi='high')

        # jets res 1
        for day in range(rounds):

            database[1][day] = dbs.init_res_levels[day][3] - dbs.res_founts_jets[1][day]

        MA_array = generate_MA_array(database[1], 5)
        
        database[1] = MA_array

        print_chart(database, [''], '', 'Total Number', 2, ['green'], run_folder, "fountains_yield_jets_res_1", data_type='-', dpi='high')

    # Print MRS standard deviation charts if we want
    if print_MRS_std_charts == 1 and print_end_of_round_charts == 1:        

        for res_1 in np.arange(num_res_founts):
            for res_2 in np.arange(num_res_founts):
                if res_1 != res_2:
    
                    MRS_STD_database = [np.arange(rounds)]
    
                    for i in [0, 1]:
    
                        MRS_STD_database.append(dbs.MRS_STDs_array[res_1][res_2][i])
    
                        colors = ['black', 'blue']
                        line_width = 2
                        labels_array = ['MRS Standard Dev Before Trading', 'MRS Standard Dev After Trading']
                        title = 'Standard Deviations of MRS (Res %s vs Res %s): Before and After Trading' % (res_1, res_2)
                        y_axis_label = 'STD'
    
                    print_chart(MRS_STD_database, labels_array, title, y_axis_label, line_width, colors, run_folder, "time_series of MRS STDs - Res %s vs Res %s" % (res_1, res_2), data_type='-', dpi='low')

    # generate and print charts showing agents' threshold probabilities and observed actual transating probabilities
#    agent.thresh_probs_array[1][day] = threshold_0_to_1
#    agent.thresh_probs_array[2][day] = threshold_1_to_0
#    agent.thresh_probs_array[3][day] = agent.trade_proby
#    agent.thresh_probs_array[4][day] = agent.detect_skills_array[0][0]
#    agent.thresh_probs_array[5][day] = agent.detect_skills_array[0][1]
#    agent.thresh_probs_array[6][day] = 1 / agent.wkg_prices_memory[0][1]
#    agent.thresh_probs_array[7][day] = 1 / agent.wkg_prices_memory[1][0]

    ref_point = 0

    # we want to look at all alive and dead agents
    if print_fine_dets == 1:
        print('agent_population.pop =', agent_population.pop)
        print('agent_population.dead_agent_array =', agent_population.dead_agent_array)    

    # lump agents (alive and dead) in to a single array, which we will iterate over
    all_agents_array = []

    for agent in agent_population.pop:

        all_agents_array.append(agent)

#    for agent in agent_population.dead_agent_array:
#
#        all_agents_array.append(agent)

    if print_fine_dets == 1:
        print('\n all_agents_array =', all_agents_array)   

    if print_end_of_round_charts == 1:

        for agent_num in range(len(all_agents_array)):
    
    #        print('\n\n agent.thresh_probs_array:\n\n', agent.thresh_probs_array)
    
            agent = all_agents_array[agent_num]
    
            end_chart_date = np.min([agent.death_date, rounds])
    
    #        print('\n agent:', agent, 'birth =', agent.birth_date, 'death =', agent.death_date, 'end_chart_date =', end_chart_date)
    
            # smooth the `ctual probs (5 rounds moving average)
    
            # remove the higher threshold and prices
            if agent.thresh_probs_array[4][end_chart_date - 1] > agent.thresh_probs_array[5][end_chart_date - 1]:
    
                agent.thresh_probs_array = np.delete(agent.thresh_probs_array, [2, 6, 7], 0)    # [2, 5, 7]
    
                name_low_det = 'skill_0'
                name_low_thresh = 'threshold_0_to_1'
                name_price = 'price of resource 0'
    
                names_array = ['Probability Threshold', 'Expected Probability', 'High Detection Probability', 'Low Detection Probability']
    
            else:
    
                agent.thresh_probs_array = np.delete(agent.thresh_probs_array, [1, 6, 7], 0)    # [1, 4, 6]
    
                name_low_det = 'skill_1'
                name_low_thresh = 'threshold_1_to_0'
                name_price = 'price of resource 1'
    
                names_array = ['Probability Threshold', 'Expected Probability', 'Low Detection Probability', 'High Detection Probability']
    
    #        print('\n\n agent.birth_date:', agent.birth_date)
    
            # now chop in the other axis - from the day after birth to death (or end)
            if agent.birth_date == 0:
    
                agent.thresh_probs_array = agent.thresh_probs_array[:, 0:end_chart_date]
    
            else:
    
                agent.thresh_probs_array = agent.thresh_probs_array[:, agent.birth_date + 1:end_chart_date]
    
    #        print('\n\nlen(agent.thresh_probs_array[0])', len(agent.thresh_probs_array[0]))
    #        print('\n\n NEW agent.thresh_probs_array:', agent.thresh_probs_array)
    
            if len(agent.thresh_probs_array[0]) > 0:
    
                # if it's a full sim, print first 200 rounds with daily data (no moving average)
                if len(agent.thresh_probs_array[0]) > 200:
        
                    print_chart(agent.thresh_probs_array[:, :200], names_array, '', 'Probability', 2, ['red', 'black', 'blue', 'green'], run_folder, "thresh_probs_agent_%d" % (agent_num), data_type='-', dpi='low')
    
        #            # create two temporary arrays to store new data
        #            mov_ag_array_act = np.zeros(shape=(len(agent.thresh_probs_array[0])))
        #            mov_ag_array_thresh = np.zeros(shape=(len(agent.thresh_probs_array[0])))
            
                    # set the number of moving average days
                    mov_av_days = mov_av_days_threshold_chart
    
                    mov_ag_array_thresh = generate_MA_array(agent.thresh_probs_array[1], mov_av_days)
                    mov_ag_array_act = generate_MA_array(agent.thresh_probs_array[2], mov_av_days)
            
    #                print('\n\n mov_ag_array_thresh =', mov_ag_array_thresh)
    #                print('\n\n mov_ag_array_act =', mov_ag_array_act)
        
        #            # rest of the cells
        #            for day in range(1, len(agent.thresh_probs_array[0])):
        #    
        #                start_day = np.max([0, day - mov_av_days])
        #    
        #                mov_ag_array_thresh[day] = np.mean(agent.thresh_probs_array[1][start_day:day])    
        #                mov_ag_array_act[day] = np.mean(agent.thresh_probs_array[2][start_day:day])
            
                    # replace old data with temp data
                    agent.thresh_probs_array[1] = copy.copy(mov_ag_array_thresh)
                    agent.thresh_probs_array[2] = copy.copy(mov_ag_array_act)
    
                    if print_fine_dets == 1:
            
                        print('\n\n agent', agent_num)
                        print('\n agent.thresh_probs_array =', agent.thresh_probs_array)
        
                    if agent.birth_date == 0 and popn_ch == 'vary':
        
                        print_chart(agent.thresh_probs_array, names_array, '', 'Probability', 2, ['red', 'black', 'blue', 'green'], run_folder, "thresh_probs_agent_%d" % (agent_num), data_type='-', dpi='high')
        
                    else:
        
                        print_chart(agent.thresh_probs_array, names_array, '', 'Probability', 2, ['red', 'black', 'blue', 'green'], run_folder, "thresh_probs_agent_%d" % (agent_num), data_type='-', dpi='low')

#        input("Press Enter to continue...")

    # Here we question how quickly the market emerged, if there was one
    num_rounds_mov_av = 20
    for res in range(num_res_founts):

#        print('\n\n\n res =', res)

        for day in range(num_rounds_mov_av, rounds - 1):

            mov_av = np.mean(dbs.net_turnover_prop[day - num_rounds_mov_av + 1:day + 1][res])       # rounds x res

#            print('day = ', day, 'mov_av =', mov_av)

            if dbs.mkt_emerged_round[0] == 0 and mov_av > 0.9:

                dbs.mkt_emerged_round[0] = day

            if dbs.mkt_emerged_round[1] == 0 and mov_av > 0.95:

                dbs.mkt_emerged_round[1] = day

            if dbs.mkt_emerged_round[2] == 0 and mov_av > 0.99:

                dbs.mkt_emerged_round[2] = day

    # print home locations again if agent_homes='random' (will be different at the end)
    # create an array to record the locations
    if day == rounds - 1:

        homes_array = np.zeros(shape=(dimen, dimen))

        if day == rounds - 1:

            dpi = 'high'

        else:

            dpi = 'low'

        for agent in agent_population.pop:
    
            x_coord = int(agent.home[0])
            y_coord = int(agent.home[1])
    
            homes_array[x_coord][y_coord] += 1
    
#        # now illustrate homes_array via a heatmap if we're printing charts
#        if print_charts == 1 and print_end_of_round_charts == 1:
    
        create_heat_map(dimen, homes_array, run_folder, 'Greys', '', "agent_homes_end", dpi)

    # present charts for habituation and RL data
    if habit_val > 0.0:

        agent_num = 0
        for agent in list(agent_population.pop) + agent_population.dead_agent_array:

            # first, find dominant market in agent's memories
            highest_weight = 0
            highest_weight_loc = None

            for location in agent.locations_weights_hist_dict:

                weight = agent.locations_weights_hist_dict[location][0][-1] + agent.locations_weights_hist_dict[location][1][-1]

                if weight > highest_weight:
                    highest_weight = weight
                    highest_weight_loc = location

                # print('\n agent.home =', agent.home, 'location', location, 'weight =', weight,
                #       'o/w RL =', agent.locations_weights_hist_dict[location][0][-1], 'o/w Hab =', agent.locations_weights_hist_dict[location][1][-1])

            # print('\n highest_weight_loc=', highest_weight_loc)

            if highest_weight_loc != None:

                RL_data = agent.locations_weights_hist_dict[highest_weight_loc][0]
                Hab_data = agent.locations_weights_hist_dict[highest_weight_loc][1]

                # useful piece of data: when was the highest_weight_loc the only location ever visited?
                first_round_solo = copy.copy(rounds)

                for i in range(1, rounds):

                    # count backwards
                    i *= -1

                    sum_rest = 0

                    if sum_rest == 0:

                        for location in agent.locations_weights_hist_dict:

                            if location != highest_weight_loc:

                                sum_rest += agent.locations_weights_hist_dict[location][1][i]

                        if sum_rest == 0:
                            first_round_solo = rounds + i

                # print('\n first_round_solo =', first_round_solo)

                # change hab data to cumulative (RL is already cumulative albeit with memory decay).
                if habit_deteriorates:

                    Hab_data_history = copy.copy(Hab_data)

                    # print('\n Hab_data_history:', Hab_data_history)

                    for d in range(1, rounds):

                        # print(' Hab_data[d] =', Hab_data[d], 'Hab_data[d - 1]', Hab_data[d - 1])

                        Hab_data[d] += Hab_data[d - 1] * (1 - memory_decay_rate)

                    # print('\n resulting Hab_data:', Hab_data)

                else:

                    for d in range(1, rounds):
                        Hab_data[d] += Hab_data[d - 1]

                chart_data = [list(range(rounds)), [[RL_data, Hab_data]]]
                file_name = 'habituation_contrs_ag_%d' % agent_num

                if agent_num < len(agent_population.pop):
                    file_name += '_alive'
                else:
                    file_name += '_dead'

                file_name += '_solo_from_%d' % first_round_solo

                # print('\n chart_data =', chart_data)

                print_contributions_to_tot_2_axes(database=chart_data, axis_labels=['Rounds', 'Weight'], labels_array=['RL', 'Habituation'], line_width=3, colors=['blue', 'red'], data_folder=run_folder, filename=file_name, show_legend=False, font_size=40, special_data=None)

            agent_num += 1

            # pause()

    # Here we run a function which processes all the information we want to return in the run_sim() function
    sim_return_data = write_success_data(params, agent_population, dbs, print_dets, print_fine_dets, run_folder, rounds, fountain_population, for_spec_db1, for_spec_means, agent_res_init, cluster_lag, town_grid,\
                                         for_strat_parts, printed_segment_size, allow_Keynes_Inst, KO_pop, constitutional_voting, constitutional_exp, num_experiments, respect_property_rights, file_type, black_shoop_exp,
                                         fight_skill, two_tribes)

#    print("\n\n iterations data\n\n")
#    for day in range(rounds):
#
#        print("num_iters = ", dbs.opt_iters_record[day], "time = ", dbs.opt_time_record[day])
#
#    print("\n mean num_iters = ", np.mean(dbs.opt_iters_record), "mean time = ", np.mean(dbs.opt_time_record))

        # # chart for first 500 rounds
        # if rounds >= 500:
        #
        #     trgt_loc_db = [list(np.arange(500))]
        #
        #     for loc in dbs.grid_trgt_hist_dict:
        #         trgt_loc_db.append(list(dbs.grid_trgt_hist_dict[loc][:500]))
        #
        #     print_chart(database=trgt_loc_db, labels_array=trgt_dict_keys, title='', y_axis_label='Number of Agents',
        #                 line_width=2, colors=colors, data_folder=run_folder, filename='lcos_visited_500', data_type='-',
        #                 dpi='high')
        #
        # # chart for first 200 rounds
        # if rounds >= 200:
        #
        #     trgt_loc_db = [list(np.arange(200))]
        #
        #     for loc in dbs.grid_trgt_hist_dict:
        #         trgt_loc_db.append(list(dbs.grid_trgt_hist_dict[loc][:200]))
        #
        #     print_chart(database=trgt_loc_db, labels_array=trgt_dict_keys, title='', y_axis_label='Number of Agents',
        #                 line_width=2, colors=colors, data_folder=run_folder, filename='lcos_visited_200', data_type='-',
        #                 dpi='high')
        #
        # # chart for first 100 rounds
        # if rounds >= 100:
        #
        #     trgt_loc_db = [list(np.arange(100))]
        #
        #     for loc in dbs.grid_trgt_hist_dict:
        #         trgt_loc_db.append(list(dbs.grid_trgt_hist_dict[loc][:100]))
        #
        #     print_chart(database=trgt_loc_db, labels_array=trgt_dict_keys, title='', y_axis_label='Number of Agents',
        #                 line_width=2, colors=colors, data_folder=run_folder, filename='lcos_visited_100', data_type='-',
        #                 dpi='high')
        #
        # # chart for first 50 rounds
        # if rounds >= 50:
        #
        #     trgt_loc_db = [list(np.arange(50))]
        #
        #     for loc in dbs.grid_trgt_hist_dict:
        #         trgt_loc_db.append(list(dbs.grid_trgt_hist_dict[loc][:50]))
        #
        #     print_chart(database=trgt_loc_db, labels_array=trgt_dict_keys, title='', y_axis_label='Number of Agents',
        #                 line_width=2, colors=colors, data_folder=run_folder, filename='lcos_visited_50', data_type='-',
        #                 dpi='high')

    # if we are recording times:
    if calc_timings:

        print('\n\n\n\n TIMINGS')

        total_time = dt.DateTime() - start_time

        print('\n Total time =', total_time)

        print('\n overheads: ', dbs.timings_dict['overheads'])

        for entry in ['foraging', 'trading', 'trading_overhead', 'trading_move_overhead', 'trading_move_agent_mtt', 'trading_move_agent_eval_own_grid_sq', 'trading_move_agent_eval_exp_gains_own_square', 'trading_move_agent_agents_interact',\
                      'trading_move_agent_eval_all_grid_sqs', 'trading_move_agent_retargetting', 'trading_move_agent_bilat_eval', 'three_updates', 'comms', 'for_strats', 'new_births']:

            total_time_entry = dt.timedelta(0, 0, 0)

            for day_entry in dbs.timings_dict[entry]:
                total_time_entry += day_entry

            mean_time_delta = total_time_entry / len(dbs.timings_dict[entry])

            years, days, hours, minutes, seconds = length_of_time(mean_time_delta)

            print('\n', entry, 'mean time =', hours, 'hours', minutes, 'minutes', seconds, 'seconds')

        print('\n\n')

        for day in range(rounds):

            print(' day ', day, 'trading time =', dbs.timings_dict['trading'][day], 'comms time =', dbs.timings_dict['comms'][day], 'proportion comms / trading', dbs.timings_dict['comms'][day] / dbs.timings_dict['trading'][day])

        print('\n\n')

    return sim_return_data

def create_new_agent(dbs, birth_date, for_strat_parts, agent_res_init, agent_res_init_std,
                     print_dets, vision_len, dimen, print_fine_dets, rounds, trade_moves,
                     trade_when_trgt, agent_mem_length, cp_trans_weight, wait_at_tgt_moves, trade_prices, cognition_factor, trade_movemnt, starting_res,
                     start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                     prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, starting_props, instantiation, tribe, fight_skill,
                     agents_die_old_age, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, popn_ch):

    """A method for creating a new agent."""

    # create a death_date to record the date when the agent died - default is 100,000, which changes if agent dies
    death_date = 100000

    # create an array to record foraging strategy array for each agents:
    for_strat_array = np.zeros(shape=(1, for_strat_parts), dtype=int)

    # now populate the for_strat_array with the various strategies open to
    # the agents.  Note 0 means agent is at fountain 0 (and so on).
    for j in np.arange(for_strat_parts):
        for_strat_array[0][j] = np.random.randint(0, num_res_founts)

    # create array to record agents' personal resource levels:
    if trade_prices == 'fixed':

        agent_res_array = []

        for res in range(num_res_founts):
            res_value = int(np.max([1, random.normalvariate(agent_res_init, agent_res_init_std)]))

            agent_res_array.append(res_value)

        agent_res_array = np.array([agent_res_array], dtype=int)

    elif trade_prices == 'variable':

        if instantiation == 0 and popn_ch == 'vary':

            agent_res_array = starting_res

        #                if starting_res is not None:
        #
        #                    print('new agent (not at instantiation) agent_res_array =', agent_res_array)

        else:

            agent_res_array = []

            for res in range(num_res_founts):
                res_value = np.max([1, random.normalvariate(agent_res_init, agent_res_init_std)])

                agent_res_array.append(res_value)

            agent_res_array = np.array([agent_res_array], dtype=float)

    #        print 'agent_res_array =', agent_res_array

    # create detection skills array:
    detect_skills_array = np.array([[prob_res_detection] * num_res_founts], dtype=float)

    # Create an array to record the history of detection skills
    detect_skills_array_hist = np.zeros(shape=(rounds, num_res_founts))

    # create basket array to record the resources collected by each agent:
    if trade_prices == 'fixed':
        basket_array = np.zeros(shape=(1, num_res_founts), dtype=int)

    if trade_prices == 'variable':
        basket_array = np.zeros(shape=(1, num_res_founts), dtype=float)

    # create a location array for each agent: this is used to track where the agent is when trying to trade
    location = [0, 0]

    # create a value for the agent's vision (the number of squares away it can see in the town_grid)
    agent_vision = vision_len

    # now create a matrix which will allow the agent to record the locations of where particular sell / buy combinations
    # were transacted
    trans_loc_mat = []
    twod_array = []
    row = []
    for k in np.arange(num_res_founts):
        row.append([])
    for l in np.arange(num_res_founts):
        twod_array.append(copy.deepcopy(row))
    for j in np.arange(rounds):
        trans_loc_mat.append(copy.deepcopy(twod_array))

    # create two arrays to record which resources each agent has on sale
    sell_array = []
    buy_array = []

    # create an array to record the agent's grid target, which it aims for in the absence of other agents
    if trade_when_trgt == 0:

        grid_trgt = np.array([1000, 1000], dtype=int)

    elif trade_when_trgt == 1:

        # I have to set grid_trgt like this because the interpreter won't accept [None, None], dtype=int...
        grid_trgt = np.array([random.randint(0, dimen - 1), random.randint(0, dimen - 1)], dtype=int)

    # create an array to record the resources an agent wants to buy and sell
    if trade_prices == 'fixed':
        trading_basket = np.zeros(shape=(1, num_res_founts), dtype=int)

    if trade_prices == 'variable':
        trading_basket = np.zeros(shape=(1, num_res_founts), dtype=float)

    # allocate a place on the town grid to the agent as its home
    home = np.array([np.random.randint(0, dimen), np.random.randint(0, dimen)], dtype=int)

    # create an array to record the agent's neighbours (updated at the beginning of every round)
    neighs = []

    # create an array to record the number of goods an agent takes to market each round
    goods_2_mkt = np.zeros(shape=(1, rounds))

    # create a variable to record the agent's expectation of trading (given neighbours' trading)
    trade_proby = 0.0

    # create an array to record the agent's locations during the trading rounds
    trade_loc_rec = []

    # create another array to record the agent's target locations during the trade_moves
    trgt_loc_rec = []

    # create a variable to track whether the agent can trade or not e.g. when it has reached the target
    can_trade = 1

    # create an array to record each agent's transactions
    ag_trans_array = []

    # create array to record which sell_good the agent chose to aim for in selecting a target grid location
    sell_good = 0

    # create array to record which buy_good the agent chose to aim for in selecting a target grid location
    buy_good = 0

    # create an array to record the agent's memory of locations
    loc_mems_array = []
    loc_mems_array_cp = []
    #        twod_array = []
    #        row = []
    #        for k in np.arange(num_res_founts):
    #            row.append([])
    #        for l in np.arange(num_res_founts):
    #            twod_array.append(copy.deepcopy(row))
    for j in np.arange(rounds):
        loc_mems_array.append([])
        loc_mems_array_cp.append([])

    #        loc_mems_array_cp = copy.deepcopy(loc_mems_array)

    # Create a variable which records the threshold probability above which the agent will specialise in each round
    # [0] is round [1] is max detection prob, [2] is r_min, [3] is threshold prob, and [4] is actual exp prob of transacting
    thresh_probs_array = np.zeros(shape=(8, rounds))
    thresh_probs_array[0] = np.arange(rounds)

    # Create varable which acknowledges if an agent trading on the way to its target has reached the target (= 1 then)
    reached_trgt = 0

    # Create an array to record the marginal rates of substitution for each agent
    MRS_array = np.zeros(shape=(num_res_founts, num_res_founts))

    # create array to record the total resource held by an agents (agent_res_array + basket_array)
    aggr_res_array = np.zeros(shape=(1, num_res_founts), dtype=int)

    dummy_basket_array = np.zeros(shape=(num_res_founts, num_res_founts, num_res_founts))

    # Create an array to record the agent's foraging strategy history
    for_strat_hist = np.zeros(shape=(rounds, for_strat_parts))

    # Create arrays to record basket_arrays and basket_array_starts
    basket_array_hist = np.zeros(shape=(rounds, num_res_founts))

    basket_array_start_hist = np.zeros(shape=(rounds, num_res_founts))

    # Create an array to record the agent's expected supply / demand of bilateral trades at the equilibrium prices.
    # [0] is the equilibrium price, [1] is the expected supply or demand of res_1 (supply of res_1 would be a positive
    # number and demand for res_1 would be negative), [2] is the counterpart expected supply or demand of res_2 (supply
    # of res_2 would be a negative number and supply of res_2 would be negative) i.e. noth positive means supply of res_1
    # and demand for res_2.
    equil_price_SD_exps = np.zeros(shape=(rounds, num_res_founts, num_res_founts, 3))

    # Create an array to record the number of actual transaction in each round - every time the agent transacts,
    # add 1 to this total
    num_act_transs = np.zeros(shape=(rounds))

    # Create a database to record the agent's MRS history
    MRS_history = np.zeros(shape=(rounds, num_res_founts, num_res_founts))

    # create array to record agents' personal resource levels:
    if trade_prices == 'fixed':
        agent_res_array_hist = np.zeros(shape=(rounds, num_res_founts), dtype=int)

    elif trade_prices == 'variable':
        agent_res_array_hist = np.zeros(shape=(rounds, num_res_founts), dtype=float)

    optimal_transs_systemic = np.zeros(shape=(rounds, num_res_founts), dtype=float)

    optimal_transs_local = np.zeros(shape=(rounds, num_res_founts), dtype=float)

    wkg_prices_memory = np.ones(shape=(num_res_founts, num_res_founts), dtype=float)

    personal_turnover_ratio = np.zeros(shape=(rounds))

    total_actual_agent_sales = np.zeros(shape=(rounds))

    total_optimal_agent_sales = np.zeros(shape=(rounds))

    over_sell_counter = 0
    didnt_over_sell_counter = 0

    foraging_strat_data = np.zeros(shape=(rounds, (3 + num_res_founts * 2)))

    resources_to_children = np.zeros(shape=num_res_founts)

    hist_trade_loc_rec = [[] for i in range(rounds)]

    # create propensities to steal and fight back in interactions
    if start_props == 'random':

        prop_steal = random.random()
        prop_fight_back = random.random()

    else:

        if starting_props == None:

            prop_steal = random.normalvariate(start_prop_steal_mean, start_prop_steal_std)

            # note we constrain these values but not at the limits of 0 and 1 - if we use either of these limits, the props will be pefectly stuck there
            if prop_steal > prop_steal_ceil:
                prop_steal = prop_steal_ceil

            if prop_steal < prop_steal_floor:
                prop_steal = prop_steal_floor

            prop_fight_back = random.normalvariate(start_prop_fight_back_mean, start_prop_fight_back_std)

            # note we constrain these values but not at the limits of 0 and 1 - if we use either of these limits, the props will be pefectly stuck there
            if prop_fight_back > prop_fight_back_ceil:
                prop_fight_back = prop_fight_back_ceil

            if prop_fight_back < prop_fight_back_floor:
                prop_fight_back = prop_fight_back_floor

        else:

            prop_steal = starting_props[0]
            prop_fight_back = starting_props[1]

    if fix_prop_fb == 0:
        prop_fight_back = 0.0

    if fixed_prop_steal == 1.0:
        prop_steal = 1.0
        prop_fight_back = 1.0

    if fix_ps_fb_0 == 1:
        prop_steal = 0.0
        prop_fight_back = 0.0

    # create a dictionary to record reputations of other agents
    reputations_dict = dict()

    # create array to record the fights the agent was involved in during that last round
    fights_array = []

    loc_fights_array = [[] for i in range(rounds)]

    loc_fights_array_cp = [[] for i in range(rounds)]

    prop_steal_history = np.zeros(shape=rounds)
    prop_fight_back_history = np.zeros(shape=rounds)
    fight_skill_history = np.zeros(shape=rounds)

    agreed_meeting_point = None
    meeting_point_cps = []

    # create agent instances:
    new_agent = Agent(birth_date, death_date, for_strat_array, agent_res_array, detect_skills_array, basket_array,
                      location, agent_vision, grid_trgt, trading_basket,
                      home, neighs, goods_2_mkt, trade_proby,
                      trans_loc_mat, trade_loc_rec, trgt_loc_rec, sell_array, buy_array, can_trade, ag_trans_array,
                      sell_good, buy_good, loc_mems_array, loc_mems_array_cp, thresh_probs_array, agent_mem_length,
                      cp_trans_weight, wait_at_tgt_moves, reached_trgt, MRS_array,
                      aggr_res_array, dummy_basket_array, for_strat_hist,
                      equil_price_SD_exps, num_act_transs, MRS_history, agent_res_array_hist,
                      detect_skills_array_hist, optimal_transs_systemic, optimal_transs_local, wkg_prices_memory,
                      personal_turnover_ratio, basket_array_hist, basket_array_start_hist, total_actual_agent_sales,
                      total_optimal_agent_sales, cognition_factor, over_sell_counter, didnt_over_sell_counter, trade_movemnt,
                      foraging_strat_data, resources_to_children, hist_trade_loc_rec,
                      prop_steal, prop_fight_back, reputations_dict, fights_array, loc_fights_array, loc_fights_array_cp,
                      prop_steal_history, prop_fight_back_history, agreed_meeting_point, meeting_point_cps, tribe, fight_skill,
                      agents_die_old_age, fight_skill_history)

    # record the birth date in this database
    dbs.birth_dates.append(birth_date)

    return new_agent


def create_agents(dbs, print_dets, for_strat_parts, agent_res_init, agent_res_init_std,
                  vision_len, dimen, print_fine_dets, rounds, trade_moves, trade_when_trgt, agent_homes, agent_mem_length, homes_spacing,
                  cp_trans_weight, wait_at_tgt_moves, trade_prices, min_trans_Q, cognition_factor, trade_movemnt,
                  start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                  prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, two_tribes, black_shoop_exp, fight_skill,
                  agents_die_old_age, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, stranger_int, corruption_prop_charge, popn_ch, must_update_neighs):
    """This function generates and returns an agent population instance with 'num_agents' agents in it."""

    #    print_fine_dets = 1

    if print_dets == 1:
        print('\n** create_agents function starts ** \n')

    # set the birth_date of all these new agents (note this function is only used awhen the agent population is instantiated)
    birth_date = 0

    # establish an array which will contain all the new agents, which will be
    # placed in to a popultion class (this class is then returned):
    group = []

    starting_res = None
    starting_props = None

    # add agents to the group:
    for i in np.arange(num_agents):  # each agent

        instantiation = 1

        agent_tribe = 'none'

        if two_tribes == 1 and i < num_agents / 2.0:

            agent_tribe = 'sharks'

        elif two_tribes == 1 and i >= num_agents / 2.0:

            agent_tribe = 'jets'

        # create agent instances (hone locations are random here):
        agent = create_new_agent(dbs, birth_date, for_strat_parts, agent_res_init, agent_res_init_std,
                                 print_dets, vision_len, dimen, print_fine_dets, rounds,
                                 trade_moves, trade_when_trgt, agent_mem_length, cp_trans_weight, wait_at_tgt_moves,
                                 trade_prices, cognition_factor, trade_movemnt, starting_res,
                                 start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                                 prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, starting_props, instantiation,
                                 agent_tribe, fight_skill, agents_die_old_age, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, popn_ch)

        # add agents to the group of agents:
        group.append(agent)

    homes_array = np.zeros(shape=(dimen, dimen))

    if two_tribes == 0 and agent_homes == 'even':  # then we have to distribute the agents over the town_grid evenly.  The function
        # 'create_agents' puts them in random locations by default so here we change that.

        if dimen % math.sqrt(num_agents) == 0:  # then this is a neat case and we can space the agents evenly around the grid

            # find the gap between agents:
            neigh_gap = float(dimen) / int(math.sqrt(num_agents))
            half_gap = int(neigh_gap / 2.0)

            for i in np.arange(int(math.sqrt(num_agents))):
                for j in np.arange(int(math.sqrt(num_agents))):

                    agent = group[i * int(math.sqrt(num_agents)) + j]

                    if homes_spacing == 'square':

                        agent.home = np.array([half_gap + (i * neigh_gap), half_gap + (j * neigh_gap)], dtype=int)

                    elif homes_spacing == 'hex':

                        if i % 2 == 0:

                            agent.home = np.array([half_gap + (i * neigh_gap), half_gap + (j * neigh_gap)], dtype=int)

                        else:

                            agent.home = np.array([half_gap + (i * neigh_gap), (j * neigh_gap)], dtype=int)

                    homes_array[agent.home[0]][agent.home[1]] += 1

    if two_tribes == 1:

        sub_dimen = dimen / 2.0

        # find the gap between agents:
        neigh_gap = float(sub_dimen) / int(math.sqrt(num_agents / 2.0))
        half_gap = int(neigh_gap / 2.0)

        for h in range(2):
            for i in np.arange(int(math.sqrt(num_agents / 2.0))):
                for j in np.arange(int(math.sqrt(num_agents / 2.0))):
                    agent = group[int(h * num_agents / 2.0) + (i * int(math.sqrt(num_agents / 2.0))) + j]

                    agent.home = np.array([(h * sub_dimen) + half_gap + (i * neigh_gap), (h * sub_dimen) + half_gap + (j * neigh_gap)], dtype=int)

    # this group is placed in a population instance:
    agent_population = Agent_Population(group, trade_prices, min_trans_Q, homes_array, for_strat_parts, black_shoop_exp, stranger_int, corruption_prop_charge, must_update_neighs)

    if print_dets == 1:
        print('\n** create_agents function ends **\n')

    # the population instance is returned
    return agent_population


def create_fountains(agent_population, print_dets, init_res_level, rounds, dimen, trade_loc, two_tribes, initial_fount_stock_high, single_tribe):
    """This function generates and returns an instance of a population of resource foutains with num_fountains in it."""

    if print_dets == 1:
        print('\n** create_fountains function starts **\n')

    # establish an array which will contain all the new foutains, which will be
    # placed in to a popultion class (this class is then returned):
    group = np.array([])

    if two_tribes == 0:

        # add agents to the group:
        for i in np.arange(num_res_founts):  # each fountain

            if single_tribe and i == 1:

                fountain = Fountain(initial_fount_stock_high, dimen, trade_loc, rounds, tribe='none')

            else:

                fountain = Fountain(init_res_level, dimen, trade_loc, rounds, tribe='none')

            # add foutain to the group of agents:
            group = np.append(group, fountain)

    elif two_tribes == 1:

        # then we create 4 fountains - we put 0 and 1 in to pop_1, 2 and 3 in to pop_2, and all in to pop

        # note that fountain 0 has more than fountain 1 (initial_fount_stock_high)
        fountain_0 = Fountain(initial_fount_stock_high, dimen, trade_loc, rounds, tribe='sharks')

        # add foutain to the group of agents:
        group = np.append(group, fountain_0)

        fountain_1 = Fountain(init_res_level, dimen, trade_loc, rounds, tribe='sharks')

        # add fountain to the group of agents:
        group = np.append(group, fountain_1)

        # foutain 3 has more than fountain 2
        fountain_2 = Fountain(init_res_level, dimen, trade_loc, rounds, tribe='jets')

        # add foutain to the group of agents:
        group = np.append(group, fountain_2)

        fountain_3 = Fountain(initial_fount_stock_high, dimen, trade_loc, rounds, tribe='jets')

        # add foutain to the group of agents:
        group = np.append(group, fountain_3)

    fountain_pop = Resource_Fountain_Population(group, two_tribes)

    if print_dets == 1:
        print('\n** create_fountains function ends **\n')

    return fountain_pop


def agents_forage(round, for_strat_parts, print_dets, print_fine_dets, agent_population, fountain_pop, dbs, print_for, two_tribes, tribe):
    """This function manages the foraging process"""

    if print_for:
        print_dets = print_fine_dets = 1

    if print_fine_dets == 1:
        print('\n tribe =', tribe)

    #    if round % 10 == 0:
    #
    #        print_dets = print_fine_dets = 1

    # we need to create four arrays to record which agents are at each fountain in each time slot every day:
    # fount_visits_array and fount_visits_agents_metaarray are created up front and agents_at_all_founts_array and
    # agents_at_fount_array are created within iteration loops

    # this array simply records the number of agents at each fountain in each time slot:
    fount_visits_array = np.zeros(shape=(for_strat_parts, num_res_founts))

    # this array is the same but instead of the number of agents in each cell, it contains an array of the agents at each
    # fountain at each time slot
    fount_visits_agents_metaarray = []

    if print_dets == 1:
        print('\n number of agents at start =', len(agent_population.pop), '\n')

    # now count the number of agents in each fountain in each time
    # slot and update fount_visits_array:

    for l in np.arange(for_strat_parts):

        if print_fine_dets == 1:
            print('\ntime slot (l) =', l)

        # this array records all of the agents at all fountains in a single time slot
        agents_at_all_founts_array = []

        for m in np.arange(num_res_founts):

            if print_fine_dets == 1:
                print('\nfountain (m) =', m, '\n')

            # create a counter to record agent numbers
            visit_counter = 0

            # create array to record agents at single fountains in each time slot
            agents_at_fount_array = np.array([])

            for agent in agent_population.pop:
                #                    print 'agent =', agent
                #                    print 'agent_population.pop[agent] =', agent_population.pop[agent]
                if two_tribes == 0 and agent.for_strat_array[0][l] == m:  # i.e. agent is at this specific fountain at
                    # this time of the day
                    #                    visit_counter += 1
                    agents_at_fount_array = np.append(agents_at_fount_array, agent)

                elif two_tribes == 1 and agent.tribe == tribe and agent.for_strat_array[0][l] == m:

                    agents_at_fount_array = np.append(agents_at_fount_array, agent)

            # add data to founts_db to record the number of agents at each fountain in each time slot
            visit_counter = len(agents_at_fount_array)
            dbs.founts_db[(num_res_founts * l) + m + 1][round] = visit_counter

            # shuffle these agents (useful below) so in effect they arrive at a fountain in a queue:
            np.random.shuffle(agents_at_fount_array)

            if print_fine_dets == 1:
                print('\nagents_at_fount_array =', agents_at_fount_array)

            agents_at_all_founts_array.append(agents_at_fount_array)
            # problem of arrays merging!!

            fount_visits_array[l][m] = visit_counter

        if print_fine_dets == 1:
            print('\nagents_at_all_founts_array =', agents_at_all_founts_array)

        fount_visits_agents_metaarray.append(agents_at_all_founts_array)

    if print_dets == 1:
        print('\n\nfount_visits_agents_metaarray =', fount_visits_agents_metaarray, '\n\n')

    # by this point we have established which agents are at which fountain in every time slot so we can move on to
    # determine which agents harvest which resources (and put these resources in their 'basket').

    # whether an agent finds a resource during a time slot depends on two factors: (i) their detection skill
    # (given in detect_skills_array); and (ii) the amount of resources remaining at the site.  An equation is used to
    # determine whether an agent detects the resource -> q = pi * L / res_index where pi is the skill level (e.g. 0.3),
    # L is the level of resource remaining, and res_index is a parameter.  For example, if pi = 0.3, L = 65, and
    # res_index = 200 then q = 0.3 * (65 / 200) = 0.0975.  We then take a random number generated (between 0 and 1) and
    # if this is below 0.0975 then the agent detects the resource (L then declines by 1).

    # for our tracking agent, we want to record the level of resources collected before trading

    agent_population.tracking_agent.add_tracking_agent_data()

    if print_dets == 1:
        print('\nForaging now starts\n')

    # there are 'for_strat_part' time slots in the day and we need to iterate over these slots:
    for slot in np.arange(for_strat_parts):

        for fount in np.arange(num_res_founts):

            # the agents have already been randomised: at each fountain they line up in a queue so that each agent
            # will attempt to forrage in order

            # record the level of resources at this fountain
            if two_tribes == 0:

                dbs.res_level_array[slot][fount] = fountain_pop[fount].res_level

            elif two_tribes == 1:

                if tribe == 'sharks':

                    dbs.res_level_array[slot][fount] = fountain_pop[fount].res_level

                elif tribe == 'jets':

                    dbs.res_level_array[slot][2 + fount] = fountain_pop[fount].res_level

            if print_fine_dets == 1:
                print('\n\n slot', slot, 'fount', fount)

            for agent in fount_visits_agents_metaarray[slot][fount]:

                if print_fine_dets == 1:
                    print('\nagent =', agent, 'for strat', agent.for_strat_array)
                    print('agent.detect_skills_array[0][fount] =', agent.detect_skills_array[0][fount])
                    print('fountain_population.pop[fount].res_level =', fountain_pop[fount].res_level)

                if tribe == 'none' or tribe == 'sharks':

                    fount_num = fount

                elif tribe == 'jets':

                    fount_num = 2 + fount

                fountain_init_level = dbs.init_res_levels[round][fount_num]

                # this is the net detection probability (see equation in notes above)
                q = agent.detect_skills_array[0][fount] * (fountain_pop[fount].res_level / fountain_init_level)

                if print_fine_dets == 1:
                    print('q =', q)

                rand_num = random.random()

                if print_fine_dets == 1:
                    print('rand_num =', rand_num)

                if rand_num < q:  # then the agent has successfully detected the resource

                    if print_fine_dets == 1:
                        print('successful forriaging!')

                    agent.basket_array[0][fount] += 1  # add resource to agent's basket

                    fountain_pop[fount].res_level -= 1  # deduct resource from fountain

                    # for the agent we're tracking,
                    if agent == agent_population.tracking_agent:
                        agent_population.tracking_agent.pre_basket_array[0][fount] += 1

                if print_fine_dets == 1:
                    print('resultant agent.basket_array =', agent.basket_array)

            # record levels of resource foutains at the end of each time slot
            if two_tribes == 0:

                dbs.res_level_array_ends[slot][fount] = fountain_pop[fount].res_level

            elif two_tribes == 1:

                if tribe == 'sharks':

                    dbs.res_level_array_ends[slot][fount] = fountain_pop[fount].res_level

                elif tribe == 'jets':

                    dbs.res_level_array_ends[slot][2 + fount] = fountain_pop[fount].res_level

    if print_dets == 1:
        print('\nForaging has finished\n')

    # now we have to record the amount of resources foraged from each fountain (initial level minus fountain levels at the end of the foraging)
    for e in np.arange(num_res_founts):
        dbs.main_db[4 + e][round] = fountain_pop[e].res_level
        dbs.foutain_levels[e][round] = dbs.fountains_init_levels_hist[e][round] - fountain_pop[e].res_level

    if tribe == 'sharks':
        dbs.res_founts_sharks[0][round] = fountain_pop[0].res_level
        dbs.res_founts_sharks[1][round] = fountain_pop[1].res_level

    if tribe == 'jets':
        dbs.res_founts_jets[0][round] = fountain_pop[0].res_level
        dbs.res_founts_jets[1][round] = fountain_pop[1].res_level

    if print_dets == 1:
        print('\nfount_visits_array =\n', fount_visits_array, '\n')

    if print_fine_dets == 1:

        for ag in agent_population.pop:
            print('\n ag', ag, 'tribe ', ag.tribe, 'basket', ag.basket_array[0])

    if print_fine_dets == 1:
        pause()


def update_neighbours(town_grid, agent_population, local_net_rad, print_dets, print_fine_dets, dimen, tracking_agent, track_agent):

    """This function takes a population of agents and updates each agent's neighbours array.  Note for each agent, its list
    of neighbours includes itself."""

    for agent in agent_population.pop:

        if track_agent and agent == agent_population.tracking_agent:
           print_fine_dets = 1

        else:
            print_fine_dets = 0

        if print_fine_dets == 1:
            print('** updating agents neighbours arrays **')
            print('\n local_net_rad', local_net_rad)
            print('\n\n agent.home', agent.home)

        # wipe the agent's neighs array first
        agent.neighs = []
        for pot_neigh in agent_population.pop:

            # if print_fine_dets == 1:
            #     print('\n\n ** pot_neigh.home', pot_neigh.home)

            if agent is not pot_neigh:

                dist_bw_neighs = abs_dist_on_torus(agent.home, pot_neigh.home, town_grid.dimen)

                # if print_fine_dets == 1:
                #     print(' dist_bw_neighs', dist_bw_neighs)

                if dist_bw_neighs[0] <= local_net_rad and dist_bw_neighs[1] <= local_net_rad:

                    agent.neighs.append(pot_neigh)

                    # if print_fine_dets:
                    #     print(' pot_neigh is a neighbour')

        if print_fine_dets == 1:
            print('\n agent home', agent.home, ': neighbours =\n', agent.neighs)
            print('\n len(neighs) =', len(agent.neighs), '\n')
            pause()


def agents_trading(params, KO_pop, town_grid, agent_population, print_dets, trade_moves, trade_movemnt, vision_len, day,
                   trade_loc, print_fine_dets, tracking_agent, wait_at_target_til_end, wait_at_tgt_moves, track_agent, trgt_sel,
                   dimen, trade_when_trgt, run_folder,
                   print_round_trans, df_daily, dbs, granular_mem, fountain_population, print_move_heat_maps, trade_prices,
                   rounds, gen_equ_thresh, gen_equ_wh_lps, SD_charts_freq, price_mean, force_prices, fixed_price,
                   keynesian_ratio, find_gen_equ_PQ, use_parallel_code, price_grid_dimen, test_par_code, print_plotly_charts,
                   print_MRS_std_charts, const_mkt_opens, ststst, respect_property_rights, adjust_props_r, fight_cost, agent_intn_beta,
                   num_rounds, len_reputations_mem, intn_error_std, agent_avoid_muggers, prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil,
                   prop_fight_back_floor, trade_at_trgt_precise, fight_balance, agree_location, use_original_model_struct, two_tribes,
                   formal_inst, prob_fine, fine, print_agents_interact, fight_skill, fix_ps_fb_0, stranger_int, two_tribes_inst,
                   strat_choice, strangers_if_unknown):

    """A function for managing the process by which agents trade.  The number of transactions is returned and changes are
    made to the agent_population instance, which contains all the agents."""

    if params.calc_timings:
        trading_start_time = dt.DateTime()

        dbs.timings_dict['trading_move_overhead'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_mtt'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_eval_own_grid_sq'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_eval_exp_gains_own_square'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_agents_interact'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_eval_all_grid_sqs'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_retargetting'].append(dt.timedelta(0, 0, 0))
        dbs.timings_dict['trading_move_agent_bilat_eval'].append(dt.timedelta(0, 0, 0))

    marker = 0

    #    for agent in agent_population.pop:
    #        print(' agent home', agent.home, 'basket', agent.basket_array)
    #
    #    pause()

    if print_dets == 1 or (track_agent and track_agent <= day):
        print('\n--- agents now start trading ---')

    print_model_2_dets = 0

    # create a database to record the successful transactions of agents in this round.  Must be a list as np array doesn't work well
    # with variable length arrays
    daily_succ_trans = []

    # same for fights
    daily_fights = []

    # zero some arrays / values: wipe the trading_cps array for the agents
    for agent in dbs.agent_list:

        agent.previous_trgt = []
        agent.trade_loc_rec = []
        agent.trgt_loc_rec = []
        agent.can_trade = 0             # this gets set to 1 below if agent walking randomly or if agent home is its target square
        agent.reached_trgt = 0
        agent.reached_tgt_on_move = 0
        agent.last_transaction = 0
        agent.wait_at_tgt_moves_pro_rata = wait_at_tgt_moves
        agent.ignore_agents_array = []
        agent.agent_last_traded_with = None
        agent.exp_int_gains_dict = dict()
        agent.exp_int_gains_dict_strangers = dict()
        agent.last_intn = None
        agent.exp_rtns_matrix = dict()
        agent.trading_basket = np.zeros(shape=(1, num_res_founts), dtype=float)

    # update dict of whether agents know other agents
    mem_start_day = np.max([0, day - len_reputations_mem])

    for agent in agent_population.pop:

        for cp_agent in agent_population.pop:

            if agent is not cp_agent:

                if (str(cp_agent) in agent.reputations_dict and np.sum(agent.reputations_dict[str(cp_agent)][1][mem_start_day:day]) > 0.0) or str(cp_agent) in agent.last_known_rep_ps_dict:

                    agent.agent_knows_cp_dict[str(cp_agent)] = 1

                else:

                    agent.agent_knows_cp_dict[str(cp_agent)] = 0

                if (str(agent) in cp_agent.reputations_dict and np.sum(cp_agent.reputations_dict[str(agent)][1][mem_start_day:day]) > 0.0) or str(agent) in cp_agent.last_known_rep_ps_dict:

                    cp_agent.agent_knows_cp_dict[str(agent)] = 1

                else:

                    cp_agent.agent_knows_cp_dict[str(agent)] = 0

    # we blank town_grid.grid_agents - this is therecord of where agents are located
    town_grid.grid_agents = []
    row = []
    for k in np.arange(town_grid.dimen):
        row.append([])
    for l in np.arange(town_grid.dimen):
        town_grid.grid_agents.append(copy.deepcopy(row))

    # Before trading, there are two important locations for the agent: where they start from and where they head to.
    # In the code which follows, we set both

    # first, the agents are placed on the town_grid - this function updates the agents' locations arrays. The important
    # variable here is trade_loc, which if == 'home' then agents start from their home location; if == 'random' then they
    # start from a random location in each round.  This function also populates town_grid.grid_accup, which counts how many
    # agents are on each grid square
    town_grid.locate_agents(agent_population, fountain_population, dbs, print_dets, trade_loc)

    # second, the agents choose a target to head towards.  They key variable here is 'trade_movemnt': if 'random' then the
    # target location is chosen randomly; and if 'set' then we use the function 'set_targets' to create a target location for
    # the agents (there are many ways in which that could be done but it uses the agent's databases)
    if trade_movemnt == 'set':

        for agent in dbs.agent_list:

            # locs_array_2, roulette_wheel, gross_pos_locs_array, gross_pos_locs_weights, gross_neg_locs_array, gross_neg_locs_weights =\
            set_agent_target(params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, respect_property_rights, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt, trade_when_trgt,
                             dbs, track_agent, agent, day, town_grid, trgt_sel,
                             trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, ststst, retarg=0, move=0, has_acted=0, print_dets=print_dets, print_fine_dets=print_fine_dets, fight_balance=fight_balance,
                             agree_location=agree_location,
                             adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta, formal_inst=formal_inst, prob_fine=prob_fine, fine=fine, fight_skill=fight_skill, fix_ps_fb_0=fix_ps_fb_0, strat_choice=strat_choice,
                             stranger_int=stranger_int,
                             two_tribes_inst=two_tribes_inst, strangers_if_unknown=strangers_if_unknown)

            # here we add to a database which records which grid squares were targetted by the agents
            # if day == 900:
            #     print(' agent.home:', agent.home, ' agent.grid_trgt:', agent.grid_trgt)

            if agent.grid_trgt[0] is not None:

                if str(agent.grid_trgt) not in dbs.grid_trgt_hist_dict:

                    dbs.grid_trgt_hist_dict[str(agent.grid_trgt)] = np.zeros(rounds)
                    dbs.grid_trgt_hist_dict[str(agent.grid_trgt)][day] = 1

                else:

                    dbs.grid_trgt_hist_dict[str(agent.grid_trgt)][day] += 1

            else:
                if 'none' not in dbs.grid_trgt_hist_dict:

                    dbs.grid_trgt_hist_dict['none'] = np.zeros(rounds)
                    dbs.grid_trgt_hist_dict['none'][day] = 1

                else:

                    dbs.grid_trgt_hist_dict['none'][day] += 1

            # if the agent has no memory then agent.trade_movemnt == 'random' and we need to set agent.can_trade = 1
            if agent.trade_movemnt == 'random':
                agent.can_trade = 1

        # here we want to find the first round in which ALL the agents have targetted the same square
        # dbs.round_all_ags_one_trgt = None by default so when it is changed, we no longer want to run this
        if dbs.round_all_ags_one_trgt == None:
            for loc in dbs.grid_trgt_hist_dict:
                if loc != 'none' and dbs.grid_trgt_hist_dict[loc][day] == len(dbs.agent_list):
                    dbs.round_all_ags_one_trgt = day
                    print('\n all the agents targetted the same location in round', day)

        # print(' dbs.grid_trgt_hist_dict:\n\n', dbs.grid_trgt_hist_dict)
        # pause()

    elif trade_movemnt == 'random':

        for agent in dbs.agent_list:
            agent.grid_trgt = [None, None]

    # load agents on to town_grid.grid_agents
    for agent in dbs.agent_list:

        x_coord = agent.location[0]
        y_coord = agent.location[1]

        town_grid.grid_agents[x_coord][y_coord].append(agent)

        # if the agent happens to start on its target location then we set can_trade = 1
        if agent.home[0] == agent.grid_trgt[0] and agent.home[1] == agent.grid_trgt[1]:
            agent.can_trade = 1
            agent.reached_trgt = 1
            agent.reached_tgt_on_move = 0

        # also if the agents can trade on the way to their target then we set:
        if trade_when_trgt == 0:
            agent.can_trade = 1

    # update MRS arrays to start and then save data if required
    for agent in agent_population.pop:

        agent.update_agent_MRS_array(print_dets, print_fine_dets, agent_population)

        if print_MRS_std_charts == 1 or (day + 1) % SD_charts_freq == 0:
            agent.MRS_history[day] = copy.copy(agent.MRS_array)

    # this line generates the supply & demand data for the 2d charts and it also finds the market clearing price and quantity when num_res_founts == 2
    if num_res_founts == 2:

        supply_demand_array = create_supply_demand_data(fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, gen_equ_thresh, dbs.agent_list, record_dbs_data=1, tribe='none')

        if two_tribes:

            sharks_pop = []
            jets_pop = []

            for agent in agent_population.pop:

                if agent.tribe == 'sharks':

                    sharks_pop.append(agent)

                elif agent.tribe == 'jets':

                    jets_pop.append(agent)

            supply_demand_array_sharks = create_supply_demand_data(fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, gen_equ_thresh, sharks_pop, record_dbs_data=0, tribe='sharks')

            supply_demand_array_jets = create_supply_demand_data(fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, gen_equ_thresh, jets_pop, record_dbs_data=0, tribe='jets')

    if num_res_founts == 3 and find_gen_equ_PQ == 1:
        find_simultaneous_equ_prices(fountain_population, agent_population, print_dets, print_fine_dets, dbs, day, gen_equ_thresh, gen_equ_wh_lps, town_grid, run_folder, use_parallel_code, price_grid_dimen, test_par_code,
                                     print_plotly_charts)

    # create a heatmap to show the position of all agents at the start of trading and at the end of each move
    if print_move_heat_maps == 1 or (track_agent is not None):

        agent_loc_db = np.zeros(shape=(dimen, dimen))

        for remain_agent in dbs.agent_list:
            x_coord = remain_agent.location[0]
            y_coord = remain_agent.location[1]
            agent_loc_db[x_coord][y_coord] += 1

        title = 'Agent locations in round %s, before moving' % (day)
        print('\n')
        create_heat_map(town_grid.dimen, agent_loc_db, df_daily, 'Blues', title, 'num agent', dpi='low')

    # In case the parameters are accidentally set to trade_when_trgt = 1 and trade_movemnt = 'random', for simplicity we
    # set trade_when_trgt = 0
    if trade_when_trgt == 1 and trade_movemnt == 'random':
        trade_when_trgt = 0

    # Blank the array which records all MRSs over all of the moves
    if (day + 1) % SD_charts_freq == 0:

        dbs.MRS_moves_array = [[[[] for move in np.arange(trade_moves + 1)] for res_1 in np.arange(num_res_founts)] for res_2 in np.arange(num_res_founts)]

        # Add agents' MRS data to MRS_moves_array (so we can see MRS through all moves)
        if (day + 1) % SD_charts_freq == 0:

            for agent in dbs.agent_list:

                for res_1 in np.arange(num_res_founts):
                    for res_2 in np.arange(num_res_founts):

                        if res_1 != res_2:
                            dbs.MRS_moves_array[res_1][res_2][0].append(agent.MRS_array[res_1][res_2])

    if print_fine_dets == 1:
        print('\n\n////////////// Start Move Iterations ////////////')

    #    input("Press Enter to continue...")
    #    print('day =', day)

    if params.calc_timings:
        # assert isinstance(trading_start_time, object) - play with this later
        dbs.timings_dict['trading_overhead'].append(dt.DateTime() - trading_start_time)

    # iterate over moves:
    for move in np.arange(trade_moves):

        if params.calc_timings:
            start_move_time = dt.DateTime()

        #        print_heatmap_end_move = 0

        # it's possible that an agent's resources decline to below zero if they fight - we make it so they cannot trade (they die at the end of the round!)
        for ag in dbs.agent_list:

            if any(res < 0.0 for res in ag.agent_res_array[0]):
                ag.can_trade = 0

        if print_fine_dets == 1:
            print('\n\n\n\n************* move =', move, 'of', trade_moves, ' | round ', day)

            for agent in dbs.agent_list:
                print('\nagents remaining on the grid:\n\n')
                print('agent', agent, ' | home =', agent.home, ' | location =', agent.location, ' | target loc =', agent.grid_trgt)

        if len(dbs.agent_list) < 2:

            #            if print_dets == 1:
            print('\nThere are either no agents or 1 agent remains: we do not carry on with move iterations because there can be no trading')

        elif len(dbs.agent_list) >= 2:

            # randomize the agent list so no one agent has an advantage due to moving earlier or later.
            # this is important when agents don't respect property rights: when agents move in the same sequence some will chase and the others run and
            # there would be no interaction.  If we change turns in each move, we allow the possibility of a chasing agent moving twice and catching the runner.
            # I think this accords with reality: it allows people to be mugged, for example.
            random.shuffle(dbs.agent_list)

            if params.calc_timings:
                dbs.timings_dict['trading_move_overhead'][day] += dt.DateTime() - start_move_time

            # Start iteration over agents in dbs.agent_list
            for agent in dbs.agent_list:

                #                print_fine_dets = 0 track_agent

                #                if day > 50:
                #                    print_fine_dets = 1
                #                    print_dets = 1

                if trade_when_trgt == 0 and track_agent is not None and agent == agent_population.tracking_agent and len(town_grid.grid_agents[agent.location[0]][agent.location[1]]) > 1:  # and agent.trade_movemnt == 'set':
                    print_fine_dets = print_dets = print_model_2_dets = 1

                else:
                    print_fine_dets = print_dets = print_model_2_dets = 0

                if print_dets == 1:
                    print('\n\n\n****** Start new agent: agent', agent, '  |  home =', agent.home, '  |  day =', day, '  |  move =', move, ' of ', trade_moves, 'reached_tgt_on_move =', agent.reached_tgt_on_move)
                    #                    print('\nlen(dbs.agent_list) =', len(dbs.agent_list))
                    print('\n agent.meeting_point_cps =', agent.meeting_point_cps, '\n')
                    print('\n home location for meeting_point_cps:\n')
                    for dude in agent.meeting_point_cps:
                        print(dude.home)
                    print('\n agent.grid_trgt', agent.grid_trgt)
                    print(' wait_at_target_til_end', wait_at_target_til_end)

                    if trade_loc == 'fountain':

                        for fount in fountain_population.pop:
                            print('fount_loc = ', fount.location)

                #                    print('\n\n lok at list locs - start')
                #
                #                    for trad_agent in dbs.agent_list:
                #
                #                        print('trad_agent ', trad_agent, 'loc ', trad_agent.location)

                if params.calc_timings:
                    agent_start_move = dt.DateTime()

                agent_has_moved = 0

                # In the following case, the agent must be moving to a set target on the grid and hasn't reached it yet
                if agent.can_trade == 0:    #and len(town_grid.grid_agents[agent.location[0]][agent.location[1]]) == 1:

                    if track_agent and agent == agent_population.tracking_agent:
                        print_fine_dets = print_dets = 1
                    else:
                        print_fine_dets = print_dets = 0

                    if print_fine_dets == 1:
                        print('\n**** agent cannot trade ****')

                    # How do we decide which cell to move to?  We look at all of the cells the agent could move to
                    # and choose the one with the shortest 'as the crow flies' distance which has a cell that isn't full.

                    # We want to remove the agent from its current location and then place it on the new location
                    x_coord = agent.location[0]
                    y_coord = agent.location[1]

                    if print_fine_dets == 1:
                        print('agent =', agent)
                        print('agent.location :', agent.location)
                        print('town_grid.grid_agents[x_coord][y_coord] =', town_grid.grid_agents[x_coord][y_coord])
                        print('\nwhere agent on grid_agents?')
                        for array in np.arange(town_grid.dimen):
                            for cell in np.arange(town_grid.dimen):
                                if agent in town_grid.grid_agents[array][cell]:
                                    print('agent in cell', array, cell)

                    # We take the agent off its current location in this database
                    town_grid.grid_agents[x_coord][y_coord].remove(agent)

                    # This function changes the agent's location, depending on its target and how full squares are in
                    # town_grid.grid.  If the agent's grid_trgt is within reach this function also sets agent.can_trade = 1
                    # whether the agent moves on to that square or not
                    agent.choose_new_loc(town_grid, print_dets, print_fine_dets, trade_movemnt, move, day, trade_when_trgt, trade_moves, wait_at_tgt_moves, dbs, respect_property_rights, trade_at_trgt_precise)

                    # Now we place the agent on the new location
                    x_coord = agent.location[0]
                    y_coord = agent.location[1]

                    town_grid.grid_agents[x_coord][y_coord].append(agent)

                    agent_has_moved = 1

                    if print_fine_dets == 1:

                        print('\n agent.home =', agent.home)
                        print('\n agent.trade_loc_rec =\n')
                        for mo in np.arange(len(agent.trade_loc_rec)):
                            print(agent.trade_loc_rec[mo])

                        print(agent.location, '<-- agent.location')
                        print('\n agent.trgt_loc_rec =\n')

                        for mo in np.arange(len(agent.trgt_loc_rec)):
                            print(agent.trgt_loc_rec[mo])

                        print(agent.grid_trgt, '<-- agent.grid_trgt =')
                        print('\n agent.home =', agent.home)
                        print(' agent.location =', agent.location)
                        print(' agent.grid_trgt =', agent.grid_trgt)
                        print(' agent_has_moved =', agent_has_moved)

                    # if track_agent:
                    # print_fine_dets = print_dets = 0

                    if params.calc_timings:
                        dbs.timings_dict['trading_move_agent_mtt'][day] += dt.DateTime() - agent_start_move

                # here an agent is heading to target and is allowed to trade on the way, and another agent is on its square - it can trade if it deems it worthwhile
                # if trade_when_trgt == 0 and agent_has_moved == 0 and len(town_grid.grid_agents[agent.location[0]][agent.location[1]]) > 1:
                #
                #     if print_fine_dets:
                #         print('\n agent.can_trade == 0 and agent_has_moved == 0 and len(town_grid.grid_agents[agent.location[0]][agent.location[1]]) > 1')
                #         print(' so we set agent.can_trade = 1')
                #
                #     agent.can_trade = 1

                if agent.can_trade == 1 and agent_has_moved == 0:

                    if params.calc_timings:
                        agent_can_trade_start_time = dt.DateTime()

                    if print_dets == 1:
                        print('\n---> agent.can_trade =', agent.can_trade)
                        print('agent.location =', agent.location)
                        print('agent.grid_trgt =', agent.grid_trgt)

                    # find out how many agents on the agent's current square:
                    agent_x_coord = agent.location[0]
                    agent_y_coord = agent.location[1]

                    num_ags_on_own_square = len(town_grid.grid_agents[agent_x_coord][agent_y_coord])

                    if print_dets == 1:

                        print('agent_x_coord =', agent_x_coord)
                        print('agent_y_coord =', agent_y_coord)
                        print('\ntown_grid.grid_agents[agent_x_coord][agent_y_coord] =\n', town_grid.grid_agents[agent_x_coord][agent_y_coord])
                        print('\nagent.trade_loc_rec =\n')

                        for mo in np.arange(len(agent.trade_loc_rec)):
                            print(agent.trade_loc_rec[mo])

                        print(agent.location, '<-- agent.location')
                        print('\ndeleting', agent, 'from agent_crop_list')
                        print('\nwhere agent on grid_agents?')
                        for array in np.arange(town_grid.dimen):
                            for cell in np.arange(town_grid.dimen):
                                if agent in town_grid.grid_agents[array][cell]:
                                    print('agent in cell', array, cell)
                                    print('agent =', agent)
                        print('\n num_ags_on_own_square (incl self)', num_ags_on_own_square)

                    agent_crop_list = []
                    # this variable records the mean expected return on the agent's current grid square, for when respect_property_rights == 0
                    own_loc_exp_rtn = 0
                    exp_cp_returns_array = []
                    cp_agent = None  # set this as default
                    agents_nearby = 0

                    if num_ags_on_own_square > 1:

                        if print_fine_dets:
                            print('\n town_grid.grid_agents[agent_x_coord][agent_y_coord]:\n\n', town_grid.grid_agents[agent_x_coord][agent_y_coord])
                            print(' len(town_grid.grid_agents[agent_x_coord][agent_y_coord])', len(town_grid.grid_agents[agent_x_coord][agent_y_coord]))

                        # First, shuffle the agents on the current square - this is to randomize the consideration of each potential counterparty (pot_cp) on the square.  We only need to do this when
                        # we have set a limit and the number of agents (+1 for agent) exceeds this limit.
                        if params.limit_agent_interaction and len(town_grid.grid_agents[agent_x_coord][agent_y_coord]) > params.limit_agent_interaction + 1:
                            random.shuffle(town_grid.grid_agents[agent_x_coord][agent_y_coord])

                        if print_fine_dets:
                            print('\n POST-SHUFFLE: town_grid.grid_agents[agent_x_coord][agent_y_coord]:\n\n', town_grid.grid_agents[agent_x_coord][agent_y_coord])

                        agent_crop_list = []

                        # start with iter of zero - this will help iterate through agents on square
                        iter = 0
                        # one condition for ending while loop is finished_iter = 1 (last agent)
                        finished_iter = 0

                        # we create a while loop which works whether params.limit_agent_interaction is positive or None.  If positive, the while loop continues until the number of selected agents equals the limit; and
                        # if None, agents are selected based on the criteria below - there is no limit
                        while (params.limit_agent_interaction and len(agent_crop_list) < params.limit_agent_interaction and finished_iter == 0) or \
                                (params.limit_agent_interaction == None and finished_iter == 0):

                            pot_cp = town_grid.grid_agents[agent_x_coord][agent_y_coord][iter]

                            if print_fine_dets:
                                print('\n iter =', iter)
                                print(' pot_cp: ', pot_cp)

                            accept_agent = 1

                            if pot_cp is agent:
                                accept_agent = 0

                                if print_fine_dets:
                                    print('\n pot_cp is agent')

                            elif respect_property_rights == 1 and pot_cp.can_trade == 0:
                                accept_agent = 0

                                if print_fine_dets:
                                    print('\n respect_property_rights == 1 and pot_cp.can_trade == 0')

                            elif agent.agent_last_traded_with is pot_cp and pot_cp.agent_last_traded_with is agent:
                                accept_agent = 0

                                # print(
                                #     '\n agent.agent_last_traded_with is pot_cp and pot_cp.agent_last_traded_with is agent')
                                # pause()

                                if print_fine_dets:
                                    print('\n agent.agent_last_traded_with is pot_cp and pot_cp.agent_last_traded_with is agent')

                            elif any(res < 0.0 for res in pot_cp.agent_res_array[0]):
                                accept_agent = 0

                                if print_fine_dets:
                                    print('\n any(res < 0.0 for res in pot_cp.agent_res_array[0])')

                            elif trade_when_trgt == 0 and agent.reached_trgt == 0 and pot_cp in agent.ignore_agents_array:
                                accept_agent = 0

                                if print_fine_dets:
                                    print('\n trade_when_trgt == 0 and agent.reached_trgt == 0 and pot_cp in agent.ignore_agents_array')

                            elif two_tribes == 1 and agent_population.ignore_strangers == 1 and pot_cp.tribe != agent.tribe:
                                accept_agent = 0

                                if print_fine_dets:
                                    print('\n two_tribes == 1 and agent_population.ignore_strangers == 1 and pot_cp.tribe != agent.tribe')

                            # if none of the above conditions are true, add pot_cp to agent_crop_list
                            if accept_agent == 1:
                                agent_crop_list.append(pot_cp)

                                if print_fine_dets:
                                    print('\n agent passed all tests - added to agent_crop_list')

                            # add 1 to iter
                            if iter < len(town_grid.grid_agents[agent_x_coord][agent_y_coord]) - 1:
                                iter += 1

                            # unless we have come to the end of the iterations
                            else:
                                finished_iter = 1
                                if print_fine_dets:
                                    print('\n this was the last iteration')

                        if print_fine_dets:
                            print('\n END agent_crop_list:', agent_crop_list)
                            # pause()
                            # print_fine_dets = 0

                    if params.calc_timings:
                        dbs.timings_dict['trading_move_agent_eval_own_grid_sq'][day] += dt.DateTime() - agent_can_trade_start_time

                    # Key point: if there are still cp_agents in agent_crop_list that means there are cp_agents on the agent's grid square
                    if len(agent_crop_list) > 0:

                        if params.calc_timings:
                            len_acl_start_time = dt.DateTime()

                        # if the agents don't respect property rights and they can trade, they will look around for other agents they might steal from or trade with.
                        # the agent needs to look on all its squares and take a view on which to locate itself (or it can trade with an agent on its current square)
                        if respect_property_rights == 0 and use_original_model_struct == 0:

                            #                            if day >= 20 and len(agent_crop_list) > 1:
                            #
                            #                                print_fine_dets = 1

                            if print_fine_dets:
                                print('\n\n\n\n\n -------------->>> There are potential cps on the agents square (day', day, 'move', move, ')')
                                print('\n strangers_if_unknown =', strangers_if_unknown)

                            pot_cps = []  # this is an array to record potneital counterparties

                            # we record the expected returns for all the agents in agent_crop_list in this array
                            exp_returns_array = []
                            # here we record only the agents with a positive return
                            exp_returns_array_pos = []

                            #                            # for testing
                            #                            for pot_cp_agent in agent_crop_list:
                            #
                            #                                if pot_cp_agent.tribe != agent.tribe:
                            #
                            #                                    print_fine_dets = 1

                            if print_fine_dets:
                                print('\n agent.tribe =', agent.tribe)
                                print(' len(agent_crop_list)', len(agent_crop_list))

                            #                                pause()

                            # if we limit the amount of agent interaction then we will take a sample from agent_crop_list of size params.limit_agent_interaction (else this is None)
                            if params.limit_agent_interaction and params.limit_agent_interaction < len(agent_crop_list):
                                agent_crop_list = random.sample(agent_crop_list, params.limit_agent_interaction)

                            # by this stage the agent is left with one or more potential cp_agent - they will evaluate which they want to interact with and then choose cp_agent
                            for pot_cp_agent in agent_crop_list:

                                if print_fine_dets:
                                    print('\n ----> pot_cp_agent.tribe =', pot_cp_agent.tribe)

                                #                                if agent == agent_population.pop[0] or pot_cp_agent == agent_population.pop[0]:
                                #                                    print_fine_dets = 1
                                #                                    print_dets = 1
                                #                                    print_model_2_dets = 1
                                #
                                #                                else:
                                #
                                #                                    print_fine_dets = 0
                                #                                    print_dets = 0
                                #                                    print_model_2_dets = 0

                                if agent.tribe == pot_cp_agent.tribe:

                                    if print_fine_dets:

                                        print('\n agent and cp are of same tribe')
                                        print('\n agent.agent_knows_cp_dict[str(pot_cp_agent)] ', agent.agent_knows_cp_dict[str(pot_cp_agent)])
                                        print('\n pot_cp_agent.agent_knows_cp_dict[str(agent)] =', pot_cp_agent.agent_knows_cp_dict[str(agent)])

                                        print('\n agent.trade_loc_rec =\n')
                                        print(agent.home, '<-- agent.home')
                                        for mo in np.arange(len(agent.trade_loc_rec)):
                                            print('end of move', mo, '\t', agent.trade_loc_rec[mo])

                                        print(agent.location, '<-- agent.location')

                                        print('\n pot_cp_agent.trade_loc_rec =\n')
                                        print(pot_cp_agent.home, '<-- pot_cp_agent.home')
                                        for mo in np.arange(len(pot_cp_agent.trade_loc_rec)):
                                            print('end of move', mo, '\t', pot_cp_agent.trade_loc_rec[mo])

                                        print(pot_cp_agent.location, '<-- pot_cp_agent.location')

                                        # pause()

                                    if strat_choice == 'heuristics' and (strangers_if_unknown == 0 or (strangers_if_unknown and agent.agent_knows_cp_dict[str(pot_cp_agent)] and pot_cp_agent.agent_knows_cp_dict[str(agent)])):

                                        agent_exp_gain, cp_exp_gain = agent.find_exp_returns_intn(params, pot_cp_agent, agent_population, print_dets, price_mean, force_prices, fixed_price,
                                                                                                  day, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                                  print_fine_dets, fight_balance, adjust_props_r, agent_intn_beta, move, formal_inst,
                                                                                                  prob_fine, fine, simulated_int=0, fight_skill=fight_skill, fix_ps_fb_0=fix_ps_fb_0, stranger_int=stranger_int,
                                                                                                  strat_choice=strat_choice, strangers_if_unknown=strangers_if_unknown)

                                        agent_dec = 1
                                        cp_agent_dec = 1

                                    else:  # i.e. strat_choice == 'rational'; or strat_choice == 'heuristics' and one or both agents don't know each other:

                                        use_start_basket = 0
                                        agent_dec, cp_agent_dec, agent_exp_gain, cp_exp_gain = strangers_interact(params, agent_population.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population,
                                                                                                                  print_dets, print_fine_dets, use_start_basket, agent, pot_cp_agent, stranger_int, formal_inst, prob_fine, fine,
                                                                                                                  two_tribes_inst, fight_cost)

                                    #                                        print('\n oooops')
                                    #                                        pause()

                                    if agent_exp_gain != None and agent_exp_gain > agent_population.min_trans_Q and agent_dec != 'none' and cp_agent_dec != 'none':
                                        pot_cps.append(pot_cp_agent)
                                        agent.expected_gains_dict[str(pot_cp_agent)] = [agent_exp_gain, cp_exp_gain]
                                        exp_returns_array_pos.append(agent_exp_gain)

                                    # we update these arrays regardless of whether the agent 'likes' the potential cp - they are used to retarget later if the agent does not want to interact in this time period
                                    exp_returns_array.append(agent_exp_gain)
                                    exp_cp_returns_array.append(cp_exp_gain)

                                    if print_fine_dets:
                                        print('\n agent is of same tribe: agent_exp_gain', agent_exp_gain, 'cp_exp_gain', cp_exp_gain)

                                elif agent_population.ignore_strangers == 0 and agent.tribe != pot_cp_agent.tribe:

                                    #                                    print_fine_dets = 1

                                    use_start_basket = 0
                                    agent_dec, cp_agent_dec, agent_exp_gain, cp_exp_gain = strangers_interact(params, agent_population.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population,
                                                                                                              print_dets, print_fine_dets, use_start_basket, agent, pot_cp_agent, stranger_int, formal_inst, prob_fine, fine, two_tribes_inst,
                                                                                                              fight_cost)

                                    if print_fine_dets:
                                        print('\n agent is of different tribe: agent_exp_gain', agent_exp_gain, 'cp_exp_gain', cp_exp_gain, 'agent_dec', agent_dec, 'cp_agent_dec', cp_agent_dec)

                                    # we are only interested in this agent if both have dominant strategies
                                    if agent_dec != 'none' and cp_agent_dec != 'none' and agent_exp_gain > agent_population.min_trans_Q:
                                        pot_cps.append(pot_cp_agent)
                                        agent.expected_gains_dict[str(pot_cp_agent)] = [agent_exp_gain, cp_exp_gain]
                                        exp_returns_array_pos.append(agent_exp_gain)

                                    # we update these arrays regardless of whether the agent 'likes' the potential cp - they are used to retarget later if the agent does not want to interact in this time period
                                    exp_returns_array.append(agent_exp_gain)
                                    exp_cp_returns_array.append(cp_exp_gain)

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    #                                    print('\n\n\n There might be agents on current square (', agent.location, ') - expected returns:')
                                    print('\n agent_exp_gain =', agent_exp_gain, 'cp_exp_gain', cp_exp_gain)
                                    print('\n len(pot_cps) =', len(pot_cps))
                                    print('\n exp_returns_array =', exp_returns_array)
                                    print('\n exp_cp_returns_array =', exp_cp_returns_array)
                                    pause()

                            if len(pot_cps) > 0:

                                max_exp_return = np.max(exp_returns_array)

                            else:

                                max_exp_return = -1

                            # expected mean return on own square
                            own_loc_exp_rtn = np.mean(exp_returns_array)

                            if max_exp_return > 0:  # if none of the expected returns are positive then the agent won't want to interact

                                for cp_agent_index in range(len(exp_returns_array_pos)):

                                    #                                    print('\n poss cp =', pot_cps[cp_agent_index])
                                    #                                    print(' exp_return = ', exp_returns_array[cp_agent_index])
                                    #                                    print(' agent.exp_rtns_matrix[str(cp_agent)]', agent.exp_rtns_matrix[str(pot_cps[cp_agent_index])])

                                    if exp_returns_array_pos[cp_agent_index] == max_exp_return:
                                        cp_agent = pot_cps[cp_agent_index]

                            if print_fine_dets == 1 or print_model_2_dets == 1 or (cp_agent is not None and agent.expected_gains_dict[str(cp_agent)][0] != max_exp_return) or \
                                    (cp_agent is not None and agent.expected_gains_dict[str(cp_agent)][
                                        0] < 0):  # or (max_exp_return > 0 and (agent.exp_int_gains_dict[str(cp_agent)][9] == 'trade' or agent.exp_int_gains_dict[str(cp_agent)][10] == 'trade')):

                                print('\n agent.home', agent.home)
                                print('\n exp_returns_array', exp_returns_array)
                                print('\n max_exp_return', max_exp_return)
                                print('\n own_loc_exp_rtn', own_loc_exp_rtn)
                                print('\n exp_cp_returns_array', exp_cp_returns_array)
                                print('\n cp_agent', cp_agent)
                                if cp_agent is not None:
                                    print('\n agent.expected_gains_dict[str(cp_agent)] =', agent.expected_gains_dict[str(cp_agent)])
                                # pause()
                        #                                print_fine_dets = 0

                        #                            else:
                        #
                        #                                if agent.trade_movemnt == 'set':
                        #                                    agents_nearby = 1

                        #                            if day > 100 and len(pot_cps) > 2:
                        #
                        #                                print('\n agent_crop_list =', agent_crop_list)
                        #                                print('\n pot_cps =', pot_cps)
                        #                                print('\n exp_returns_array =', exp_returns_array)
                        #                                print('\n max_exp_return =', max_exp_return)
                        #                                print('\n cp_agent =', cp_agent)
                        #                                print('\n agent_population.min_trans_Q =', agent_population.min_trans_Q)
                        #                                pause()

                        elif respect_property_rights == 1 or use_original_model_struct == 1:

                            # select a counterparty from the list
                            cp_agent = random.choice(agent_crop_list)

                            if print_fine_dets == 1:
                                print('\n*** there is more than one agent on agent.location ***')
                                print(' agent.ignore_agents_array =', agent.ignore_agents_array)
                                print('\nlen(agent_crop_list) =', len(agent_crop_list))
                                print('cp_agent =', cp_agent)
                                print('\n**** agents at same location ****')
                                print('\nchosen agent =', cp_agent)

                        if params.calc_timings:
                            dbs.timings_dict['trading_move_agent_eval_exp_gains_own_square'][day] += dt.DateTime() - len_acl_start_time

                        # the following method manages the agent interaction and returns an array with 4 elements:
                        # ret_array[0] is an array of agents to remove; ret_array[1] the number of transactions;
                        # ret_array[2] is an array of the resources traded in the interaction; and [3] is the
                        # transaction number(s) asigned to the transaction(s).

                        here = 0

                        if move >= const_mkt_opens and cp_agent is not None:  # here we allow for the market not opening until a certain move, which occurs when weare testing different market constitutions
                            # the 'is not None' part of this deals with the possibility that when respect_property_rights == 1 there might be no cp the agent wants to interact with (exp return < 0)

                            #                            if cp_agent.trade_movemnt == 'set' and len(cp_agent.meeting_point_cps) > 0 and day > 50:
                            #                                print_dets = 1
                            #                                print_fine_dets = 1
                            #                                print_model_2_dets = 1
                            #
                            #                            else:
                            #                                print_dets = 0
                            #                                print_fine_dets = 0
                            #                                print_model_2_dets = 0

                            #                            print_fine_dets = 1

                            if params.calc_timings:
                                agents_interact_start_time = dt.DateTime()

                            remove_agents, numb_trans, res_traded, trans_numbs, fight_num = agent_population.agents_interact(params, fountain_population, agent, cp_agent, day, town_grid, move, dbs, price_mean, force_prices, fixed_price,
                                                                                                                             print_dets, respect_property_rights, adjust_props_r, fight_cost, agent_intn_beta, num_rounds, print_fine_dets,
                                                                                                                             prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, fight_balance, len_reputations_mem,
                                                                                                                             intn_error_std, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt, trade_when_trgt,
                                                                                                                             track_agent,
                                                                                                                             trgt_sel, trade_moves, granular_mem, wait_at_tgt_moves, ststst, agree_location, formal_inst, prob_fine, fine,
                                                                                                                             print_agents_interact, fight_skill, fix_ps_fb_0, two_tribes_inst, strat_choice, stranger_int, strangers_if_unknown)

                            if print_fine_dets == 1:
                                print('remove_agents, numb_trans, res_traded, trans_numbs:', [remove_agents, numb_trans, res_traded, trans_numbs])

                            # Add 1 to each agent's num_act_transs[day] to record actual transactions, whether or not successful
                            #                        if numb_trans > 0:
                            agent.num_act_transs[day] += 1
                            cp_agent.num_act_transs[day] += 1

                            # if the agents are trading on the way to target, they must ignore their counterpart until they get to target.
                            # they will also ignore each other if they are wondering around randomly and have traded
                            if trade_when_trgt == 0 and agent.reached_trgt == 0:
                                agent.ignore_agents_array.append(cp_agent)
                                cp_agent.ignore_agents_array.append(agent)

                            if agent.trade_movemnt == 'random' and cp_agent not in agent.ignore_agents_array:
                                agent.ignore_agents_array.append(cp_agent)

                            if cp_agent.trade_movemnt == 'random' and agent not in cp_agent.ignore_agents_array:
                                cp_agent.ignore_agents_array.append(agent)

                            # append daily_succ_trans with all trans_num
                            for trans_num in trans_numbs:
                                daily_succ_trans.append(trans_num)

                            if fight_num is not None:
                                daily_fights.append(fight_num)

                            # post-interaction, there are three scenarios: (i) no transaction; (ii) transaction with one
                            # agent removed; and (iii) transaction with both removed:
                            if numb_trans > 0:
                                # update the town_grid.all_trans_array
                                x_coord = agent.location[0]
                                y_coord = agent.location[1]
                                town_grid.all_trans_array[day][x_coord][y_coord] += numb_trans

                                # register transaction in this database too
                                dbs.transactions_record[x_coord][y_coord][day] += 1

                                # update last_transaction for both
                                agent.last_transaction = move
                                cp_agent.last_transaction = move

                            if params.calc_timings:
                                dbs.timings_dict['trading_move_agent_agents_interact'][day] += dt.DateTime() - agents_interact_start_time

                    #                        print_fine_dets = 0
                    #                        pause()

                    # here, there is nobody else on the agent's square it can trade with but it hasn't moved yet
                    # agent will look to its neighbouring squares if it can trade when not at target, there are no agents to trade with on own square and if it hasn't already reached its target; or the agent has no memory so it's moving randomly
                    # note this is only for when agents respect property rights - we create a different approach for when they don't below
                    elif (respect_property_rights == 1 and len(agent_crop_list) == 0 and ((trade_when_trgt == 0 and agent.reached_trgt == 0) or agent.trade_movemnt == 'random')) or (
                            respect_property_rights == 0 and use_original_model_struct == 1):

                        if print_dets == 1:
                            print('\n\n *** no cp_agents on same grid square ***')
                            print('\n ** checking if any cp_agents are near to the subject agent **')
                            print('\n agent.can_trade =', agent.can_trade)
                            print(' agent.location =', agent.location)
                            print(' agent.grid_trgt =', agent.grid_trgt)

                        # We run a function called find_nearby_agent() in order to find the agents not on same square but within sight (and the agent can trade with)
                        nearby_agents, best_cp_agent = find_nearby_agents(print_dets, print_fine_dets, dbs, town_grid, agent, trade_prices, agent_population, day, trade_when_trgt)

                        if print_fine_dets == 1:
                            print('\n\n--> summary after checking if agents nearby')
                            print('\nnearby_agents =', nearby_agents)
                            print('\nagent.trade_loc_rec =\n')

                            for mo in np.arange(len(agent.trade_loc_rec)):
                                print(agent.trade_loc_rec[mo])

                            print(agent.location, '<-- agent.location')
                            print('\nagent.trgt_loc_rec =\n')

                            for mo in np.arange(len(agent.trgt_loc_rec)):
                                print(agent.trgt_loc_rec[mo])

                            print(agent.grid_trgt, '<-- agent.grid_trgt =')
                            print('\nagent.home =', agent.home)
                            print('agent.location =', agent.location)

                        if len(nearby_agents) > 0:  # there are agents nearby... the agent moves

                            if print_fine_dets == 1:
                                print('\nrandomly chosen best_cp_agent =', best_cp_agent)
                                print('\npre agent.location =', agent.location)
                                print('best_cp_agent.location =', best_cp_agent.location)
                                print('agent =', agent)

                            # we want to remove the agent from its current location and then place him on the new location
                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].remove(agent)

                            # copy the neighbour's location in to the agent's
                            agent.location = copy.copy(best_cp_agent.location)

                            # Now we place the agent on the new location
                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].append(agent)

                            if print_fine_dets == 1:
                                print('\npost agent.location =', agent.location)

                            # if it happens to be the case the agent moves on to its target location when moving on to a cp_agent's square, we must do the following:
                            if agent.location[0] == agent.grid_trgt[0] and agent.location[1] == agent.grid_trgt[1]:
                                agent.reached_trgt = 1
                                agent.reached_tgt_on_move = move

                                # we set ignore_agents_array to blank - agent can now trade with whomever
                                agent.ignore_agents_array = []

                        elif len(nearby_agents) == 0:

                            if print_fine_dets == 1:
                                print('\n\n *** Agent is trading on way to target but hasnt reached it yet and there was nobody to play with')
                                print('\n agent.reached_trgt =', agent.reached_trgt)

                            # we want to remove the agent from its current location and then place him on the new location
                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].remove(agent)

                            # This function changes the agent's location, depending on its target and how full squares are in
                            # town_grid.grid.  If the agent's grid_trgt is within reach this function also sets agent.can_trade = 1
                            # whether the agent moves on to that square or not (i.e. if the target square is full then
                            # agent.can_trade = 1).
                            agent.choose_new_loc(town_grid, print_dets, print_fine_dets, trade_movemnt, move, day, trade_when_trgt, trade_moves, wait_at_tgt_moves, dbs, respect_property_rights, trade_at_trgt_precise)

                            here = 0

                            # Now we place the agent on the new location
                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].append(agent)

                    # when the agents dont respect property rights and the agent doesn't want to interact with any agent on own square (or there are none)
                    if respect_property_rights == 0 and cp_agent is None:

                        if params.calc_timings:
                            eval_all_grid_sqs_start = dt.DateTime()

                        ##                        print('\n respect_property_rights == 0 and cp_agent is None, agents_nearby ', agents_nearby, 'location =', agent.location)
                        #
                        #                        if (agents_nearby == 0 or print_model_2_dets == 1) and day > 0 and agent.trade_movemnt == 'set':
                        #
                        #                            for i in range(-1, 2):
                        #                                for j in range(-1, 2):
                        #
                        #                                    x_coord = (agent.location[0] + i) % town_grid.dimen
                        #                                    y_coord = (agent.location[1] + j) % town_grid.dimen
                        #
                        #                                    if (i == 0 and j == 0) == False and len(town_grid.grid_agents[x_coord][y_coord]) > 0:
                        #
                        #                                        agents_nearby = 1
                        #
                        #                                    if i == 0 and j == 0 and len(town_grid.grid_agents[x_coord][y_coord]) > 1:
                        #
                        #                                        agents_nearby = 1

                        #                        if print_model_2_dets == 0:
                        #                            agents_nearby = 0
                        #                        else:
                        #                            agents_nearby = 1

                        exp_returns_array, max_mean_exp_return, max_grid_square, number_neighbours, neigh_exp_returns_array, head_to_target = \
                            agent.evaluate_exp_rtns_all_grid_sqs(params, town_grid, own_loc_exp_rtn, exp_cp_returns_array, agent_population, print_dets, price_mean, force_prices, fixed_price, day,
                                                                 move, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std, print_fine_dets,
                                                                 agent_avoid_muggers, fight_balance, adjust_props_r, agent_intn_beta, two_tribes, formal_inst,
                                                                 prob_fine, fine, fight_skill, fix_ps_fb_0, two_tribes_inst, strat_choice, stranger_int, strangers_if_unknown,
                                                                 respect_property_rights, trade_when_trgt, track_agent)

                        # if head_to_target:
                        #     print_fine_dets = 1

                        if print_fine_dets:
                            print('\n\n\n\n agent.home', agent.home, 'day', day, 'move', move)
                            print('\n number_neighbours', number_neighbours)
                            print(' current location', agent.location)
                            print(' max_grid_square', max_grid_square)
                            print('\n exp_returns_array:\n', exp_returns_array)
                            print('\n max_mean_exp_return', max_mean_exp_return)
                            print('\n neigh_exp_returns_array \n', neigh_exp_returns_array[0], '\n', neigh_exp_returns_array[1], '\n', neigh_exp_returns_array[2])
                            print('\n head_to_target =', head_to_target)
                            print('\n agent.trade_movemnt', agent.trade_movemnt)

                        # we don't want the agent to head to target if it is wandering around randomly
                        if agent.trade_movemnt != 'set':
                            head_to_target = 0

                        # if there are no agents in sight then the problem is simple: we just move the agent as in the case of respecting property rights
                        if head_to_target == 1:

                            if (print_fine_dets or print_model_2_dets == 1):  # and ((agent.location[0] == agent.grid_trgt[0] and agent.location[1] == agent.grid_trgt[1]) is False):

                                print('\n number_neighbours =', number_neighbours)
                                print('\n we call agent.choose_new_loc  |  agent.trade_movemnt ', agent.trade_movemnt)
                                print('\n trade_movemnt', trade_movemnt)
                                print(' trade_when_trgt', trade_when_trgt)
                                print('\n agent.trade_movemnt', agent.trade_movemnt)
                                print('\n prior location = ', agent.location)

                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].remove(agent)

                            agent.choose_new_loc(town_grid, print_dets, print_fine_dets, trade_movemnt, move, day, trade_when_trgt, trade_moves, wait_at_tgt_moves, dbs, respect_property_rights, trade_at_trgt_precise)

                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].append(agent)

                        else:

                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].remove(agent)

                            agent.location = copy.copy(max_grid_square)

                            x_coord = agent.location[0]
                            y_coord = agent.location[1]
                            town_grid.grid_agents[x_coord][y_coord].append(agent)

                            # it's possible that this max_grid_square is the target location
                            if agent.location[0] == agent.grid_trgt[0] and agent.location[1] == agent.grid_trgt[1]:

                                if print_fine_dets:
                                    print('\n agent hit target!')

                                agent.can_trade = 1
                                agent.reached_trgt = 1
                                agent.reached_tgt_on_move = move

                        if print_fine_dets:
                            print('\n head_to_target =', head_to_target)
                            print(' day', day, 'move', move)
                            print(' resulting agent.loction', agent.location)
                            print(' agent.grid_trgt', agent.grid_trgt)
                            pause()

                        if params.calc_timings:
                            dbs.timings_dict['trading_move_agent_eval_all_grid_sqs'][day] += dt.DateTime() - eval_all_grid_sqs_start

                    if print_fine_dets == 1:
                        print('\n\n trade_movemnt =', trade_movemnt, '  |  move =', move, '  |  agent.reached_tgt_on_move =', agent.reached_tgt_on_move, '  |  agent.wait_at_tgt_moves_pro_rata =', agent.wait_at_tgt_moves_pro_rata,
                              '  |  moves left until shift:', agent.reached_tgt_on_move + 1 + agent.wait_at_tgt_moves_pro_rata - move)

                    # If the agent has been waiting at the target location for a while and we haven't designated that it must wait til the end, and it is time to move... (note we don't move the agent until the next move)
                    if (agent.grid_trgt[0] == agent.location[0] and agent.grid_trgt[1] == agent.location[1]) and \
                            wait_at_target_til_end == 0 and trade_movemnt == 'set' and move != town_grid.trade_moves - 1 and move == agent.reached_tgt_on_move + 1 + agent.wait_at_tgt_moves_pro_rata:  # and agent.last_transaction - move > 10:

                        if params.calc_timings:
                            retarget_start = dt.DateTime()

                        # before retargeting we must pro rata the wait_at_target value:

                        agent.wait_at_tgt_moves_pro_rata = math.ceil(wait_at_tgt_moves * ((trade_moves - move) / float(trade_moves)))

                        if print_fine_dets == 1:
                            print('trade_moves', trade_moves, 'agent.wait_at_tgt_moves_pro_rata', agent.wait_at_tgt_moves_pro_rata)

                        set_agent_target(params, respect_property_rights, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt, trade_when_trgt, dbs, track_agent, agent, day,
                                         town_grid, trgt_sel, trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, retarg=1, move=move, has_acted=1,
                                         print_dets=0, print_fine_dets=0, agree_location=agree_location, adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta,
                                         formal_inst=formal_inst, prob_fine=prob_fine, fine=fine, fight_skill=fight_skill, strat_choice=strat_choice, stranger_int=stranger_int,
                                         two_tribes_inst=two_tribes_inst, strangers_if_unknown=strangers_if_unknown)

                        # can_trade is only 0 after the start of the trading phase and before the agent reaches its target (or is intercepted) so here it is set = 1
                        agent.can_trade = 1
                        agent.reached_tgt_on_move = 0

                        # agent.reached_trgt is 0 when agent is heading to target and 1 after it has reached it, unless moving randomly
                        if agent.trade_movemnt == 'set' and trade_when_trgt == 1 and (agent.grid_trgt[0] == agent.location[0] and agent.grid_trgt[1] == agent.location[1]) == False:

                            agent.reached_trgt = 0

                        else:

                            agent.reached_trgt = 1

                        # We want to remove the agent from its current location and then place it on the new location
                        x_coord = agent.location[0]
                        y_coord = agent.location[1]
                        town_grid.grid_agents[x_coord][y_coord].remove(agent)

                        # The agent moves - to get to this stage trade_movemnt == 'set' only so we don't move the
                        # agent randomly
                        agent.choose_new_loc(town_grid, print_dets, print_fine_dets, trade_movemnt, move, day, trade_when_trgt, trade_moves, wait_at_tgt_moves, dbs, respect_property_rights, trade_at_trgt_precise)

                        # Now we place the agent on the new location
                        x_coord = agent.location[0]
                        y_coord = agent.location[1]
                        town_grid.grid_agents[x_coord][y_coord].append(agent)

                        if print_fine_dets == 1:
                            print('\npost agent.location =', agent.location)

                        if params.calc_timings:
                            dbs.timings_dict['trading_move_agent_retargetting'][day] += dt.DateTime() - retarget_start

                #                if print_fine_dets == 1:
                #
                #                    print('\n\n lok at list locs - end')
                #
                #                    for trad_agent in dbs.agent_list:
                #
                #                        print('trad_agent ', trad_agent, 'loc ', trad_agent.location)

                # we update two records of the agent in order for us to track its movement and its target over the trade moves
                agent.trade_loc_rec.append(copy.copy(agent.location))
                agent.trgt_loc_rec.append(copy.copy(agent.grid_trgt))

                if track_agent is not None and agent == agent_population.tracking_agent:

                    if agent_population.tracking_agent.grid_trgt[0] is not None:
                        dist_to_target = abs_dist_on_torus(agent_population.tracking_agent.location,
                                                           agent_population.tracking_agent.grid_trgt, town_grid.dimen)
                        travel_dist = np.max(dist_to_target)

                    else:
                        travel_dist = 'random walk'

                    print(' end of agent move: tracking_agent.location ', agent_population.tracking_agent.location, 'versus target ',
                          agent_population.tracking_agent.grid_trgt, '\tcan_trade?\t', agent.can_trade == 1,
                          'dist \t\t\t', travel_dist)

            if print_model_2_dets == 1:

                town_grid_count = np.zeros(shape=(town_grid.dimen, town_grid.dimen))

                for x_coord in range(town_grid.dimen):
                    for y_coord in range(town_grid.dimen):
                        town_grid_count[x_coord][y_coord] = len(town_grid.grid_agents[x_coord][y_coord])

                create_heat_map(town_grid.dimen, town_grid_count, run_folder, 'Blues', '', 'move_locs_day_%d_move_%d' % (day, move), dpi='low')

        #                if print_fine_dets == 1 or print_dets == 1 or print_model_2_dets == 1:
        #
        #                    pause()

        # this marks the end of the agent iterations over this one move i.e. we have iterated over all agents

        if print_fine_dets == 1:
            print('\n************************ End of move', move, 'of [', town_grid.trade_moves - 1, '] ************************')
            print('len(dbs.agent_list) =', len(dbs.agent_list))
            # pause()

        #        if print_fine_dets == 1:
        #            print('\npost-rem dbs.agent_list =', dbs.agent_list)
        #            print('len(dbs.agent_list) =', len(dbs.agent_list))

        # Print move-by-move heatmaps if required
        if print_move_heat_maps or (track_agent is not None):

            grid_count = np.zeros(shape=(town_grid.dimen, town_grid.dimen))

            for x_coord in np.arange(town_grid.dimen):
                for y_coord in np.arange(town_grid.dimen):
                    grid_count[x_coord][y_coord] = len(town_grid.grid_agents[x_coord][y_coord])

            title = 'Agent locations at end of round %s, move %s' % (day, move)
            create_heat_map(town_grid.dimen, grid_count, df_daily, 'Blues', title, 'num agent', dpi='low')

            if track_agent is not None:

                if agent_population.tracking_agent.grid_trgt[0] is not None:
                    dist_to_target = abs_dist_on_torus(agent_population.tracking_agent.location, agent_population.tracking_agent.grid_trgt, town_grid.dimen)
                    travel_dist = np.max(dist_to_target)

                else:
                    travel_dist = 'random walk'

                print(' tracking_agent.location ', agent_population.tracking_agent.location, 'versus target ', agent_population.tracking_agent.grid_trgt, '\tcan_trade?\t', agent_population.tracking_agent.can_trade == 1, 'dist \t\t\t', travel_dist)

        # Add agents' MRS data to MRS_moves_array (so we can see MRS through all moves)
        if (day + 1) % SD_charts_freq == 0:

            for agent in dbs.agent_list:

                for res_1 in np.arange(num_res_founts):
                    for res_2 in np.arange(num_res_founts):

                        if res_1 != res_2:
                            dbs.MRS_moves_array[res_1][res_2][move + 1].append(agent.MRS_array[res_1][res_2])

        # This is the end of a move iteration

    for ag in dbs.agent_list:
        # record the agent's history of moves in this array Agent
        ag.hist_trade_loc_rec[day] = copy.copy(ag.trade_loc_rec)

    #        if (day + 1) % SD_charts_freq == 0:
    #
    #            print('agent', ag, 'agent.trade_loc_rec', ag.trade_loc_rec)

    # Update dbs.transs_daily_db with daily transaction data
    dbs.transs_daily_db[day] = daily_succ_trans
    dbs.fights_daily_db[day] = daily_fights

    # if we want to track the agent MRSs at the beginning and end of rounds, we must record the data:
    if print_MRS_std_charts == 1:

        for res_1 in np.arange(num_res_founts):

            for res_2 in np.arange(num_res_founts):

                if res_1 != res_2:

                    MRS_scatter_db_start = []
                    MRS_scatter_db_end = []

                    for agent in dbs.agent_list:
                        MRS_scatter_db_start.append(agent.MRS_history[day][res_1][res_2])
                        MRS_scatter_db_end.append(agent.MRS_array[res_1][res_2])

                    start_std = np.std(MRS_scatter_db_start)
                    end_std = np.std(MRS_scatter_db_end)

                    dbs.MRS_STDs_array[res_1][res_2][0][day] = start_std
                    dbs.MRS_STDs_array[res_1][res_2][1][day] = end_std

    # Update dbs.net_transs_db, which is used to create some charts
    dbs.update_net_transs_db(day, print_dets, print_fine_dets, fountain_population, agent_population, town_grid, daily_succ_trans, two_tribes, respect_property_rights)

    # If we're allowing prices to vary then we will print the supply & demand curves.  Here we combine the
    # supply_demand_data array and the average price and total quantity data.
    if SD_charts_freq > 0:

        if (day + 1) % SD_charts_freq == 0:

            create_supply_demand_charts(num_res_founts, supply_demand_array, fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, rounds, trade_moves, SD_charts_freq, daily_succ_trans, pop='all')

            if two_tribes:
                create_supply_demand_charts(supply_demand_array_sharks, fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, rounds, trade_moves, SD_charts_freq, daily_succ_trans, pop='sharks')

                create_supply_demand_charts(supply_demand_array_jets, fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, rounds, trade_moves, SD_charts_freq, daily_succ_trans, pop='jets')

    if print_fine_dets == 1:
        print('\n\n----------> at the end of trading, trade_tally = ')
        print('\ndbs.agent_list =', dbs.agent_list)
        print('\nlen(dbs.agent_list) =', len(dbs.agent_list))

    # if we print daily data, here we print 3 text files
    if print_round_trans != 0 and (day + 1) % print_round_trans == 0:
        # write successful transactions data
        write_succ_trans_data(day, town_grid, print_dets, df_daily, daily=1, daily_db=daily_succ_trans)

    if print_dets == 1:
        print('\n***************** END OF TRADING ******************\n')


def create_supply_demand_data(fountain_population, agent_population, print_dets, print_fine_dets, data_folder, day, dbs, gen_equ_thresh, agent_list, record_dbs_data, tribe):
    """This function creates the data for the supply and demand charts when we have 2 resources.  This data has
    to be created at the beginning of agents_trading since we want data prior to any transactions.  But we need to overlay
    the actual trading data (average transaction price and total quantity), which can only be known after trading.  So we
    create some of the data here."""

    #    here = 0

    #    print_fine_dets = 1

    #    if day == 100:
    #        print_fine_dets = 1

    # We default to 20 price points (so there are 19 gaps)
    num_price_points = 20

    # Data for res_1 versus combined resources
    supply_demand_array = []
    for k in np.arange(num_res_founts):
        supply_demand_array.append([])

    price_points_array = np.zeros(shape=(num_res_founts, num_price_points))

    # First create the price points and put them in price_points_array
    for res_1 in np.arange(num_res_founts):

        if print_fine_dets == 1:
            print('\nFind high and low prices')

        # Find the highest and lowest possible prices
        highest_price = 1.0
        lowest_price = 1.0
        for agent in agent_list:

            for other_res in np.arange(num_res_founts):

                if other_res != res_1 and agent.MRS_array[res_1][other_res] > highest_price:

                    highest_price = agent.MRS_array[res_1][other_res]

                    if print_fine_dets == 1:
                        print('\nres_1 =', res_1)
                        print('other_res =', other_res)
                        print('\nagent.MRS_array =\n', agent.MRS_array)
                        print('\nagent.MRS_array[res_1][other_res] =', agent.MRS_array[res_1][other_res])
                        print('highest_price at this stage =', highest_price)

                if other_res != res_1 and agent.MRS_array[res_1][other_res] < lowest_price:

                    lowest_price = agent.MRS_array[res_1][other_res]

                    if print_fine_dets == 1:
                        print('\nres_1 =', res_1)
                        print('other_res =', other_res)
                        print('\nagent.MRS_array =\n', agent.MRS_array)
                        print('\nagent.MRS_array[res_1][other_res] =', agent.MRS_array[res_1][other_res])
                        print('lowest_price at this stage =', lowest_price)

        price_points = np.linspace(lowest_price, highest_price, num_price_points)

        if print_fine_dets == 1:
            print('\n\nlowest_price =', lowest_price)
            print('highest_price =', highest_price)
            print('price_points =', price_points)
            print('len(price_points) =', len(price_points))

        price_points_array[res_1] = price_points

        if print_fine_dets == 1:
            print('\nFINAL highest_price =', highest_price)
            print('FINAL lowest_price =', lowest_price)
            print('\nprice_points =', price_points)
            print('\n\nNow going through each price point')

        #        if res_1 == 0:

        # record the resource's highest price (note this is a working price but we want the highest chart price so we take the lowest working price)
        fountain_population.pop[res_1].highest_prices[day] = lowest_price

    if print_fine_dets == 1:
        print('\nprice_points_array =\n', price_points_array)

        input("Press Enter to continue...")

    # In the 2d charts we allow the price between 2 resources to vary and we assume that the prices of all the other resource
    # combinations is equal to the expected prices contained in exp_prices_array.
    for res_1 in [0, 1]:

        if res_1 == 0:

            other_res = 1

        elif res_1 == 1:

            other_res = 0

        # unpack relevant price points
        price_points = price_points_array[res_1]

        # Create an array to record the chart data (all non-res_1 resources) & populate with price points. [0] is supply,
        # [1] is demand.
        S_D_charts_array = np.zeros(shape=(3, len(price_points)))
        S_D_charts_array[0] = price_points

        # Iterate through all the price points
        for price_index in np.arange(num_price_points):

            # create counters for total supply & demand
            total_supply = 0
            total_demand = 0

            # unpack price
            price = price_points[price_index]

            if print_fine_dets == 1:
                print('\n\n\n\n\nprice =', price, '\n')

            for agent in agent_list:  # these are the agents with resources (don't need those without)

                agent.aggr_res_array = agent.agent_res_array + agent.basket_array

                if print_fine_dets == 1:
                    print('\n\nagent =', agent)

                agent_supply = 0
                agent_demand = 0

                MRS = agent.MRS_array[res_1][other_res]

                if print_fine_dets == 1:
                    print('\n--> res_1 =', res_1, 'other_res =', other_res)
                    print('agent.MRS_array:\n', agent.MRS_array)
                    print('MRS =', MRS)
                    print('price =', price)

                if MRS > price:  # then the agent will supply res_1

                    tot_Q = Q_at_price(res_1, other_res, price, agent.aggr_res_array)

                    # For multiple res:
                    agent_supply += tot_Q
                    # For single res:
                    agent_holding = agent.basket_array[0][res_1]
                    max_supply = np.min([agent.basket_array[0][res_1], tot_Q])

                    if print_fine_dets == 1:
                        print('\nMRS > price')
                        print('agent.basket_array =', agent.basket_array)
                        print('agent.aggr_res_array =', agent.aggr_res_array)
                        print('tot_Q (would supply, without constraints) =', tot_Q)
                        print('for multiple good comparison: supply in total with constraint', agent_supply)
                        print('\nfor 2 good comparison: agent_holding =', agent_holding)
                        print('max_supply (min of agent_holding and tot_Q) =', max_supply)

                    total_supply += max_supply

                elif MRS < price:  # then the agent will demand res_1

                    # use a substitute price
                    subst_price = 1.0 / price

                    # note we switch the resources - this gives us a preferred supply of other_res
                    tot_Q = Q_at_price(other_res, res_1, subst_price, agent.aggr_res_array)

                    # For multiple res:
                    agent_demand += tot_Q / subst_price
                    # For single res:
                    agent_holding = agent.basket_array[0][other_res]
                    max_supply_other_res = np.min([agent_holding, tot_Q])
                    max_demand = max_supply_other_res * price

                    total_demand += max_demand

                    if print_fine_dets == 1:
                        print('\nMRS < price')
                        print('agent.basket_array =', agent.basket_array)
                        print('agent.aggr_res_array =', agent.aggr_res_array)
                        print('tot_Q =', tot_Q)
                        print('price =', price)
                        print('subst_price =', subst_price)
                        print('for multiple good comparison: demand in total without constraint', agent_demand)
                        print('\nfor 2 good comparison: agent_holding (other res) =', agent_holding)
                        print('max_supply_other_res (min of agent_holding and tot_Q) =', max_supply_other_res)

                if print_fine_dets == 1:
                    print('\ntotal_supply now =', total_supply)
                    print('total_demand now =', total_demand)

                # This is the end of the agent iterations

            if print_fine_dets == 1:
                input("Press Enter to continue...")

            S_D_charts_array[1][price_index] = total_supply
            S_D_charts_array[2][price_index] = total_demand

        supply_demand_array[res_1] = S_D_charts_array

    if print_fine_dets == 1:
        input("Press Enter to continue...")

    # Here we will find the intersection of the S&D curves when we only have 2 resources
    net_demand_array = supply_demand_array[0][1] - supply_demand_array[0][2]
    price_points = supply_demand_array[0][0]

    if print_fine_dets == 1:
        print('\n net_demand_array \n', net_demand_array)

    max_boundary_p = 0.0
    min_boundary_p = 0.0
    tot_net_demand = 10.0
    while_loop_counter = 0

    while np.abs(tot_net_demand) > gen_equ_thresh:

        for price_point_ind in range(len(price_points) - 1):

            # We find the two prices below which and above which the intersection point lies
            if net_demand_array[price_point_ind] >= 0 and net_demand_array[price_point_ind + 1] <= 0:

                min_boundary_p = price_points[price_point_ind]
                max_boundary_p = price_points[price_point_ind + 1]

                mean_price = np.mean([max_boundary_p, min_boundary_p])

                # we now test whether this mean price is close enough to market clearing

                if print_fine_dets == 1:
                    print('\n\n while loop counter =', while_loop_counter)
                    print(' max_boundary_p', max_boundary_p)
                    print(' min_boundary_p', min_boundary_p)
                    print(' mean_price', mean_price)

                tot_demand, tot_supply = find_total_S_D(agent_list, dbs, day, agent_population, mean_price, res_1=0, res_2=1, print_fine_dets=0, find_optimals=0)

                tot_net_demand = tot_demand - tot_supply

                # we need to create new set of price_points for next while loop only if the while loop's condition still holds
                if np.abs(tot_net_demand) > gen_equ_thresh:

                    price_points = np.linspace(min_boundary_p, max_boundary_p, num_price_points)

                    if print_fine_dets == 1:
                        print('\n new price_points:\n', price_points)

                    for new_price_ind in range(num_price_points):

                        new_price = price_points[new_price_ind]

                        new_supply, new_demand = find_total_S_D(agent_list, dbs, day, agent_population, new_price, res_1=0, res_2=1, print_fine_dets=0, find_optimals=0)

                        net_demand_array[new_price_ind] = new_demand - new_supply

                        if print_fine_dets == 1:
                            print('\n new_price =', new_price)
                            print(' new_supply =', new_supply)
                            print(' new_demand =', new_demand)
                            print(' new_demand - new_supply =', new_demand - new_supply)

                    if print_fine_dets == 1:
                        print('\n net_demand_array =\n', net_demand_array)

                    while_loop_counter += 1

    # we need to set agent.optimal_transs_systemic[day] when we know the market clearing level of P & Q
    tot_demand, tot_supply = find_total_S_D(agent_list, dbs, day, agent_population, mean_price, res_1=0, res_2=1, print_fine_dets=0, find_optimals=1)

    #    print('\nday', day, 'Q =', np.mean([tot_demand, tot_supply]), 'P =', mean_price)

    turnover_res_0 = np.mean([tot_demand, tot_supply])
    turnover_res_1 = turnover_res_0 / mean_price  # it's x conventional price so divide by inverse price

    if record_dbs_data:
        dbs.optimal_price_array[day][0][1] = mean_price
        dbs.optimal_price_array[day][1][0] = 1 / float(mean_price)

        dbs.optimal_bskt_turnover[day] = np.array([turnover_res_0, turnover_res_1])

        dbs.optimal_bskt_errors[day] = np.array([tot_supply - tot_demand, (tot_demand - tot_supply) / mean_price])

        dbs.optimal_bskt_iters[day] = while_loop_counter

    if tribe == 'sharks':

        dbs.optimal_price_array_sharks[day][0][1] = mean_price
        dbs.optimal_price_array_sharks[day][1][0] = 1 / float(mean_price)

        dbs.optimal_bskt_turnover_sharks[day] = np.array([turnover_res_0, turnover_res_1])

    elif tribe == 'jets':

        dbs.optimal_price_array_jets[day][0][1] = mean_price
        dbs.optimal_price_array_jets[day][1][0] = 1 / float(mean_price)

        dbs.optimal_bskt_turnover_jets[day] = np.array([turnover_res_0, turnover_res_1])

    # Here we invert the prices: above, res_0 is move valued the lower the price (equivalent to an appreciation).
    # For visual comfort we will invert the prices.
    for res_1 in np.arange(num_res_founts):

        for price_index in np.arange(num_price_points):
            price = S_D_charts_array[0][price_index]

            inv_price = 1.0 / price

            S_D_charts_array[0][price_index] = inv_price

        supply_demand_array[res_1] = S_D_charts_array

    if print_fine_dets == 1:
        print('\n\n supply_demand_array[0]:\n\n', supply_demand_array[0])
        print('\n\n supply_demand_array[1]:\n\n', supply_demand_array[1])

    if print_fine_dets == 1:
        input("\n Press Enter to continue...")

    return supply_demand_array


def find_total_S_D(agent_list, dbs, day, agent_population, price, res_1, res_2, print_fine_dets, find_optimals):
    #    if find_optimals == 1:
    #
    #        print_fine_dets == 1

    if print_fine_dets == 1:

        print('\n agent_list:', agent_list)

        for agent in agent_list:
            print(' agent.home', agent.home, 'tribe', agent.tribe)

    total_demand = 0
    total_supply = 0

    for agent in agent_list:

        #        if day > 100 and find_optimals == 1:
        #
        #            if agent_population.pop[0] == agent:
        #
        #                print_fine_dets = 1
        #
        #            else:
        #
        #                print_fine_dets = 0

        agent.aggr_res_array = agent.agent_res_array + agent.basket_array

        MRS = agent.MRS_array[res_1][res_2]

        if print_fine_dets == 1:
            print('\n\n ----> find_total_S_D:\n agent', agent)
            print(' agent.MRS_array:\n', agent.MRS_array)
            print(' agent.agent_res_array:', agent.agent_res_array)
            print(' agent.basket_array: ', agent.basket_array)
            print(' MRS =', MRS)
            print(' price =', price)

        if MRS > price:  # then the agent will supply res_1

            tot_Q = Q_at_price(res_1, res_2, price, agent.aggr_res_array)

            agent_holding = agent.basket_array[0][res_1]
            max_supply = np.min([agent.basket_array[0][res_1], tot_Q])

            total_supply += max_supply

            if print_fine_dets == 1:
                print('\n agent supplies', max_supply)

            if find_optimals == 1:
                agent.optimal_transs_systemic[day][0] = max_supply
                # note that when we use price_MRS we must divide by the price to get the amount of res 1 units in exchange for this res 0 supply
                # and we multiply by -1 to denote it's demanded not supplied
                agent.optimal_transs_systemic[day][1] = (max_supply / price) * -1
                dbs.optimal_price_array[day][0][1] = price

        elif MRS < price:  # then the agent will demand res_1

            # use a substitute price
            subst_price = 1.0 / price

            # note we switch the resources - this gives us a preferred supply of other_res
            tot_Q = Q_at_price(res_2, res_1, subst_price, agent.aggr_res_array)

            agent_holding = agent.basket_array[0][res_2]
            max_supply_other_res = np.min([agent_holding, tot_Q])

            max_demand_res_1 = max_supply_other_res * price

            total_demand += max_demand_res_1

            if find_optimals == 1:
                agent.optimal_transs_systemic[day][0] = -1 * max_demand_res_1
                agent.optimal_transs_systemic[day][1] = max_supply_other_res
                dbs.optimal_price_array[day][1][0] = 1 / float(price)

            if print_fine_dets == 1:
                print('\n agent demands (res_1)', max_demand_res_1)

    if print_fine_dets == 1:

        if print_fine_dets == 1:
            print('\n\n total_demand = ', total_demand)
            print(' total_supply = ', total_supply)
            print(' net demand = ', total_demand - total_supply)

    return total_demand, total_supply


def set_agent_target(params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, respect_property_rights, KO_pop,
                     agent_population, keynesian_ratio, trade_prices, trade_movemnt, trade_when_trgt, dbs, track_agent,
                     agent, day, town_grid, trgt_sel, trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, ststst, retarg,
                     move, has_acted, print_dets, print_fine_dets, fight_balance, agree_location, adjust_props_r, agent_intn_beta,
                     formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0, strat_choice, stranger_int, two_tribes_inst, strangers_if_unknown):

    # location_memories_habits_dict

    """This function sets the target of a single agent."""

    if track_agent is not None and agent_population.tracking_agent == agent:
        print_fine_dets = 1

    if print_fine_dets == 1:
        print('\n\n\n ***** set_agent_target has started *****')
        print(' day =', day)
        print(' agent.birth_date =', agent.birth_date)
        print(' trade_movemnt =', trade_movemnt)
        print('\n agent.location =', agent.location, '| home =', agent.home, ' | agent.grid_trgt =', agent.grid_trgt)

        print('\n town_grid.trade_moves =', town_grid.trade_moves)
        print(' move =', move)
        print('\n granular_mem =', granular_mem)
        print(' retarg =', retarg)
        print(' has_acted =', has_acted)
        print('\n agent.MRS_array =', agent.MRS_array)
        print('\n agent.agreed_meeting_point =', agent.agreed_meeting_point)
        print('\n agent.can_trade:', agent.can_trade)

    # At the beginning of each round we do two things: time decay the existing entries in the dictionary and remove those value with a v small value.  If Keynesian insts are being applied, we also do this here
    if retarg == 0:

        # we want to create a dictionary in which we save all positive entries, which will reduce time.  Note we originate it at the start of the round and it is then used for retargetting
        agent.positive_locations_dict = dict()

        if print_fine_dets == 1:
            print('\n\n\n ****** Starting dictionary values: \n')

        # when a location's value decays to zero then we remove it - to do this we have to add these items to a list and then delete
        items_to_be_removed = []

        # first we time_decay all the values in the dictionary - note the equation used is designed to decay any entry to zero over 20 rounds
        for entry in agent.location_memories_dict:

            # NOTE that we want time decay to zero but with the equation used, positive values decay to negative and vv, so we want to limit to zero
            if agent.location_memories_dict[entry] != 0.0:

                # here we decay each value in the dictionary
                agent.location_memories_dict[entry] *= (1 - params.memory_decay_rate)

                # in this situation the time decay has moved to a very low level so we will remove it from the dictionary - the threshold will depend on the nature of the weights (params.target_location_weights)
                if (params.target_location_weights == 'crude' and -0.05 < agent.location_memories_dict[entry] < 0.05) or (params.target_location_weights == 'reduced_value' and -0.001 < agent.location_memories_dict[entry] < 0.001):
                    items_to_be_removed.append(entry)

                # to qualify for positive_locations_dict, the entry location should not be in agent.previous_trgt and the entry must be positive and not about to be removed
                if (params.target_location_weights == 'crude' and agent.location_memories_dict[entry] >= 0.05) or (params.target_location_weights == 'reduced_value' and agent.location_memories_dict[entry] >= 0.001):
                    agent.positive_locations_dict[entry] = agent.location_memories_dict[entry]

            # it's possible that agent.location_memories_dict[entry] == 0.0 (e.g., 1 trade, 1 fight)
            elif agent.location_memories_dict[entry] == 0.0:

                items_to_be_removed.append(entry)

            if print_fine_dets == 1:
                print(' location ', entry, 'value', agent.location_memories_dict[entry])

        if print_fine_dets:
            print('\n items_to_be_removed', items_to_be_removed)

        # we remove any dictionary entries if the value is zero
        for entry in items_to_be_removed:
            del agent.location_memories_dict[entry]

        if print_fine_dets:
            print('\n agent.positive_locations_dict before habits', agent.positive_locations_dict)

        # if we're applying habit values and these do not deteriorate, we add the weights in agent.location_memories_habits_dict
        if params.habit_val > 0.0 and params.habit_deteriorates == 0 and len(agent.location_memories_habits_dict) > 0:

            # it's possible entries in agent.location_memories_habits_dict are not in agent.positive_locations_dict
            for entry in agent.location_memories_habits_dict:

                if entry in agent.positive_locations_dict:

                    agent.positive_locations_dict[entry] += agent.location_memories_habits_dict[entry]

                else:

                    agent.positive_locations_dict[entry] = agent.location_memories_habits_dict[entry]

        if print_fine_dets:
            print('\n agent.location_memories_habits_dict', agent.location_memories_habits_dict)
            print('\n agent.positive_locations_dict after habits', agent.positive_locations_dict)

        # if we apply Keynesian institutions, we add them here (NOTE: this code has not been tested - test when next using KIs)
        # we only proceed if len(KO_pop.pop) > 0 and if the KIs' target agents include the agent...
        if len(KO_pop.pop) > 0:

            agent_is_target = 0

            for KI in KO_pop.pop:

                if agent in KI.target_agents:
                    agent_is_target = 1

            if agent_is_target:

                # start by finding aggregate weights for positive squares
                aggregate_positive_weight = 0.0

                for entry in agent.location_memories_dict:

                    if agent.location_memories_dict[entry] > 0.0:
                        aggregate_positive_weight += agent.location_memories_dict[entry]

                for KI in KO_pop.pop:

                    if agent in KI.target_agents and day == KI.day_created:

                        str_target_loc = str(list(KI.loc))

                        # look at the total transactions-locations weight
                        keynesian_weight = keynesian_ratio * aggregate_positive_weight

                        # In the case of the agent having no locations in memory, we must force the KI weight to be non-zero:
                        if aggregate_positive_weight == 0:
                            keynesian_weight = 1

                        if str_target_loc in agent.location_memories_dict:
                            agent.location_memories_dict[str_target_loc] += keynesian_weight

                        elif str_target_loc not in agent.location_memories_dict:
                            agent.location_memories_dict[str_target_loc] = keynesian_weight

                        # we add the location to the positive_locations_dict (the entry can only be positive)
                        agent.positive_locations_dict[str_target_loc] = agent.location_memories_dict[str_target_loc]

    # if we are retargetting during a trading phase, we remove any previous targets from the agent.positive_locations_dict
    if retarg:

        # append record
        agent.previous_trgt.append(str(list(agent.grid_trgt)))

        # work out agent.wait_at_tgt_moves_pro_rata
        if wait_at_target_til_end == 0:
            agent.wait_at_tgt_moves_pro_rata = math.ceil(wait_at_tgt_moves * ((trade_moves - move) / float(trade_moves)))

            if print_fine_dets:
                print(' agent.wait_at_tgt_moves_pro_rata =', agent.wait_at_tgt_moves_pro_rata)

        if print_fine_dets:
            print('\n agent.previous_trgt: ', agent.previous_trgt)

            print('\n\n\n retarg: STARTING agent.positive_locations_dict:\n')
            for item in agent.positive_locations_dict:
                print(' location', item, 'value', agent.positive_locations_dict[item])

        # we remove any previous targets from agent.positive_locations_dict
        for target in agent.previous_trgt:
            if target in agent.positive_locations_dict:

                del agent.positive_locations_dict[target]

                if print_fine_dets:
                    print('\n removing ', target, 'from agent.positive_locations_dict')

    if print_fine_dets:
        print('\n\n\n agent.positive_locations_dict:\n')
        for item in agent.positive_locations_dict:
            print(' location', item, 'value', agent.positive_locations_dict[item])

    # when agents don't respect property rights but they have interacted at the end of the last round, and they both expect a positive result frmo interacting,
    # if they have no transaction locations in memory and no positive fight locations then they will agree a location to head towards
    if agent.agreed_meeting_point is not None:

        if print_fine_dets:
            print('\n\n agent.agreed_meeting_point is not None')
            print(' agent.agreed_meeting_point =', agent.agreed_meeting_point)

        agent.trade_movemnt = 'set'
        agent.grid_trgt = copy.copy(agent.agreed_meeting_point)

        # we set agent.agreed_meeting_point back to None - it has done its job; and it is not longer needed - if the agent retargets, it will not be used
        agent.agreed_meeting_point = None

        if print_fine_dets:
            print('\n resulting agent.grid_trgt ', agent.grid_trgt)
            print(' and agent.agreed_meeting_point =', agent.agreed_meeting_point)

    # here we impose a market location of ststst[3] if we want to force a steady state start:
    elif ststst[0] == 1 and 0 <= day < agent.agent_mem_length:

        agent.trade_movemnt = trade_movemnt
        agent.grid_trgt = ststst[3]

    # by this point, the entries in the agent's location_memories_dict are up to date.  We now find the total decayed value of all positive entries, which helps with the roulette wheel approach.
    # Note this code accounts for both targetting at the beginning of the round and re-targetting during the round
    elif agent.agreed_meeting_point is None:

        if print_fine_dets:
            print('\n\n agent.agreed_meeting_point is None \n')

        # if a target location is not longer within striking distance, we will remove it
        to_be_removed = []

        if len(agent.positive_locations_dict) == 0:

            agent.trade_movemnt = 'random'
            agent.grid_trgt = [None, None]
            agent.can_trade = 1
            agent.reached_trgt = 1

        # if the length of the positive_locations_dict is one then we can simply extract the one value as the agent's target and not have to run the roulette wheel process
        elif len(agent.positive_locations_dict) == 1:

            if print_fine_dets:
                print('\n ONLY one entry in agent.positive_locations_dict')

            # set agent.entry_loc so we can test if within_striking_dist
            exec('agent.entry_loc = %s' % list(agent.positive_locations_dict.keys())[0])

            if within_striking_dist(wait_at_target_til_end, town_grid, agent.location, agent.wait_at_tgt_moves_pro_rata, agent.agent_vision, agent.entry_loc, move, has_acted, print_dets=0):

                if print_fine_dets:
                    print(' within_striking_dist')

                agent.trade_movemnt = 'set'
                exec('agent.grid_trgt = %s' % list(agent.positive_locations_dict.keys())[0])

            else:

                to_be_removed.append(list(agent.positive_locations_dict.keys())[0])

                if print_fine_dets:
                    print(' NOT within_striking_dist')
                    print(' to_be_removed:', to_be_removed)

                # we must set trade_movemnt to random - there are no locations within striking distance
                agent.trade_movemnt = 'random'
                agent.grid_trgt = [None, None]
                agent.can_trade = 1
                agent.reached_trgt = 1

        else:

            agent.trade_movemnt = 'set'

            if trgt_sel == 'roulette':
                aggregate_wheel_weight = 0.0

            elif trgt_sel == 'WTA':
                max_dict_value = 0.0

            if print_fine_dets:
                print('\n *** finding target location now')
                print('\n trgt_sel =', trgt_sel)
                print(' retarg =', retarg)

            for entry in agent.positive_locations_dict:

                if print_fine_dets:
                    print('\n entry:', entry, 'value', agent.positive_locations_dict[entry])

                # for some reason this exec function will not run with a simple exec('entry_loc = %s' % entry), hence use of agent object
                exec('agent.entry_loc = %s' % entry)

                if within_striking_dist(wait_at_target_til_end, town_grid, agent.location, agent.wait_at_tgt_moves_pro_rata, agent.agent_vision, agent.entry_loc, move, has_acted, print_dets=0):

                    if print_fine_dets:
                        print(' within_striking_dist')

                    if trgt_sel == 'roulette':
                        aggregate_wheel_weight += agent.positive_locations_dict[entry]

                    elif trgt_sel == 'WTA' and agent.positive_locations_dict[entry] > max_dict_value:
                        max_dict_value = agent.positive_locations_dict[entry]

                else:

                    to_be_removed.append(entry)

                    if print_fine_dets:
                        print(' NOT within_striking_dist')

            if trgt_sel == 'roulette' and print_fine_dets:
                print('\n resulting aggregate_wheel_weight =', aggregate_wheel_weight)

            elif trgt_sel == 'WTA' and print_fine_dets:
                print('\n resulting max_dict_value =', max_dict_value)

            # this condition will be true if all locations in the agent.positive_locations_dict are not within striking distance
            if (trgt_sel == 'roulette' and aggregate_wheel_weight == 0.0) or (trgt_sel == 'WTA' and max_dict_value == 0.0):

                agent.trade_movemnt = 'random'
                agent.grid_trgt = [None, None]
                agent.can_trade = 1
                agent.reached_trgt = 1

            else:

                # select value for roulette wheel
                if trgt_sel == 'roulette':
                    roulette_value = random.uniform(0, aggregate_wheel_weight)

                if print_fine_dets:
                    print('\n\n roulette_value =', roulette_value)

                start_value = 0.0
                found_loc = 0
                for entry in agent.positive_locations_dict:

                    if found_loc == 0:

                        if print_fine_dets:
                            print('\n entry', entry, 'value', agent.positive_locations_dict[entry])

                        exec('agent.entry_loc = %s' % entry)

                        if within_striking_dist(wait_at_target_til_end, town_grid, agent.location, agent.wait_at_tgt_moves_pro_rata, agent.agent_vision, agent.entry_loc, move, has_acted, print_dets=0):

                            if print_fine_dets:
                                print(' within_striking_dist')

                            if trgt_sel == 'roulette':

                                if print_fine_dets:
                                    print('\n start_value', start_value, 'start_value + positive_locations_dict[entry]', start_value + agent.positive_locations_dict[entry])

                                if start_value < roulette_value < start_value + agent.positive_locations_dict[entry]:

                                    exec('agent.grid_trgt = %s' % entry)

                                    found_loc = 1

                                    if print_fine_dets:
                                        print('\n FOUND agent.grid_trgt =', agent.grid_trgt)

                                else:

                                    start_value += agent.positive_locations_dict[entry]

                                    if print_fine_dets:
                                        print('\n new start_value =', start_value)

                            elif trgt_sel == 'WTA':

                                if agent.positive_locations_dict[entry] == max_dict_value:
                                    exec('agent.grid_trgt = %s' % entry)

                                    found_loc = 1

                        else:

                            # we don't add to to_be_removed again - this would create double counting and an error

                            if print_fine_dets:
                                print(' NOT within_striking_dist')

        # if any locations were not within striking distance, we remove them from agent.positive_locations_dict
        if print_fine_dets:
            if len(to_be_removed) > 0:
                print('\n there are items to be removed:')

        for entry in to_be_removed:

            if print_fine_dets:
                print(' removing ', entry)

            del agent.positive_locations_dict[entry]

        if print_fine_dets:

            print('\n Final agent.positive_locations_dict:\n')
            for item in agent.positive_locations_dict:
                print(' location', item, 'value', agent.positive_locations_dict[item])

    # we append the previous_trgt array with whatever the agent's target is, at the start of the round
    if retarg == 0:
        agent.previous_trgt.append(str(list(agent.grid_trgt)))

    if print_fine_dets == 1:
        print('\n agent.grid_trgt =', agent.grid_trgt)
        print(' agent.trade_movemnt =', agent.trade_movemnt)
        print(' retarg =', retarg)

    # # this is necessary if two agents are fighting
    # if retarg == 0:
    #
    #     agent.previous_trgt = copy.copy(agent.grid_trgt)

    if print_fine_dets:# and len(agent.positive_locations_dict) > 0:  # and agent.grid_trgt[0] == None and agent.trade_movemnt == 'set':

        pause()

    # This function only sets an agent's target - it does not return anything


def find_nearby_agents(print_dets, print_fine_dets, dbs, town_grid, agent, trade_prices, agent_population, day, trade_when_trgt):

    best_cp_agent = None

    if print_fine_dets == 1:
        print('\n** starting find_nearby_agents()')

    agent_x_coord = agent.location[0]
    agent_y_coord = agent.location[1]

    if print_fine_dets == 1:
        print('\nagent_x_coord =', agent_x_coord)
        print('agent_y_coord =', agent_y_coord, '\n')
        print('agent.ignore_agents_array =', agent.ignore_agents_array, '\n')

    # create array to place nearby agents
    nearby_agents = []

    for x_shift in np.arange(-1 * agent.agent_vision, agent.agent_vision + 1):

        for y_shift in np.arange(-1 * agent.agent_vision, agent.agent_vision + 1):

            check_x_coord = (agent_x_coord + x_shift) % town_grid.dimen
            check_y_coord = (agent_y_coord + y_shift) % town_grid.dimen

            if print_fine_dets == 1:
                print('check_x_coord , check_y_coord =', check_x_coord, check_y_coord, 'num agents on grid =', len(town_grid.grid_agents[check_x_coord][check_y_coord]))

            # don't add the agents on own square, including the agent itself
            if check_x_coord != agent_x_coord or check_y_coord != agent_y_coord:

                for cp_agent in town_grid.grid_agents[check_x_coord][check_y_coord]:

                    if print_fine_dets == 1:
                        print('cp_agent =', cp_agent, '\n')

                    # if the agents are trading on the way to their target, they should ignore agents they have already traded with
                    if trade_when_trgt == 0 and cp_agent not in agent.ignore_agents_array:

                        # append nearby_agents
                        nearby_agents.append(cp_agent)

            else:       # any agent on full squares is ignored

                for cp_agent in town_grid.grid_agents[check_x_coord][check_y_coord]:

                    if print_fine_dets == 1:
                        print('\nlocation full: ignoring cp_agent =', cp_agent)

    if print_fine_dets == 1:
        print('\npre-nearby_agents =', nearby_agents)

    # now we run agent_crop_list through remove_unwanted_cp_agents, assuming there are agents in nearby_agents
    if len(nearby_agents) > 0:

        best_cp_agent = random.choice(nearby_agents)

    else:

        if print_fine_dets == 1:
            print('\nthere are no agents nearby')

    if print_fine_dets == 1:
        print('\npost-nearby_agents =', nearby_agents)

    return nearby_agents, best_cp_agent


def update_trade_probys(agent_population, trade_prob_mem, day, print_dets, print_fine_dets, rounds, track_agent, trade_prices, Walrasian_Trading, ststst, fight_skill, fight_skill_r, dbs):

    """This function updates each agent's trade_proby variable.  It looks at the trading data of all of an agent's neighbours
    and sets trade_proby = goods traded / goods_2_mkt over the past [trade_prob_mem] periods."""

    for agent in agent_population.pop:

        if agent == agent_population.change_agent:

            total_sales = agent.total_actual_agent_sales[day]
            total_desired_sales = agent.total_optimal_agent_sales[day]

            if total_sales == 0 or total_desired_sales == 0:

                turnover_ratio = 0

            else:

                turnover_ratio = total_sales / float(total_desired_sales)

            # we set trade_proby with a maximum of 1
            agent.trade_proby = np.min([1.0, turnover_ratio])

        else:

            if Walrasian_Trading == 1 or (ststst[0] == 1 and 0 <= day < 20):  # agent.agent_mem_length

                agent.trade_proby = 1.0

            else:

                if track_agent and agent == agent_population.tracking_agent:

                    print_fine_dets = print_dets = 1

                else:

                    print_fine_dets = print_dets = 0

                if print_fine_dets == 1:
                    print('\n\n ---> update_trade_probys---\n')
                    print(' agent =', agent)

                if trade_prices == 'variable':  # We use personal_turnover_ratio for agent and neighs to derive proby of transacting

                    # We create an array to record all the personal turnover ratio data, starting with the agent

                    #            turnover_array = []

                    total_sales = agent.total_actual_agent_sales[day]
                    total_desired_sales = agent.total_optimal_agent_sales[day]

                    if print_fine_dets == 1:
                        print('\n agent.total_actual_agent_sales[day]', agent.total_actual_agent_sales[day])
                        print(' agent.total_optimal_agent_sales[day]', agent.total_optimal_agent_sales[day])
                        print(' agent.basket_array_start ', agent.basket_array_start[0], ' agent.agent_res_array ', agent.agent_res_array[0])

                    #            if agent.personal_turnover_ratio[day] == 0:
                    #
                    #                turnover_array.append(0.0)
                    #
                    #            elif agent.personal_turnover_ratio[day] > 0:
                    #
                    #                if agent.personal_turnover_ratio[day] < 1:
                    #                    turnover_array.append(agent.personal_turnover_ratio[day])
                    #
                    #                else:
                    #                    turnover_array.append(1.0)

                    for neigh in agent.neighs:

                        if print_fine_dets:
                            print('\n neigh.home', neigh.home, 'sales', neigh.total_actual_agent_sales[day], ' vs optimal', neigh.total_optimal_agent_sales[day], ' neigh.basket_array_start ', neigh.basket_array_start[0], \
                                  ' neigh.agent_res_array ', neigh.agent_res_array[0])

                        total_sales += neigh.total_actual_agent_sales[day]
                        total_desired_sales += neigh.total_optimal_agent_sales[day]

                    #                if print_fine_dets == 1:
                    #
                    #                    print('\n neigh ', neigh)
                    #                    print(' neigh.total_actual_agent_sales[day]', neigh.total_actual_agent_sales[day])
                    #                    print(' neigh.total_optimal_agent_sales[day]', neigh.total_optimal_agent_sales[day])

                    #                if neigh.personal_turnover_ratio[day] == 0:
                    #
                    #                    turnover_array.append(0.0)
                    #
                    #                elif neigh.personal_turnover_ratio[day] > 0:      # ignore those == 0 (they did not want to trade)
                    #
                    #                    if neigh.personal_turnover_ratio[day] < 1:
                    #                        turnover_array.append(neigh.personal_turnover_ratio[day])
                    #
                    #                    else:
                    #                        turnover_array.append(1.0)
                    #
                    #            if len(turnover_array) == 0:
                    #
                    #                agent.trade_proby = 0
                    #
                    #            else:
                    #
                    #                agent.trade_proby = np.mean(turnover_array)

                    if print_fine_dets:
                        print('\n total_sales', total_sales, 'total_desired_sales', total_desired_sales)

                    if total_sales == 0 or total_desired_sales == 0:

                        self_and_neighs_turnover_ratio = 0

                    else:

                        self_and_neighs_turnover_ratio = total_sales / float(total_desired_sales)

                    # we set trade_proby with a maximum of 1
                    agent.trade_proby = np.min([1.0, self_and_neighs_turnover_ratio])

                    if print_fine_dets == 1:
                        #
                        #                print('\n\n total_sales', total_sales)
                        #                print(' total_desired_sales', total_desired_sales)
                        #                print(' self_and_neighs_turnover_ratio', self_and_neighs_turnover_ratio)

                        #                print('\n agent.personal_turnover_ratio = ', agent.personal_turnover_ratio)
                        #                print('\n turnover_array =', turnover_array)
                        print(' agent.trade_proby =', agent.trade_proby, '\n')

                    if math.isnan(agent.trade_proby):
                        print('\n math.isnan(agent.trade_proby)', math.isnan(agent.trade_proby))
                        print('\n agent.total_actual_agent_sales[day]', agent.total_actual_agent_sales[day])
                        print(' agent.total_optimal_agent_sales[day]', agent.total_optimal_agent_sales[day])
                        input("Press Enter to continue...")

        if print_fine_dets == 1:
            pause()

    if fight_skill is not None:

        #        print_fine_dets = 1

        # start by zeroing this variable
        for agent in agent_population.pop:
            agent.num_fights_today = 0

        todays_fights = dbs.fights_daily_db[day]

        total_fights = 0

        # now add one to agent.num_fights_today for all agents involved in a fight
        for fight_num in todays_fights:

            fight = dbs.fights_db[fight_num]

            for agent in agent_population.pop:

                if str(agent) == fight.initiator:
                    agent.num_fights_today += 1

                if str(agent) == fight.counterpart:
                    agent.num_fights_today += 1

            total_fights += 1

        if len(agent_population.pop) > 0:

            mean_num_fights = total_fights / float(len(agent_population.pop))

        else:

            mean_num_fights = 0

        if print_fine_dets == 1:
            print('\n total_fights =', total_fights)
            print('\n mean_num_fights =', mean_num_fights)

        #        aggr_fight_skill_ch = 0

        for agent in agent_population.pop:

            if print_fine_dets == 1:
                print('\n start fight_skill = ', agent.fight_skill)
                print(' num fights =', agent.num_fights_today)

            # deflate the existing fight_skill
            agent.fight_skill *= (1 - fight_skill_r)

            # then add the number of fights in the last round
            agent.fight_skill += agent.num_fights_today

            if print_fine_dets == 1:
                print('\n ending fight_skill = ', agent.fight_skill)

    #            # we apply agent.num_fights_today to a logistic equation, to increase or decrease
    #            adj_param = agent.num_fights_today - mean_num_fights
    #
    #            fight_skill_change = (fight_skill_r * adj_param) * (agent.fight_skill) * (1.0 - agent.fight_skill)
    #
    #            aggr_fight_skill_ch += fight_skill_change
    #
    #            if print_fine_dets == 1:
    #
    #                print('\n agent home ', agent.home, 'pre change agent.fight_skill =', agent.fight_skill)
    #
    #            agent.fight_skill += fight_skill_change
    #
    #            # set max and min
    #            if agent.fight_skill > 0.99:
    #
    #                agent.fight_skill = 0.99
    #
    #            if agent.fight_skill < 0.01:
    #
    #                agent.fight_skill = 0.01
    #
    #            if print_fine_dets == 1:
    #
    #                print('agent.num_fights_today =', agent.num_fights_today, 'adj_param =', adj_param, 'fight_skill_r =', fight_skill_r, 'fight_skill_change =', fight_skill_change, 'new agent.fight_skill=', agent.fight_skill)
    #
    #        mean_fight_skill_ch = aggr_fight_skill_ch / float(len(agent_population.pop))
    #
    #        if print_fine_dets == 1:
    #
    #            print('\n mean_fight_skill_ch =', mean_fight_skill_ch)


def end_of_day_cons_metab(track_agent, KO_pop, agent_population, print_fine_dets, dbs, round, allow_Keynes_Inst, respect_property_rights, record_dead_agents, black_shoop_exp, agents_die_old_age):

    """This function adds personal resource arrays to basket_arrays, deducts metablism costs, and orgnises dead agents."""

    # we create a counter to count the number of agents who die at the end of the day:
    dead_agent_counter = 0

    # measure the number of agents currently in the population:
    start_agent_pop = len(agent_population.pop)

    # this records the number of new agents at the very end of each round
    dbs.davy_jones_locker = []

    # clear the dead agents arrays
    if record_dead_agents == 0:
        agent_population.dead_agent_array = []

    for x in np.arange(start_agent_pop):

        working_agent_num = x - dead_agent_counter

        if track_agent and agent_population.pop[working_agent_num] == agent_population.tracking_agent:
            print_fine_dets = print_dets = 1

        else:
            print_fine_dets = print_dets = 0

        # for speed we track whether each agent is alive or dead (0 = dead, 1 = alive)
        agent_alive = 1

        if print_fine_dets == 1:
            print('\n\n *** Starting end_of_day_cons_metab')
            print('\n iter of agents (x) =', x)
            print(' len(agent_population.pop) =', len(agent_population.pop))
            print(' dead_agent_counter =', dead_agent_counter)

            print('\n *** PRE-consumption and deduction of living cost ***')
            print(' agent ', working_agent_num, 'for_strat =', agent_population.pop[working_agent_num].for_strat_array)
            print(' agent ', working_agent_num, 'basket =', agent_population.pop[working_agent_num].basket_array)
            print(' agent ', working_agent_num, 'agent_res_array =', agent_population.pop[working_agent_num].agent_res_array, '\n')

        for y in np.arange(num_res_founts):

            if agent_alive == 1:

                if print_fine_dets == 1:
                    print('iter over resources (y) =', y)

                # this line adds the basket to the agent's reserves
                agent_population.pop[working_agent_num].agent_res_array[0][y] += agent_population.pop[working_agent_num].basket_array[0][y]

                # this line deducts one unit from each agent's reserves (the cost of living)
                agent_population.pop[working_agent_num].agent_res_array[0][y] -= 1

                if print_fine_dets == 1:
                    print('resource level for res', y, 'equals:', agent_population.pop[working_agent_num].agent_res_array[0][y])

                agent_died_of_old_age = 0

                if type(agents_die_old_age) == int:

                    if agent_population.pop[working_agent_num].age >= agents_die_old_age:
                        agent_died_of_old_age = 1

                if agent_population.pop[working_agent_num].agent_res_array[0][y] <= 0 or agent_died_of_old_age:

                    # append the round number to this list to record the date of death
                    dbs.death_dates.append(round)

                    # name it
                    dead_agent = agent_population.pop[working_agent_num]

                    # if we are running the black_shoop_exp and the black shoop dies, rename agent_population.black_shoop
                    if black_shoop_exp and dead_agent in agent_population.black_shoop_list:

                        print('\n black shoop died :-(')
                        #                        agent_population.black_shoop = None

                        text = '\n\nThe Black Shoop died!! :-( day %d (lifespan = %d) \n' % (round, round - dead_agent.birth_date)
                        with open(dead_agent.black_shoop_file, 'a') as myfile:
                            myfile.write(text)

                    elif agent_died_of_old_age:

                        print('\n --> day %d: agent agent died of old age (age = %d) \n' % (round, agent_population.pop[working_agent_num].age))

                    else:

                        print('\n --> day %d: agent just died from malnutrition \n' % round)

                    agent_alive = 0  # agent dies if any reserves fall below zero
                    dead_agent_counter += 1
                    # add agent to davy_jones_locker
                    dbs.davy_jones_locker.append(agent_population.pop[working_agent_num])
                    # add agent to dead_agent_array
                    agent_population.dead_agent_array.append(agent_population.pop[working_agent_num])

                    if allow_Keynes_Inst == 'total' or allow_Keynes_Inst == 'sparse':
                        KO_pop.KI_stiffs.append(agent_population.pop[working_agent_num])

                    agent_population.pop[working_agent_num].death_date = round

                    # Add dead agent home location to dbs.dead_ags_grid_counter
                    x_coord = agent_population.pop[working_agent_num].home[0]
                    y_coord = agent_population.pop[working_agent_num].home[1]

                    dbs.dead_ags_grid_counter[x_coord][y_coord] += 1

                    # and remove from population
                    agent_population.remove_agent(working_agent_num)

            else:

                # if an agent dies, we must update neighbours in the next round
                agent_population.must_update_neighs = 1

                if print_fine_dets == 1:
                    print('\n ignore fountain iteration - agent is dead')
                    print(' len(agent_population.pop', len(agent_population.pop))

        if agent_alive == 1:

            if print_fine_dets == 1:
                print('\n***POST-consumption and deduction of living cost***')
                print('agent ', working_agent_num, 'agent_res_array =', agent_population.pop[working_agent_num].agent_res_array, '\n')

        else:

            if respect_property_rights == 0:  # if the agent dies, we remove it from all agents' reputations dictionaries

                #                print('\n agent died:', dead_agent, 'res_array check', dead_agent.agent_res_array)

                for alive_agent in agent_population.pop:

                    #                    print('\n BEFORE removal: alive_agent', alive_agent, 'str(dead_agent) in alive_agent.reputations_dict', str(dead_agent) in alive_agent.reputations_dict)

                    if alive_agent is not dead_agent and str(dead_agent) in alive_agent.reputations_dict:
                        del (alive_agent.reputations_dict[str(dead_agent)])

    #                    print('\n AFTER removal: alive_agent', alive_agent, 'str(dead_agent) in alive_agent.reputations_dict', str(dead_agent) in alive_agent.reputations_dict)

        # if print_fine_dets:
        #     pause()

    # record number of dead agents in main_db:
    dbs.main_db[2][round] = dead_agent_counter

    if print_fine_dets:
        pause()


def update_foraging_skills(for_strat_parts, print_dets, print_fine_dets, tracking_agent, track_agent, for_skill_r, agent_population, day):

    """This function updates agents' foraging skills i.e. the probabilities of detecting the various resources at the fountains."""

#    print_dets = 1
#    print_fine_dets = 1

    if print_dets == 1:
        print('\n---------- updating forraging skills ----------\n')

    # first find a norm index - this is the number of time slots in the day / number of resource fountains i.e. for an
    # average agent this will be the number of times we would expect them to visit a resource each round.
    norm_res_for = for_strat_parts / float(num_res_founts)

    if print_fine_dets == 1:
        print('norm_res_for =', norm_res_for)

    for agent in agent_population.pop:

        if track_agent and agent == agent_population.tracking_agent:

            print_fine_dets = print_dets = 1

        else:

            print_fine_dets = print_dets = 0

        if print_fine_dets == 1:
            print('\n---------- updating forraging skills ----------\n')
            print('\n foraging agent: agent.for_strat_array =', agent.for_strat_array)

        # count the number of times the agent has visited each resource:
        for fount in np.arange(num_res_founts):

            if print_fine_dets == 1:
                print('\niter fountain (fount) =', fount)

            res_counter = 0
            for slot in np.arange(for_strat_parts):

               if agent.for_strat_array[0][slot] == fount:
                   res_counter += 1

            if print_fine_dets == 1:
                print('res_counter =', res_counter)

            # we change the skill level of this agent for this resource by using a type of logistic equation
            # agent's probability skill associated with this resource:
            skill_prob = agent.detect_skills_array[0][fount]
            if print_fine_dets == 1:
                print('skill_prob =', skill_prob)

            # create a parameter to adjust the probability skill of the agent (amount of time spent forraging on this
            # resource minus the average)
            skill_adj_param = res_counter - norm_res_for

            if print_fine_dets == 1:
                print('skill_adj_param =', skill_adj_param)
                print('for_skill_r =', for_skill_r)

            # account for potential of these two being the same:
            if max_prob_det == min_prob_det:

                new_skill_prob_change = 0.0

            else:

                new_skill_prob_change = (for_skill_r * skill_adj_param) * (skill_prob - min_prob_det) * (max_prob_det - skill_prob) / (max_prob_det - min_prob_det)

            # update the agent's skill for this resource:
            agent.detect_skills_array[0][fount] += new_skill_prob_change

            if print_fine_dets == 1:
                print('new_skill_prob_change =', new_skill_prob_change)
                print('new prob skill = ', agent.detect_skills_array[0][fount])

        if print_fine_dets == 1:
            print('\n')
            pause()


def update_locations_dicts(params, respect_property_rights, town_grid, dbs, agent_population, day, wait_at_target_til_end, wait_at_tgt_moves):

    """This function takes an agent population and updates the location_memories_dict for each agent, using the day's loc_mems_array and loc_fights_array"""

    # if day > 49:
    #     print_fine_dets = 1
    # else:
    #     print_fine_dets = 0

    # if print_fine_dets:
    #     print('\n\n *** Starting update_locations_dicts - day %d' % day)

    # if day > 80:
    #     print('\n Agents locations dictionaries:')

    for agent in agent_population.pop:

        if agent == agent_population.tracking_agent and params.track_agent:
            print_fine_dets = 1
        else:
            print_fine_dets = 0

        if print_fine_dets:
            print('\n\n *** update_locations_dicts *** day', day)
            print('\n agent', agent)
            print('\n agent.location_memories_dict:\n')
            for item in agent.location_memories_dict:
                print(' ', item, '\t', agent.location_memories_dict[item])
            if len(agent.location_memories_dict) == 0:
                print(' none')
            print('\n params.target_location_weights:  ', params.target_location_weights)
            print(' params.local_fight:  ', params.local_fight)
            print('\n ----> agent.loc_mems_array[day]:', agent.loc_mems_array[day])

        # update the agents' location_memories_dict
        for trans_num in agent.loc_mems_array[day]:

            trans = dbs.trans_db[trans_num]

            if print_fine_dets:
                print('\n --> trans_num', trans_num)
                print(' trans.location', trans.location)
                print(' trans.good_a', trans.good_a)
                print(' trans.agent_a_home =', trans.agent_a_home)
                print(' trans.agent_b_home =', trans.agent_b_home)
                print(' within_striking_dist =', within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, trans.location, move=0, has_acted=0, print_dets=0))

            if trans.good_a is not None:

                if within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, trans.location, move=0, has_acted=0, print_dets=0):

                    if params.target_location_weights == 'reduced_value':

                        if str(agent) == trans.agent_a:
                            agent_net_benefit = trans.agent_a_reduced_value

                        else:
                            agent_net_benefit = trans.agent_b_reduced_value

                        if print_fine_dets:
                            print('\n agent_net_benefit', agent_net_benefit)

                    if print_fine_dets:
                        print('\n str(list(trans.location)) in agent.location_memories_dict?', str(list(trans.location)) in agent.location_memories_dict)

                    if str(list(trans.location)) not in agent.location_memories_dict:

                        if params.target_location_weights == 'crude':
                            agent.location_memories_dict[str(list(trans.location))] = 1.0

                        elif params.target_location_weights == 'reduced_value':
                            agent.location_memories_dict[str(list(trans.location))] = agent_net_benefit

                    else:

                        if params.target_location_weights == 'crude':
                            agent.location_memories_dict[str(list(trans.location))] += 1.0

                        elif params.target_location_weights == 'reduced_value':
                            agent.location_memories_dict[str(list(trans.location))] += agent_net_benefit

                if print_fine_dets:
                    print('\n resulting agent.location_memories_dict[str(list(trans.location))]:', agent.location_memories_dict[str(list(trans.location))])

        if print_fine_dets:
            print('\n post-transactions agent.location_memories_dict:\n')
            for item in agent.location_memories_dict:
                print(' ', item, '\t', agent.location_memories_dict[item])
            if len(agent.location_memories_dict) == 0:
                print(' none')

        # now we update the agents' location_memories_dict from the fights they were involved in
        if respect_property_rights == 0:

            if print_fine_dets:
                print('\n\n ----> agent.loc_fights_array[day]', agent.loc_fights_array[day])

            for fight_num in agent.loc_fights_array[day]:

                if print_fine_dets:
                    print('\n\n --> fight_num', fight_num)

                fight = dbs.fights_db[fight_num]

                if print_fine_dets:
                    print(' agent:', str(agent))

                    if str(agent) == fight.initiator:
                        print(' other agent:', fight.counterpart)
                    else:
                        print(' other agent:', fight.initiator)

                    if str(agent) == fight.initiator:
                        print('\n agent change basket', fight.agent_res_gain)
                    else:
                        print('\n agent change basket', fight.cp_agent_res_gain)

                if str(agent) != fight.winner:

                    if print_fine_dets:
                        print('\n agent lost fight')

                    if params.local_fight == 'minus_one':

                        local_list = [-1, 0, +1]

                    else:

                        local_list = [0]

                    if print_fine_dets:
                        print('\n local_list', local_list)

                    if params.target_location_weights == 'reduced_value':

                        if str(agent) == fight.initiator:
                            agent_net_benefit = fight.initiator_reduced_value

                        else:
                            agent_net_benefit = fight.counterpart_reduced_value

                        if print_fine_dets:
                            print('\n agent_net_benefit', agent_net_benefit)

                    if agent_net_benefit != 0.0:

                        for offset_x in local_list:

                            for offset_y in local_list:

                                grid_square = [(fight.location[0] + offset_x) % town_grid.dimen, (fight.location[1] + offset_y) % town_grid.dimen]

                                if print_fine_dets:
                                    print('\n grid_square', grid_square)
                                    print(' str(list(grid_square)) in agent.location_memories_dict', str(list(grid_square)) in agent.location_memories_dict)
                                    print(' within_striking_dist =', within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, grid_square, move=0, has_acted=0, print_dets=0))

                                if within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, grid_square, move=0, has_acted=0, print_dets=0):

                                    if str(list(grid_square)) not in agent.location_memories_dict:

                                        if params.target_location_weights == 'crude':
                                            agent.location_memories_dict[str(list(grid_square))] = -1.0

                                        elif params.target_location_weights == 'reduced_value':
                                            agent.location_memories_dict[str(list(grid_square))] = agent_net_benefit

                                    else:
                                        if params.target_location_weights == 'crude':
                                            agent.location_memories_dict[str(list(grid_square))] -= 1.0

                                        elif params.target_location_weights == 'reduced_value':
                                            agent.location_memories_dict[str(list(grid_square))] += agent_net_benefit

                        if print_fine_dets:
                            print('\n resulting agent.location_memories_dict[str(list(fight.location))]:', agent.location_memories_dict[str(list(fight.location))])

                else:       # then agent won the fight

                    if print_fine_dets:
                        print('\n agent won fight')

                    if params.target_location_weights == 'reduced_value':

                        if str(agent) == fight.initiator:
                            agent_net_benefit = fight.initiator_reduced_value

                        else:
                            agent_net_benefit = fight.counterpart_reduced_value

                        if print_fine_dets:
                            print('\n agent_net_benefit', agent_net_benefit)

                    if agent_net_benefit != 0.0:

                        if print_fine_dets:
                            print('\n fight.location', fight.location)
                            print(' str(list(fight.location)) in agent.location_memories_dict', str(list(fight.location)) in agent.location_memories_dict)
                            print(' within_striking_dist =', within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, fight.location, move=0, has_acted=0, print_dets=0))

                        if within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent.agent_vision, fight.location, move=0, has_acted=0, print_dets=0):

                            if str(list(fight.location)) not in agent.location_memories_dict:

                                if params.target_location_weights == 'crude':
                                    agent.location_memories_dict[str(list(fight.location))] = 1.0

                                elif params.target_location_weights == 'reduced_value':
                                    agent.location_memories_dict[str(list(fight.location))] = agent_net_benefit

                            else:
                                if params.target_location_weights == 'crude':
                                    agent.location_memories_dict[str(list(fight.location))] += 1.0

                                elif params.target_location_weights == 'reduced_value':
                                    agent.location_memories_dict[str(list(fight.location))] += agent_net_benefit

                        if print_fine_dets:
                            print('\n resulting agent.location_memories_dict[str(list(fight.location))]:', agent.location_memories_dict[str(list(fight.location))])

        # Now we introduce habituation if this is being included.  We add a value of `habit_param' to the weights for any location the agents has visited
        if print_fine_dets:
            print('\n agent.grid_trgt = ', agent.grid_trgt)
            print(' params.habit_val =', params.habit_val)

        # here we apply any habituation values - we do this if these two conditions both hold
        if params.habit_val > 0.0 and agent.grid_trgt[0] is not None:

            # if we allow habits to deteriorate, we simply add the value to agent.location_memories_dict
            if params.habit_deteriorates:

                if str(list(agent.grid_trgt)) not in agent.location_memories_dict:

                    agent.location_memories_dict[str(list(agent.grid_trgt))] = params.habit_val

                else:

                    agent.location_memories_dict[str(list(agent.grid_trgt))] += params.habit_val

            # if not, we have to record the values in a seperate database
            else:

                if str(list(agent.grid_trgt)) not in agent.location_memories_habits_dict:

                    agent.location_memories_habits_dict[str(list(agent.grid_trgt))] = params.habit_val

                else:

                    agent.location_memories_habits_dict[str(list(agent.grid_trgt))] += params.habit_val

        # note that in a specific situation, we apply habituation weights to (a) transaction location(s) -
        # this is when we switch off reinforcement learning and use habituation only to decide target locations
        if params.habit_val > 0.0 and params.memory_decay_rate == 1.0 and \
                len(agent.location_memories_habits_dict) == 0 and len(agent.loc_mems_array[day]) > 0:

            # we apply the habit_val value to the locations
            for trans_num in agent.loc_mems_array[day]:

                trans = dbs.trans_db[trans_num]

                if trans.good_a is not None:

                    agent.location_memories_habits_dict[str(list(trans.location))] = params.habit_val

                    # and record in history
                    if str(list(trans.location)) not in agent.locations_weights_hist_dict:

                        agent.locations_weights_hist_dict[str(list(trans.location))] = [np.zeros(params.rounds), np.zeros(params.rounds)]

                    agent.locations_weights_hist_dict[str(list(trans.location))][1][day] += params.habit_val

        # record the weights (both via reinforcement learning and habituation) in agent.locations_weights_hist_dict
        # First, RL:
        for location in agent.location_memories_dict:

            if location not in agent.locations_weights_hist_dict:

                agent.locations_weights_hist_dict[location] = [np.zeros(params.rounds), np.zeros(params.rounds)]

            agent.locations_weights_hist_dict[location][0][day] += agent.location_memories_dict[location]

        # Next, habituation
        if str(list(agent.grid_trgt)) not in agent.locations_weights_hist_dict:

            agent.locations_weights_hist_dict[str(list(agent.grid_trgt))] = [np.zeros(params.rounds), np.zeros(params.rounds)]

        agent.locations_weights_hist_dict[str(list(agent.grid_trgt))][1][day] += params.habit_val

        # if print_fine_dets:
        # print('\n FINAL agent.location_memories_dict:\n')

        # if day > 80:
        #     print('\n Agent home:', agent.home)
        #     print('\n location_memories_dict')
        #     for item in agent.location_memories_dict:
        #         print(' ', item, '\t', agent.location_memories_dict[item])
        #     if len(agent.location_memories_dict) == 0:
        #         print(' none')
        #     print('\n location_memories_habits_dict')
        #     for item in agent.location_memories_habits_dict:
        #         print(' ', item, '\t', agent.location_memories_habits_dict[item])
        #     if len(agent.location_memories_habits_dict) == 0:
        #         print(' none \n')

    # if print_fine_dets:
    # if day > 80:
    #     pause()


def agents_communicate(params, agent_population, fountain_population, dbs, agents_comm_prob, day, town_grid, print_dets, print_fine_dets, respect_property_rights, num_rounds, price_mean,
                       force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, agree_location, agent_mem_length, prop_steal_floor, fight_balance, adjust_props_r,
                       agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0, clear_of_fights_radius, rounds, stranger_int, strat_choice, two_tribes_inst,
                       strangers_if_unknown, track_agent):
    """This function organises the communication of agents, which is when the agents on the grid tell each other about
    their transaction locations.  An important parameter here is agents_comm_prob, which is the prob'y that an agent
    communicates with each other agent.  This is a 'slider': we can increase it until agents converge on a single
    market square (or not).  The prob'y corresponds to the prob'y that an agent interacts with each of the other agent i.e.
    the agent is given an opportunity to interact with every other agent."""

    # print_fine_dets = 1
    # print_dets = 1

    if print_fine_dets or (track_agent is not None):
        print('\n\n *** Starting agents_communicate')
        print('\n agents_comm_prob', agents_comm_prob)
        print(' agree_location ', agree_location)
        pause()

    # blank these before proceeding
    for agent in agent_population.pop:
        agent.agreed_meeting_point = None
        agent.meeting_point_cps = []

        # at this stage we also clear the agent's exp_returns_dict
        agent.exp_returns_dict = dict()
        agent.exp_int_gains_dict = dict()
        agent.exp_int_gains_dict_strangers = dict()

    # We allow the agents to interact bilaterally first - this happens regardless of agree_location (if == 'super_strong' then the above code is executed - if anthing else, i.e. strong or
    # weak) then agents are organised in this bit of code, which also allows agents to communicate transaction locations, possibly fight location, and reputation information).
    # We want to do this before the sophisticated form of organisation because the agents can communicate about reputations, which is useful for organising.

    # copy the agent population - this copy is for the iteration over all agents (for agent in...)
    copy_population = list(copy.copy(agent_population.pop))
    random.shuffle(copy_population)

    # this copy manages the residual populations - we remove each agent one by one
    copy_population_2 = copy.copy(copy_population)

    #    if print_dets == 1:
    #        print('\n copy_population', copy_population)

    #    if day >= 10:
    #
    #        print_dets = print_fine_dets = 1

    counter = 1

    # we want any pair of agents to have a probability of communicating of agents_comm_prob: we can think of this as a squre matrix with the list of agents on each axis.
    # we want to use one side of the matrix (a triangle) without the diagonal elements only.  so if we take a copy of the agent population, remove the first agent, we are left
    # with the top line of the triangular matrix to choose a cp_agent.  We then remove each agent in turn and iterate over the remaining agents.
    for agent in copy_population:

        #        if 0 < day - agent.birth_date < 5 and day > 100:
        #
        #            print_dets = 1

        #        print('\n len(copy_population)', len(copy_population))

        copy_population_2.remove(agent)

        # this copy of the population manages the iteration over residual agents (note we shuffle this too)
        #        copy_population_3 = copy.copy(copy_population_2)
        #        random.shuffle(copy_population_3)

        #        print('\n len(copy_population_2)', len(copy_population_2))

        #        if len(copy_population_2) > 0:

        # if print_fine_dets:
        #     print('\n\n\n\n\n\n\n\n -------------->agent =', agent, agent.home)

        for cp_agent in copy_population_2:

            if track_agent and (agent_population.tracking_agent == agent or cp_agent == agent_population.tracking_agent):
                print_dets = 1
                print_fine_dets = 1
            else:
                print_dets = 0
                print_fine_dets = 0

            if print_dets == 1:
                print('\n\n ------> agent =', agent, agent.home, 'tribe is', agent.tribe)
                print(' ----> cp_agent =', cp_agent, cp_agent.home, 'tribe is', cp_agent.tribe)
                print(' counter = ', counter)
                print(' len(copy_population) =', len(copy_population))
                print(' len(copy_population_2) =', len(copy_population_2))
                print(' agree_location =', agree_location)

            if cp_agent == agent:
                print('\n PROMBLEM!! agent interacting with self')
                pause()

            if print_fine_dets == 1:
                print('\n str(cp_agent) in agent.reputations_dict ', str(cp_agent) in agent.reputations_dict)
                print(' str(agent) in cp_agent.reputations_dict ', str(agent) in cp_agent.reputations_dict)

            agents_want_to_comm = 'reputations_only'

            agent_exp_gain = cp_agent_exp_gain = 0

            rand_num = random.random()

            if print_fine_dets:
                print('\n rand_num =', rand_num, 'agents_comm_prob', agents_comm_prob)

            if rand_num < agents_comm_prob and agent.tribe == cp_agent.tribe:  # if agree_location == 'none' then we just use the probability of interaction to determine if agents interact

                # if the agents don't respect property rights, they will only communicate with each other if (i) they both know of each other (in each other's reputations_dict) - if cp_agent
                # is not in agent.reputations_dict then agent won't listen and won't divulge, and vv; and (ii) if both of them think the interaction would be worthwhile (if the interaction is
                # expected to be negative for one agent then they won't listen and won't divulge.
                # We test (ii) by running the method find_exp_returns_intn for both agents and then seeing if they would expect to gain from an interaction.  Note we assume both have baskets of [1, 1].
                # Also, we assume they always communicate about reputations.
                # I might want to re-think this in due course - at the moment, I assume agents are very precious about divulging transaction locations but they are more comfortable divulging information
                # about other agents.
                # we don't test if the agents are in each other's dictionaries: we ask if the agents have heard about the other's prop_steal in the length of their memories
                if agree_location != 'none':

                    if print_fine_dets:
                        print('str(agent) in cp_agent.reputations_dict  ', str(agent) in cp_agent.reputations_dict, 'str(cp_agent) in agent.reputations_dict   ', str(cp_agent) in agent.reputations_dict)

                    if str(agent) in cp_agent.reputations_dict and str(cp_agent) in agent.reputations_dict:

                        if strat_choice == 'heuristics':

                            ag_exp_cp_prop_steal, ag_exp_cp_prop_fight_back, num_interactions = find_cp_props(agent, cp_agent, day, len_reputations_mem, print_fine_dets)
                            cp_exp_ag_prop_steal, cp_exp_ag_prop_fight_back, num_interactions = find_cp_props(cp_agent, agent, day, len_reputations_mem, print_fine_dets)

                            if print_fine_dets:
                                print('\n ag_exp_cp_prop_steal', ag_exp_cp_prop_steal, 'cp_exp_ag_prop_steal', cp_exp_ag_prop_steal)

                        # both agents must be known to have transactioned over the memory length of reach other (note no fb used here)
                        if respect_property_rights == 0 and (strat_choice == 'rational' or (strat_choice == 'heuristics' and ag_exp_cp_prop_steal is not None and cp_exp_ag_prop_steal is not None)):

                            # print_fine_dets = print_dets = 1

                            agent_exp_gain, cp_agent_exp_gain = check_if_want_to_interact(params, agent, cp_agent, agent_population, price_mean, force_prices, fixed_price, day,
                                                                                          dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                          fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill,
                                                                                          fix_ps_fb_0, stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                            if agent_exp_gain > 0 and cp_agent_exp_gain > 0:
                                agents_want_to_comm = 'both'

                #                                if day >= 0:
                #
                #                                    print('\n\n day ', day, 'agents know about each other')
                #                                    print(' ag_exp_cp_prop_steal', ag_exp_cp_prop_steal, 'cp_exp_ag_prop_steal', cp_exp_ag_prop_steal, 'num_interactions', num_interactions, '\n')
                #                                    print(' agent_exp_gain', agent_exp_gain, 'cp_agent_exp_gain', cp_agent_exp_gain)
                #                                    print('agents_want_to_comm', agents_want_to_comm, '\n')
                #
                #                                    pause()

                two_agents_communicate(params, agent_population, town_grid, agent, cp_agent, day, print_dets, respect_property_rights, num_rounds, day, agents_want_to_comm, dbs,
                                       price_mean, force_prices, fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
                                       agent_exp_gain, cp_agent_exp_gain, agent_mem_length, fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                       clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst, print_fine_dets, track_agent, strangers_if_unknown)

                if track_agent is not None and (agent_population.tracking_agent == agent or cp_agent == agent_population.tracking_agent):
                    print(' Two agents just communicated...')
                    pause()

            counter += 1

    # set these to None - speeds code up so we don't keep finding these
    dbs.latest_trans = None
    dbs.latest_fights = None

    # if we allow the agents to organise themselves in a sophisticated way (agree_location == 'super_strong') then we run this code first
    if respect_property_rights == 0 and agree_location == 'super_strong':

        # print_fine_dets = 1

        if print_fine_dets == 1:
            print('\n\n\n\n ******* starting new group organisation process')

        # first collect all the agents who have prop_steal equal to the prop_stel_floor
        min_prop_steal_agents = []
        residual_agents = []

        for agent in agent_population.pop:

            if agent.prop_steal == prop_steal_floor:

                min_prop_steal_agents.append(agent)

            else:

                residual_agents.append(agent)

        # in this situation we ensure that every agent in min_prop_steal_agents has each other in their dictionary with no fights, i.e., exp prop_steal = 0
        # here we assume two things: first, that prop_steal_floor is always zero or very low (e.g. 0.01); and, second, that if an agent doesn't have another agent in its reputations dict,
        # it will give that agent the benefit of the doubt, and assume it is an angel
        for agent in agent_population.pop:

            for cp_agent in agent_population.pop:

                if agent is not cp_agent:

                    if cp_agent is not agent_population.change_agent and agent is not agent_population.change_agent:

                        str_agent = str(agent)
                        str_cp_agent = str(cp_agent)

                        if str_agent not in cp_agent.reputations_dict:
                            cp_agent.reputations_dict[str_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                    np.zeros(shape=(num_rounds), dtype=int)]

                            # add one interaction to this (cp_agent will then assume that in this interaction the agent did not fight)
                            cp_agent.reputations_dict[str_agent][1][day] += 1
                            cp_agent.reputations_dict[str_agent][3][day] += 1

                        if str_cp_agent not in agent.reputations_dict:
                            agent.reputations_dict[str_cp_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                    np.zeros(shape=(num_rounds), dtype=int)]

                            # add one interaction to this (agent will then assume that in this interaction the agent did not fight)
                            agent.reputations_dict[str_cp_agent][1][day] += 1
                            agent.reputations_dict[str_cp_agent][3][day] += 1

                    elif agent is agent_population.change_agent:

                        str_agent = str(agent)
                        str_cp_agent = str(cp_agent)

                        if str_agent not in cp_agent.reputations_dict:
                            cp_agent.reputations_dict[str_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                    np.zeros(shape=(num_rounds), dtype=int)]

                            # the cp_agent knows from the outset that change_agent's reputation is 0.5 steal, 0.5 fb
                            cp_agent.reputations_dict[str_agent][0][day] += 1
                            cp_agent.reputations_dict[str_agent][1][day] += 2
                            cp_agent.reputations_dict[str_agent][2][day] += 1
                            cp_agent.reputations_dict[str_agent][3][day] += 2

                        if str_cp_agent not in agent.reputations_dict:
                            agent.reputations_dict[str_cp_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                    np.zeros(shape=(num_rounds), dtype=int)]

                            # add one interaction to this (agent will then assume that in this interaction the agent did not fight)
                            agent.reputations_dict[str_cp_agent][1][day] += 1
                            agent.reputations_dict[str_cp_agent][3][day] += 1

        #        if day == 0 or day > 20:

        #        print('\n first agent reputations arrays \n')
        #
        #        for agent in agent_population.pop:
        #
        #            if agent is not agent_population.pop[0]:
        #
        #                print('\n agent.home', agent.home, 'reputations 0', agent_population.pop[0].reputations_dict[str(agent)][0][0:day + 1])
        #                print(' agent.home', agent.home, 'reputations 1', agent_population.pop[0].reputations_dict[str(agent)][1][0:day + 1])
        #                print(' agent.home', agent.home, 'reputations 2', agent_population.pop[0].reputations_dict[str(agent)][2][0:day + 1])
        #                print(' agent.home', agent.home, 'reputations 3', agent_population.pop[0].reputations_dict[str(agent)][3][0:day + 1])
        #
        #        pause()

        if print_fine_dets == 1:
            print('\n len(min_prop_steal_agents)', len(min_prop_steal_agents))
            print('\n min_prop_steal_agents:\n', min_prop_steal_agents)

            print('\n len(residual_agents)', len(residual_agents))
            print('\n residual_agents:\n', residual_agents)

        #            pause()

        # it is not enough that the agents have prop_steal = floor; they must also be comfortable with each other, so we allow the agents to opt in or out of this group
        if print_fine_dets == 1:
            print('\n now each of the new A Team decides if it wants to be in or not - reputations might differ from current reality')

        already_considered_group = copy.copy(min_prop_steal_agents)
        new_angel_group = []

        for angel_agent in min_prop_steal_agents:

            if print_fine_dets == 1:
                print('\n potential A Team member home = ', angel_agent.home)

            ag_aggr_gain = 0

            for cp_agent in min_prop_steal_agents:

                if angel_agent is not cp_agent:

                    if print_fine_dets == 1:
                        print('\n other A Team member home =', cp_agent.home)

                    angel_exp_gain, cp_agent_exp_gain = check_if_want_to_interact(params, angel_agent, cp_agent, agent_population, price_mean, force_prices, fixed_price, day,
                                                                                  dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                  fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill,
                                                                                  fix_ps_fb_0, stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                    if print_fine_dets == 1:
                        print(' angel_exp_gain =', angel_exp_gain)
                        print(' cp_agent_exp_gain =', cp_agent_exp_gain)

                    ag_aggr_gain += angel_exp_gain

            if print_fine_dets == 1:
                print('\n ag_aggr_gain =', ag_aggr_gain)

            if ag_aggr_gain >= 0:

                if print_fine_dets == 1:
                    print('\n => angel is staying - awww')

                new_angel_group.append(angel_agent)

            else:

                if print_fine_dets == 1:
                    print('\n => angel is outta there')

                # add the agent to residual agents = joins the crowd
                residual_agents.append(angel_agent)

        if print_fine_dets == 1:
            print('\n len(new_angel_group) = ', len(new_angel_group))
            print('\n new_angel_group \n', new_angel_group)
            print('\n new_angel_group becomes min_prop_steal_agents')

        #            pause()

        min_prop_steal_agents = copy.copy(new_angel_group)

        # randomise min_prop_steal_agents so there are no systematic biases in this process
        if len(min_prop_steal_agents) > 1:
            random.shuffle(min_prop_steal_agents)

        if print_fine_dets == 1:
            print('\n Now considering if any agents in residual_agents should join')

        # it's possible that agents in residual_agents would want to be in this group and this group would want the agent, i.e. the resid agent doesn't have prop steal at floor but people want it
        # if both these conditions are true then we add the agent
        if len(min_prop_steal_agents) > 0:

            for resid_agent in residual_agents:

                if resid_agent not in already_considered_group:  # if they were in the original group and left, they cannot re-join

                    if print_fine_dets == 1:
                        print('\n resid_agent.home \n', resid_agent.home)

                    # first of all, does the resid_agent want to be a part of this min_prop_steal_agents group?
                    resid_aggr_exp_gain = 0
                    lovely_aggr_exp_gain = 0

                    for lovely_agent in min_prop_steal_agents:

                        resid_exp_gain, lovely_exp_gain = check_if_want_to_interact(params, resid_agent, lovely_agent, agent_population, price_mean, force_prices, fixed_price, day,
                                                                                    dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                    fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                                                                    stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                        if print_fine_dets == 1:
                            print(' lovely_agent.home', lovely_agent.home, 'resid_exp_gain =', resid_exp_gain, 'lovely_exp_gain =', lovely_exp_gain)

                        #                        if print_fine_dets == 1:
                        #                            print(' resid_exp_gain =', resid_exp_gain)
                        #                            print(' lovely_exp_gain =', lovely_exp_gain)

                        resid_aggr_exp_gain += resid_exp_gain
                        lovely_aggr_exp_gain += lovely_exp_gain

                    if print_fine_dets == 1:
                        print('\n resid_aggr_exp_gain =', resid_aggr_exp_gain)
                        print(' lovely_aggr_exp_gain =', lovely_aggr_exp_gain)

                    if resid_aggr_exp_gain >= 0 and lovely_aggr_exp_gain >= 0:  # then the resid_agent joins the group

                        if print_fine_dets == 1:
                            print('\n resid_agent joins the A group!')

                        min_prop_steal_agents.append(resid_agent)
                        residual_agents.remove(resid_agent)

                    else:

                        if print_fine_dets == 1:
                            print('\n resid_agent did not join the A group.')

        #                    pause()

        if print_fine_dets == 1:
            print('\n len(min_prop_steal_agents)', len(min_prop_steal_agents))
            print(' min_prop_steal_agents \n', min_prop_steal_agents)

            print('\n now we consider if all of these agents want to be in the group!')

        # by this stage we will have agents in min_prop_steal_agents but we have to allow the agents in the group now to leave if they want
        newer_angel_group = []

        for angel_agent in min_prop_steal_agents:

            if print_fine_dets == 1:
                print('\n potential A Team member home = ', angel_agent.home)

            ag_aggr_gain = 0

            for cp_agent in min_prop_steal_agents:

                if angel_agent is not cp_agent:

                    if print_fine_dets == 1:
                        print('\n does this agent want to remain in the group?')

                    angel_exp_gain, cp_agent_exp_gain = check_if_want_to_interact(params, angel_agent, cp_agent, agent_population, price_mean, force_prices, fixed_price, day,
                                                                                  dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                  fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                                                                  stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                    if print_fine_dets == 1:
                        print(' angel_exp_gain =', angel_exp_gain)
                        print(' cp_agent_exp_gain =', cp_agent_exp_gain)

                    ag_aggr_gain += angel_exp_gain

            if print_fine_dets == 1:
                print('\n ag_aggr_gain =', ag_aggr_gain)

            if ag_aggr_gain >= 0:

                if print_fine_dets == 1:
                    print(' angel is staying - awww')

                newer_angel_group.append(angel_agent)

            else:

                if print_fine_dets == 1:
                    print('\n angel is outta there')

                # add the agent to residual agents = joins the crowd
                residual_agents.append(angel_agent)

            if print_fine_dets == 1:
                print('\n len(newer_angel_group) = ', len(newer_angel_group))
                print('\n newer_angel_group \n', newer_angel_group)
                print(' newer_angel_group becomes min_prop_steal_agents')

        min_prop_steal_agents = copy.copy(newer_angel_group)

        if len(min_prop_steal_agents) == 1:  # just one dude, no one else: it can't agree to meet anyone this way...

            min_prop_steal_agents[0].agreed_meeting_point = None

        elif len(min_prop_steal_agents) > 1:

            agreed_loc = find_agreed_loc(min_prop_steal_agents, dbs, town_grid, agent_mem_length, day, print_fine_dets, clear_of_fights_radius, rounds)

            if print_fine_dets == 1:
                print(' agreed_loc ', agreed_loc)

            # we should have a best_grid_loc now - all the agents in the lovelies group will go to this
            for lovely_agent in min_prop_steal_agents:
                lovely_agent.agreed_meeting_point = agreed_loc
                lovely_agent.meeting_point_cps = min_prop_steal_agents

            # we add the location and number of this first group of agents to dbs.agreed_locs[day] like so
            num_ags = len(min_prop_steal_agents)
            loc_x = agreed_loc[0]
            loc_y = agreed_loc[1]

            dbs.agreed_locs[day].append([loc_x, loc_y, num_ags])

        if print_fine_dets == 1:
            print('\n\n we have the A team organised now - we focus on the residual_agents')
            print('\n len(residual_agents) = ', len(residual_agents))

            pause()

        # the first group of the loveliest agents is now sorted - we move on to the next bunch of agents who were not in this group - residual_agents
        if len(residual_agents) > 1:

            # we sort the residual_agents array by the agents' propensity to steal, so the agents with the lowest prop_steal go first
            #            print('\n residual_agents =', residual_agents)

            residual_agents = sorted(residual_agents, key=lambda agent: agent.prop_steal)

            #            print('\n  post residual_agents =', residual_agents)
            #
            #            pause()

            copy_residual_agents = copy.copy(residual_agents)

            # we allow each agent in this group to attempt to form a group, going in turns (note the group was shuffled to make it random)
            for resid_agent in residual_agents:

                if print_fine_dets == 1:
                    print('\n ----> resid_agent.home = ', resid_agent.home)

                if resid_agent in copy_residual_agents and len(copy_residual_agents) > 1:  # for the first agent this will be true but it might not be true thereafter - if the agent has been removed then it is in a group

                    if print_fine_dets == 1:
                        print(' resid_agent in copy_residual_agents and len(copy_residual_agents) > 1')

                    new_group = [resid_agent]

                    # remove the agent so we iterate over remaining
                    copy_residual_agents.remove(resid_agent)

                    if print_fine_dets == 1:
                        print(' len(copy_residual_agents) = ', len(copy_residual_agents))
                        print(' agent iterates over all other agents in copy_residual_agents: \n')

                    for cp_agent in copy_residual_agents:

                        if print_fine_dets == 1:
                            print(' cp_agent.home = ', cp_agent.home)

                        resid_agent_exp_gain, cp_agent_exp_gain = check_if_want_to_interact(params, resid_agent, cp_agent, agent_population, price_mean, force_prices, fixed_price, day,
                                                                                            dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                            fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                                                                            stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                        if print_fine_dets == 1:
                            print('\n resid_agent_exp_gain =', resid_agent_exp_gain)
                            print(' cp_agent_exp_gain =', cp_agent_exp_gain)

                        if resid_agent_exp_gain >= 0 and cp_agent_exp_gain >= 0:

                            if print_fine_dets == 1:
                                print('\n cp_agent joins resid_agent gang')

                            new_group.append(cp_agent)

                    if print_fine_dets == 1:
                        print('\n len(new_group)', len(new_group))

                    if len(new_group) == 1:

                        if print_fine_dets == 1:
                            print(' Only 1 agent in group - dude is on his own.  Next hombre or move on')

                        new_group[0].agreed_meeting_point = None

                    elif len(new_group) > 1:

                        # new_group currently has agents who will interact with the resid_agent - now allow each to decide if it wants to be part of this group

                        if print_fine_dets == 1:
                            print('\n now each of the new gang decides if it wants to be in or not')

                        final_new_group = []

                        for ag_new_group in new_group:

                            if print_fine_dets == 1:
                                print('\n potential gang member home = ', ag_new_group.home)

                            ag_aggr_gain = 0

                            for cp_agent in new_group:

                                if ag_new_group is not cp_agent:

                                    if print_fine_dets == 1:
                                        print(' does it like this gang member?')

                                    ag_new_group_exp_gain, cp_agent_exp_gain = check_if_want_to_interact(params, ag_new_group, cp_agent, agent_population, price_mean, force_prices, fixed_price,
                                                                                                         day, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std,
                                                                                                         fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                                                                                         stranger_int, strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                                    if print_fine_dets == 1:
                                        print(' ag_new_group_exp_gain =', ag_new_group_exp_gain)
                                        print(' cp_agent_exp_gain =', cp_agent_exp_gain)

                                    ag_aggr_gain += ag_new_group_exp_gain

                            if print_fine_dets == 1:
                                print('\n ag_aggr_gain =', ag_aggr_gain)

                            if ag_new_group_exp_gain >= 0:

                                if print_fine_dets == 1:
                                    print('\n dude is staying')

                                final_new_group.append(ag_new_group)

                            else:

                                if print_fine_dets == 1:
                                    print('\n dude is outta there')

                            if print_fine_dets == 1:
                                print('\n len(final_new_group) = ', len(final_new_group))

                        if print_fine_dets == 1:
                            print('\n\n final_new_group hombres now invites each of the remaining residual agents to apply to join the group, hommy \n')

                        # this group now invites each of the remaining residual agents to apply to join the group
                        for cp_agent in copy_residual_agents:

                            if cp_agent not in new_group and cp_agent not in final_new_group:  # i.e. it hasn't been considered by the final_new_group nor the resid_agent

                                if print_fine_dets == 1:
                                    print('\n ----> cp_agent.home = ', cp_agent.home)
                                    print(' cp_agent not in new_group and cp_agent not in final_new_group')

                                cp_aggr_gain = 0
                                final_new_group_aggr_gain = 0

                                for ag_final_new_group in final_new_group:

                                    if print_fine_dets == 1:
                                        print('\n ag_final_new_group.home =', ag_final_new_group.home)

                                    cp_agent_exp_gain, ag_final_new_group_exp_gain = check_if_want_to_interact(params, cp_agent, ag_final_new_group, agent_population, price_mean, force_prices, fixed_price, day, dbs,
                                                                                                               fountain_population, fight_cost, len_reputations_mem, intn_error_std, fight_balance, adjust_props_r,
                                                                                                               formal_inst, prob_fine, fine, agent_intn_beta, fight_skill, fix_ps_fb_0, stranger_int, strat_choice,
                                                                                                               two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets)

                                    if print_fine_dets == 1:
                                        print(' cp_agent_exp_gain =', cp_agent_exp_gain)
                                        print(' ag_final_new_group_exp_gain =', ag_final_new_group_exp_gain)

                                    cp_aggr_gain += cp_agent_exp_gain
                                    final_new_group_aggr_gain += ag_final_new_group_exp_gain

                                if print_fine_dets == 1:
                                    print('\n cp_aggr_gain =', cp_aggr_gain)
                                    print(' final_new_group_aggr_gain =', final_new_group_aggr_gain)

                                if cp_aggr_gain > 0 and final_new_group_aggr_gain > 0:  # then cp_agent joins final_new_group

                                    if print_fine_dets == 1:
                                        print('\n => hombre is joining the gang!')

                                    final_new_group.append(cp_agent)

                                else:

                                    if print_fine_dets == 1:
                                        print('\n => hombre is a douche, he aint joinin')

                        # now find location for group:
                        agreed_loc = find_agreed_loc(final_new_group, dbs, town_grid, agent_mem_length, day, print_fine_dets, clear_of_fights_radius, rounds)

                        if print_fine_dets == 1:
                            print('\n len(final_new_group)', len(final_new_group))
                            print('\n final_new_group ', final_new_group)
                            print(' agreed_loc', agreed_loc)

                        for ag_final_new_group in final_new_group:

                            ag_final_new_group.agreed_meeting_point = agreed_loc
                            ag_final_new_group.meeting_point_cps = final_new_group

                            # remove the agents from residual_agents
                            if ag_final_new_group in copy_residual_agents:
                                copy_residual_agents.remove(ag_final_new_group)

                        # we add the location and number of this first group of agents to dbs.agreed_locs[day] like so
                        num_ags = len(final_new_group)
                        loc_x = agreed_loc[0]
                        loc_y = agreed_loc[1]

                        dbs.agreed_locs[day].append([loc_x, loc_y, num_ags])

        if print_fine_dets == 1:
            print('\n lets look at the population after these grouping: \n')

            for agent in agent_population.pop:
                print('agent.home', agent.home, 'agreed_meeting_point =', agent.agreed_meeting_point, '  res [%1.2f %1.2f]' % (agent.agent_res_array[0][0], agent.agent_res_array[0][1]),
                      '  basket [%1.2f %1.2f]' % (agent.basket_array_start[0][0], agent.basket_array_start[0][1]), '  prop_steal %1.3f' % agent.prop_steal, 'prop_fight_back %1.3f' % agent.prop_fight_back)

    #        if day % 10 == 0:

    #        print('\n day', day, 'agents organising to meet:\n')
    #
    #        for agent in agent_population.pop:
    #
    #            print(' agent.home', agent.home, 'agreed_meeting_point =', agent.agreed_meeting_point, '  res [%1.2f %1.2f]' % (agent.agent_res_array[0][0], agent.agent_res_array[0][1]), '  basket [%1.2f %1.2f]' % (agent.basket_array_start[0][0], agent.basket_array_start[0][1]), '  prop_steal %1.3f' % agent.prop_steal, 'prop_fight_back %1.3f' % agent.prop_fight_back)
    #
    #        print('\n first agent journey that day:', agent_population.pop[0].trade_loc_rec)
    #        print('\n first agent targets that day:', agent_population.pop[0].trgt_loc_rec)
    #
    #        print('\n second agent journey that day:', agent_population.pop[1].trade_loc_rec)
    #        print('\n second agent targets that day:', agent_population.pop[1].trgt_loc_rec)
    #
    #        print('\n change_agent journey that day:', agent_population.change_agent.trade_loc_rec)
    #        print('\n change_agent targets that day:', agent_population.change_agent.trgt_loc_rec)

    if print_fine_dets == 1:
        pause()

    # summarise any groups
    #    if day > 49:
    #
    #        print('\n\n\n groupings of buddies:')
    #
    #        for agent in agent_population.pop:
    #
    #            if len(agent.meeting_point_cps) > 0:
    #
    #                print('\n\n agent.home', agent.home, 'agent.agreed_meeting_point', agent.agreed_meeting_point, 'prop_steal', agent.prop_steal, 'prop_fight_back', agent.prop_fight_back)
    #                print(' agent.meeting_point_cps', agent.meeting_point_cps)
    #                print('\n perceived reputation by agent of each cp')
    #
    #                for cp in agent.meeting_point_cps:
    #
    #                    cp_prop_steal, cp_prop_fight_back, num_interactions = find_cp_props(agent, cp, day, len_reputations_mem, print_fine_dets=1)
    #
    #                    print('\n ', cp, ': agent exp prop_steal', cp_prop_steal, 'cv actual cp.prop_steal = ', cp.prop_steal, 'agent exp prop_fight_back', cp_prop_fight_back, 'cv actual cp.prop_fight_back = ', cp.prop_fight_back)
    #                    print('\n cp in agent.reputations_dict?', str(cp) in agent.reputations_dict)

    #    pause()
    #
    #    print_dets = 0
    #    print_fine_dets = 0

    #                if print_dets == 1 and agents_want_to_comm == 'both':
    #                    input("Press Enter to continue...")

    #    # print reputation dictionaries
    #    print('\n\n reputations dictionaries:\n')

    #    for agent in agent_population.pop:
    #
    #        print(agent, agent.reputations_dict)
    #
    #    input("Press Enter to continue...")

    # Here we update the agents' perceived prices
    if print_fine_dets == 1:
        print('\n ------> Updating prices')

    # Each agent now looks through its memory and updates its agent.wkg_prices_memory
    start_round = np.max([0, day - agent.agent_mem_length])

    if print_fine_dets == 1:
        print('\n start_round =', start_round)

    for agent in agent_population.pop:

        if track_agent:
           print_dets = 1
           print_fine_dets = 1

        else:
           print_dets = 0
           print_fine_dets = 0

        if print_fine_dets == 1:
            print('\n\n agent =', agent)

        if print_fine_dets == 1:
            print('\n agent.loc_mems_array[start_round : (day + 1)] =\n')
            for day_line in agent.loc_mems_array[start_round: (day + 1)]:
                print(day_line)
            print('\n agent.loc_mems_array[day] =\n', agent.loc_mems_array[day])

        # get transactions in agent's own memories ([sell_res][buy_res])
        transs_for_prices = np.array([agent.loc_mems_array[d][i] for d in np.arange(start_round, (day + 1)) for i in np.arange(len(agent.loc_mems_array[d]))], dtype=int)

        #        # get transactions in agent's own memories ([buy_res][sell_res])
        #        transs_for_prices = np.append(transs_for_prices, np.array([agent.loc_mems_array[d][i] for d in np.arange(start_round, (day + 1)) for i in np.arange(len(agent.loc_mems_array[d])) if agent.loc_mems_array[d][i] not in transs_for_prices], dtype=int))

        # add transactions in memories from second persons ([sell_res][buy_res])
        transs_for_prices = np.append(transs_for_prices,
                                      np.array([agent.loc_mems_array_cp[d][i] for d in np.arange(start_round, (day + 1)) for i in np.arange(len(agent.loc_mems_array_cp[d])) if agent.loc_mems_array_cp[d][i] not in transs_for_prices],
                                               dtype=int))

        #        # add transactions in memories from second persons ([buy_res][sell_res])
        #        transs_for_prices = np.append(transs_for_prices, np.array([agent.loc_mems_array_cp[d][i] for d in np.arange(start_round, (day + 1)) for i in np.arange(len(agent.loc_mems_array_cp[d])) if agent.loc_mems_array_cp[d][i] not in transs_for_prices], dtype=int))

        #                if len(transs_for_prices) > 0:

        if print_fine_dets == 1:
            print('\n transs_for_prices =\n', transs_for_prices)

        # Find total value of sell_res and divide by total value of buy_res => working price
        tot_value_sell_res = 0.0
        tot_value_buy_res = 0.0

        if print_fine_dets == 1:
            print('\n working through transactions in transs_for_prices :\n')

        for trans_num in transs_for_prices:

            trans = dbs.trans_db[trans_num]

            if trans.good_a is not None:

                if print_fine_dets == 1:
                    print('\n trans_num =', trans_num)
                    print(' trans.good_a =', trans.good_a)
                    print(' trans.tot_trans_ag_sell =', trans.tot_trans_ag_sell)
                    print(' trans.good_b =', trans.good_b)
                    print(' trans.tot_trans_ag_buy =', trans.tot_trans_ag_buy)

                for sell_res in np.arange(num_res_founts):

                    for buy_res in np.arange(num_res_founts):

                        if sell_res < buy_res:  # this ensures we only do it the necessary number of times (default: 0, 1; 0, 2; and 1, 2)

                            if trans.good_a == sell_res:

                                tot_value_sell_res += trans.tot_trans_ag_sell
                                tot_value_buy_res += trans.tot_trans_ag_buy

                            elif trans.good_a == buy_res:

                                tot_value_sell_res += trans.tot_trans_ag_buy
                                tot_value_buy_res += trans.tot_trans_ag_sell

                            if print_fine_dets == 1:
                                print('\n tot_value_sell_res =', tot_value_sell_res)
                                print(' tot_value_buy_res =', tot_value_buy_res)

                            working_price = tot_value_sell_res / float(tot_value_buy_res)

                            if print_fine_dets == 1:
                                print('\n working_price =', working_price)

                            agent.wkg_prices_memory[sell_res][buy_res] = working_price
                            agent.wkg_prices_memory[buy_res][sell_res] = 1 / float(working_price)

        if print_fine_dets == 1:
            print('\n agent.wkg_prices_memory =\n', agent.wkg_prices_memory)

    if track_agent:
        pause()

#    if print_dets == 1 or print_fine_dets == 1:
#
#        input("Press Enter to continue...")


def two_agents_communicate(params, agent_population, town_grid, agent, cp_agent, round, print_dets, respect_property_rights, num_rounds, day, agents_want_to_comm, dbs,
                           price_mean, force_prices, fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
                           start_agent_exp_gain, start_cp_agent_exp_gain, agent_mem_length, fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine,
                           fight_skill, fix_ps_fb_0, clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst, print_fine_dets, track_agent, strangers_if_unknown):
    """This function organises the communication of two agents i.e. the exchange of information about transaction
    locations and also prices."""

    # print_fine_dets = 1

    if print_fine_dets:
        print('\n\n ** Starting two_agents_communicate')

    # now we allow the agents to communicate about their own transactions in the current round
    # they do this regardless of whether they have transacted with each other

    #    if day >= 0:
    #
    #        print_fine_dets = print_dets = 1

    #    else:
    #
    #        print_fine_dets = print_dets = 0
    #
    #    if agents_want_to_comm == 'both' and day > 49:
    #        print_fine_dets = print_dets = 1

    # if print_fine_dets:
    if track_agent is not None and (agent_population.tracking_agent == agent or agent_population.tracking_agent == cp_agent):
        print_dets = print_fine_dets = 1

        print('\n\n\n -> two_agents_communicate starts - day', day)
        print(' agent.home =', agent.home, 'cp_agent.home', cp_agent.home)
        print(' agree_location', agree_location)

        print('\n start_agent_exp_gain =', start_agent_exp_gain, 'start_cp_agent_exp_gain', start_cp_agent_exp_gain)
        print('\n agents_want_to_comm: ', agents_want_to_comm)

    if print_dets == 1 and agents_want_to_comm == 'both':
        print('\n agents communicate with each other about these arrays:')
        print('\n pre-agent.loc_mems_array[round] =', agent.loc_mems_array[round])
        print(' pre-cp_agent.loc_mems_array[round] =', cp_agent.loc_mems_array[round])

        print('\n other agents transactions arrays - today prior to including any new information')
        print('\n pre-agent.loc_mems_array_cp[round] =', agent.loc_mems_array_cp[round])
        print(' pre-cp_agent.loc_mems_array_cp[round] =', cp_agent.loc_mems_array_cp[round])

    if respect_property_rights == 1 or agents_want_to_comm == 'both' or agree_location == 'none':

        num_transs_in_mem = 0
        last_round_trans_loc = None

        pass_strong_to_weak_org = 0

        locs_where_traded_before = []

        all_ags_trans_locs = []

        # if (len(agent.loc_mems_array[round]) > 0 or len(cp_agent.loc_mems_array[round]) > 0): # or ((agree_location == 'weak' or agree_location == 'strong') and (len(agent.loc_fights_array[day]) > 0 or len(cp_agent.loc_fights_array[day]) > 0)):
        #     print_fine_dets = 1

        # if print_fine_dets:
        #     print('\n\n ** Starting two_agents_communicate')

        if print_fine_dets:
            print('\n does agent have anything to tell cp_agent? agent.loc_mems_array[round] =', agent.loc_mems_array[round])

        # start with the subject agent telling the cp_agent about transactions in the previous round
        if len(agent.loc_mems_array[day]) > 0:  # then there's data, add them one at a time

            if print_fine_dets:
                print('\n agent.loc_mems_array[day]:', agent.loc_mems_array[day])
                print('\n cp_agent.location_memories_dict: \n')
                for item in cp_agent.location_memories_dict:
                    print(' ', item, '\t', cp_agent.location_memories_dict[item])
                print('\n params.target_location_weights:', params.target_location_weights)

            for trans_num in agent.loc_mems_array[day]:

                trans = dbs.trans_db[trans_num]

                if print_fine_dets:
                    print('\n --> trans_num', trans_num)
                    print(' trans.location', trans.location)
                    print(' trans.good_a', trans.good_a)

                if trans.good_a is not None:

                    num_transs_in_mem += 1

                    all_ags_trans_locs.append(copy.copy(trans.location))

                    if print_fine_dets:
                        print('\n trans_num in cp_agent.loc_mems_array[day]', trans_num in cp_agent.loc_mems_array[day])

                    # we are not interested in transactions which cp_agent was involved in (double counting)
                    if trans_num not in cp_agent.loc_mems_array[day]:

                        # if str(cp_agent) is not trans.agent_a and str(cp_agent) is not trans.agent_b:

                        # if the location weights are using reduced values then we need to find these:
                        if params.target_location_weights == 'reduced_value':

                            # note that we want the agent to inform the cp_agent of its reduced value in the transaction
                            if str(agent) == trans.agent_a:
                                agent_reduced_value = trans.agent_a_reduced_value

                            elif str(agent) == trans.agent_b:
                                agent_reduced_value = trans.agent_b_reduced_value

                            if print_fine_dets:
                                print('\n agent_reduced_value', agent_reduced_value)

                        if print_fine_dets:
                            print(' str(list(trans.location)) in cp_agent.location_memories_dict', str(list(trans.location)) in cp_agent.location_memories_dict)

                        if str(list(trans.location)) not in cp_agent.location_memories_dict:

                            if params.target_location_weights == 'crude':
                                cp_agent.location_memories_dict[str(list(trans.location))] = 1.0        # cp_agent.cp_trans_weight

                            elif params.target_location_weights == 'reduced_value':
                                cp_agent.location_memories_dict[str(list(trans.location))] = agent_reduced_value * cp_agent.cp_trans_weight

                        else:

                            if params.target_location_weights == 'crude':
                                cp_agent.location_memories_dict[str(list(trans.location))] += cp_agent.cp_trans_weight

                            elif params.target_location_weights == 'reduced_value':
                                cp_agent.location_memories_dict[str(list(trans.location))] += agent_reduced_value * cp_agent.cp_trans_weight

                    if print_fine_dets:
                        print('\n resulting cp_agent.location_memories_dict[str(list(trans.location))] =', cp_agent.location_memories_dict[str(list(trans.location))])

                # find out if the two agents had transacted in the last round
                if str(cp_agent) is trans.agent_a or str(cp_agent) is trans.agent_b:
                    locs_where_traded_before.append(copy.copy(trans.location))

            if print_fine_dets:
                print('\n end of agent telling cp_agent: cp_agent.location_memories_dict: \n')
                for item in cp_agent.location_memories_dict:
                    print(' ', item, '\t', cp_agent.location_memories_dict[item])

        if print_fine_dets:
            print('\n does cp_agent have anything to tell agent? cp_agent.loc_mems_array[round] =', cp_agent.loc_mems_array[round])

        # now switch - cp_agent shows agent its transactions
        if len(cp_agent.loc_mems_array[round]) > 0:  # then there's data, add then one at a time

            if print_fine_dets:
                print('\n\n cp_agent.loc_mems_array[day]:', cp_agent.loc_mems_array[day])
                print('\n agent.location_memories_dict: \n')
                for item in agent.location_memories_dict:
                    print(' ', item, '\t', agent.location_memories_dict[item])
                print('\n params.target_location_weights', params.target_location_weights)

            for trans_num in cp_agent.loc_mems_array[round]:

                trans = dbs.trans_db[trans_num]

                if print_fine_dets:
                    print('\n --> trans_num', trans_num)
                    print(' trans.location', trans.location)
                    print(' trans.good_a', trans.good_a)

                if trans.good_a is not None:

                    num_transs_in_mem += 1

                    all_ags_trans_locs.append(copy.copy(trans.location))

                    if print_fine_dets:
                        print('\n trans_num in agent.loc_mems_array[day]', trans_num in agent.loc_mems_array[day])

                    # we are not interested in transactions which agent was involved in (double counting)
                    if trans_num not in agent.loc_mems_array[day]:

                        # if str(agent) is not trans.agent_a and str(agent) is not trans.agent_b:

                        # if the location weights are using reduced values then we need to find these:
                        if params.target_location_weights == 'reduced_value':

                            if str(cp_agent) == trans.agent_a:
                                cp_agent_reduced_value = trans.agent_a_reduced_value

                            elif str(cp_agent) == trans.agent_b:
                                cp_agent_reduced_value = trans.agent_b_reduced_value

                            if print_fine_dets:
                                print('\n cp_agent_reduced_value', cp_agent_reduced_value)

                        if print_fine_dets:
                            print('\n str(list(trans.location)) in agent.location_memories_dict', str(list(trans.location)) in agent.location_memories_dict)

                        if str(list(trans.location)) not in agent.location_memories_dict:

                            if params.target_location_weights == 'crude':
                                agent.location_memories_dict[str(list(trans.location))] = agent.cp_trans_weight

                            elif params.target_location_weights == 'reduced_value':
                                agent.location_memories_dict[str(list(trans.location))] = cp_agent_reduced_value * cp_agent.cp_trans_weight

                        else:

                            if params.target_location_weights == 'crude':
                                agent.location_memories_dict[str(list(trans.location))] += agent.cp_trans_weight

                            elif params.target_location_weights == 'reduced_value':
                                agent.location_memories_dict[str(list(trans.location))] += cp_agent_reduced_value * cp_agent.cp_trans_weight

                    if print_fine_dets:
                        print('\n resulting agent.location_memories_dict[str(list(trans.location))] =', agent.location_memories_dict[str(list(trans.location))])

                # find out if the two agents had transacted in the last round
                if str(agent) is trans.agent_a or str(agent) is trans.agent_b:
                    locs_where_traded_before.append(copy.copy(trans.location))

            if print_fine_dets:
                print('\n agent.location_memories_dict: \n')
                for item in agent.location_memories_dict:
                    print(' ', item, '\t', agent.location_memories_dict[item])

        # if print_fine_dets:
        #     pause()
        #     print_fine_dets = 0

        if print_dets == 1:
            print('\n agents transactions arrays - today AFTER including any new information')
            print('\n post- agent.loc_mems_array_cp[round] =', agent.loc_mems_array_cp[round])
            print(' post- cp_agent.loc_mems_array_cp[round] =', cp_agent.loc_mems_array_cp[round])
            print(' num_transs_in_mem', num_transs_in_mem)

        # here the agents exchange fight location information:
        if agree_location == 'weak' or agree_location == 'strong':

            if len(agent.loc_fights_array[day]) > 0:

                if print_fine_dets:
                    print('\n agent.loc_fights_array[day]:', agent.loc_fights_array[day])

                    print('\n cp_agent.location_memories_dict: \n')
                    for item in cp_agent.location_memories_dict:
                        print(' ', item, '\t', cp_agent.location_memories_dict[item])
                    print('\n params.target_location_weights', params.target_location_weights)

                for fight_num in agent.loc_fights_array[day]:

                    fight = dbs.fights_db[fight_num]

                    if print_fine_dets:
                        print('\n --> fight_num', fight_num)
                        print(' fight.location', fight.location)

                        if str(agent) == fight.initiator:
                            print(' agent change basket', fight.agent_res_gain)
                        else:
                            print(' agent change basket', fight.cp_agent_res_gain)

                    if print_fine_dets:
                        print('\n fight.initiator != str(cp_agent) and fight.counterpart != str(cp_agent)', fight.initiator != str(cp_agent) and fight.counterpart != str(cp_agent))

                    if fight.initiator != str(cp_agent) and fight.counterpart != str(cp_agent):  # the cp_agent doesn't know about the fight

                        # if the location weights are using reduced values then we need to find these:
                        if params.target_location_weights == 'reduced_value':

                            if str(agent) == fight.initiator:
                                agent_reduced_value = fight.initiator_reduced_value

                            elif str(agent) == fight.counterpart:
                                agent_reduced_value = fight.counterpart_reduced_value

                            if print_fine_dets:
                                print(' agent_reduced_value', agent_reduced_value)

                            if agent_reduced_value != 0.0:

                                if params.local_fight == 'minus_one' and agent_reduced_value < 0.0:

                                    local_list = [-1, 0, +1]

                                else:

                                    local_list = [0]

                                if print_fine_dets:
                                    print('\n local_list', local_list)

                                for offset_x in local_list:

                                    for offset_y in local_list:

                                        grid_square = [(fight.location[0] + offset_x) % town_grid.dimen, (fight.location[1] + offset_y) % town_grid.dimen]

                                        if print_fine_dets:
                                            print('\n grid_square', grid_square)
                                            print('\n str(list(grid_square)) in cp_agent.location_memories_dict:  ', str(list(grid_square)) in cp_agent.location_memories_dict)

                                            if str(list(grid_square)) in cp_agent.location_memories_dict:
                                                print(' original value: ', cp_agent.location_memories_dict[str(list(grid_square))])

                                        if str(list(grid_square)) not in cp_agent.location_memories_dict:
                                            cp_agent.location_memories_dict[str(list(grid_square))] = agent_reduced_value * cp_agent.cp_trans_weight

                                        else:
                                            cp_agent.location_memories_dict[str(list(grid_square))] += agent_reduced_value * cp_agent.cp_trans_weight

                                        if print_fine_dets:
                                            print(' resulting cp_agent.location_memories_dict[str(list(grid_square))] :', cp_agent.location_memories_dict[str(list(grid_square))])

                        elif params.target_location_weights == 'crude':

                            if str(agent) == fight.winner:
                                location_value = 1.0

                                if print_fine_dets:
                                    print('\n agent won the fight: location_value =', location_value)

                            else:
                                location_value = -1.0

                                if print_fine_dets:
                                    print('\n agent lost the fight: location_value =', location_value)

                            if params.local_fight == 'minus_one' and location_value < 0.0:

                                local_list = [-1, 0, +1]

                            else:

                                local_list = [0]

                            if print_fine_dets:
                                print('\n local_list', local_list)

                            for offset_x in local_list:

                                for offset_y in local_list:

                                    grid_square = [(fight.location[0] + offset_x) % town_grid.dimen, (fight.location[1] + offset_y) % town_grid.dimen]

                                    if print_fine_dets:
                                        print('\n grid_square', grid_square)

                                    if print_fine_dets:
                                        print('\n str(list(grid_square)) in cp_agent.location_memories_dict:  ', str(list(grid_square)) in cp_agent.location_memories_dict)

                                        if str(list(grid_square)) in cp_agent.location_memories_dict:
                                            print(' original value: ', cp_agent.location_memories_dict[str(list(grid_square))])

                                    if str(list(grid_square)) not in cp_agent.location_memories_dict:
                                        cp_agent.location_memories_dict[str(list(grid_square))] = location_value * cp_agent.cp_trans_weight

                                    else:
                                        cp_agent.location_memories_dict[str(list(grid_square))] += location_value * cp_agent.cp_trans_weight

                                    if print_fine_dets:
                                        print(' resulting cp_agent.location_memories_dict[str(list(grid_square))] :', cp_agent.location_memories_dict[str(list(grid_square))])

                if print_fine_dets:
                    print('\n end of agent telling cp_agent: cp_agent.location_memories_dict: \n')
                    for item in cp_agent.location_memories_dict:
                        print(' ', item, '\t', cp_agent.location_memories_dict[item])

            if len(cp_agent.loc_fights_array[day]) > 0:

                if print_fine_dets:
                    print('\n\n\n cp_agent.loc_fights_array[day]:', cp_agent.loc_fights_array[day])

                    print('\n agent.location_memories_dict: \n')
                    for item in agent.location_memories_dict:
                        print(' ', item, '\t', agent.location_memories_dict[item])
                    print('\n params.target_location_weights', params.target_location_weights)

                for fight_num in cp_agent.loc_fights_array[day]:

                    fight = dbs.fights_db[fight_num]

                    if print_fine_dets:
                        print('\n --> fight_num', fight_num)
                        print(' fight.location', fight.location)

                        if str(cp_agent) == fight.initiator:
                            print(' cp_agent change basket', fight.agent_res_gain)
                        else:
                            print(' cp_agent change basket', fight.cp_agent_res_gain)

                        print('\n fight.initiator != str(agent) and fight.counterpart != str(agent)', fight.initiator != str(agent) and fight.counterpart != str(agent))

                    if fight.initiator != str(agent) and fight.counterpart != str(agent):  # the agent doesn't know about the fight

                        # if the location weights are using reduced values then we need to find these:
                        if params.target_location_weights == 'reduced_value':

                            if str(cp_agent) == fight.initiator:
                                cp_agent_reduced_value = fight.initiator_reduced_value

                            elif str(cp_agent) == fight.counterpart:
                                cp_agent_reduced_value = fight.counterpart_reduced_value

                            if print_fine_dets:
                                print(' cp_agent_reduced_value', cp_agent_reduced_value)

                            if cp_agent_reduced_value != 0.0:

                                if params.local_fight == 'minus_one' and cp_agent_reduced_value < 0.0:

                                    local_list = [-1, 0, +1]

                                else:

                                    local_list = [0]

                                if print_fine_dets:
                                    print('\n local_list', local_list)

                                for offset_x in local_list:

                                    for offset_y in local_list:

                                        grid_square = [(fight.location[0] + offset_x) % town_grid.dimen, (fight.location[1] + offset_y) % town_grid.dimen]

                                        if print_fine_dets:
                                            print('\n grid_square', grid_square)
                                            print('\n str(list(grid_square)) in agent.location_memories_dict', str(list(grid_square)) in agent.location_memories_dict)

                                            if str(list(grid_square)) in agent.location_memories_dict:
                                                print(' original value: ', agent.location_memories_dict[str(list(grid_square))])

                                        if str(list(grid_square)) not in agent.location_memories_dict:
                                            agent.location_memories_dict[str(list(grid_square))] = cp_agent_reduced_value * agent.cp_trans_weight

                                        else:
                                            agent.location_memories_dict[str(list(grid_square))] += cp_agent_reduced_value * agent.cp_trans_weight

                                        if print_fine_dets:
                                            print(' resulting agent.location_memories_dict[str(list(grid_square))] :', agent.location_memories_dict[str(list(grid_square))])

                        elif params.target_location_weights == 'crude':

                            if str(cp_agent) == fight.winner:
                                location_value = 1.0

                                if print_fine_dets:
                                    print('\n cp_agent won the fight: location_value =', location_value)

                            else:
                                location_value = -1.0

                                if print_fine_dets:
                                    print('\n cp_agent lost the fight: location_value =', location_value)

                            if params.local_fight == 'minus_one' and location_value < 0.0:

                                local_list = [-1, 0, +1]

                            else:

                                local_list = [0]

                            if print_fine_dets:
                                print('\n local_list', local_list)

                            for offset_x in local_list:

                                for offset_y in local_list:

                                    grid_square = [(fight.location[0] + offset_x) % town_grid.dimen, (fight.location[1] + offset_y) % town_grid.dimen]

                                    if print_fine_dets:
                                        print('\n grid_square', grid_square)
                                        print('\n str(list(grid_square)) in agent.location_memories_dict', str(list(grid_square)) in agent.location_memories_dict)

                                        if str(list(grid_square)) in agent.location_memories_dict:
                                            print(' original value: ', agent.location_memories_dict[str(list(grid_square))])

                                    if str(list(grid_square)) not in agent.location_memories_dict:
                                        agent.location_memories_dict[str(list(grid_square))] = location_value * agent.cp_trans_weight

                                    elif str(list(grid_square)) in agent.location_memories_dict:
                                        agent.location_memories_dict[str(list(grid_square))] += location_value * agent.cp_trans_weight

                                    if print_fine_dets:
                                        print(' resulting agent.location_memories_dict[str(list(grid_square))] :', agent.location_memories_dict[str(list(grid_square))])

                if print_fine_dets:
                    print('\n end of cp_agent telling agent: agent.location_memories_dict: \n')
                    for item in agent.location_memories_dict:
                        print(' ', item, '\t', agent.location_memories_dict[item])

            # if print_fine_dets:
            #     pause()
            #     print_fine_dets = 0

        if agree_location == 'strong':

            # print_fine_dets = 1

            if print_fine_dets:
                print('\n agree_location == strong')
                print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)

            # both_group = 0

            if agent.agreed_meeting_point == None and cp_agent.agreed_meeting_point == None:

                pass_strong_to_weak_org = 1

            # in the next 2 conditions, one agent copies the other
            elif agent.agreed_meeting_point != None and cp_agent.agreed_meeting_point == None:

                cp_agent.agreed_meeting_point = copy.copy(agent.agreed_meeting_point)

            elif agent.agreed_meeting_point == None and cp_agent.agreed_meeting_point != None:

                agent.agreed_meeting_point = copy.copy(cp_agent.agreed_meeting_point)

            # elif agent.agreed_meeting_point != None and cp_agent.agreed_meeting_point != None:
            #     both_group = 1

            # Note we do not include the fourth possibility whereby both agents have agreed locations already.  In this case, nothing happens - it is possible that it is the same location
            # but it might not be.

            if print_fine_dets:
                print('\n resulting:')
                print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)
                print(' pass_strong_to_weak_org', pass_strong_to_weak_org)

            # print_fine_dets = 0
            #
            # if both_group:
            #
            #     pause()

        # the essential condition here is agree_location == 'weak' but we also only want to run this code if pass_strong_to_weak_org, when agree_loc is strong and neither agent is currently in a group
        if (agree_location == 'weak' and agent.agreed_meeting_point == None and cp_agent.agreed_meeting_point == None) or pass_strong_to_weak_org:

            # the approach we take is to compare the two agents' location_memories_dict's: if both have positive locations in common then we choose the location with the most
            # positive to meet in the next round.  Otherwise we choose a location with the highest value where one agent has a positive score and the other zero.  Otherwise,
            # we choose a location with a zero score which is furthest from any combined negative location.

            # print_fine_dets = 1

            if print_fine_dets:

                print('\n\n agent.location_memories_dict: \n')
                for item in agent.location_memories_dict:
                    print(' ', item, '\t', agent.location_memories_dict[item])

                print('\n\n cp_agent.location_memories_dict: \n')
                for item in cp_agent.location_memories_dict:
                    print(' ', item, '\t', cp_agent.location_memories_dict[item])

                print('\n')

            # we start by designating 2 values and 2 corresponding locations, for the double-positive locations and single-positive locations
            double_positive_score = 0.0
            double_positive_location = None

            single_positive_score = 0.0
            single_positive_location = None

            positive_and_negative_score = 0.0
            positive_and_negative_location = None

            # first we iterate over agent.location_memories_dict and update all four variables
            for entry in agent.location_memories_dict:

                if print_fine_dets:
                    print('\n agent[entry] =', agent.location_memories_dict[entry])

                    if entry in cp_agent.location_memories_dict:
                        print(' cp_agent[entry] =', cp_agent.location_memories_dict[entry])

                    else:
                        print(' cp_agent[entry] = None')

                if agent.location_memories_dict[entry] > 0.0 and entry in cp_agent.location_memories_dict and cp_agent.location_memories_dict[entry] > 0.0:

                    if agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry] > double_positive_score:

                        double_positive_score = agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry]
                        double_positive_location = copy.copy(entry)

                        if print_fine_dets:
                            print('\n agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry] > double_positive_score')
                            print(' NEW double_positive_score =', double_positive_score)
                            print(' double_positive_location', double_positive_location)

                if agent.location_memories_dict[entry] > 0.0 and (entry not in cp_agent.location_memories_dict or cp_agent.location_memories_dict[entry] == 0.0):

                    exec('town_grid.ad_hoc_location = %s' % entry)

                    if within_striking_dist(params.wait_at_target_til_end, town_grid, cp_agent.home, params.wait_at_tgt_moves, cp_agent.agent_vision, town_grid.ad_hoc_location, move=0, has_acted=0, print_dets=0):

                        if agent.location_memories_dict[entry] > single_positive_score:

                            single_positive_score = agent.location_memories_dict[entry]
                            single_positive_location = copy.copy(entry)

                            if print_fine_dets:
                                print('\n agent.location_memories_dict[entry] > single_positive_score')
                                print(' NEW single_positive_score =', single_positive_score)
                                print(' single_positive_location', single_positive_location)

                if (agent.location_memories_dict[entry] > 0.0 and entry in cp_agent.location_memories_dict and cp_agent.location_memories_dict[entry] < 0.0) or \
                        (agent.location_memories_dict[entry] < 0.0 and entry in cp_agent.location_memories_dict and cp_agent.location_memories_dict[entry] > 0.0):

                    if agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry] > positive_and_negative_score:

                        positive_and_negative_score = agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry]
                        positive_and_negative_location = copy.copy(entry)

                        if print_fine_dets:
                            print('\n agent.location_memories_dict[entry] + cp_agent.location_memories_dict[entry] > positive_and_negative_score')
                            print(' NEW positive_and_negative_score =', positive_and_negative_score)
                            print(' positive_and_negative_location', positive_and_negative_location)

            if print_fine_dets:
                print('\n Now looking at cp dict \n')

            # second we iterate over cp_agent.location_memories_dict and update only single_positive_score and single_positive_location
            for entry in cp_agent.location_memories_dict:

                if print_fine_dets:
                    print('\n cp_agent[entry] =', cp_agent.location_memories_dict[entry])

                    if entry in agent.location_memories_dict:
                        print(' agent[entry] =', agent.location_memories_dict[entry])

                    else:
                        print(' agent[entry] = None')

                if cp_agent.location_memories_dict[entry] > 0.0 and (entry not in agent.location_memories_dict or agent.location_memories_dict[entry] == 0.0):

                    exec('town_grid.ad_hoc_location = %s' % entry)

                    if within_striking_dist(params.wait_at_target_til_end, town_grid, agent.home, params.wait_at_tgt_moves, agent.agent_vision, town_grid.ad_hoc_location, move=0, has_acted=0, print_dets=0):

                        if cp_agent.location_memories_dict[entry] > single_positive_score:

                            single_positive_score = cp_agent.location_memories_dict[entry]
                            single_positive_location = copy.copy(entry)

                            if print_fine_dets:
                                print('\n cp_agent.location_memories_dict[entry] > single_positive_score')
                                print(' NEW single_positive_score =', single_positive_score)
                                print(' single_positive_location', single_positive_location)

            # by now we will know if any location has a positive value for both agents (and the highest combined value if there was more than 1) and what that location is.
            # we will also have the same information for any location which has a positive value for one agent and no value for (or is not known to) the other.

            if print_fine_dets:
                print('\n\n double_positive_score =', double_positive_score)
                print(' double_positive_location =', double_positive_location)

                print('\n single_positive_score =', single_positive_score)
                print(' single_positive_location =', single_positive_location)

                print('\n positive_and_negative_score =', positive_and_negative_score)
                print(' positive_and_negative_location =', positive_and_negative_location)

            if double_positive_score > 0.0:

                exec('agent.agreed_meeting_point = %s' % double_positive_location)
                cp_agent.agreed_meeting_point = copy.copy(agent.agreed_meeting_point)

                if print_fine_dets:
                    print('\n double_positive_score > 0.0')
                    print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                    print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)

            elif single_positive_score > 0.0:

                exec('agent.agreed_meeting_point = %s' % single_positive_location)
                cp_agent.agreed_meeting_point = copy.copy(agent.agreed_meeting_point)

                if print_fine_dets:
                    print('\n single_positive_score > 0.0')
                    print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                    print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)

            elif positive_and_negative_score > 0.0:

                exec('agent.agreed_meeting_point = %s' % positive_and_negative_location)
                cp_agent.agreed_meeting_point = copy.copy(agent.agreed_meeting_point)

                if print_fine_dets:
                    print('\n positive_and_negative_score > 0.0')
                    print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                    print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)

            else:

                # if the three methods above do not work then we find a location which is zero to both agents.  We do this by developing a combined dictionary,
                # and then choosing a random location which is not in this dictionary.

                # find a combined dictionary
                combined_dict = copy.copy(agent.location_memories_dict)

                for entry in cp_agent.location_memories_dict:

                    if entry in combined_dict:
                        combined_dict[entry] += cp_agent.location_memories_dict[entry]

                    else:
                        combined_dict[entry] = cp_agent.location_memories_dict[entry]

                if print_fine_dets:
                    print('\n len(agent.location_memories_dict) =', len(agent.location_memories_dict))
                    print(' len(cp_agent.location_memories_dict) =', len(cp_agent.location_memories_dict))
                    print(' len(combined_dict) =', len(combined_dict))

                # start with a random location
                random_loc = [random.randint(0, town_grid.dimen - 1), random.randint(0, town_grid.dimen - 1)]
                str_random_loc = str(random_loc)

                wsd_agent = within_striking_dist(params.wait_at_target_til_end, town_grid, agent.home, params.wait_at_tgt_moves, agent.agent_vision, random_loc, move=0, has_acted=0, print_dets=0)
                wsd_cp = within_striking_dist(params.wait_at_target_til_end, town_grid, cp_agent.home, params.wait_at_tgt_moves, cp_agent.agent_vision, random_loc, move=0, has_acted=0, print_dets=0)

                if print_fine_dets:
                    print('\n initial random_loc =', random_loc)
                    print(' wsd_agent', wsd_agent)
                    print(' wsd_cp', wsd_cp)

                # we don't want to be stuck in a while loop so we give it 10 opportunities to find a solution
                while_counter = 0

                while str_random_loc in combined_dict and while_counter < 10 and wsd_agent == 0 and wsd_cp == 0:

                    random_loc = [random.randint(0, town_grid.dimen - 1), random.randint(0, town_grid.dimen - 1)]
                    str_random_loc = str(random_loc)

                    wsd_agent = within_striking_dist(params.wait_at_target_til_end, town_grid, agent.home, params.wait_at_tgt_moves, agent.agent_vision, random_loc, move=0, has_acted=0, print_dets=0)
                    wsd_cp = within_striking_dist(params.wait_at_target_til_end, town_grid, cp_agent.home, params.wait_at_tgt_moves, cp_agent.agent_vision, random_loc, move=0, has_acted=0, print_dets=0)

                    if print_fine_dets:
                        print('\n NEXT random_loc =', random_loc)
                        print(' wsd_agent', wsd_agent)
                        print(' wsd_cp', wsd_cp)

                    while_counter += 1

                if while_counter < 10:

                    agent.agreed_meeting_point = random_loc
                    cp_agent.agreed_meeting_point = random_loc

                else:

                    agent.agreed_meeting_point = None
                    cp_agent.agreed_meeting_point = None

                if print_fine_dets:
                    print('\n while_counter =', while_counter)
                    print(' agent.agreed_meeting_point', agent.agreed_meeting_point)
                    print(' cp_agent.agreed_meeting_point', cp_agent.agreed_meeting_point)

            # print(' day %d two agents organised to meet at %s' % (day, agent.agreed_meeting_point))

            if print_fine_dets:
                print('\n\n')
                pause()
                # print_fine_dets = 0

    # now we allow the pair to communicate about any fights / muggings they were involved in, assuming the agents don't respect property rights - this is how reputations are spread.
    # note we don't bother with this when agents are 'rational' - reputations are irrelevant.
    if respect_property_rights == 0 and strat_choice == 'heuristics':

        # if len(agent.trades_array) > 0 or len(cp_agent.trades_array) > 0:
        #     print_fine_dets = 1

        if print_fine_dets == 1:

            print('\n\n\n\n Reputations:\n')
            print(' len(agent.trades_array)', len(agent.trades_array))
            print(' len(agent.fights_array)', len(agent.fights_array))
            print(' len(cp_agent.trades_array)', len(cp_agent.trades_array))
            print(' len(cp_agent.fights_array)', len(cp_agent.fights_array))

            print('\n\n agent divulging:', agent)
            print('\n start cp_agent.reputations_dict:')

            start_day = np.max([0, day - params.agent_mem_length])

            if len(cp_agent.reputations_dict) == 0:

                print('\n none')

            else:

                for rep_agent in cp_agent.reputations_dict:

                    ps = np.sum(cp_agent.reputations_dict[str(rep_agent)][0][start_day:day + 1]) / float(np.sum(cp_agent.reputations_dict[str(rep_agent)][1][start_day:day + 1]))

                    if np.sum(cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]) > 0.0:

                        pfb = np.sum(cp_agent.reputations_dict[str(rep_agent)][2][start_day:day + 1]) / float(np.sum(cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]))

                    else:

                        pfb = 0.0

                    for ag in agent_population.pop:
                        if str(ag) == rep_agent:

                            print('\n rep_agent', rep_agent, 'exp prop_steal %4.2f' % ps, 'vs actual %4.2f' % ag.prop_steal, 'exp prop_fight_back %4.2f' % pfb, 'vs actual %4.2f' % ag.prop_fight_back)

                    print(' ps numerator =', cp_agent.reputations_dict[str(rep_agent)][0][start_day:day + 1], 'ps denom =', cp_agent.reputations_dict[str(rep_agent)][1][start_day:day + 1])
                    print(' pfb numerator =', cp_agent.reputations_dict[str(rep_agent)][2][start_day:day + 1], 'pfb denom =', cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1])

            print('\n agent.fights_array', agent.fights_array, '\n\n')

        for fight_record in agent.fights_array:

            # unpack
            other_agent, fought, fought_back, i_fought, i_fought_back = fight_record

            if print_fine_dets:
                print(' fight: other agent', other_agent, 'fought?', fought, 'fought_back?', fought_back, 'i_fought?', i_fought, 'i_fought_back?', i_fought_back)

            if other_agent == str(cp_agent):

                if print_fine_dets == 1:
                    print('\n other agent in fights_array is the same as the cp_agent')

            else:

                if fought == 0:

                    fought_back_tally = 1  # the other agent wanted to trade; I tried to steal; it could have fought back

                else:

                    fought_back_tally = 0  # vice versa

                if other_agent not in cp_agent.reputations_dict:
                    cp_agent.reputations_dict[other_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                cp_agent.reputations_dict[other_agent][0][day] += fought
                cp_agent.reputations_dict[other_agent][1][day] += 1
                cp_agent.reputations_dict[other_agent][2][day] += fought_back
                cp_agent.reputations_dict[other_agent][3][day] += fought_back_tally

                # if agents have informed each other about any fight
                cp_agent.need_to_update_reps[str(other_agent)] = 1

        #        if len(agent.trades_array) > 10:
        #
        #            for transaction in agent.trades_array:
        #
        #                print('\n good_a', transaction.good_a)         # Transaction
        #                print(' good_b', transaction.good_b)         # Transaction
        #                print(' agent_a_home', transaction.agent_a_home)         # Transaction
        #                print(' agent_b_home', transaction.agent_b_home)         # Transaction
        #                print(' tot_trans_ag_sell', transaction.tot_trans_ag_sell)         # Transaction
        #                print(' tot_trans_ag_sell', transaction.tot_trans_ag_buy)         # Transaction
        #
        #            pause()

        if print_fine_dets:
            print('\n\n agent.trades_array ', agent.trades_array, '\n\n')

        for transaction in agent.trades_array:

            if print_fine_dets:
                print('\n transaction', transaction, 'location', transaction.location)

            if transaction.agent_a != str(agent) and transaction.agent_a != str(cp_agent):

                if print_fine_dets:
                    print(' transaction.agent_a', transaction.agent_a)

                if transaction.agent_a not in cp_agent.reputations_dict:

                    if print_fine_dets:
                        print(' transaction.agent_a not in cp_agent.reputations_dict')

                    cp_agent.reputations_dict[transaction.agent_a] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                        np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                cp_agent.reputations_dict[transaction.agent_a][1][day] += 1

                if print_fine_dets:
                    print(' transaction.agent_a added')

                # set this so will have to update reps data
                cp_agent.need_to_update_reps[transaction.agent_a] = 1

            elif transaction.agent_b != str(agent) and transaction.agent_b != str(cp_agent):

                if print_fine_dets:
                    print(' transaction.agent_b ', transaction.agent_b)

                if transaction.agent_b not in cp_agent.reputations_dict:

                    cp_agent.reputations_dict[transaction.agent_b] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds),dtype=int),
                                                                        np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                    if print_fine_dets:
                        print(' transaction.agent_b not in cp_agent.reputations_dict')

                cp_agent.reputations_dict[transaction.agent_b][1][day] += 1

                if print_fine_dets:
                    print(' transaction.agent_b added')

                # set this so will have to update reps data
                cp_agent.need_to_update_reps[transaction.agent_b] = 1

        if print_fine_dets == 1:
            print('\n end cp_agent.reputations_dict: ')

            if len(cp_agent.reputations_dict) == 0:

                print('\n none')

            else:

                for rep_agent in cp_agent.reputations_dict:

                    ps = np.sum(cp_agent.reputations_dict[str(rep_agent)][0][start_day:day + 1]) / float(np.sum(cp_agent.reputations_dict[str(rep_agent)][1][start_day:day + 1]))

                    if np.sum(cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]) > 0.0:

                        pfb = np.sum(cp_agent.reputations_dict[str(rep_agent)][2][start_day:day + 1]) / float(np.sum(cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]))

                    else:

                        pfb = 0.0

                    for ag in agent_population.pop:
                        if str(ag) == rep_agent:

                            print('\n rep_agent', rep_agent, 'exp prop_steal %4.2f' % ps, 'vs actual %4.2f' % ag.prop_steal, 'exp prop_fight_back %4.2f' % pfb, 'vs actual %4.2f' % ag.prop_fight_back)

                    print(' ps numerator =', cp_agent.reputations_dict[str(rep_agent)][0][start_day:day + 1], 'ps denom =', cp_agent.reputations_dict[str(rep_agent)][1][start_day:day + 1])
                    print(' pfb numerator =', cp_agent.reputations_dict[str(rep_agent)][2][start_day:day + 1], 'pfb denom =', cp_agent.reputations_dict[str(rep_agent)][3][start_day:day + 1])

        if print_fine_dets == 1:

            print('\n\n\n cp_agent divulging:', cp_agent)
            print('\n start agent.reputations_dict')

            if len(agent.reputations_dict) == 0:

                print('\n none')

            else:

                start_day = np.max([0, day - 10])

                for rep_agent in agent.reputations_dict:

                    ps = np.sum(agent.reputations_dict[str(rep_agent)][0][start_day:day + 1]) / float(np.sum(agent.reputations_dict[str(rep_agent)][1][start_day:day + 1]))

                    if np.sum(agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]) > 0.0:

                        pfb = np.sum(agent.reputations_dict[str(rep_agent)][2][start_day:day + 1]) / float(np.sum(agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]))

                    else:

                        pfb = 0.0

                    for ag in agent_population.pop:
                        if str(ag) == rep_agent:

                            print(' rep_agent', rep_agent, 'exp prop_steal %4.2f' % ps, 'vs actual %4.2f' % ag.prop_steal, 'exp prop_fight_back %4.2f' % pfb, 'vs actual %4.2f' % ag.prop_fight_back)

                    print(' ps numerator =', agent.reputations_dict[str(rep_agent)][0][start_day:day + 1], 'ps denom =', agent.reputations_dict[str(rep_agent)][1][start_day:day + 1])
                    print(' pfb numerator =', agent.reputations_dict[str(rep_agent)][2][start_day:day + 1], 'pfb denom =', agent.reputations_dict[str(rep_agent)][3][start_day:day + 1])

        if print_fine_dets == 1:

            print('\n cp_agent.fights_array', cp_agent.fights_array, '\n')

        for fight_record in cp_agent.fights_array:

            # unpack
            other_agent, fought, fought_back, i_fought, i_fought_back = fight_record

            if print_fine_dets:
                print(' fight: other agent', other_agent, 'fought?', fought, 'fought_back?', fought_back, 'i_fought?', i_fought, 'i_fought_back?', i_fought_back)

            if other_agent == str(agent):

                if print_fine_dets == 1:
                    print('\n other agent in fights_array is the same as the agent')

            else:

                if fought == 0:

                    fought_back_tally = 1  # the other agent wanted to trade; I tried to steal; it could have fought back

                else:

                    fought_back_tally = 0  # vice versa

                if other_agent not in agent.reputations_dict:
                    agent.reputations_dict[other_agent] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                agent.reputations_dict[other_agent][0][day] += fought
                agent.reputations_dict[other_agent][1][day] += 1
                agent.reputations_dict[other_agent][2][day] += fought_back
                agent.reputations_dict[other_agent][3][day] += fought_back_tally

                # set this so will have to update reps data
                agent.need_to_update_reps[str(other_agent)] = 1

        if print_fine_dets:
            print('\n\n cp_agent.trades_array ', cp_agent.trades_array)

        for transaction in cp_agent.trades_array:

            if print_fine_dets:
                print('\n transaction', transaction, 'location', transaction.location)

            if transaction.agent_a != str(cp_agent) and transaction.agent_a != str(agent):        # then agent_a was the agent's counterpart

                if print_fine_dets:
                    print(' transaction.agent_a', transaction.agent_a)
                    # print(' transaction.agent_a != str(agent)')

                if transaction.agent_a not in agent.reputations_dict:

                    if print_fine_dets:
                        print(' transaction.agent_a not in agent.reputations_dict')

                    agent.reputations_dict[transaction.agent_a] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                   np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                agent.reputations_dict[transaction.agent_a][1][day] += 1

                if print_fine_dets:
                    print(' transaction.agent_a added')

                # set this so will have to update reps data
                agent.need_to_update_reps[transaction.agent_a] = 1

            elif transaction.agent_b != str(cp_agent) and transaction.agent_b != str(agent):        # then agent_b was the agent's counterpart

                if print_fine_dets:
                    print(' transaction.agent_b ', transaction.agent_b)

                if transaction.agent_b not in agent.reputations_dict:

                    if print_fine_dets:
                        print(' transaction.agent_b not in agent.reputations_dict')

                    agent.reputations_dict[transaction.agent_b] = [np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int),
                                                                   np.zeros(shape=(num_rounds), dtype=int), np.zeros(shape=(num_rounds), dtype=int)]

                agent.reputations_dict[transaction.agent_b][1][day] += 1

                if print_fine_dets:
                    print(' transaction.agent_b added')

                # set this so will have to update reps data
                agent.need_to_update_reps[transaction.agent_b] = 1

        if print_fine_dets == 1:  # and len(cp_agent.fights_array) > 0:
            print('\n end agent.reputations_dict')

            if len(agent.reputations_dict) == 0:

                print('\n none')

            else:

                for rep_agent in agent.reputations_dict:

                    ps = np.sum(agent.reputations_dict[str(rep_agent)][0][start_day:day + 1]) / float(np.sum(agent.reputations_dict[str(rep_agent)][1][start_day:day + 1]))

                    if np.sum(agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]) > 0.0:

                        pfb = np.sum(agent.reputations_dict[str(rep_agent)][2][start_day:day + 1]) / float(np.sum(agent.reputations_dict[str(rep_agent)][3][start_day:day + 1]))

                    else:

                        pfb = 0.0

                    for ag in agent_population.pop:
                        if str(ag) == rep_agent:

                            print('\n rep_agent', rep_agent, 'exp prop_steal %4.2f' % ps, 'vs actual %4.2f' % ag.prop_steal, 'exp prop_fight_back %4.2f' % pfb, 'vs actual %4.2f' % ag.prop_fight_back)

                    print(' ps numerator =', agent.reputations_dict[str(rep_agent)][0][start_day:day + 1], 'ps denom =', agent.reputations_dict[str(rep_agent)][1][start_day:day + 1])
                    print(' pfb numerator =', agent.reputations_dict[str(rep_agent)][2][start_day:day + 1], 'pfb denom =', agent.reputations_dict[str(rep_agent)][3][start_day:day + 1])

    if (track_agent and track_agent <= day and (agent == agent_population.tracking_agent or cp_agent == agent_population.tracking_agent) and \
            (len(agent.trades_array) > 0 or len(cp_agent.trades_array) > 0 or len(agent.fights_array) > 0 or len(cp_agent.fights_array) > 0 or agents_want_to_comm == 'both')):
        print('\n -> two_agents_communicate ends \n')
        # pause()

    # pause()


def find_agreed_loc(agent_group, dbs, town_grid, agent_mem_length, day, print_fine_dets, clear_of_fights_radius, total_rounds):
    """This function takes a group of agents, searches dbs.trans_db and finds the best location for all of them to meet."""

    # print_fine_dets = 1

    if print_fine_dets == 1:
        print('\n\n ** find_agreed_loc starting on day', day)

    # find combined dictionary of all agents:
    combined_dict = copy.copy(agent_group[0].location_memories_dict)

    for agent in agent_group[1:]:

        for entry in agent.location_memories_dict:

            if entry in combined_dict:
                combined_dict[entry] += agent.location_memories_dict[entry]

            else:
                combined_dict[entry] = agent.location_memories_dict[entry]

    # now check for any positive locations
    max_value = 0.0
    best_loc = None

    for entry in combined_dict:

        if combined_dict[entry] > max_value:
            max_value = combined_dict[entry]
            best_loc = copy.copy(entry)

    if max_value > 0.0:

        exec('town_grid.best_grid_loc = %s' % best_loc)

        best_grid_loc = town_grid.best_grid_loc

        if print_fine_dets:
            print('\n max_value > 0.0: ', max_value)
            print(' best_grid_loc', best_grid_loc)
            pause()

    else:

        if print_fine_dets:
            print('\n max_value == 0.0: ', max_value)

        best_grid_loc = find_location_furthest_away(town_grid, combined_dict, print_fine_dets, complete=0)

    return best_grid_loc


def check_if_want_to_interact(params, resid_agent, lovely_agent, agent_population, price_mean, force_prices, fixed_price, day, dbs, fountain_population, fight_cost, len_reputations_mem,
                              intn_error_std, fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0, stranger_int,
                              strat_choice, two_tribes_inst, strangers_if_unknown, print_dets, print_fine_dets):
    """This function tests if two agents want to interact or not, returning the expected gains (losses) of both agents."""

    if print_fine_dets:
        print('\n Starting check_if_want_to_interact function')

        print('\n str(lovely_agent) in resid_agent.exp_returns_dict: ', str(lovely_agent) in resid_agent.exp_returns_dict)
        print(' str(resid_agent) in lovely_agent.exp_returns_dict: ', str(resid_agent) in lovely_agent.exp_returns_dict)

    # if they are in each other's exp_returns_dict then we don't need to look further = we return the values already calculated
    if str(lovely_agent) in resid_agent.exp_returns_dict and str(resid_agent) in lovely_agent.exp_returns_dict:

        #        print('\n agents in each others exp_returns_dict: resid_agent.exp_returns_dict[str(lovely_agent)] =', resid_agent.exp_returns_dict[str(lovely_agent)],\
        #              'lovely_agent.exp_returns_dict[str(resid_agent)', lovely_agent.exp_returns_dict[str(resid_agent)])

        if print_fine_dets == 1:
            print('\n agents know about each other: resid_agent_exp_gain =', resid_agent.exp_returns_dict[str(lovely_agent)], 'lovely_agent_exp_gain =', lovely_agent.exp_returns_dict[str(resid_agent)])

        return resid_agent.exp_returns_dict[str(lovely_agent)], lovely_agent.exp_returns_dict[str(resid_agent)]

    # if not, we calculated the expected returns, add them to the exp_returns_dict's and return the values also build_tot_cons_surp_array
    else:

        simulated_int = 1
        move = None
        #        print_fine_dets = 0
        #        print_dets = 0
        if strat_choice == 'heuristics' and (strangers_if_unknown == 0 or (strangers_if_unknown and resid_agent.agent_knows_cp_dict[str(lovely_agent)] and lovely_agent.agent_knows_cp_dict[str(resid_agent)])):

            resid_agent_exp_gain, resid_agent_cp_exp_gain = resid_agent.find_exp_returns_intn(params, lovely_agent, agent_population, print_dets, price_mean, force_prices, fixed_price,
                                                                                              day, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std, print_fine_dets,
                                                                                              fight_balance, adjust_props_r, agent_intn_beta, move, formal_inst, prob_fine, fine, simulated_int,
                                                                                              fight_skill, fix_ps_fb_0, stranger_int, strat_choice, strangers_if_unknown)

            lovely_agent_exp_gain, lovely_agent_agent_exp_gain = lovely_agent.find_exp_returns_intn(params, resid_agent, agent_population, print_dets, price_mean, force_prices, fixed_price,
                                                                                                    day, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std, print_fine_dets,
                                                                                                    fight_balance, adjust_props_r, agent_intn_beta, move, formal_inst, prob_fine, fine, simulated_int,
                                                                                                    fight_skill, fix_ps_fb_0, stranger_int, strat_choice, strangers_if_unknown)

        else:  # strat_choice == 'rational' or == 'heuristics' nut one or both agents don't know each other.
            # note we only have to run this once as both exp gains will be identical whichever agent checks - this is not true when we use heuristics (because perceived props are different to actual)

            use_start_basket = simulated_int
            agent_dec, cp_agent_dec, resid_agent_exp_gain, lovely_agent_exp_gain = strangers_interact(params, agent_population.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population,
                                                                                                      print_dets, print_fine_dets, use_start_basket, resid_agent, lovely_agent, agent_population.stranger_int, formal_inst, prob_fine, fine,
                                                                                                      two_tribes_inst, fight_cost)

        resid_agent.exp_returns_dict[str(lovely_agent)] = resid_agent_exp_gain
        lovely_agent.exp_returns_dict[str(resid_agent)] = lovely_agent_exp_gain

        if print_fine_dets == 1:
            #        if day >= 10:

            print('\n agents did NOT know about each other: ')
            print('\n agent.basket_array_start ', resid_agent.basket_array_start, 'cp_agent.basket_array_start ', lovely_agent.basket_array_start)
            print('\nresid_agent_exp_gain =', resid_agent_exp_gain, 'lovely_agent_exp_gain =', lovely_agent_exp_gain)
            pause()

        return resid_agent_exp_gain, lovely_agent_exp_gain


def place_agent_in_best_spot(agent_population, town_grid, agent, two_tribes):
    """When the agent population is allowed to vary but agent homes are even spaced then finding a home for a new agent is tricky: how we do this is we find the spot furthest from all other agents and place the new agent there."""

    # start with finding existing homes:
    existing_homes = []

    for current_agent in agent_population.pop:

        if current_agent.home[0] is not None and current_agent.tribe == agent.tribe:
            x_coord = current_agent.home[0]
            y_coord = current_agent.home[1]

            existing_homes.append([x_coord, y_coord])

    #    print('\n existing_homes', existing_homes)

    # we measure the z_dist from all homes on every place on the grid and chose the place with the highest z_dist
    max_z_dist = 0

    # create array to collect possible locations
    poss_new_homes = []

    #    print('\n existing_homes =', existing_homes)

    if two_tribes == 0:
        x_min = 0
        x_max = town_grid.dimen

        y_min = 0
        y_max = town_grid.dimen

    if two_tribes == 1 and agent.tribe == 'sharks':
        x_min = 0
        x_max = int(town_grid.dimen / 2.0)

        y_min = 0
        y_max = int(town_grid.dimen / 2.0)

    if two_tribes == 1 and agent.tribe == 'jets':
        x_min = int(town_grid.dimen / 2.0 + 1)
        x_max = town_grid.dimen

        y_min = int(town_grid.dimen / 2.0 + 1)
        y_max = town_grid.dimen

    for x_coord in range(x_min, x_max):

        for y_coord in range(y_min, y_max):

            # larger than highest possible z_dist
            min_z_dist = (town_grid.dimen ** 2) + 1

            for existing_home in existing_homes:

                x_dist = (x_coord - existing_home[0]) % town_grid.dimen

                if x_dist > town_grid.dimen / 2.0:
                    x_dist = town_grid.dimen - x_dist

                y_dist = (y_coord - existing_home[1]) % town_grid.dimen

                if y_dist > town_grid.dimen / 2.0:
                    y_dist = town_grid.dimen - y_dist

                z_dist = ((x_dist ** 2) + (y_dist ** 2)) ** 0.5

                if z_dist < min_z_dist:
                    min_z_dist = z_dist

            if min_z_dist > max_z_dist:
                poss_new_homes = [[x_coord, y_coord]]
                max_z_dist = min_z_dist

            if min_z_dist == max_z_dist:
                poss_new_homes.append([x_coord, y_coord])

    #    print('\n poss_new_homes =', poss_new_homes)

    new_home = random.choice(poss_new_homes)

    #    print('new_home', new_home)

    new_home = np.array(new_home)

    #                print('x_coord', x_coord, 'y_coord', y_coord, 'existing_home', existing_home, 'x_dist =', x_dist,'y_dist =', y_dist, 'min_z_dist =', min_z_dist)

    #    here = 0

    #    print('\n new_home', new_home)

    #    input("Press Enter to continue")

    return new_home


def update_for_strats(fountain_population, for_strat_parts, agent_population, print_dets,
                      tracking_agent, trade_prob, track_agent, print_fine_dets, trade_loc, day, dbs, trade_prices, Walrasian_Trading, two_tribes):
    """This function updates agents' foraging strategies.  This function allows each agent to adjust one of its foraging
    strategy elements, and to simulate different strategies for this element.  The agent calculates 'what if' expected
    end-of-round baskets under each strategy.  If a basket would require the agent to trade then it uses historical
    trading probabilities (the number of agents who traded / the number of agents wanting to trade) as an estimate of the
    likelihood of trading."""

    #    here = 0

    #    print_fine_dets = 1

    # Find mean foutain levels in each time slot

    if two_tribes == 0:

        mean_fount_levels = np.zeros(shape=(agent_population.for_strat_parts, num_res_founts))

        for time_slot in range(agent_population.for_strat_parts):

            for res in range(num_res_founts):
                # the resource levels of this fountain (fount_visd) at the random slot time (beginning & end) were:
                start_res_level = dbs.res_level_array[time_slot][res]
                end_res_level = dbs.res_level_array_ends[time_slot][res]

                # the average of these two:
                mean_res_level = np.mean([start_res_level, end_res_level])

                # record this
                mean_fount_levels[time_slot][res] = mean_res_level

    elif two_tribes == 1:

        mean_fount_levels_sharks = np.zeros(shape=(agent_population.for_strat_parts, num_res_founts))

        for time_slot in range(agent_population.for_strat_parts):

            for res in range(num_res_founts):
                # the resource levels of this fountain (fount_visd) at the random slot time (beginning & end) were:
                start_res_level = dbs.res_level_array[time_slot][res]
                end_res_level = dbs.res_level_array_ends[time_slot][res]

                # the average of these two:
                mean_res_level = np.mean([start_res_level, end_res_level])

                # record this
                mean_fount_levels_sharks[time_slot][res] = mean_res_level

        mean_fount_levels_jets = np.zeros(shape=(agent_population.for_strat_parts, num_res_founts))

        for time_slot in range(agent_population.for_strat_parts):

            for res in range(num_res_founts):
                # the resource levels of this fountain (fount_visd) at the random slot time (beginning & end) were:
                start_res_level = dbs.res_level_array[time_slot][2 + res]
                end_res_level = dbs.res_level_array_ends[time_slot][2 + res]

                # the average of these two:
                mean_res_level = np.mean([start_res_level, end_res_level])

                # record this
                mean_fount_levels_jets[time_slot][res] = mean_res_level

    # Now iterate over agents
    for agent in agent_population.pop:

        if track_agent and agent == agent_population.tracking_agent:

            print_fine_dets = print_dets = 1

        else:

            print_fine_dets = print_dets = 0

        if two_tribes == 1 and agent.tribe == 'sharks':
            mean_fount_levels = mean_fount_levels_sharks

        if two_tribes == 1 and agent.tribe == 'jets':
            mean_fount_levels = mean_fount_levels_jets

        if print_fine_dets == 1:
            print('\n\n\n\n *************** running update_for_strats() ******\n')
            print(' day = ', day)
            print('\n res_level_array =\n\n', dbs.res_level_array)
            print('\n dbs.res_level_array_ends =\n\n', dbs.res_level_array_ends)
            print('\n mean_fount_levels =\n\n', mean_fount_levels)
            print('\n start agent.for_strat_array =', agent.for_strat_array)

        # choose a random time slot:
        random_slot = np.random.randint(0, agent_population.for_strat_parts)

        agent.foraging_strat_data[day][0] = random_slot

        #        # designate 'random_res' as the resource currently being forraged in this time slot
        #        random_res = agent.for_strat_array[0][random_slot]

        # identify the resource for which the agent has highest probability (denote spec_res)
        max_skill = np.max(agent.detect_skills_array)

        for prob in np.arange(len(agent.detect_skills_array[0])):

            if agent.detect_skills_array[0][prob] == max_skill:
                # we denote the specialization resource that which has the highest probability
                spec_res = prob

        # the technique I developed worked but it is unecessarily complicated - here I will focus specifically in random_slot
        # - we only need to find the expected yield for this slot (converted by trading if different to min_res)
        exp_for_yields = []
        exp_for_yields_no_noise = []

        # here I find the expected yields of the time slots for all slots other than the random_slot
        other_slot_yields = np.zeros(shape=num_res_founts)

        for time_slot in range(agent_population.for_strat_parts):

            if time_slot != random_slot:

                # this is the resource foraged for in the time slot:
                res = agent.for_strat_array[0][time_slot]

                # this is its mean level during that time slot
                mean_res_level = mean_fount_levels[time_slot][res]

                # this is the starting level of the fountain
                if two_tribes == 0:

                    initial_resource_level = dbs.init_res_levels[day][res]

                elif two_tribes == 1:

                    if agent.tribe == 'sharks':

                        initial_resource_level = dbs.init_res_levels[day][res]

                    elif agent.tribe == 'jets':

                        initial_resource_level = dbs.init_res_levels[day][2 + res]

                # and this is the resulting yield
                E_yield = agent.detect_skills_array[0][res] * (mean_res_level / float(initial_resource_level))

                other_slot_yields[res] += E_yield

                if print_fine_dets == 1:
                    print('\n ------> time_slot', time_slot, 'with res', res)
                    print(' mean_res_level', mean_res_level, 'initial_resource_level', initial_resource_level)
                    print(' agent.detect_skills_array[0][res]', agent.detect_skills_array[0][res])
                    print(' E_yield', E_yield)

        if print_fine_dets == 1:
            print('\n other_slot_yields', other_slot_yields)

        # find resource the agent is most concerned about
        agent.aggr_res_array = agent.basket_array + agent.agent_res_array

        exp_post_for_ress = agent.basket_array[0] + agent.agent_res_array[0] - np.ones(shape=num_res_founts) + other_slot_yields

        min_res_value = np.min(exp_post_for_ress)

        r_min = 0

        for res in range(num_res_founts):

            if exp_post_for_ress[res] == min_res_value:
                r_min = res

        agent.foraging_strat_data[day][1] = r_min

        # for analysis: I have a theory that agents oversell the resources they forage most for i.e. they end up deficient in the resource they had more of in their basket
        if agent.basket_array_start[0][r_min] > 0:

            if agent.basket_array_start[0][r_min] > agent.basket_array[0][r_min]:  # the agent must have sold the resource it ended up being deficient in

                agent.over_sell_counter += 1

            else:

                agent.didnt_over_sell_counter += 1

        if print_fine_dets == 1:
            print('\n start agent.for_strat_array =', agent.for_strat_array)
            print(' random_slot =', random_slot)
            print(' random_res =', agent.for_strat_array[0][random_slot])
            print('\n agent.agent_res_array =', agent.agent_res_array)
            print('\n agent.basket_array_start =', agent.basket_array_start)
            print(' agent.optimal_transs_systemic[day] =', agent.optimal_transs_systemic[day])
            print(' agent.basket_array =', agent.basket_array)
            print(' agent.aggr_res_array =', agent.aggr_res_array)
            print('\n other_slot_yields =', other_slot_yields)
            print(' exp_post_for_ress =', exp_post_for_ress)
            #            print('\n agent.over_sell_counter = %d (%2.2f)' % (agent.over_sell_counter, agent.over_sell_counter / float(day + 1)))
            #            print(' agent.didnt_over_sell_counter = %d (%2.2f)' % (agent.didnt_over_sell_counter, agent.didnt_over_sell_counter / float(day + 1)))
            print(' agent.detect_skills_array =', agent.detect_skills_array)

            print('\n r_min =', r_min)
            print(' spec_res =', spec_res)
            print('\n Iterating....')

        # the expected yield of any resource is driven by the equation p_j . (E(l) / L) . Price . prob_trans)
        for res in range(num_res_founts):

            # the average reserve level for this resource in this time slot:
            mean_res_level = mean_fount_levels[random_slot][res]

            agent.foraging_strat_data[day][2 + res] = mean_res_level

            if two_tribes == 0:

                initial_resource_level = dbs.init_res_levels[day][res]

            elif two_tribes == 1:

                if agent.tribe == 'sharks':

                    initial_resource_level = dbs.init_res_levels[day][res]

                elif agent.tribe == 'jets':

                    initial_resource_level = dbs.init_res_levels[day][2 + res]

            if print_fine_dets == 1:
                print('\n ------> res iter =', res)
                print('\n mean_res_level', mean_res_level)
                print(' mean_res_level as proportion', mean_res_level / float(initial_resource_level))
                print(' agent.detect_skills_array[0][res] =', agent.detect_skills_array[0][res])

            if res == r_min:

                E_yield = agent.detect_skills_array[0][res] * (mean_res_level / float(initial_resource_level))

                if print_fine_dets == 1:
                    print('\n res == r_min')
                    print(' agent.detect_skills_array[0][res] =', agent.detect_skills_array[0][res])
                    print('\n E_yield', E_yield)

            else:

                if Walrasian_Trading == 1:

                    mean_working_price = dbs.optimal_price_array[day][res][r_min]

                else:

                    if trade_prices == 'variable':
                        mean_working_price = agent.wkg_prices_memory[res][r_min]
                    elif trade_prices == 'fixed':
                        mean_working_price = 1.0

                if print_fine_dets == 1:
                    print(' mean_working_price =', mean_working_price)
                    print('\n dbs.optimal_price_array[day][res][r_min]', dbs.optimal_price_array[day][res][r_min])

                agent.foraging_strat_data[day][2 + num_res_founts] = mean_working_price

                E_yield = agent.detect_skills_array[0][res] * (mean_res_level / float(initial_resource_level)) * (1 / float(mean_working_price)) * agent.trade_proby

                if print_fine_dets == 1:
                    print('\n res != r_min')
                    print(' price (number of units of r_min received for 1 unit of non-r_min), the inverse of mean_working_price =', 1 / mean_working_price)
                    print(' agent.trade_proby =', agent.trade_proby)
                    print('\n E_yield', E_yield)

            exp_for_yields_no_noise.append(E_yield)

            # now we adjust the expected yield by a cognition factor - agent.cognition_factor is a used as a standard deviation to vary the E_yield
            E_yield = random.normalvariate(E_yield, agent.cognition_factor)

            # make sure yield does not dip below 0 - agents wouldn't expect negative yield
            E_yield = np.max([0, E_yield])

            if print_fine_dets == 1:
                print('\n agent.cognition_factor =', agent.cognition_factor)
                print('\n adjusted E_yield =', E_yield)

            exp_for_yields.append(E_yield)

            agent.foraging_strat_data[day][3 + num_res_founts + res] = E_yield

        if print_fine_dets == 1:
            print('\n ------------- End of Iterations ---------------')
            #            print('\n exp_for_yields_no_noise = [%1.2f, %1.2f]' % (exp_for_yields_no_noise[0], exp_for_yields_no_noise[1]))
            print('\n start agent.for_strat_array =', agent.for_strat_array, 'random_slot =', random_slot, '(res', agent.for_strat_array[0][random_slot], ')')
            print(' r_min =', r_min, 'spec_res =', spec_res)
            print(' agent.trade_proby = %1.2f' % (agent.trade_proby))
            print('\n exp_for_yields = [%1.2f, %1.2f]' % (exp_for_yields[0], exp_for_yields[1]))
            print('\n agent.foraging_strat_data[day] =', agent.foraging_strat_data[day])

        max_yield = np.max(exp_for_yields)

        res_choice = 0

        choice_array = []

        for res in range(num_res_founts):

            if exp_for_yields[res] == max_yield:
                choice_array.append(res)

        res_choice = random.choice(choice_array)

        agent.for_strat_array[0][random_slot] = res_choice

        if print_fine_dets == 1:
            print('\n res_choice =', res_choice)
            print(' new agent.for_strat_array[0] =', agent.for_strat_array[0])

        # here we work out the threshold probability above which the agent would switch to not r_min.
        # For now, do this for 2 resources only.

        if num_res_founts == 2:

            # record data in agent.thresh_probs_array
            # agent.thresh_probs_array: [0] is round [1] is threshold_0_1, which is the threshold probability for the agent choosing res 0 and trading to to res 1,
            # [2] threshold_0_1 is the same as 1 but other way round, [3] is actual exp prob of transacting, [4] is detection prob for res 0, and [5] is the same for res 1

            threshold_1_to_0 = (agent.detect_skills_array[0][0] / agent.detect_skills_array[0][1]) * (mean_fount_levels[random_slot][0] / mean_fount_levels[random_slot][1]) * (1 / agent.wkg_prices_memory[0][1])
            threshold_0_to_1 = (agent.detect_skills_array[0][1] / agent.detect_skills_array[0][0]) * (mean_fount_levels[random_slot][1] / mean_fount_levels[random_slot][0]) * (1 / agent.wkg_prices_memory[1][0])

            if math.isnan(threshold_1_to_0) or math.isnan(threshold_0_to_1) or math.isnan(agent.trade_proby) or math.isnan(agent.detect_skills_array[0][0]) or math.isnan(agent.detect_skills_array[0][1]) or math.isnan(
                    1 / agent.wkg_prices_memory[1][0]) or math.isnan(1 / agent.wkg_prices_memory[0][1]):

                print('\n\n agent', agent, 'r_min', r_min)
                print('\n agent.detect_skills_array[0]', agent.detect_skills_array[0][0])
                print(' agent.detect_skills_array[1]', agent.detect_skills_array[0][1])
                print('\n mean_fount_levels[random_slot][0]', mean_fount_levels[random_slot][0])
                print(' mean_fount_levels[random_slot][1]', mean_fount_levels[random_slot][1])
                print('\n chart_price_1_0', 1 / agent.wkg_prices_memory[1][0])
                print(' chart_price_0_1', 1 / agent.wkg_prices_memory[0][1])
                print('\n threshold_0_to_1', threshold_0_to_1)
                print(' threshold_1_to_0', threshold_1_to_0)
                print('\n agent.trade_proby', agent.trade_proby)

                print('\n fountain levels:\n\n')
                for time_slot in range(agent_population.for_strat_parts):

                    for res in range(num_res_founts):

                        # the resource levels of this fountain (fount_visd) at the random slot time (beginning & end) were:
                        if two_tribes == 0:
                            start_res_level = dbs.res_level_array[time_slot][res]
                            end_res_level = dbs.res_level_array_ends[time_slot][res]

                        if two_tribes == 1:

                            if agent.tribe == 'sharks':

                                start_res_level = dbs.res_level_array[time_slot][res]
                                end_res_level = dbs.res_level_array_ends[time_slot][res]

                            elif agent.tribe == 'jets':

                                start_res_level = dbs.res_level_array[time_slot][2 + res]
                                end_res_level = dbs.res_level_array_ends[time_slot][2 + res]

                        # the average of these two:
                        mean_res_level = np.mean([start_res_level, end_res_level])

                        print('\n time_slot', time_slot, 'res', res, 'start_res_level', start_res_level, 'end_res_level', end_res_level, 'mean_res_level', mean_res_level)

                if math.isnan(threshold_1_to_0) or math.isnan(threshold_0_to_1):
                    threshold_1_to_0 = None
                    threshold_0_to_1 = None

            #                input("Press Enter to continue...")

            agent.thresh_probs_array[1][day] = threshold_0_to_1
            agent.thresh_probs_array[2][day] = threshold_1_to_0
            agent.thresh_probs_array[3][day] = agent.trade_proby
            agent.thresh_probs_array[4][day] = agent.detect_skills_array[0][0]
            agent.thresh_probs_array[5][day] = agent.detect_skills_array[0][1]
            agent.thresh_probs_array[6][day] = 1 / agent.wkg_prices_memory[0][1]
            agent.thresh_probs_array[7][day] = 1 / agent.wkg_prices_memory[1][0]

        if print_fine_dets == 1:
            pause()


def new_births(params, agent_population, print_dets, print_fine_dets, agent_homes, init_res_level, dbs, day,
               for_strat_parts, agent_res_init, vision_len,
               dimen, rounds, trade_moves, trade_when_trgt, popn_ch, agent_mem_length, cp_trans_weight,
               wait_at_tgt_moves, trade_prices, agent_res_init_std, mating_thresh, cognition_factor,
               town_grid, run_folder, trade_movemnt, agents_comm_prob, respect_property_rights,
               start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
               children_props, child_prop_std, prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor,
               adjust_props_r, agent_intn_beta, two_tribes, black_shoop_exp, black_shoop_pop, fight_skill, agents_die_old_age,
               black_shoop_prop_start, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, start_child_births, price_mean, force_prices,
               fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
               fight_balance, formal_inst, prob_fine, fine, clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst,
               track_agent, strangers_if_unknown):

    """This function organises new births in to the population."""

    here = 0
    # pause_code = 0
    #
    # print_fine_dets = 0
    # for agent in agent_population.pop:
    #     if np.min(agent.agent_res_array) > mating_thresh:
    #         print_fine_dets = 1

    if print_fine_dets == 1:
        print('\n\n---- births... ----\n')
        print('mating_thresh =', mating_thresh)
        print('len(agent_population.pop) = ', len(agent_population.pop))
        print('popn_ch = ', popn_ch)

    # first decide how many new births there will be at the end of the period - we use a logistic equation.
    new_agents_res_arrays = []
    new_agent_props = []
    new_children_tribes = []
    parents_array = []

    if popn_ch == 'vary':

        # we find new_agents by using a counter in this instance
        new_agents = 0

        for agent in agent_population.pop:

            agent_min_res = np.min(agent.agent_res_array)

            if agent_min_res > mating_thresh:

                cp_agent = random.choice(agent_population.pop)

                cp_agent_min_res = np.min(cp_agent.agent_res_array)

                # if cp_agent_min_res > mating_thresh:
                #     pause_code = 1
                #     print('\n agents are getting it on...')
                #     print(' agent_min_res =', agent_min_res)
                #     print(' cp_agent_min_res =', cp_agent_min_res)

                if agent is not cp_agent and cp_agent_min_res >= mating_thresh and agent.tribe == cp_agent.tribe and agent.age > start_child_births and cp_agent.age > start_child_births \
                        and agent is not agent_population.change_agent and cp_agent is not agent_population.change_agent:  # then the agents will mate

                    new_children_tribes.append(copy.copy(agent.tribe))

                    # if an agent is born, we must update neighbours in the next round
                    agent_population.must_update_neighs = 1

                    #                        print_fine_dets = 1

                    if print_fine_dets == 1:
                        print('\n\n **** agents mated')
                        print('\n agent.agent_res_array =', agent.agent_res_array)
                        print(' cp_agent.agent_res_array =', cp_agent.agent_res_array)

                    parent_1 = agent
                    parent_2 = cp_agent

                    parents_array.append([parent_1, parent_2])

                    # we instantiate the child with 1/4 of both its parents resources, we append new_agents_res_arrays
                    start_res_ratio = agent_res_init / (float(mating_thresh) * 2.0)

                    starting_res = (agent.agent_res_array + cp_agent.agent_res_array) * start_res_ratio

                    new_agents_res_arrays.append(starting_res)

                    parent_1.resources_to_children += (agent.agent_res_array[0] * start_res_ratio)
                    parent_2.resources_to_children += (cp_agent.agent_res_array[0] * start_res_ratio)

                    if print_fine_dets == 1:
                        print('\nparent_1.resources_to_children:', parent_1.resources_to_children)
                        print('\nparent_2.resources_to_children:', parent_2.resources_to_children)

                    if children_props == 'mean_props_and_dev':

                        # find mean of parent props and then add / subtr some value depending on std-dev
                        child_prop_steal_mean = np.mean([parent_1.prop_steal, parent_2.prop_steal])
                        child_prop_steal = random.normalvariate(child_prop_steal_mean, child_prop_std)

                        child_prop_fight_back_mean = np.mean([parent_1.prop_fight_back, parent_2.prop_fight_back])
                        child_prop_fight_back = random.normalvariate(child_prop_fight_back_mean, child_prop_std)

                        # constraint to max and min values
                        if child_prop_steal > prop_steal_ceil:
                            child_prop_steal = prop_steal_ceil

                        if child_prop_steal < prop_steal_floor:
                            child_prop_steal = prop_steal_floor

                        if child_prop_fight_back > prop_fight_back_ceil:
                            child_prop_fight_back = prop_fight_back_ceil

                        if child_prop_fight_back < prop_fight_back_floor:
                            child_prop_fight_back = prop_fight_back_floor

                        if print_fine_dets:
                            print('\n parent_1.prop_steal', parent_1.prop_steal, 'parent_2.prop_steal', parent_2.prop_steal, 'mean', child_prop_steal_mean, 'resulting prop_steal (with var)', child_prop_steal)
                            print('\n parent_1.prop_fight_back', parent_1.prop_fight_back, 'parent_2.prop_fight_back', parent_2.prop_fight_back, 'mean', child_prop_fight_back_mean, 'resulting fight_back (with var)', child_prop_fight_back)

                        new_agent_props.append([child_prop_steal, child_prop_fight_back])

                    new_agents += 1

                    deduct_ress = np.array([[agent_res_init for res in range(num_res_founts)]])

                    # deduct resources from parents: half the initial resource amount each
                    agent.agent_res_array -= deduct_ress / 2.0
                    cp_agent.agent_res_array -= deduct_ress / 2.0

                    # add a child to each parent's tally
                    agent.number_of_children += 1
                    cp_agent.number_of_children += 1

                    if print_fine_dets == 1:
                        print('\n\n Agents mated!')
                        print('\n new_agents =', new_agents)
                        print('\n deduct_ress =', deduct_ress)
                        print('\n new agent.agent_res_array =', agent.agent_res_array)
                        print(' new cp_agent.agent_res_array =', cp_agent.agent_res_array)

        #                    else:
        #
        #                        print_fine_dets = 0

        if print_fine_dets == 1:
            print('\n new_agent_props', new_agent_props)

    elif popn_ch == 'fixed':  # we only replace dead agents

        new_agents = len(dbs.davy_jones_locker)

    # record new_agents in main_db:
    dbs.main_db[1][day] = new_agents

    #    if new_agents > 0:
    #
    #        print_dets = 1
    #        print_fine_dets = 1

    if print_fine_dets == 1:
        print('\n new_agents =', new_agents)
        print(' new_agents_res_arrays =', new_agents_res_arrays)

    # add the new agents to a new_agent_array and also the agent_population
    new_agent_array = []
    brand_new_agents = []

    for i in np.arange(new_agents):

        if popn_ch == 'vary':

            starting_res = new_agents_res_arrays[i]

        else:

            starting_res = None

        if popn_ch == 'vary' and children_props == 'mean_props_and_dev':

            starting_props = new_agent_props[i]

        else:

            starting_props = [0.5, 0.5]

        if popn_ch == 'vary' and two_tribes == 1:

            new_child_tribe = new_children_tribes[i]

        else:

            new_child_tribe = 'none'

        if print_fine_dets == 1:
            print('\n popn_ch ', popn_ch)
            print('\n data going in to create_new_agent: starting_res', starting_res, 'starting_props', starting_props)

        instantiation = 0
        agents_die_old_age = None

        new_agent = create_new_agent(dbs, day, for_strat_parts, agent_res_init, agent_res_init_std,
                                     print_dets, vision_len, dimen, print_fine_dets, rounds,
                                     trade_moves, trade_when_trgt, agent_mem_length, cp_trans_weight,
                                     wait_at_tgt_moves, trade_prices, cognition_factor, trade_movemnt, starting_res,
                                     start_props, start_prop_steal_mean, start_prop_steal_std, start_prop_fight_back_mean, start_prop_fight_back_std,
                                     prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, starting_props, instantiation,
                                     new_child_tribe, fight_skill, agents_die_old_age, fix_prop_fb, fixed_prop_steal, fix_ps_fb_0, popn_ch)

        if popn_ch == 'vary':

            new_agent.parents = parents_array[i]

        else:

            new_agent.parents = [None, None]

        # we track these values so need to record them
        new_agent.prop_steal_record = copy.copy(new_agent.prop_steal)
        new_agent.prop_fight_back_record = copy.copy(new_agent.prop_fight_back)
        new_agent.agent_res_array_record = copy.copy(new_agent.agent_res_array)
        new_agent.detect_skills_array_record = copy.copy(new_agent.detect_skills_array)

        # if we are conducting the black sheep experiment and this is the first child in the sim, then make it the black sheep child
        if (black_shoop_exp == 1 and len(agent_population.black_shoop_list) == 0) or (black_shoop_exp == 'all' and len(agent_population.pop) >= black_shoop_pop):
            #           print('\n pre agent_population.black_shoop', agent_population.black_shoop, 'new_agent.agent_res_array =', new_agent.agent_res_array)

            agent_population.black_shoop_list.append(new_agent)

            # create a data file to record black_shoop data
            black_shoop_file = '%s/black_shoop_file_%d.txt' % (run_folder, len(agent_population.black_shoop_list) - 1)

            with open(black_shoop_file, 'a') as myfile:
                myfile.write("This text file is for recording notes concerning a black shoop (a child which is born with prop_steal and prop_fight_back = 1)\n")

            new_agent.black_shoop_file = black_shoop_file

            # this is a switch so we don't create any more black shoops after the first
            #            agent_population.black_shoop_seen = 1

            new_agent.prop_steal = black_shoop_prop_start
            new_agent.prop_fight_back = black_shoop_prop_start

            print('\n A black shoop was born!!!! - baaaaaaaaaaaaaa!!!!!')

            text = '\n\nThe Black Shoop was born on day %d  |  home = %s\n' % (day, new_agent.home)
            with open(new_agent.black_shoop_file, 'a') as myfile:
                myfile.write(text)

        brand_new_agents.append(new_agent)

        # note that new agents will have a randomly placed home by default so we need to overwrite this if we would like
        if agent_homes == 'even':  # we need to overwrite the agent's location

            if popn_ch == 'fixed':  # then the agent just uses the dead agent's home

                dead_agent = dbs.davy_jones_locker[i]

                new_agent.home = dead_agent.home

            elif popn_ch == 'vary':  # then we need to place the agent in the largest space possible

                new_agent.home = place_agent_in_best_spot(agent_population, town_grid, new_agent, two_tribes)

        agent_population.add_agent(new_agent)
        new_agent_array.append(new_agent)

        if new_agents > 0:
            print('\n *** New agent created: day', day, ' mating_thresh', mating_thresh, 'prop_steal ', new_agent.prop_steal, ' prop_fight_back ', new_agent.prop_fight_back, ' home ', new_agent.home, 'tribe ', new_agent.tribe,
                  'res_array = ', new_agent.agent_res_array, '\n')

    # if our tracking agent has died this round, we replace it with one of the new births
    if agent_population.tracking_agent in dbs.davy_jones_locker and len(new_agent_array) > 0:
        agent_population.tracking_agent = random.choice(new_agent_array)

    # record population size at end of day
    dbs.main_db[3][day] = len(agent_population.pop)

    if two_tribes:

        num_sharks = 0
        num_jets = 0

        for agent in agent_population.pop:

            if agent.tribe == 'sharks':

                num_sharks += 1

            elif agent.tribe == 'jets':

                num_jets += 1

        dbs.pop_sharks[day] = num_sharks
        dbs.pop_jets[day] = num_jets

    if (new_agents > 0 and popn_ch == 'vary' and agent_homes == 'random') or day == rounds - 1:

        if day == rounds - 1:

            dpi = 'high'

        else:

            dpi = 'low'

        homes_array = np.zeros(shape=(dimen, dimen))

        for agent in agent_population.pop:
            x_coord = int(agent.home[0])
            y_coord = int(agent.home[1])

            homes_array[x_coord][y_coord] += 1

        # now illustrate homes_array via a heatmap if we're printing charts
        create_heat_map(dimen, homes_array, run_folder, 'Greys', 'After addition - day % d' % (day), "agent_homes", dpi)

    if respect_property_rights:

        # We also allow the newly born agent to communicate with all the other agents, so it is aware of trading locations
        # copy the agent population
        copy_population = list(copy.copy(agent_population.pop))

        # we want any pair of agents to have a probability of communicating of agents_comm_prob: we can think of this as a squre matrix with the list of agents on each axis.
        # we want to use one side of the matrix (a triangle) without the diagonal elements only.  so if we take a copy of the agent population, remove the first agent, we are left
        # with the top line of the triangular matrix to choose a cp_agent.  We then remove each agent in turn and iterate over the remaining agents.
        for agent in brand_new_agents:

            #        if 0 <= day - agent.birth_date < 5 and day > 100:
            #
            #            print_dets = 1

            if len(copy_population) > 1:

                copy_population.remove(agent)

                if print_dets == 1:
                    print('\n NEW BIRTH - copying location information')
                    print('\n\n------->agent =', agent, agent.home)

                for cp_agent in copy_population:

                    #                    if 1:
                    if random.random() < agents_comm_prob:

                        if print_dets == 1:
                            print('\ncp_agent =', cp_agent, cp_agent.home)

                        agents_want_to_comm = 'both'
                        agent_exp_gain = 1
                        cp_agent_exp_gain = 1
                        two_agents_communicate(params, agent_population, town_grid, agent, cp_agent, day, print_dets, respect_property_rights, rounds, day, agents_want_to_comm, dbs,
                                               price_mean, force_prices, fixed_price, fountain_population, fight_cost, len_reputations_mem, intn_error_std, agree_location,
                                               agent_exp_gain, cp_agent_exp_gain, agent_mem_length, fight_balance, adjust_props_r, agent_intn_beta, formal_inst, prob_fine, fine, fight_skill, fix_ps_fb_0,
                                               clear_of_fights_radius, stranger_int, strat_choice, two_tribes_inst, print_fine_dets, track_agent, strangers_if_unknown)

    # if pause_code:
    #     pause()

#                        two_agents_communicate(agent_population, town_grid, agent, cp_agent, day, print_dets, respect_property_rights, rounds, day, agents_want_to_comm, dbs,
#                                               adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta)

#            if print_dets == 1:
#                input("Press Enter to continue...")

#    if new_agents > 0 or print_fine_dets == 1:
#        pause()


def propose_keynesian_inst(KO_pop, dbs, agent_population, min_res_levels_db, day, agent_res_init, town_grid,
                           print_fine_dets, print_dets, data_folder, trade_moves, wait_at_tgt_moves, agent_vision, fountain_population,
                           trade_prices, granular_mem, loc_mkt, restrict_by_district):
    """This function runs an algorithm which leads to the proposition of a new market square for certain agents.  The aim
    is to attempt to create a new market in a location where agents have been persistently dying."""

    # We look in dead_agent_array to see which agents have died.  A Keynesian institution gets proposed if
    # (i) 2 or more agents have died in (a) specific location(s); (ii) there is a location which both agents can reach

    #    print_fine_dets = 1

    print('\n *** A Keynesian institution is being proposed ***')

    if print_fine_dets == 1:
        print('\n KO_pop.KI_stiffs =\n', KO_pop.KI_stiffs)
        print('len(KO_pop.KI_stiffs) =', len(KO_pop.KI_stiffs), '\n')

    dead_ags_copy = copy.copy(dbs.dead_ags_grid_counter)

    # First we want to maximize the number of agents that can reach any proposed square, which is within striking distance
    # of a location where more than one agent has died.  We look at those squares only and then find the minimum aggregated distance.

    # Find location with more than one death in dbs.dead_ags_grid_counter
    more_than_one_death_array = [[x, y] for x in np.arange(town_grid.dimen) for y in np.arange(town_grid.dimen) if dbs.dead_ags_grid_counter[x][y] > 1]

    print(' more_than_one_death_array =', more_than_one_death_array)

    if print_fine_dets == 1:
        print(' dbs.sign_mkt_locs[day] =', dbs.sign_mkt_locs[day])

    # for simplicity, we deal with only one square in each round and we choose it randomly:
    if len(more_than_one_death_array) > 1:
        more_than_one_death_array = [random.choice(more_than_one_death_array)]

    # Create an array to count the number of agents that can reach each grid square (number of agents in striking distance)
    num_agent_in_strdist = np.zeros(shape=(town_grid.dimen, town_grid.dimen), dtype=int)

    # we want to find all the current trading agents, to minimize interference
    if print_fine_dets == 1:
        print('\n dbs.trades_array_ags ', dbs.trades_array_ags)

    trading_agents = []

    for i in range(town_grid.dimen):
        for j in range(town_grid.dimen):

            if len(dbs.trades_array_ags[i][j]) > 0:

                for ag in dbs.trades_array_ags[i][j]:
                    trading_agents.append(ag)

    if print_fine_dets == 1:
        print('\n trading_agents ', trading_agents)

    # Create array to record the home locations of agents not trading
    home_locs = []

    for agent in agent_population.pop:

        if agent not in trading_agents:
            home_locs.append(agent.home)

    print(' more_than_one_death_loc =', more_than_one_death_array)

    # we populate num_agent_in_strdist with tallies for the number of dead agent locations within striking distance of each grid square
    for more_than_one_death_loc in more_than_one_death_array:

        #        print('\n more_than_one_death_loc', more_than_one_death_loc, 'from more_than_one_death_array', more_than_one_death_array)

        # if we are using districts we need to find the boundaries of the district which the double-death location falls within (x_min, x_mix, y_min, y_max)
        if restrict_by_district == 1:

            if math.floor(more_than_one_death_loc[0] / (town_grid.dimen / 2.0)) == 0:
                boundary_x_min = 0
                boundary_x_max = int(town_grid.dimen / 2.0 - 1)

            if math.floor(more_than_one_death_loc[0] / (town_grid.dimen / 2.0)) == 1:
                boundary_x_min = int(town_grid.dimen / 2.0)
                boundary_x_max = town_grid.dimen - 1

            if math.floor(more_than_one_death_loc[1] / (town_grid.dimen / 2.0)) == 0:
                boundary_y_min = 0
                boundary_y_max = int(town_grid.dimen / 2.0 - 1)

            if math.floor(more_than_one_death_loc[1] / (town_grid.dimen / 2.0)) == 1:
                boundary_y_min = int(town_grid.dimen / 2.0)
                boundary_y_max = town_grid.dimen - 1

        for x_coord in np.arange(town_grid.dimen):

            for y_coord in np.arange(town_grid.dimen):

                poss_tgt_location = [x_coord, y_coord]

                # The first condition is that the grid square must be within striking distance of any location where two or more agents have died
                if within_striking_dist(wait_at_target_til_end, town_grid, more_than_one_death_loc, wait_at_tgt_moves, agent_vision, poss_tgt_location, move=0, has_acted=0, print_dets=0):

                    #                    print('\n restrict_by_district', restrict_by_district)
                    #                    print(' x_coord', x_coord, 'y_coord', y_coord)
                    #                    print(' math.floor(x_coord / (town_grid.dimen / 2.0))', math.floor(x_coord / (town_grid.dimen / 2.0)))
                    #                    print(' math.floor(x_coord / (town_grid.dimen / 2.0)) == 0?', math.floor(x_coord / (town_grid.dimen / 2.0)) == 0)
                    #                    print(' math.floor(y_coord / (town_grid.dimen / 2.0))', math.floor(y_coord / (town_grid.dimen / 2.0)))

                    within_district = 0

                    # Now we ask if the grid square is within the same policy quadrant as the more_than_one_death_loc
                    if restrict_by_district == 1:

                        #                        print('\n restrict_by_district == 1', restrict_by_district == 1)

                        #                        print_fine_dets = 1

                        if print_fine_dets == 1:
                            print('\n x_coord', x_coord, 'boundary_x_min', boundary_x_min, 'boundary_x_max', boundary_x_max, 'y_coord', y_coord, 'boundary_y_min', boundary_y_min, 'boundary_y_max', boundary_y_max)

                        if boundary_x_min <= x_coord <= boundary_x_max and boundary_y_min <= y_coord <= boundary_y_max:
                            within_district = 1

                        if print_fine_dets == 1:
                            print('within_district:', within_district)

                    if (restrict_by_district == 1 and within_district == 1) or restrict_by_district == 0:

                        # now we test if the grid square is within striking distance of any existing market:
                        within_reach_of_existing_mkt = 0

                        #                        if print_fine_dets == 1:
                        #                            print('\n loc_mkt =', loc_mkt)

                        # Test each market only if loc_mkt == 'avoid_interference'
                        if loc_mkt == 'avoid_interference':

                            for market_loc in dbs.sign_mkt_locs[day]:

                                #                                if print_fine_dets == 1:
                                #                                    print('\n market_loc', market_loc)

                                # if the grid square is within striking distance of any market we will ignore it
                                if within_striking_dist(wait_at_target_til_end, town_grid, market_loc, wait_at_tgt_moves, agent_vision, poss_tgt_location, move=0, has_acted=0, print_dets=0):
                                    #                                    if print_fine_dets == 1:
                                    #                                        print('within str dist of market')

                                    within_reach_of_existing_mkt = 1

                        #                        if print_fine_dets == 1:
                        #                            print('\n within_reach_of_existing_mkt ', within_reach_of_existing_mkt)

                        # we carry on if the grid square is not within reach of an existing market OR we don't care about this
                        if within_reach_of_existing_mkt == 0:

                            # now we consider all the live agents: all if we don't care about interference; or those currently not trading if we care
                            for agent in agent_population.pop:

                                if loc_mkt != 'avoid_interference' or (loc_mkt == 'avoid_interference' and agent not in trading_agents):

                                    home_loc = agent.home

                                    #                                if print_fine_dets == 1:
                                    #                                    print('home_loc =', home_loc)

                                    # If the poss_tgt_location is within striking distance of the agent location...
                                    if within_striking_dist(wait_at_target_til_end, town_grid, home_loc, wait_at_tgt_moves, agent_vision, poss_tgt_location, move=0, has_acted=0, print_dets=0):
                                        num_agent_in_strdist[x_coord][y_coord] += 1

    print(' home_locs =', home_locs, '\n')

    if print_fine_dets == 1:
        print(' len(home_locs) =', len(home_locs), '\n')
        print('\n more_than_one_death_array =\n', more_than_one_death_array)

    # we have to be careful when there are multiple existing markets which leads to an empty home_locs array - in this case, we don't do anything
    if len(home_locs) > 0:

        # Find the maximum number of agents within reach of any location in num_agent_in_strdist - we are only interested in these locations
        max_num_ags_reach = np.max(num_agent_in_strdist)

        if print_fine_dets == 1:
            print('\n max_num_ags_reach =', max_num_ags_reach)

        # Now we create a list comprehension which develops an array which contains all of the locations equal to this maximum
        top_locs_array = [[x, y] for x in np.arange(town_grid.dimen) for y in np.arange(town_grid.dimen) if num_agent_in_strdist[x][y] == max_num_ags_reach]

        if print_fine_dets == 1:
            print('\n top_locs_array =\n', top_locs_array)
            print(' len(top_locs_array) =', len(top_locs_array), '\n')

        # The number of top locations is:
        num_top_locs = len(top_locs_array)

        # We want to look at every location in top_locs_array and find the distance with the smallest total distance for the dead
        # agent locations (we are finding the best possible square for these locations).  We record that in this array:
        total_moves_to_location_array = np.zeros(shape=(town_grid.dimen, town_grid.dimen), dtype=int)

        # We write the same information in this array
        top_loc_tot_dists = np.zeros(shape=(num_top_locs), dtype=int)

        for top_loc_index in np.arange(num_top_locs):

            top_loc = top_locs_array[top_loc_index]

            if print_fine_dets == 1:
                print('\n\n\n top_loc_index =', top_loc_index)
                print(' iter top_loc =', top_loc)

            for loc in home_locs:

                if print_fine_dets == 1:
                    print('\n loc =', loc)

                x_dist = math.fabs(top_loc[0] - loc[0])

                if x_dist > town_grid.dimen / 2.0:
                    x_dist = town_grid.dimen - x_dist

                y_dist = math.fabs(top_loc[1] - loc[1])

                if y_dist > town_grid.dimen / 2.0:
                    y_dist = town_grid.dimen - y_dist

                # The number of trading moves it will take to get there:
                travel_time = int(np.max([math.ceil(x_dist / float(agent_vision)), math.ceil(y_dist / float(agent_vision))]))

                if print_fine_dets == 1:
                    print('\n x_dist', x_dist)
                    print(' y_dist', y_dist)
                    print(' travel_time', travel_time)
                    print(' trade_moves - wait_at_tgt_moves', trade_moves - wait_at_tgt_moves)

                if travel_time <= trade_moves - wait_at_tgt_moves:  # then the agent at this home can reach the location

                    top_loc_tot_dists[top_loc_index] += travel_time

                    x_coord = top_loc[0]
                    y_coord = top_loc[1]

                    total_moves_to_location_array[x_coord][y_coord] += travel_time

            if print_fine_dets == 1:
                print('\n total_travel_time for this top loc = ', top_loc_tot_dists[top_loc_index])

                # Find the least total distance:
        min_tot_travel = np.min(top_loc_tot_dists)

        if print_fine_dets == 1:
            print('\n top_loc_tot_dists =\n', top_loc_tot_dists)
            print('\n min_tot_travel =', min_tot_travel, '(mean per agent is', min_tot_travel / float(max_num_ags_reach), ')\n')

        # We create an array to record the locations where these shortest total distance are
        min_locs_array = []

        # And we also record, for LIVE agents, the total number of agents within striking distance - if we are dividing in to districts then we still do this
        # as we have already fully prioritised district agents - this process means a market located in a district might get business from outside
        live_ag_dists = []

        live_ag_grid = np.zeros(shape=(town_grid.dimen, town_grid.dimen), dtype=int)

        for top_loc_index in np.arange(num_top_locs):

            if print_fine_dets == 1:
                print('\n\n top_loc_index =', top_loc_index)
                print('\n\n top_loc_tot_dists[top_loc_index] =', top_loc_tot_dists[top_loc_index])

            # We are only interested in the shortest total distance:
            if top_loc_tot_dists[top_loc_index] == min_tot_travel:

                # if this location has the shortest total distance then we record it in min_locs_array, live_ag_grid and live_ag_dists
                top_loc = top_locs_array[top_loc_index]

                x_coord = top_loc[0]
                y_coord = top_loc[1]

                if print_fine_dets == 1:
                    print('\n top_loc =', top_loc)

                min_locs_array.append([x_coord, y_coord])

                tot_live_dist = 0

                for agent in agent_population.pop:

                    #                    print('\n loc_mkt =', loc_mkt)
                    #                    print('\n agent', agent.home, 'in dbs.trades_array_ags?', agent in trading_agents)

                    if loc_mkt != 'avoid_interference' or (loc_mkt == 'avoid_interference' and agent not in trading_agents):

                        if within_striking_dist(wait_at_target_til_end, town_grid, agent.home, wait_at_tgt_moves, agent_vision, top_loc, move=0, has_acted=0, print_dets=0):
                            tot_live_dist += 1
                            live_ag_grid[x_coord][y_coord] += 1

                live_ag_dists.append(tot_live_dist)

                if print_fine_dets == 1:
                    print('\n tot_live_dist =', tot_live_dist)

        # The maximum number of live agents which can reach the best locations for the dead agent locations is:
        max_tot_live_within = np.max(live_ag_dists)

        if print_fine_dets == 1:
            print('\n min_locs_array =', min_locs_array)
            print(' len(min_locs_array) =', len(min_locs_array))
            print('\n live_ag_dists =', live_ag_dists)
            print(' len(live_ag_dists) =', len(live_ag_dists))
            print(' max_tot_live_within =', max_tot_live_within)

        # We find all these locations and choose one of them randomly
        best_dead_alive_locs = []

        for min_loc_index in np.arange(len(min_locs_array)):

            if live_ag_dists[min_loc_index] == max_tot_live_within:
                best_dead_alive_locs.append(min_locs_array[min_loc_index])

        dbs.proposed_KI_loc = random.choice(best_dead_alive_locs)

        if print_fine_dets == 1:
            print('\n dbs.proposed_KI_loc =', dbs.proposed_KI_loc)
            print('\n home_locs =', home_locs)
            print('\n dbs.sign_mkt_locs[day] =', dbs.sign_mkt_locs[day])

        # We wipe this array in order to repopulate it
        KIagents = []
        trgt_locations = []

        for loc in home_locs:

            if print_fine_dets == 1:
                print('\n loc', loc)

            if within_striking_dist(wait_at_target_til_end, town_grid, loc, wait_at_tgt_moves, agent_vision, dbs.proposed_KI_loc, move=0, has_acted=0,
                                    print_dets=0):  # the dead agent's location is within striking distance of the proposed_KI_loc

                if print_fine_dets == 1:
                    print('\n within str dist of dbs.proposed_KI_loc ', dbs.proposed_KI_loc)

                #                within_reach_of_existing_mkt = 0
                #
                #                # Test each market only if we're seeking to avoid interference with existing markets
                #                if loc_mkt == 'avoid_interference':
                #
                #                    for market_loc in dbs.sign_mkt_locs[day]:
                #
                #                        # if the loc is within striking distance of any market we will ignore it
                #                        if within_striking_dist(wait_at_target_til_end, town_grid, market_loc, wait_at_tgt_moves, agent_vision, loc, move=0, has_acted=0, print_dets=0):
                #
                #                            within_reach_of_existing_mkt = 1
                #
                #                # we carry on if the loc is not within reach of an existing market
                #                if within_reach_of_existing_mkt == 0:

                for agent in agent_population.pop:

                    if loc[0] == agent.home[0] and loc[1] == agent.home[1]:  # then we want this agent on our list

                        if print_fine_dets == 1:
                            print(' agent', agent, 'home', agent.home)

                        if agent not in KIagents:
                            KIagents.append(agent)
                            trgt_locations.append(list(agent.home))

        if print_fine_dets == 1:
            print('\n KIagents =', KIagents)
            print('\n trgt_locations =', trgt_locations)
            print('len(KO_pop.KI_stiffs)', len(KO_pop.KI_stiffs))
        #            print('\n pre-home_locs = ', home_locs)
        #
        #        # before moving on we need to remove trgt_locations from home_locations
        #        for loc in home_locs:
        #
        #            for trgt_loc in trgt_locations:
        #
        #                if print_fine_dets == 1:
        #                    print('\n trgt_loc =', trgt_loc)
        #
        #                if trgt_loc[0] == loc[0] and trgt_loc[1] == loc[1]:
        #
        #                    if print_fine_dets == 1:
        #                        print(' trgt_loc[0] == loc[0] and trgt_loc[1] == loc[1]')
        #
        #                    home_locs.remove(trgt_loc)
        #
        #        if print_fine_dets == 1:
        #            print('\n post-home_locs = ', home_locs)

        copy_stiffs = copy.copy(KO_pop.KI_stiffs)

        # we only want to create the KI if there are more than 1 live agents who would benefit
        if len(KIagents) > 1:

            for trgt_loc in trgt_locations:

                if print_fine_dets == 1:
                    print('\n trgt_loc =', trgt_loc, '\n')

                # set the values of dbs.dead_ags_grid_counter to zero for these locations
                dbs.dead_ags_grid_counter[trgt_loc[0]][trgt_loc[1]] = 0

                for stiff in copy_stiffs:

                    if print_fine_dets == 1:
                        print('\n stiff home =', stiff.home)
                        print(' stiff.home[0] == trgt_loc[0]', stiff.home[0] == trgt_loc[0])
                        print(' stiff.home[1] == trgt_loc[1]', stiff.home[1] == trgt_loc[1])

                    if stiff.home[0] == trgt_loc[0] and stiff.home[1] == trgt_loc[1]:

                        if print_fine_dets == 1:
                            print('\n stiff.home[0] == trgt_loc[0] and stiff.home[1] == trgt_loc[1]')
                            print('stiff in KO_pop.KI_stiffs ', stiff in KO_pop.KI_stiffs)

                        if stiff in KO_pop.KI_stiffs:
                            KO_pop.KI_stiffs.remove(stiff)

                        if print_fine_dets == 1:
                            print('AFTER : stiff in KO_pop.KI_stiffs ', stiff in KO_pop.KI_stiffs)

            #                        if stiff not in remaining_stiffs:
            #
            #                            remaining_stiffs.append(the_stiff)

            #            if print_fine_dets == 1:
            #                print('\n remaining_stiffs =', remaining_stiffs)
            #
            #            KO_pop.KI_stiffs = copy.copy(remaining_stiffs)

            if print_fine_dets == 1:

                print('\n KO_pop.KI_stiffs =', KO_pop.KI_stiffs, '\n')

                for stiff in KO_pop.KI_stiffs:
                    print(' stiff.home =', stiff.home)

            # create new sub directory to record data
            new_ko_folder = '%s/KI_day_%s' % (data_folder, day)

            ko_notes_file = '%s/00_notes_file.txt' % (new_ko_folder)

            # this line creates the directory
            os.makedirs(new_ko_folder)

            # Finally, create the Keynesian Object
            new_ko = Keynesian_Object(day, copy.copy(dbs.proposed_KI_loc), new_ko_folder, ko_notes_file, dead_ags_copy, copy.copy(dbs.dead_ags_grid_counter),
                                      copy.copy(KIagents), trgt_locations)

            KO_pop.pop.append(new_ko)

            # Append dbs.KI_notes_file
            add_text = "\n\n A Keynesian Institution was proposed on day %s at location %s" % (day, dbs.proposed_KI_loc)

            with open(dbs.KI_notes_file, 'a') as myfile:
                myfile.write(add_text)

            # Append new_ko text_file
            add_text = "This is a Notes File pertaining to a proposed Keynesian Institution.\n\nThe Institution was proposed on day %s at location %s" % (day, dbs.proposed_KI_loc)

            new_ko.write_to_notes(add_text)

            new_ko.add_initial_text(fountain_population, trade_prices, granular_mem, print_fine_dets, print_dets, dbs, town_grid, day, wait_at_tgt_moves)

            # Print the following charts
            title = 'Dead Agents Heatmap (KI proposed) - Day %s (start)' % (day)
            create_heat_map(town_grid.dimen, dead_ags_copy, new_ko.folder, 'Greens', title, 'KI_day_%s_1_dead_ags' % (day), dpi='low')

            title = 'KI proposed: Number of Agents - Day %s' % (day)
            create_heat_map(town_grid.dimen, num_agent_in_strdist, new_ko.folder, 'Greens', title, 'KI_day_%s_2_num_ags' % (day), dpi='low')

            title = 'KI proposed: Total Moves to Location - Day %s' % (day)
            create_heat_map(town_grid.dimen, total_moves_to_location_array, new_ko.folder, 'Greens', title, 'KI_day_%s_3_moves_to_locs' % (day), dpi='low')

            title = 'KI proposed: Total Moves to Location (Live and Dead Agents) - Day %s' % (day)
            create_heat_map(town_grid.dimen, live_ag_grid, new_ko.folder, 'Greens', title, 'KI_day_%s_4_moves_to_locs' % (day), dpi='low')

            title = 'Dead Agents Heatmap (KI proposed) - Day %s (end)' % (day)
            create_heat_map(town_grid.dimen, dbs.dead_ags_grid_counter, new_ko.folder, 'Greens', title, 'KI_day_%s_5_dead_ags' % (day), dpi='low')

    #    else:
    #
    #        # Append dbs.KI_notes_file
    #        add_text = "\n\n A Keynesian Institution was NOT proposed on day %s because there were a number of significant market locations already existing across the grid (the array home_locs was empty)" % (day)
    #
    #        with open(ko_notes_file, 'a') as myfile:
    #            myfile.write(add_text)

    if print_fine_dets == 1:
        input("Press Enter to continue...")


def form_exps_rtns_props(params, agent, pot_cp, cp_agent_prop_steal, cp_agent_prop_fight_back, agent_population, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, simulated_int, adjust_props_r,
                         agent_intn_beta, fight_balance, fight_cost, formal_inst, prob_fine, fine, print_fine_dets, fight_skill, stranger_int, strat_choice, strangers_if_unknown):

    """This function takes two agents and finds their expected returns from any interaction between them.  It also finds the expected changes in prop_steal
    and prop_fight_back if they interacted."""

    if print_fine_dets:
        print('\n\n *** Starting form_exps_rtns_props')

    # we are dealing with 2 scenarios - when we are simulating an interaction and when we are not
    if simulated_int:

        agent_basket_array = agent.basket_array_start
        cp_agent_basket_array = pot_cp.basket_array_start

    else:

        agent_basket_array = agent.basket_array
        cp_agent_basket_array = pot_cp.basket_array

    # update MRS arrays
    agent_aggr_resources = agent.agent_res_array + agent_basket_array
    cp_agent_aggr_resources = pot_cp.agent_res_array + cp_agent_basket_array

    agent.MRS_array = generate_MRS_array(agent_aggr_resources, print_fine_dets)
    pot_cp.MRS_array = generate_MRS_array(cp_agent_aggr_resources, print_fine_dets)

    # find lowest resource
    agent_lowest_res = 0
    if agent_aggr_resources[0][0] < agent_aggr_resources[0][1]:
        agent_lowest_res = 1

    cp_agent_lowest_res = 0
    if cp_agent_aggr_resources[0][0] < cp_agent_aggr_resources[0][1]:
        cp_agent_lowest_res = 1

    # find probabilities of winning and losing fights
    if fight_skill is not None:

        sum_skill = agent_fight_skill + cp_agent_fight_skill

        if sum_skill != 0.0:
            
            prob_agent_wins_fight = agent_fight_skill / float(sum_skill)

        else:
            
            prob_agent_wins_fight = 0.5

        prob_agent_loses_fight = 1 - prob_agent_wins_fight

    elif fight_balance == '50_50':

        prob_agent_wins_fight = prob_agent_loses_fight = 0.5
        
    elif fight_balance == 'res_power':

        agent_mean_res = np.mean(agent_res_array[0])
        cp_agent_mean_res = np.mean(cp_agent_res_array[0])

        # this means that if agent has more resources then it will have more chance of winning the fight
        prob_agent_wins_fight = agent_mean_res / float(agent_mean_res + cp_agent_mean_res)
        prob_agent_loses_fight = 1 - prob_agent_wins_fight

        if print_fine_dets == 1:

            print('\n agent_mean_res =', agent_mean_res)
            print(' cp_agent_mean_res =', cp_agent_mean_res)            
            print('\n prob_agent_wins_fight =', prob_agent_wins_fight)
            print(' prob_agent_loses_fight =', prob_agent_loses_fight)
            print('\n fight_cost =', fight_cost)

    if print_fine_dets == 1 and formal_inst:
        print('\n formal institution in effect: prob_fine = ', prob_fine, 'fine =', fine, 'prob_fine * fine =', prob_fine * fine, 'agent_population.mean_ps', agent_population.mean_ps, 'agent_population.corruption_prop_charge',
              agent_population.corruption_prop_charge)

    if print_fine_dets == 1:
        
        print('\n prob_agent_wins_fight =', prob_agent_wins_fight)
        print(' prob_agent_loses_fight =', prob_agent_loses_fight)
        print('\n simulated_int ', simulated_int)

        print('\n applied: agent_basket_array', agent_basket_array)
        print(' applied: cp_agent_basket_array', cp_agent_basket_array)

    # New Code from scratch

    # Start with finding the 'building blocks' for all the values in all the interaction types

    # First find the agent's estimate of cp's basket (reduced value)
    agent_values_own_basket_reduced = 0.0
    agent_values_cp_basket_reduced = 0.0
    agent_values_fight_costs_reduced = 0.0

    cp_values_own_basket_reduced = 0.0
    cp_values_agent_basket_reduced = 0.0
    cp_values_fight_costs_reduced = 0.0

    # now we find these values by iterating over the resources like so
    for res in range(num_res_founts):

        # agent own basket
        agent_values_own_basket_reduced += agent_basket_array[0][res] * agent.MRS_array[agent_lowest_res][res]
        # agent values cp's basket
        agent_values_cp_basket_reduced += cp_agent_basket_array[0][res] * agent.MRS_array[agent_lowest_res][res]
        # fight costs
        agent_values_fight_costs_reduced += fight_cost * agent.MRS_array[agent_lowest_res][res]

        # cp own basket
        cp_values_own_basket_reduced += cp_agent_basket_array[0][res] * pot_cp.MRS_array[cp_agent_lowest_res][res]
        # cp values agent's basket
        cp_values_agent_basket_reduced += agent_basket_array[0][res] * pot_cp.MRS_array[cp_agent_lowest_res][res]
        # cp fight costs
        cp_values_fight_costs_reduced += fight_cost * pot_cp.MRS_array[cp_agent_lowest_res][res]

    # We use these values to determine the expected gain (loss) from fighting (excluding any fines or comensation)
    agent_exp_gross_gain_fight_reduced = (prob_agent_wins_fight * agent_values_cp_basket_reduced) + (prob_agent_loses_fight * (-1 * agent_values_own_basket_reduced)) + agent_values_fight_costs_reduced
    cp_exp_gross_gain_fight_reduced = (prob_agent_loses_fight * cp_values_agent_basket_reduced) + (prob_agent_wins_fight * (-1 * cp_values_own_basket_reduced)) + cp_values_fight_costs_reduced

    # If the agents are fined then we also want to find the amount each is fined (in reduced value terms
    if formal_inst:

        # start with finding net fine
        net_fine = prob_fine * fine * ((agent_population.mean_ps * agent_population.corruption_prop_charge) + (1 - agent_population.mean_ps))

        # agent's expected fine
        agent_exp_fine_reduced = 0.0
        # cp's expected fine
        cp_exp_fine_reduced = 0.0

        # iterate over resources again
        for res in range(num_res_founts):

            agent_exp_fine_reduced += net_fine * agent.MRS_array[agent_lowest_res][res]

            cp_exp_fine_reduced += net_fine * pot_cp.MRS_array[cp_agent_lowest_res][res]

        # if comepnsation is being paid to the victim then:
        if formal_inst == 'compensate':

            # find net compensation
            net_compensation = (1 - agent_population.mean_ps) * prob_fine * fine

            # agent's expected compensation
            agent_exp_comp_reduced = 0.0
            # cp's expected compensation
            cp_exp_comp_reduced = 0.0

            # iterate over resources again
            for res in range(num_res_founts):

                agent_exp_comp_reduced += net_compensation * agent.MRS_array[agent_lowest_res][res]

                cp_exp_comp_reduced += net_compensation * pot_cp.MRS_array[cp_agent_lowest_res][res]

    # Now we look at all of the quadrants:

    # Quadrant 1 is transacting

    # Find out what they would trade, if at all:
    if (simulated_int and ((agent.basket_array_start[0][0] > 0.0 and pot_cp.basket_array_start[0][1] > 0.0) or (agent.basket_array_start[0][1] > 0.0 and pot_cp.basket_array_start[0][0] > 0))) or \
       (simulated_int == 0 and ((agent.basket_array[0][0] > 0.0 and pot_cp.basket_array[0][1] > 0.0) or (agent.basket_array[0][1] > 0.0 and pot_cp.basket_array[0][0] > 0))):  # then they might trade

        tot_cons_surp_array, best_trans_data = build_tot_cons_surp_array(agent_population.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, print_fine_dets,
                                                                         simulated_int, agent.agent_res_array, agent_basket_array, agent.basket_array_start, pot_cp.agent_res_array, pot_cp.basket_array, pot_cp.basket_array_start)

    else:  # then they won't trade

        tot_cons_surp_array, best_trans_data = ([[0.0, 0.0], [0.0, 0.0]], [None, None, None, None, None])

    # Now we need to convert this in to a reduce gain
    if print_fine_dets == 1:
        print('\n tot_cons_surp_array:\n', tot_cons_surp_array)
        print('\n best_trans_data =', best_trans_data)

    agent_sells, agent_buys, tot_trans_ag_sell, tot_trans_ag_buy, trans_agr_MRS = best_trans_data

    # if agent_sells is not None:
    #     agent_sells = int(agent_sells)
    #     agent_buys = int(agent_buys)

    # this code is only relevant when the agents are expected to trade
    if tot_trans_ag_buy is not None and tot_trans_ag_buy > 0 and tot_trans_ag_sell > 0:

        agent_exp_gain_1_reduced = (agent.MRS_array[agent_lowest_res][agent_buys] * tot_trans_ag_buy) - (agent.MRS_array[agent_lowest_res][agent_sells] * tot_trans_ag_sell)

        cp_exp_gain_1_reduced = (pot_cp.MRS_array[cp_agent_lowest_res][agent_sells] * tot_trans_ag_sell) - (pot_cp.MRS_array[cp_agent_lowest_res][agent_buys] * tot_trans_ag_buy)

    else:

        agent_exp_gain_1_reduced = 0.0
        cp_exp_gain_1_reduced = 0.0


    # Quadrant 2F - the agent wanted to trade but the cp wanted to steal.  The agent decided to fight.
    # For the agent:
    agent_exp_gain_2F_reduced = copy.copy(agent_exp_gross_gain_fight_reduced)

    # if there is a formal institution, the agent will not get fined but it might get compensated
    if formal_inst == 'compensate':
        agent_exp_gain_2F_reduced += agent_exp_comp_reduced

    # For the cp:
    cp_exp_gain_2F_reduced = copy.copy(cp_exp_gross_gain_fight_reduced)

    # if there is a formal institution, the cp will get fined
    if formal_inst:
        cp_exp_gain_2F_reduced += cp_exp_fine_reduced


    # Quadrant 2A - the agent wanted to trade but the cp wanted to steal.  The agent acquiesced.
    # For the agent:
    agent_exp_gain_2A_reduced = -1 * agent_values_own_basket_reduced

    # if there is a formal institution, the agent will not get fined but it might get compensated
    if formal_inst == 'compensate':
        agent_exp_gain_2A_reduced += agent_exp_comp_reduced

    # For the cp:
    cp_exp_gain_2A_reduced = copy.copy(cp_values_agent_basket_reduced)

    # if there is a formal institution, the cp will get fined
    if formal_inst:
        cp_exp_gain_2A_reduced += cp_exp_fine_reduced


    # Quadrant 3F - the cp wanted to trade but the agent wanted to steal.  The cp decided to fight.
    # For the agent:
    agent_exp_gain_3F_reduced = copy.copy(agent_exp_gross_gain_fight_reduced)

    # if there is a formal institution, the agent will get fined
    if formal_inst:
        agent_exp_gain_3F_reduced += agent_exp_fine_reduced

    # For the cp:
    cp_exp_gain_3F_reduced = copy.copy(cp_exp_gross_gain_fight_reduced)

    # if there is a formal institution, the cp will not get fined but it might get compensated
    if formal_inst == 'compensate':
        cp_exp_gain_3F_reduced += cp_exp_comp_reduced


    # Quadrant 3A - the cp wanted to trade but the agent wanted to steal.  The cp acquiesced.
    # For the agent:
    agent_exp_gain_3A_reduced = copy.copy(agent_values_cp_basket_reduced)

    # if there is a formal institution, the agent will get fined
    if formal_inst:
        agent_exp_gain_3A_reduced += agent_exp_fine_reduced

    # For the cp:
    cp_exp_gain_3A_reduced = -1 * cp_values_own_basket_reduced

    # if there is a formal institution, the cp will not get fined but it might get compensated
    if formal_inst == 'compensate':
        cp_exp_gain_3A_reduced += cp_exp_comp_reduced


    # Quadrant 4 - both agents attempt to steal from each other
    # For the agent:
    agent_exp_gain_4_reduced = copy.copy(agent_exp_gross_gain_fight_reduced)

    # if there is a formal institution, the agent will get fined
    if formal_inst:
        agent_exp_gain_4_reduced += agent_exp_fine_reduced

    # For the cp:
    cp_exp_gain_4_reduced = copy.copy(cp_exp_gross_gain_fight_reduced)

    # if there is a formal institution, the cp will get fined
    if formal_inst:
        cp_exp_gain_4_reduced += cp_exp_fine_reduced


    # Find probabilities
    prob_quad_1 = (1 - agent.prop_steal) * (1 - cp_agent_prop_steal)
    prob_quad_2F = (1 - agent.prop_steal) * agent.prop_fight_back * cp_agent_prop_steal
    prob_quad_2A = (1 - agent.prop_steal) * (1 - agent.prop_fight_back) * cp_agent_prop_steal
    prob_quad_3F = agent.prop_steal * (1 - cp_agent_prop_steal) * cp_agent_prop_fight_back
    prob_quad_3A = agent.prop_steal * (1 - cp_agent_prop_steal) * (1 - cp_agent_prop_fight_back)
    prob_quad_4 = agent.prop_steal * cp_agent_prop_steal


    # now combine all all prob weighted gains / losses
    agent_total_exp_gain = (prob_quad_1 * agent_exp_gain_1_reduced) + (prob_quad_2F * agent_exp_gain_2F_reduced) + (prob_quad_2A * agent_exp_gain_2A_reduced) +\
                           (prob_quad_3F * agent_exp_gain_3F_reduced) + (prob_quad_3A * agent_exp_gain_3A_reduced) + (prob_quad_4 * agent_exp_gain_4_reduced)

    pot_cp_total_exp_gain = (prob_quad_1 * cp_exp_gain_1_reduced) + (prob_quad_2F * cp_exp_gain_2F_reduced) + (prob_quad_2A * cp_exp_gain_2A_reduced) +\
                            (prob_quad_3F * cp_exp_gain_3F_reduced) + (prob_quad_3A * cp_exp_gain_3A_reduced) + (prob_quad_4 * cp_exp_gain_4_reduced)

    # we create an array which records the 6 expected returns for 2 agents (order: 1 (trading), 2F, 2A, 3F, 3A, 4 (fight))
    exp_rtns_matrix = [[agent_exp_gain_1_reduced, cp_exp_gain_1_reduced], [agent_exp_gain_2F_reduced, cp_exp_gain_2F_reduced], [agent_exp_gain_2A_reduced, cp_exp_gain_2A_reduced],
                       [agent_exp_gain_3F_reduced, cp_exp_gain_3F_reduced], [agent_exp_gain_3A_reduced, cp_exp_gain_3A_reduced], [agent_exp_gain_4_reduced, cp_exp_gain_4_reduced]]

    # now create the 4-pyaoff matrix
    payoffs_4_scenarios = [[agent_exp_gain_1_reduced, cp_exp_gain_1_reduced], [] ,[], [agent_exp_gain_4_reduced, cp_exp_gain_4_reduced]]

    if stranger_int == 'fb' and (strat_choice == 'rational' or (strangers_if_unknown and agent.agent_knows_cp_dict[str(pot_cp)] == 0 or pot_cp.agent_knows_cp_dict[str(agent)] == 0)):

        payoffs_4_scenarios[1] = [agent_exp_gain_2F_reduced, cp_exp_gain_2F_reduced]

        payoffs_4_scenarios[2] = [agent_exp_gain_2F_reduced, cp_exp_gain_3F_reduced]

    elif stranger_int == 'acq' and (strat_choice == 'rational' or (strangers_if_unknown and agent.agent_knows_cp_dict[str(pot_cp)] == 0 or pot_cp.agent_knows_cp_dict[str(agent)] == 0)):

        payoffs_4_scenarios[1] = [agent_exp_gain_2A_reduced, cp_exp_gain_2A_reduced]

        payoffs_4_scenarios[2] = [agent_exp_gain_3F_reduced, cp_exp_gain_3F_reduced]

    else:

        payoffs_4_scenarios[1] = [(agent_exp_gain_2F_reduced * agent.prop_fight_back) + agent_exp_gain_2A_reduced * (1 - agent.prop_fight_back), \
                                  (cp_exp_gain_2F_reduced * agent.prop_fight_back) + cp_exp_gain_2A_reduced * (1 - agent.prop_fight_back)]

        # Note: we use the pot_cp's actual prop_fb here because we want an actual reading on outcomes
        payoffs_4_scenarios[2] = [(agent_exp_gain_3F_reduced * pot_cp.prop_fight_back) + agent_exp_gain_3A_reduced * (1 - pot_cp.prop_fight_back), \
                                  (cp_exp_gain_3F_reduced * pot_cp.prop_fight_back) + cp_exp_gain_3A_reduced * (1 - pot_cp.prop_fight_back)]

    if print_fine_dets:
        print('\n agent_total_exp_gain ', agent_total_exp_gain, 'pot_cp_total_exp_gain', pot_cp_total_exp_gain)

        print('\n exp_rtns_matrix', exp_rtns_matrix)

        print('\n payoffs_4_scenarios\n\n [', payoffs_4_scenarios[0], payoffs_4_scenarios[1])
        print('  ', payoffs_4_scenarios[2], payoffs_4_scenarios[3], ']')

    # now we derive the game bit strings
    if params.track_game_types:

        a = payoffs_4_scenarios[0][0]
        b = payoffs_4_scenarios[0][1]
        c = payoffs_4_scenarios[1][0]
        d = payoffs_4_scenarios[1][1]
        e = payoffs_4_scenarios[2][0]
        f = payoffs_4_scenarios[2][1]
        g = payoffs_4_scenarios[3][0]
        h = payoffs_4_scenarios[3][1]

        game_bit_string = ''

        pairs = [[a, c], [a, e], [a, g], [e, c], [e, g], [c, g], [b, d], [b, f], [b, h], [f, d], [f, h], [d, h]]

        for pair in pairs:

            if pair[0] < pair[1]:

                game_bit_string += '0'

            elif pair[0] == pair[1]:

                game_bit_string += '1'

            elif pair[0] > pair[1]:

                game_bit_string += '2'

        es_dict = dict()

        es_dict['a'] = a
        es_dict['c'] = c
        es_dict['e'] = e
        es_dict['g'] = g

        sorted_str = ''
        sorted_array = []

        for key, value in sorted(es_dict.items(), key=lambda item: (item[1], item[0])):

            sorted_str += key
            sorted_array.append(value)

        des_string = 'heuristics '
        des_string += sorted_str[0]

        oops = 0

        for iter_num in range(len(sorted_array) - 1):

            if sorted_array[iter_num] < sorted_array[iter_num + 1]:
                des_string += ' < '

            elif sorted_array[iter_num] == sorted_array[iter_num + 1]:
                des_string += ' = '

            elif sorted_array[iter_num] > sorted_array[iter_num + 1]:
                des_string += ' > '

                oops = 1

            des_string += sorted_str[iter_num + 1]

        des_string += '  |  '

        es_dict = dict()

        es_dict['b'] = b
        es_dict['d'] = d
        es_dict['f'] = f
        es_dict['h'] = h

        sorted_str = ''
        sorted_array = []

        for key, value in sorted(es_dict.items(), key=lambda item: (item[1], item[0])):

            sorted_str += key
            sorted_array.append(value)

        des_string += sorted_str[0]

        for iter_num in range(len(sorted_array) - 1):

            if sorted_array[iter_num] < sorted_array[iter_num + 1]:
                des_string += ' < '

            elif sorted_array[iter_num] == sorted_array[iter_num + 1]:
                des_string += ' = '

            elif sorted_array[iter_num] > sorted_array[iter_num + 1]:
                des_string += ' > '

                oops = 1

            des_string += sorted_str[iter_num + 1]

        if oops != 0:

            print('\n sorted_array =', sorted_array)
            print(' des_string ', des_string)
            pause()

        # for when 'rational' and fb - need to know how many a & b == 0 or > 0
        if des_string == 'c = e = g < a  |  d = f = h < b':

            if a == 0.0:

                des_string += '  |  a = 0'

            else:

                des_string += '  |  a > 0'

            if b == 0.0:

                des_string += ' b = 0'

            else:

                des_string += ' b > 0'

        # there is a problem with numbers which are identical to many decimal places (and should be identical) but which the 'puter thinks are not identical... so I correct that here
        if game_bit_string == '000220222012':

            game_bit_string = '000210222012'

            des_string = 'a < c < g = e  |  f = h < d < b'

        if game_bit_string == '222111000012':

            game_bit_string = '222111000111'

            des_string = 'c = e = g < a  |  b < d = f = g'

        if game_bit_string == '000221222111':

            game_bit_string = '000111222111'

            des_string = 'a < c = e = g  |  d = f = g < b'

        if game_bit_string == '222221000002':

            game_bit_string = '222221000001'

            des_string = 'c = g < e < a  |  b < f < d = h'

        classic_game = check_vs_classic_games(payoffs_4_scenarios)

        if classic_game != 'Other':

            des_string += ' '
            des_string += classic_game

        exp_rtns_matrix.append(des_string)

        exp_rtns_matrix.append(classic_game)

    # some code checking:
    if params.run_code_tests and (agent_basket_array[0][0] > 0.0 and agent_basket_array[0][1] > 0.0 and agent_exp_gain_2A_reduced == 0.0 and cp_exp_gain_2A_reduced == 0.0) or \
            (cp_agent_basket_array[0][0] > 0.0 and cp_agent_basket_array[0][1] > 0.0 and agent_exp_gain_3A_reduced == 0.0 and cp_exp_gain_3A_reduced == 0.0):

        print('\n Euston we have a problem in form_exps_rtns_props...')
        print('\n exp_rtns_matrix =', exp_rtns_matrix)
        print('\n agent_lowest_res =', agent_lowest_res)
        print(' tot_trans_ag_buy', tot_trans_ag_buy)
        print(' agent_MRS_array[agent_lowest_res][agent_buys]', agent_MRS_array[agent_lowest_res][agent_buys])
        print(' tot_trans_ag_sell', tot_trans_ag_sell)
        print(' agent_MRS_array[agent_lowest_res][agent_sells]', agent_MRS_array[agent_lowest_res][agent_sells])
        print(' agent_trade_gain', agent_trade_gain)
        print('\n cp_agent_lowest_res =', cp_agent_lowest_res)
        print(' tot_trans_ag_sell', tot_trans_ag_sell)
        print(' cp_agent_MRS_array[cp_agent_lowest_res][agent_sells]', pot_cp.MRS_array[cp_agent_lowest_res][agent_sells])
        print(' tot_trans_ag_buy', tot_trans_ag_buy)
        print(' cp_agent_MRS_array[pcp_agent_lowest_res][agent_buys]', pot_cp.MRS_array[cp_agent_lowest_res][agent_buys])
        print(' pot_cp_trade_gain', pot_cp_trade_gain)

        print('\n gain_agent_low_res_6', gain_agent_low_res_6)
        print(' gain_agent_low_res_6_prob_weighted', gain_agent_low_res_6_prob_weighted)
        print('\n gain_pot_cp_low_res_6', gain_pot_cp_low_res_6)
        print(' gain_pot_cp_low_res_6_prob_weighted', gain_pot_cp_low_res_6_prob_weighted)
        print('\n\n check all probs of scenarios: total =', prob_scen_1 + prob_scen_2 + prob_scen_3 + prob_scen_4 + prob_scen_5 + prob_scen_6)

        pause()

    if params.run_code_tests and (agent_trade_gain < 0.0 or pot_cp_trade_gain < 0.0):
        
        print('\n Euston we have that problem again: agent_trade_gain < 0.0 or pot_cp_trade_gain < 0.0 see end of form_exps_rtns_props fct')
        
        print(' agent_trade_gain =', agent_trade_gain, 'pot_cp_trade_gain =', pot_cp_trade_gain)

    return agent_total_exp_gain, pot_cp_total_exp_gain, exp_rtns_matrix


def find_cp_props(agent, cp, day, len_reputations_mem, print_fine_dets):

    """This function finds and returns an agent' expected prop_steal and prop_fight_back for a cp.  The default return values are None but the function
    returns real positive values if the denominator is not zero, i.e., if they could have stolen at any time or if they could have fought back."""

    # if cp not in agent.reputations_dict then we assume props of 0.5.
    # if cp is in agent.reputations_dict then...
    # there are 2 situations: 1) the agent's information about the cp is up-to-date (so we access agent.latest_cps_dict); and 2) the agent's information is
    # not up to date.  For the second scenario, we need to test the agent.reputations_dict: if there is recent data (within memory) then we use this; else,
    # we use the last known reputations data.  If all of this fails, we assume the prop data both = 0.5.

    if print_fine_dets:
        print('\n ** Starting find_cp_props')

    pot_cp_prop_steal = 0.5
    pot_cp_prop_fight_back = 0.5

    num_interactions = 0

    if print_fine_dets:
        print('\n str(cp) in agent.reputations_dict', str(cp) in agent.reputations_dict)

    if str(cp) in agent.reputations_dict:

        if print_fine_dets and str(cp) in agent.need_to_update_reps:
            print('\n agent.need_to_update_reps[str(cp)]', agent.need_to_update_reps[str(cp)])

        if str(cp) in agent.need_to_update_reps and agent.need_to_update_reps[str(cp)] == 0:

            pot_cp_prop_steal = agent.latest_cps_dict[str(cp)][0]
            pot_cp_prop_fight_back = agent.latest_cps_dict[str(cp)][1]

            if print_fine_dets:
                print('n agent.latest_cps_dict[str(cp)]', agent.latest_cps_dict[str(cp)])

        else:

            if print_fine_dets:
                print('\n doing it long hand...')

            # for the dict look-ups below, find the day memory starts (this will be included)
            mem_start_day = np.max([0, day - len_reputations_mem])

            # this array counts the number of fights pot_cp tried to start
            num_fights_array = agent.reputations_dict[str(cp)][0]

            # this array counts the number of interactions the agent has been in
            num_interactions_array = agent.reputations_dict[str(cp)][1]

            # this arrar contains the number of times the agent fought back
            num_fight_backs_array = agent.reputations_dict[str(cp)][2]

            # this array counts the number of times the pot_cp could have fought back
            num_fight_back_interactions_array = agent.reputations_dict[str(cp)][3]

            # we want to count the number of fights the pot_cp tried to start over the memory length of the agent len_reputations_mem
            # note that we have to include any data we might have from today's interactions
            num_times_fought_slice = num_fights_array[mem_start_day:day]
            num_times_fought_slice = np.append(num_times_fought_slice, num_fights_array[day])

            num_times_pot_cp_fought = np.sum(num_times_fought_slice)

            # now the number of times the agent could have fought:
            num_interactions_slice = num_interactions_array[mem_start_day:day]
            num_interactions_slice = np.append(num_interactions_slice, num_interactions_array[day])

            num_interactions = np.sum(num_interactions_slice)

            if print_fine_dets == 1:
                print('\n num_times_pot_cp_fought =', num_times_pot_cp_fought)
                print(' num_interactions', num_interactions)

            if num_interactions > 0:

                pot_cp_prop_steal = num_times_pot_cp_fought / float(num_interactions)

            # Looking at fighting back:
            # we need to evaluate whether there were any times the pot_cp could have fought back over the length of memory and then use this in a condition
            num_fight_back_interactions_slice = num_fight_back_interactions_array[mem_start_day:day]
            num_fight_back_interactions_slice = np.append(num_fight_back_interactions_slice, num_fight_back_interactions_array[day])

            num_fight_back_interactions = np.sum(num_fight_back_interactions_slice)

            # we want to count the number of times the pot_cp actually fought back
            num_times_pot_cp_fought_back_slice = num_fight_backs_array[mem_start_day:day]
            num_times_pot_cp_fought_back_slice = np.append(num_times_pot_cp_fought_back_slice, num_fight_backs_array[day])

            num_times_pot_cp_fought_back = np.sum(num_times_pot_cp_fought_back_slice)

            if print_fine_dets == 1:
                print('\n num_times_pot_cp_fought_back =', num_times_pot_cp_fought_back)
                print(' num_fight_back_interactions', num_fight_back_interactions)

            if num_fight_back_interactions > 0:   # i.e. we have reputational information about pot_cp fighting back

                pot_cp_prop_fight_back = num_times_pot_cp_fought_back / float(num_fight_back_interactions)

            # if pot_cp_prop_steal is None (either because cp not known to agent or because nothing in memory) then we revert to the agent's last known reputation.
            # The same it true of p_fb

            if pot_cp_prop_steal is None and str(cp) in agent.last_known_rep_ps_dict:
                pot_cp_prop_steal = copy.copy(agent.last_known_rep_ps_dict[str(cp)])

            elif pot_cp_prop_steal is not None:
                agent.last_known_rep_ps_dict[str(cp)] = pot_cp_prop_steal

            if pot_cp_prop_fight_back is None and str(cp) in agent.last_known_rep_pfb_dict:
                pot_cp_prop_fight_back = copy.copy(agent.last_known_rep_pfb_dict[str(cp)])

            elif pot_cp_prop_fight_back is not None:
                agent.last_known_rep_pfb_dict[str(cp)] = pot_cp_prop_fight_back

    if print_fine_dets:
        print('\n ** Ending find_cp_props \n')

    return pot_cp_prop_steal, pot_cp_prop_fight_back, num_interactions


def strangers_interact(params, min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, print_fine_dets, use_start_basket, agent, cp_agent,
                       stranger_int, formal_inst, prob_fine, fine, two_tribes_inst, fight_cost):

    """This function organises the interaction of two strangers."""

    # if str(cp_agent) in agent.exp_int_gains_dict_strangers:
    #     print_fine_dets = 1

    if print_fine_dets:
        print('\n\n\n *** Starting strangers_interact')
        print(' str(cp_agent) in agent.exp_int_gains_dict_strangers', str(cp_agent) in agent.exp_int_gains_dict_strangers)
        print(' use_start_basket', use_start_basket)

    new_eval_requd = 1

    if str(cp_agent) in agent.exp_int_gains_dict_strangers and use_start_basket == 0:

        known_cp_int_data = agent.exp_int_gains_dict_strangers[str(cp_agent)]

        if print_fine_dets:
            print('\n known_cp_int_data:', known_cp_int_data)

        # if this condition is true then neither the cp_agent nor the agent have interacted since the last time the agent evaluated the outcomes for cp_agent so we can use the previous evaluation payoffs_4_scenarios
        if known_cp_int_data[0] == cp_agent.last_intn and known_cp_int_data[1] == agent.last_intn:

            ag_gain, cp_gain = known_cp_int_data[2]

            des_string = known_cp_int_data[3]
            classic_game_type = known_cp_int_data[4]

            agent_dom_strat = known_cp_int_data[5]
            cp_dom_strat = known_cp_int_data[6]

            new_eval_requd = 0

            if print_fine_dets:

                print('\n Using Old Evaluation: agent.exp_int_gains_dict_strangers[str(cp_agent)] =', agent.exp_int_gains_dict_strangers[str(cp_agent)])
                print(' new_eval_requd =', new_eval_requd)
                print('\n cp_agent.last_intn', cp_agent.last_intn)
                print(' agent.last_intn', agent.last_intn)

    if new_eval_requd == 1:

        if print_fine_dets:
            print('\n New evaluation required:')

        if use_start_basket == 0:
    
            start_agent_tot_ress = agent.agent_res_array[0] + agent.basket_array[0]
            start_cp_agent_tot_ress = cp_agent.agent_res_array[0] + cp_agent.basket_array[0]
    
            agent_basket_used = agent.basket_array
            cp_agent_basket_used = cp_agent.basket_array
    
        elif use_start_basket == 1:
            
            start_agent_tot_ress = agent.agent_res_array[0] + agent.basket_array_start[0]
            start_cp_agent_tot_ress = cp_agent.agent_res_array[0] + cp_agent.basket_array_start[0]
    
            agent_basket_used = agent.basket_array_start
            cp_agent_basket_used = cp_agent.basket_array_start
    
        agent.MRS_array = generate_MRS_array(agent.agent_res_array + agent_basket_used, print_fine_dets=0)
        cp_agent.MRS_array = generate_MRS_array(cp_agent.agent_res_array + cp_agent_basket_used, print_fine_dets=0)
    
        agent_min_res_value = np.min(start_agent_tot_ress)
        cp_agent_min_res_value = np.min(start_cp_agent_tot_ress)
    
        agent_min_res = 0
        cp_agent_min_res = 0
            
        for res in range(num_res_founts):
    
            if start_agent_tot_ress[res] == agent_min_res_value:
    
                agent_min_res = res
    
            if start_cp_agent_tot_ress[res] == cp_agent_min_res_value:
    
                cp_agent_min_res = res
    
        if print_fine_dets:
            
            print('\n agent.agent_res_array[0] ', agent.agent_res_array[0])
            print(' agent.basket_array[0] ', agent.basket_array[0])
            print(' agent.basket_array_start[0] ', agent.basket_array_start[0])        
            print(' agent_basket_used', agent_basket_used)
            print(' agent_min_res ', agent_min_res)
    
            print('\n cp_agent.agent_res_array[0] ', cp_agent.agent_res_array[0])
            print(' cp_agent.basket_array[0] ', cp_agent.basket_array[0])
            print(' cp_agent.basket_array_start[0] ', cp_agent.basket_array_start[0])        
            print(' cp_agent_basket_used', cp_agent_basket_used)
            print(' cp_agent_min_res ', cp_agent_min_res)
            
            print('\n stranger_int =', stranger_int)
            
            print('\n fight_cost =', fight_cost)

        # we look at 4 scenarios to derive an appreciation of outcomes for the agents in each quadrant of a game: 1 trade / trade, 2 steal / trade, 3 trade / steal, and 4 steal / steal
    
        # scenario 1 is the same refardless of self.stranger_int - both trade
        # start with finding whether and how much both would trade, and the price

        if (use_start_basket and ((agent.basket_array_start[0][0] > 0.0 and cp_agent.basket_array_start[0][1] > 0.0) or (agent.basket_array_start[0][1] > 0.0 and cp_agent.basket_array_start[0][0] > 0))) or\
            (use_start_basket == 0 and ((agent.basket_array[0][0] > 0.0 and cp_agent.basket_array[0][1] > 0.0) or (agent.basket_array[0][1] > 0.0 and cp_agent.basket_array[0][0] > 0))): # then they might trade

            tot_cons_surp_array, best_trans_data = build_tot_cons_surp_array(min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, print_fine_dets, use_start_basket,
                                                                             agent.agent_res_array, agent.basket_array, agent.basket_array_start, cp_agent.agent_res_array, cp_agent.basket_array, cp_agent.basket_array_start)

        else: # then they won't trade
            
            tot_cons_surp_array, best_trans_data = ([[0.0, 0.0], [0.0, 0.0]], [0.0, 0.0, 0.0, 0.0, 0.0])

        # find the maximum change in consumer surplus
        max_cons_surp_ch = np.max(tot_cons_surp_array)
    
        if print_fine_dets == 1:
            print('\n tot_cons_surp_array:\n', tot_cons_surp_array)
            print('\n max_cons_surp_ch', max_cons_surp_ch)
            print('\n best_trans_data =', best_trans_data)
    
        # We only carry on if max_cons_surp_ch is positive.  It can't be negative but all cells might be zero in which
        # case there's no advantage to both agents in transacting
        if max_cons_surp_ch > 0:
    
            agent_sells, agent_buys, tot_trans_ag_sell, tot_trans_ag_buy, trans_agr_MRS = best_trans_data
    
            # we find the reduced gain for the agents:
            exp_gain_agent_1 = tot_trans_ag_buy * agent.MRS_array[agent_min_res][agent_buys] - tot_trans_ag_sell * agent.MRS_array[agent_min_res][agent_sells]
            exp_cp_gain_1 = tot_trans_ag_sell * cp_agent.MRS_array[cp_agent_min_res][agent_sells] - tot_trans_ag_buy * cp_agent.MRS_array[cp_agent_min_res][agent_buys]
    
            if print_fine_dets == 1:
                print('\n exp_gain_agent_1:', exp_gain_agent_1)
                print('\n exp_cp_gain_1', exp_cp_gain_1)
    
        else:
    
            exp_gain_agent_1 = 0
            exp_cp_gain_1 = 0
            
            if print_fine_dets == 1:
                print('\n they would not trade')
    
    #                        pause()

        # before moving forward, let us fine reduced value of fines.  We use this in various places below.
        ag_fine_red_val = 0
        cp_fine_red_val = 0

        for res in range(num_res_founts):

            ag_fine_red_val += fight_cost * agent.MRS_array[agent_min_res][res]
            cp_fine_red_val += fight_cost * cp_agent.MRS_array[cp_agent_min_res][res]

        if print_fine_dets:
            
            print('\n ag_fine_red_val ', ag_fine_red_val)
            print('\n cp_fine_red_val ', cp_fine_red_val)

        if stranger_int == 'acq':       # then if one trades and the other fights, the trader acquiesces
    
            if print_fine_dets == 1:
                print('\n when interacting, trading means acquiescing when the other steals')
    
                print('\n agent.agent_res_array[0] ', agent.agent_res_array[0])
                print(' agent.basket_array[0] ', agent.basket_array[0])
                print(' agent_basket_used', agent_basket_used)
                print(' agent_min_res ', agent_min_res)
        
                print('\n cp_agent.agent_res_array[0] ', cp_agent.agent_res_array[0])
                print(' cp_agent.basket_array[0] ', cp_agent.basket_array[0])
                print(' cp_agent_basket_used', cp_agent_basket_used)
                print(' cp_agent_min_res ', cp_agent_min_res)
    
            # scenario 2 - agent wants to trade and cp_agent wants to steal.  agent acquiesces, cp_agent gets all
            exp_gain_agent_2 = 0
            exp_cp_gain_2 = 0
    
            for res in range(num_res_founts):
    
                exp_gain_agent_2 -= agent_basket_used[0][res] * agent.MRS_array[agent_min_res][res]
    
                exp_cp_gain_2 += agent_basket_used[0][res] * cp_agent.MRS_array[cp_agent_min_res][res]
    
            if print_fine_dets == 1:
                print('\n\n gross exp_gain_agent_2:', exp_gain_agent_2)
                print('\n gross exp_cp_gain_2', exp_cp_gain_2)
    
            # but the cp_agent might get fined:
            exp_fine_cp_agent_2 = 0
    
            if formal_inst or two_tribes_inst:
    
                for res in range(num_res_founts):
        
                    exp_fine_cp_agent_2 += prob_fine * fine * cp_agent.MRS_array[cp_agent_min_res][res]
        
                if print_fine_dets == 1:
                    print('\n exp_fine_cp_agent_2:', exp_fine_cp_agent_2)
    
            exp_gain_agent_2_pre_fine = copy.copy(exp_gain_agent_2)
            exp_cp_gain_2_pre_comp = copy.copy(exp_cp_gain_2)
    
            exp_cp_gain_2 += exp_fine_cp_agent_2
    
            if print_fine_dets == 1:
                print('\n NET of fine exp_cp_gain_2:', exp_cp_gain_2)
    
            # we add compensation if
            if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
    
                exp_comp_agent_2 = 0
    
                for res in range(num_res_founts):
    
                    exp_comp_agent_2 -= prob_fine * fine * agent.MRS_array[agent_min_res][res]
    
                exp_gain_agent_2 += exp_comp_agent_2
    
                if print_fine_dets == 1:
                    print('\n ag compensated by ', exp_comp_agent_2)
                    print('\n exp_gain_agent_2 final: ', exp_gain_agent_2)
    
            # scenario 3 - agent wants to steal and cp_agent wants to trade.  cp acquiesces, agent gets all
            exp_gain_agent_3 = 0
            exp_cp_gain_3 = 0
    
            for res in range(num_res_founts):
    
                exp_gain_agent_3 += cp_agent_basket_used[0][res] * agent.MRS_array[agent_min_res][res]
                
                exp_cp_gain_3 -= cp_agent_basket_used[0][res] * cp_agent.MRS_array[cp_agent_min_res][res]
    
            exp_cp_gain_3_pre_fine = copy.copy(exp_cp_gain_3)
            exp_gain_agent_3_pre_comp = copy.copy(exp_gain_agent_3)
    
            if print_fine_dets == 1:
                print('\n\n exp_gain_agent_3:', exp_gain_agent_3)
                print('\n exp_cp_gain_3', exp_cp_gain_3)
    
            # the agent might get fined:
            exp_fine_agent_3 = 0
            
            if formal_inst or two_tribes_inst:
    
                for res in range(num_res_founts):
        
                    exp_fine_agent_3 += prob_fine * fine * agent.MRS_array[agent_min_res][res]
        
                if print_fine_dets == 1:
                    print('\n exp_fine_agent_3:', exp_fine_agent_3)
    
            exp_gain_agent_3 += exp_fine_agent_3
    
            if print_fine_dets == 1:
                print('\n NET of fine exp_gain_agent_3:', exp_gain_agent_3)
    
            # we add compensation to the agent if
            if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
    
                exp_comp_cp_3 = 0
    
                for res in range(num_res_founts):
    
                    exp_comp_cp_3 -= prob_fine * fine * cp_agent.MRS_array[cp_agent_min_res][res]
    
                exp_cp_gain_3 += exp_comp_cp_3
    
                if print_fine_dets == 1:
                    print('\n cp compensated by ', exp_comp_cp_3)
                    print('\n exp_cp_gain_3 final', exp_cp_gain_3)
    
            # scenario 4 - they both try to steal.  their expected gains (losses) are determined by their expected gains less a fine
            # first fine reduced value of fine
            
            
            exp_gain_agent_4 = ag_fine_red_val + ((exp_gain_agent_2_pre_fine + exp_gain_agent_3_pre_comp) / 2.0) + exp_fine_agent_3
            exp_cp_gain_4 = cp_fine_red_val + ((exp_cp_gain_3_pre_fine + exp_cp_gain_2_pre_comp) / 2.0) + exp_fine_cp_agent_2

            if print_fine_dets == 1:
                print('\n\n exp_gain_agent_4:', exp_gain_agent_4)
                print('\n exp_cp_gain_4', exp_cp_gain_4)
    
        elif stranger_int == 'fb':
    
    #        formal_inst = 'fine_only'
            
            if print_fine_dets == 1:
                print('\n when interacting, trading means fighting back when the other steals')
    
                print('\n agent.agent_res_array[0] ', agent.agent_res_array[0])
                print(' agent.basket_array[0] ', agent.basket_array[0])
                print(' agent_basket_used =', agent_basket_used)
                print(' agent_min_res ', agent_min_res)
        
                print('\n cp_agent.agent_res_array[0] ', cp_agent.agent_res_array[0])
                print(' cp_agent.basket_array[0] ', cp_agent.basket_array[0])
                print(' cp_agent_basket_used =', cp_agent_basket_used)
                print(' cp_agent_min_res ', cp_agent_min_res)
    
            # let's first work out the gain / loss of each fighting - both incur whatever fight cost there is
            ag_gain_both_fight_ex_fine = ag_fine_red_val
            cp_gain_both_fight_ex_fine = cp_fine_red_val
    
            ag_exp_fine = 0
            cp_exp_fine = 0
    
            if print_fine_dets == 1:
                print('\n both agents incur a fight cost: ', fight_cost)
                print(' prob_fine', prob_fine, 'fine ', fine)
                print(' formal_inst =', formal_inst)
    
            # agent wins
            for res in range(num_res_founts):
    
                ag_gain_both_fight_ex_fine += cp_agent_basket_used[0][res] * agent.MRS_array[agent_min_res][res]
    
                cp_gain_both_fight_ex_fine -= cp_agent_basket_used[0][res] * cp_agent.MRS_array[cp_agent_min_res][res]
    
                if formal_inst or two_tribes_inst:
    
                    ag_exp_fine += prob_fine * fine * agent.MRS_array[agent_min_res][res]
    
            # cp wins
            for res in range(num_res_founts):
    
                ag_gain_both_fight_ex_fine -= agent_basket_used[0][res] * agent.MRS_array[agent_min_res][res]
    
                cp_gain_both_fight_ex_fine += agent_basket_used[0][res] * cp_agent.MRS_array[cp_agent_min_res][res]
    
                if formal_inst or two_tribes_inst:
                    
                    cp_exp_fine += prob_fine * fine * cp_agent.MRS_array[cp_agent_min_res][res]
    
            # divide these by 2
            ag_gain_both_fight_ex_fine *= 0.5
            cp_gain_both_fight_ex_fine *= 0.5
    
            if print_fine_dets == 1:
                print('\n agent: expected gross gain from fighting (given 50 50) =', ag_gain_both_fight_ex_fine)
                print('\n cp: expected gross gain from fighting (given 50 50) =', cp_gain_both_fight_ex_fine)
    
                print('\n agent: expected fine =', ag_exp_fine)
                print('\n cp: expected fine =', cp_exp_fine)
    
            # scenario 2 - agent fights back (no fine), cp steals (fine) build_tot_cons_surp_array
            exp_gain_agent_2 = ag_gain_both_fight_ex_fine
            exp_cp_gain_2 = cp_gain_both_fight_ex_fine
    
            if print_fine_dets == 1:
                print('\n\n exp_gain_agent_2 (gross gain no fine)', exp_gain_agent_2)
                print('\n exp_cp_gain_2 (gross gain with fine)', exp_cp_gain_2)
    
            if formal_inst or two_tribes_inst:
                
                exp_cp_gain_2 += cp_exp_fine
    
                if print_fine_dets == 1:
                    print('\n cp_agent fined by', cp_exp_fine, 'so exp_cp_gain_2 =', exp_cp_gain_2)
    
            if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
                
                exp_gain_agent_2 -= ag_exp_fine
    
                if print_fine_dets == 1:
                    print('\n ag compensated by', ag_exp_fine, 'so exp_gain_agent_2 =', exp_gain_agent_2)
    
            # scenario 3 - agent steals (exp fine), cp fights back (no fine)
            exp_gain_agent_3 = ag_gain_both_fight_ex_fine
            exp_cp_gain_3 = cp_gain_both_fight_ex_fine
    
            if print_fine_dets == 1:
                print('\n\n exp_gain_agent_3 (gross gain less fine)', exp_gain_agent_3)
                print('\n exp_cp_gain_3 (gross gain no fine)', exp_cp_gain_3)
    
            if formal_inst or two_tribes_inst:
                
                exp_gain_agent_3 += ag_exp_fine
    
                if print_fine_dets == 1:
                    print('\n agent fined by', ag_exp_fine, 'so exp_gain_agent_3 =', exp_gain_agent_3)
    
            if formal_inst == 'compensate' or two_tribes_inst == 'compensate':
    
                exp_cp_gain_3 -= cp_exp_fine
    
                if print_fine_dets == 1:
                    print('\n cp compensated by', cp_exp_fine, 'so exp_cp_gain_3 =', exp_cp_gain_3)
    
            # scenario 4 - both steal, both fined
            exp_gain_agent_4 = ag_gain_both_fight_ex_fine + ag_exp_fine
            exp_cp_gain_4 = cp_gain_both_fight_ex_fine + cp_exp_fine
    
            if print_fine_dets == 1:
                print('\n\n exp_gain_agent_4 (gross gain with fine)', exp_gain_agent_4)
                print('\n exp_cp_gain_4 (gross gain with fine)', exp_cp_gain_4)

        # now we can work out if the agents have dominant strategies
        agent_dom_strat = 'none'
        cp_dom_strat = 'none'
        
        matrix_4_quads = [[exp_gain_agent_1, exp_cp_gain_1], [exp_gain_agent_2, exp_cp_gain_2], [exp_gain_agent_3, exp_cp_gain_3], [exp_gain_agent_4, exp_cp_gain_4]]
        
        # for the agent:
        if (exp_gain_agent_1 > exp_gain_agent_3 and exp_gain_agent_2 >= exp_gain_agent_4) or (exp_gain_agent_1 >= exp_gain_agent_3 and exp_gain_agent_2 > exp_gain_agent_4):
            
            agent_dom_strat = 'trade'
    
        if (exp_gain_agent_1 < exp_gain_agent_3 and exp_gain_agent_2 <= exp_gain_agent_4) or (exp_gain_agent_1 <= exp_gain_agent_3 and exp_gain_agent_2 < exp_gain_agent_4):
        
            agent_dom_strat = 'steal'
    
        # for the cp_agent
        if (exp_cp_gain_1 > exp_cp_gain_2 and exp_cp_gain_3 >= exp_cp_gain_4) or (exp_cp_gain_1 >= exp_cp_gain_2 and exp_cp_gain_3 > exp_cp_gain_4):
            
            cp_dom_strat = 'trade'
    
        if (exp_cp_gain_1 < exp_cp_gain_2 and exp_cp_gain_3 <= exp_cp_gain_4) or (exp_cp_gain_1 <= exp_cp_gain_2 and exp_cp_gain_3 < exp_cp_gain_4):
        
            cp_dom_strat = 'steal'
    
        if print_fine_dets == 1:
            
            print('\n initial strats: agent =', agent_dom_strat, 'cp =', cp_dom_strat)
    
        # if one agent has a dominant strategy and the other does not, it's likely the other will have a dominant strategy given the one dominant strategy
        if agent_dom_strat == 'none' and cp_dom_strat == 'trade':
            
            if exp_gain_agent_1 > exp_gain_agent_3:
                
                agent_dom_strat = 'trade'
    
            if exp_gain_agent_1 < exp_gain_agent_3:
                
                agent_dom_strat = 'steal' 
        
        if agent_dom_strat == 'none' and cp_dom_strat == 'steal':
            
            if exp_gain_agent_2 > exp_gain_agent_4:
                
                agent_dom_strat = 'trade'
    
            if exp_gain_agent_2 < exp_gain_agent_4:
                
                agent_dom_strat = 'steal' 
    
        if cp_dom_strat == 'none' and agent_dom_strat == 'trade':
            
            if exp_cp_gain_1 > exp_cp_gain_2:
                
                cp_dom_strat = 'trade'
    
            if exp_cp_gain_1 < exp_cp_gain_2:
                
                cp_dom_strat = 'steal' 
        
        if cp_dom_strat == 'none' and agent_dom_strat == 'steal':
            
            if exp_cp_gain_3 > exp_cp_gain_4:
                
                cp_dom_strat = 'trade'
    
            if exp_cp_gain_3 < exp_cp_gain_4:
                
                cp_dom_strat = 'steal' 
    
        if print_fine_dets == 1:
            print('\n agent_dom_strat:', agent_dom_strat)
            print('\n cp_dom_strat', cp_dom_strat)
    
    #        pause()
    
        if agent_dom_strat == 'trade' and cp_dom_strat == 'trade':
            
            ag_gain = exp_gain_agent_1
            cp_gain = exp_cp_gain_1
            
            # if they prefer to trade but they won't as there's no benefit then they should ignore each other
            if max_cons_surp_ch == 0:
                
                agent_dom_strat = 'none'
                cp_dom_strat = 'none'
            
                ag_gain = 0
                cp_gain = 0
           
        elif agent_dom_strat == 'trade' and cp_dom_strat == 'steal':

            ag_gain = exp_gain_agent_2
            cp_gain = exp_cp_gain_2
    
            if stranger_int == 'fb':
            
                agent_dom_strat = 'fight_back'
    
        elif agent_dom_strat == 'steal' and cp_dom_strat == 'trade':

            ag_gain = exp_gain_agent_3
            cp_gain = exp_cp_gain_3
    
            if stranger_int == 'fb':
            
                cp_dom_strat = 'fight_back'
    
        elif agent_dom_strat == 'steal' and cp_dom_strat == 'steal':
            
            ag_gain = exp_gain_agent_4
            cp_gain = exp_cp_gain_4
    
        else:
            
            ag_gain = None
            cp_gain = None   

        # if we are tracking game types:
        des_string = ''
        classic_game_type = ''

        if params.track_game_types:

            # create des_string
            es_dict = dict()

            a = exp_gain_agent_1
            b = exp_cp_gain_1
            c = exp_gain_agent_2
            d = exp_cp_gain_2
            e = exp_gain_agent_3
            f = exp_cp_gain_3
            g = exp_gain_agent_4
            h = exp_cp_gain_4

            es_dict['a'] = a
            es_dict['c'] = c
            es_dict['e'] = e
            es_dict['g'] = g

            sorted_str = ''
            sorted_array = []

            for key, value in sorted(es_dict.items(), key=lambda item: (item[1], item[0])):

                sorted_str += key
                sorted_array.append(value)

            des_string = sorted_str[0]

            oops = 0

            for iter_num in range(len(sorted_array) - 1):

                if sorted_array[iter_num] < sorted_array[iter_num + 1]:
                    des_string += ' < '

                elif sorted_array[iter_num] == sorted_array[iter_num + 1]:
                    des_string += ' = '

                elif sorted_array[iter_num] > sorted_array[iter_num + 1]:
                    des_string += ' > '

                    oops = 1

                des_string += sorted_str[iter_num + 1]

            des_string += '  |  '

            es_dict = dict()

            es_dict['b'] = b
            es_dict['d'] = d
            es_dict['f'] = f
            es_dict['h'] = h

            sorted_str = ''
            sorted_array = []

            for key, value in sorted(es_dict.items(), key=lambda item: (item[1], item[0])):

                sorted_str += key
                sorted_array.append(value)

            des_string = 'rational '

            des_string += sorted_str[0]

            for iter_num in range(len(sorted_array) - 1):

                if sorted_array[iter_num] < sorted_array[iter_num + 1]:
                    des_string += ' < '

                elif sorted_array[iter_num] == sorted_array[iter_num + 1]:
                    des_string += ' = '

                elif sorted_array[iter_num] > sorted_array[iter_num + 1]:
                    des_string += ' > '

                    oops = 1

                des_string += sorted_str[iter_num + 1]

            if oops != 0:

                print('\n sorted_array =', sorted_array)
                print(' des_string ', des_string)
                pause()

            # for when 'rational' and fb - need to know how many a & b == 0 or > 0
            if des_string == 'c = e = g < a  |  d = f = h < b':

                if a == 0.0:

                    des_string += '  |  a = 0'

                else:

                    des_string += '  |  a > 0'

                if b == 0.0:

                    des_string += ' b = 0'

                else:

                    des_string += ' b > 0'

            # there is a problem with numbers which are identical to many decimal places (and should be identical) but which the 'puter thinks are not identical... so I correct that here
            if des_string == 'a < c < g < e  |  f = h < d < b':

                des_string = 'a < c < g = e  |  f = h < d < b'

            if des_string == 'c = e = g < a  |  b < f = h < d':

                des_string = 'c = e = g < a  |  b < d = f = h'

            if des_string == 'a < c = g < e  |  d = f = h < b':

                des_string = 'a < c = e = g  |  d = f = h < b'

            if des_string == 'c = g < e < a  |  b < f < h < d':

                des_string = 'c = g < e < a  |  b < f < d = h'

            # we also update agent.exp_rtns_matrix[str(cp_agent)]
            classic_game_type = check_vs_classic_games(matrix_4_quads)

            if classic_game_type != 'Other':

                des_string += ' '
                des_string += classic_game_type

        if use_start_basket == 0:

            if stranger_int == 'acq':
                
                agent.exp_rtns_matrix[str(cp_agent)] = [[exp_gain_agent_1, exp_cp_gain_1], [None, None], [exp_gain_agent_2, exp_cp_gain_2], [None, None], [exp_gain_agent_3, exp_cp_gain_3], [exp_gain_agent_4, exp_cp_gain_4], des_string,
                                                        classic_game_type, agent_dom_strat, cp_dom_strat, ag_gain, cp_gain]
        
            if stranger_int == 'fb':
        
                agent.exp_rtns_matrix[str(cp_agent)] = [[exp_gain_agent_1, exp_cp_gain_1], [exp_gain_agent_2, exp_cp_gain_2], [None, None], [exp_gain_agent_3, exp_cp_gain_3], [None, None], [exp_gain_agent_4, exp_cp_gain_4], des_string,
                                                        classic_game_type, agent_dom_strat, cp_dom_strat, ag_gain, cp_gain]

            agent.exp_int_gains_dict_strangers[str(cp_agent)] = [cp_agent.last_intn, agent.last_intn, [ag_gain, cp_gain], des_string, classic_game_type, agent_dom_strat, cp_dom_strat]

            if print_fine_dets == 1:
                
                print('\n matrix_4_quads :\n', matrix_4_quads[0], matrix_4_quads[1], '\n', matrix_4_quads[2], matrix_4_quads[3])
                print('\n agent.exp_int_gains_dict_strangers[str(cp_agent)] =', agent.exp_int_gains_dict_strangers[str(cp_agent)])
                print('\n agent.exp_rtns_matrix[str(cp_agent)] =', agent.exp_rtns_matrix[str(cp_agent)])
                pause()

        elif use_start_basket:

            agent.exp_int_gains_dict_strangers[str(cp_agent)] = [[ag_gain, cp_gain], des_string, classic_game_type, agent_dom_strat, cp_dom_strat]

            # agent.MRS_array = generate_MRS_array(agent.agent_res_array + agent.basket_array, print_fine_dets=0)
            # cp_agent.MRS_array = generate_MRS_array(cp_agent.agent_res_array + cp_agent.basket_array, print_fine_dets=0)

            if print_fine_dets == 1:
                
                print('\n matrix_4_quads :\n', matrix_4_quads[0], matrix_4_quads[1], '\n', matrix_4_quads[2], matrix_4_quads[3])
                print('\n agent.exp_int_gains_dict_strangers[str(cp_agent)] =', agent.exp_int_gains_dict_strangers[str(cp_agent)])
#                pause()        

    # add considered game type to these dictionaries if not simulated
    if params.track_game_types and use_start_basket == 0:

        if des_string in dbs.games_type_considered_dict:
    
            dbs.games_type_considered_dict[des_string][day] += 1
    
        else:
            
            dbs.games_type_considered_dict[des_string] = np.zeros(shape=dbs.num_rounds, dtype=int)
    
            dbs.games_type_considered_dict[des_string][day] += 1

        if classic_game_type in dbs.classic_games_considered:
            
            dbs.classic_games_considered[classic_game_type][day] += 1
         
        else:
            
            dbs.classic_games_considered[classic_game_type] = np.zeros(shape=dbs.num_rounds, dtype=int)
    
            dbs.classic_games_considered[classic_game_type][day] += 1

    # code test
    if params.run_code_tests and (ag_gain == None or cp_gain == None): # or agent_dom_strat == 'trade' or cp_dom_strat == 'trade':
        
        print('\n oops - strangers_interact: ag_gain == None or cp_gain == None')
        print('\n agent.exp_int_gains_dict_strangers[str(cp_agent)] =', agent.exp_int_gains_dict_strangers[str(cp_agent)])
        
        if new_eval_requd and use_start_basket == 0:

            print('\n matrix_4_quads :\n', matrix_4_quads[0], matrix_4_quads[1], '\n', matrix_4_quads[2], matrix_4_quads[3])
            print('\n agent.exp_rtns_matrix[str(cp_agent)] =', agent.exp_rtns_matrix[str(cp_agent)])

        print('\n agent.agent_res_array[0] ', agent.agent_res_array[0])
        print(' agent.basket_array[0] ', agent.basket_array[0])
        print(' agent.basket_array_start[0] ', agent.basket_array_start[0])        
        print(' agent_basket_used', agent_basket_used)
        print(' agent_min_res ', agent_min_res)

        print('\n cp_agent.agent_res_array[0] ', cp_agent.agent_res_array[0])
        print(' cp_agent.basket_array[0] ', cp_agent.basket_array[0])
        print(' cp_agent.basket_array_start[0] ', cp_agent.basket_array_start[0])        
        print(' cp_agent_basket_used', cp_agent_basket_used)
        print(' cp_agent_min_res ', cp_agent_min_res)
        
        print('\n stranger_int =', stranger_int)
        print('\n use_start_basket', use_start_basket)

        pause()

    if print_fine_dets:
        print('\n returned data: agent_dom_strat', agent_dom_strat, 'cp_dom_strat', cp_dom_strat, 'ag_gain', ag_gain, 'cp_gain', cp_gain)
        print('\n *** Ending strangers_interact')
        pause()

    return agent_dom_strat, cp_dom_strat, ag_gain, cp_gain


def build_tot_cons_surp_array(min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, print_fine_dets, use_start_basket,
                              agent_res_array, agent_basket_array, agent_basket_array_start, cp_agent_res_array, cp_agent_basket_array, cp_agent_basket_array_start):

    """This function builds the total consumer surplus array, which measures the change in the consumer surplus if the agents
    transacted.  It returns the array, which is num_res_founts X num_res_founts."""

#    print_fine_dets = 0 prob_agent_wins_fight

    if print_fine_dets == 1:
        print('\n\n *** starting build_tot_cons_surp_array ***')
        print('\n build... use_start_basket =', use_start_basket)
#        print('\nagent.basket_array =', agent.basket_array)
#        print('agent.aggr_res_array =', agent.aggr_res_array)
#        print('\nagent.MRS_array =\n', agent.MRS_array)
#        print('\ncp_agent.basket_array =', cp_agent.basket_array)
#        print('cp_agent.aggr_res_array =', cp_agent.aggr_res_array)
#        print('\ncp_agent.MRS_array =\n', cp_agent.MRS_array)

    # Create an array to record the potential transactions between the agents (agent sells x cp_agent buys).
    # We do this for every sell / buy combination
    tot_cons_surp_array = np.zeros(shape=(num_res_founts, num_res_founts))

    highest_surpl_so_far = 0.0
    record_trans_data = []
    for agent_sell_res in np.arange(num_res_founts):

        for cp_agent_sell_res in np.arange(num_res_founts):

            if agent_sell_res != cp_agent_sell_res:     # only carry on when resources are not the same

                ch_cons_surpl, ag_sells, ag_buys, trans_agr_MRS = process_transaction_PQ(print_fine_dets, agent_sell_res, cp_agent_sell_res, min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, use_start_basket,
                                                                                         agent_res_array, agent_basket_array, agent_basket_array_start, cp_agent_res_array, cp_agent_basket_array, cp_agent_basket_array_start)

                if ch_cons_surpl > highest_surpl_so_far:

                    highest_surpl_so_far = ch_cons_surpl
                    record_trans_data = [[agent_sell_res, cp_agent_sell_res, ag_sells, ag_buys, trans_agr_MRS]]

                elif ch_cons_surpl > highest_surpl_so_far and ch_cons_surpl != 0.0:

                    record_trans_data.append([agent_sell_res, cp_agent_sell_res, ag_sells, ag_buys, trans_agr_MRS])

                tot_cons_surp_array[agent_sell_res][cp_agent_sell_res] = ch_cons_surpl

    if len(record_trans_data) > 0:

        best_trans_data = random.choice(record_trans_data)

    else:

        best_trans_data = [None, None, None, None, None]

    if print_fine_dets == 1:
        print('\n tot_cons_surp_array:\n', tot_cons_surp_array)
#        print('\nrecord_trans_data =\n', record_trans_data)
#        print('\nbest_trans_data:\n', best_trans_data)
        print('\n*** ENDING build_tot_cons_surp_array ***')

    return tot_cons_surp_array, best_trans_data


def process_transaction_PQ(print_fine_dets, agent_sell_res, cp_agent_sell_res, min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, use_start_basket,
                           agent_res_array, agent_basket_array, agent_basket_array_start, cp_agent_res_array, cp_agent_basket_array, cp_agent_basket_array_start):

#    print_fine_dets = 1 agent, cp_agent,

    if print_fine_dets == 1:
        print('\n\n -> agent_sell_res', agent_sell_res, 'cp_agent_sell_res', cp_agent_sell_res)
        print('\n agent.agent_res_array', agent_res_array)
        print(' agent.basket_array =', agent_basket_array)
        print(' agent_basket_array_start =', agent_basket_array_start)
        print('\n cp_agent.agent_res_array', cp_agent_res_array)
        print(' cp_agent_basket_array =', cp_agent_basket_array)
        print(' cp_agent_basket_array_start =', cp_agent_basket_array_start)

    # update MRS arrays
    if use_start_basket == 0:
        
        agent_aggr_res_array = agent_res_array + agent_basket_array

    elif use_start_basket == 1:
        
        agent_aggr_res_array = agent_res_array + agent_basket_array_start
        
    agent_MRS_array = generate_MRS_array(agent_aggr_res_array, print_fine_dets)

    if use_start_basket == 0:

        cp_agent_aggr_res_array = cp_agent_res_array + cp_agent_basket_array

    elif use_start_basket == 1:

        cp_agent_aggr_res_array = cp_agent_res_array + cp_agent_basket_array_start

    cp_agent_MRS_array = generate_MRS_array(cp_agent_aggr_res_array, print_fine_dets)

    if print_fine_dets == 1:

        print(' use_start_basket =', use_start_basket)
        print(' agent_aggr_res_array =', agent_aggr_res_array)
        print(' cp_agent_aggr_res_array =', cp_agent_aggr_res_array)

    # find relevant MRS
    agent_MRS = agent_MRS_array[agent_sell_res][cp_agent_sell_res]
    cp_agent_MRS = cp_agent_MRS_array[agent_sell_res][cp_agent_sell_res]

    # There are two approaches we take to deriving the mean: geometric and arithmetic

    if price_mean == 'geometric':

        # Working out price using geometric mean (taken from Epstein & Axtell)
        it_trans_agr_MRS = np.sqrt(agent_MRS_array[agent_sell_res][cp_agent_sell_res] * cp_agent_MRS_array[agent_sell_res][cp_agent_sell_res])

    elif price_mean == 'arithmetic':

        it_trans_agr_MRS = np.mean([agent_MRS_array[agent_sell_res][cp_agent_sell_res], cp_agent_MRS_array[agent_sell_res][cp_agent_sell_res]])

    # In this option we force the prices to be the optimal prices, to see what happens (note the prices are recorded as chart prices, so here we invert them)
    if force_prices == 'optimal':

        it_trans_agr_MRS = float(dbs.optimal_price_array[day][agent_sell_res][cp_agent_sell_res])

    if force_prices == 'fixed':

        if agent_sell_res == 0:

            it_trans_agr_MRS = fixed_price

        else:

            it_trans_agr_MRS = 1 / float(fixed_price)

    if force_prices == 'power':

        it_trans_agr_MRS = (dbs.optimal_price_array[day][agent_sell_res][cp_agent_sell_res] + fountain_population.pop[agent_sell_res].highest_prices[day]) / 2.0

    # Alternative mean is arithmetic
#    it_trans_price = np.mean([agent.MRS_array[agent_sell_res][cp_agent_sell_res], cp_agent.MRS_array[agent_sell_res][cp_agent_sell_res]])

    # If the price > 1 then the trade is in favour of the cp: think of it as the agent having too much of the good it
    # wants to sell relative to the cp. This also means the units of the good being sold exceed the units of the good
    # being received by the agent.  So if the agent sells x then it receives x / p.  Or, if it buys y then it sells
    # p * y.

    # Find the quantities the agents would sell if there were no basket constraints.  This would make the MRS = price by
    # allowing any adjustment required of the agent's resources:

    try:
        a = 1 / float(it_trans_agr_MRS)
    except ZeroDivisionError:
        print('\n problem: it_trans_agr_MRS =', it_trans_agr_MRS)
        print('\n agent_MRS_array\n\n', agent_MRS_array, '\n cp_agent_MRS_array\n\n', cp_agent_MRS_array)
        print('\n agent_res_array', agent_res_array, ' agent_basket_array', agent_basket_array)
        print('\n cp_agent_res_array', cp_agent_res_array, ' cp_agent_basket_array', cp_agent_basket_array)
        pause()

    ag_MRS_equ_price_Q = Q_at_price(agent_sell_res, cp_agent_sell_res, it_trans_agr_MRS, agent_aggr_res_array)
    cp_MRS_equ_price_Q = Q_at_price(cp_agent_sell_res, agent_sell_res, 1 / float(it_trans_agr_MRS), cp_agent_aggr_res_array)

#    # check MRSs with these unconstrained desired sell / buy amounts
#    check_MRS_agent = (agent_aggr_res_array[0][agent_sell_res] + agent.basket_array[0][agent_sell_res] - ag_MRS_equ_price_Q) / float(agent.agent_res_array[0][cp_agent_sell_res] + agent.basket_array[0][cp_agent_sell_res] + (ag_MRS_equ_price_Q / float(it_trans_agr_MRS)))
#    check_MRS_cp_agent = (cp_agent.agent_res_array[0][agent_sell_res] + cp_agent.basket_array[0][agent_sell_res] + (cp_MRS_equ_price_Q * it_trans_agr_MRS)) / float(cp_agent.agent_res_array[0][cp_agent_sell_res] + cp_agent.basket_array[0][cp_agent_sell_res] - cp_MRS_equ_price_Q)
#
#    if print_fine_dets == 1:
#
#        print('\n Here we check the unconstrained preferred sale and purchases against the expected MRSs if these were achieved:')
#        print('\n check_MRS_agent =', check_MRS_agent, 'which should equal it_trans_agr_MRS =', it_trans_agr_MRS, 'difference = %1.8f' % (check_MRS_agent - it_trans_agr_MRS))
#        print('\n check_MRS_cp_agent =', check_MRS_cp_agent, 'which should equal it_trans_agr_MRS =', it_trans_agr_MRS, 'difference = %1.8f' % (check_MRS_cp_agent - it_trans_agr_MRS))
#
#        print('\n decompose cp numbers:\n\n num: cp_agent.agent_res_array[0][agent_sell_res]', cp_agent.agent_res_array[0][agent_sell_res], '+ cp_agent.basket_array[0][agent_sell_res]', cp_agent.basket_array[0][agent_sell_res], '+ cp_MRS_equ_price_Q * it_trans_agr_MRS:', cp_MRS_equ_price_Q, '*', it_trans_agr_MRS)
#        print('\n denom: agent.agent_res_array[0][cp_agent_sell_res]', agent.agent_res_array[0][cp_agent_sell_res], 'agent.basket_array[0][cp_agent_sell_res]', agent.basket_array[0][cp_agent_sell_res], '- cp_MRS_equ_price_Q', cp_MRS_equ_price_Q)

    # We use these to find the minimum amount of the goods each would sell - the lowest is the constraint (I have given the constraint a floor of zero)
    if use_start_basket == 0:

        ag_constr = np.min([agent_basket_array[0][agent_sell_res], ag_MRS_equ_price_Q])
        cp_constr = np.min([cp_agent_basket_array[0][cp_agent_sell_res], cp_MRS_equ_price_Q])

    elif use_start_basket == 1:

        ag_constr = np.min([agent_basket_array_start[0][agent_sell_res], ag_MRS_equ_price_Q])
        cp_constr = np.min([cp_agent_basket_array_start[0][cp_agent_sell_res], cp_MRS_equ_price_Q])

    ag_constr = np.max([ag_constr, 0])
    cp_constr = np.max([cp_constr, 0])

    if print_fine_dets == 1:
        print('\n agent_MRS =', agent_MRS)
        print(' cp_agent_MRS =', cp_agent_MRS)
        print('\n it_trans_agr_MRS =', it_trans_agr_MRS)
        print(' 1 / it_trans_agr_MRS =', 1 / float(it_trans_agr_MRS))
        print('\n ag_MRS_equ_price_Q =', ag_MRS_equ_price_Q)
        print(' cp_MRS_equ_price_Q =', cp_MRS_equ_price_Q)
        print('\n ag_constr =', ag_constr)
        print(' cp_constr =', cp_constr)
        print(' min_trans_Q =', min_trans_Q)
        print('\n ag_constr <= cp_constr * it_trans_agr_MRS =', ag_constr <= cp_constr * it_trans_agr_MRS)

    # We only acknowledge the transaction if they both want to sell (above the min threshold)
    if ag_constr > min_trans_Q and cp_constr > min_trans_Q:

        # There are two situations: first, when the ag's constraint is binding, and the second where the cp's constraint is
        # binding.  In the first, the agent will sell its constraint (in units of sell_res) and receive constraint / price
        # (in units of buy_res): this is when the amount it would receive is less than or = to the cp's constraint i.e.
        # ag_constr / float(it_trans_agr_MRS) <= cp_constr:
        if ag_constr / float(it_trans_agr_MRS) <= cp_constr:     # then the ag's constraint is most binding

            ag_sells = ag_constr
            ag_buys = ag_constr / float(it_trans_agr_MRS)

        elif ag_constr / float(it_trans_agr_MRS) > cp_constr:    # then the cp's constraint is most binding

            ag_sells = cp_constr * it_trans_agr_MRS
            ag_buys = cp_constr

        # the change in the consumer surplus in units of the resource being sold by the agent is: new_ag_MRS
        ch_cons_surpl = (agent_MRS - cp_agent_MRS) * ag_sells

        new_Q_ag_numer = agent_aggr_res_array[0][agent_sell_res] - ag_sells
        new_Q_ag_denom = agent_aggr_res_array[0][cp_agent_sell_res] + ag_buys

        new_Q_cp_numer = cp_agent_aggr_res_array[0][cp_agent_sell_res] - ag_buys
        new_Q_cp_denom = cp_agent_aggr_res_array[0][agent_sell_res] + ag_sells

        new_ag_MRS = new_Q_ag_numer / float(new_Q_ag_denom)
        new_cp_MRS = new_Q_cp_numer / float(new_Q_cp_denom)

        if print_fine_dets == 1:
#                print '\nQ_change =', Q_change
            print('\n ag_sells =', ag_sells)
            print(' ag_buys =', ag_buys)
            print('\n ch_cons_surpl =', ch_cons_surpl)
#            print('\n new_Q_ag_numer =', new_Q_ag_numer)
#            print(' new_Q_ag_denom =', new_Q_ag_denom)
#            print('\n new_Q_cp_numer =', new_Q_cp_numer)
#            print(' new_Q_cp_denom =', new_Q_cp_denom)
            print('\n new_ag_MRS =', new_ag_MRS)
            print(' new_cp_MRS =', new_cp_MRS)

#            pause()

        return ch_cons_surpl, ag_sells, ag_buys, it_trans_agr_MRS

    else:

        if print_fine_dets == 1:
            print('\n One or both the agents didnt want to sell (negative constraint and / or none to sell)')

#            pause()

        return 0.0, 0.0, 0.0, 0.0       # agent_trade_gain


def Q_at_price(sell_res, buy_res, price, agent_aggr_res_array):

    """This function assesses the amount an agent would sell of a resource (sell_res) in exchange for another resource
    (buy_res).  Note that if the resulting value is negative it means the agent will demand this Q of sell_res at the given
    price."""

    total_Q = (agent_aggr_res_array[0][sell_res] - (price * agent_aggr_res_array[0][buy_res])) / 2.0

    return total_Q


def generate_MRS_array(res_array, print_fine_dets):
    """This function takes an agent's resource array and returns its counterpart MRS array"""

    if print_fine_dets:
        print('\n\n Starting generate_MRS_array')

    MRS_array = np.ones(shape=(num_res_founts, num_res_founts))

    for numerat in np.arange(num_res_founts):

        for denom in np.arange(num_res_founts):

            if numerat != denom:

                # Update the agent's MRS_array
                MRS = res_array[0][numerat] / float(res_array[0][denom])
                MRS_array[numerat][denom] = MRS

                if print_fine_dets:
                    print('\n numerat =', numerat)
                    print(' denom =', denom)
                    print(' MRS =', MRS)

                if print_fine_dets:
                    print('\n res_array[0][numerat]', res_array[0][numerat])
                    print(' res_array[0][denom] =', res_array[0][denom])

    if print_fine_dets:
        print('\n Ending generate_MRS_array \n')

    return MRS_array


def add_game_to_game_dict(agent_population, fountain_population, agent, cp_agent, payoffs_6_scenarios, dbs, day, print_fine_dets, strat_choice, stranger_int, strangers_if_unknown):
    """This function takes a 6-scenario payoff matrix, converts it to 4-scenario payoff and then adds the game to the games dictionary."""

    if print_fine_dets:
        print('\n starting add_game_to_game_dict')
        print('\n payoffs_6_scenarios =', payoffs_6_scenarios)
        print('\n agent.prop_fight_back', agent.prop_fight_back)
        print('\n cp_agent.prop_fight_back', cp_agent.prop_fight_back)
        print('\n stranger_int', stranger_int)
        print('\n strat_choice', strat_choice)
        print('\n strangers_if_unknown', strangers_if_unknown)
        print('\n agent.agent_knows_cp_dict[str(cp_agent)]', agent.agent_knows_cp_dict[str(cp_agent)])
        print('\n cp_agent.agent_knows_cp_dict[str(agent)]', cp_agent.agent_knows_cp_dict[str(agent)])

    # now create the 4-payoff matrix
    payoffs_4_scenarios = [payoffs_6_scenarios[0], [], [], payoffs_6_scenarios[5]]

    if stranger_int == 'fb' and (strat_choice == 'rational' or (strangers_if_unknown and (agent.agent_knows_cp_dict[str(cp_agent)] == 0 or cp_agent.agent_knows_cp_dict[str(agent)] == 0))):

        payoffs_4_scenarios[1] = payoffs_6_scenarios[1]

        payoffs_4_scenarios[2] = payoffs_6_scenarios[3]

        des_string = 'rational '
        intn_type = 'rational'

    elif stranger_int == 'acq' and (strat_choice == 'rational' or (strangers_if_unknown and (agent.agent_knows_cp_dict[str(cp_agent)] == 0 or cp_agent.agent_knows_cp_dict[str(agent)] == 0))):

        payoffs_4_scenarios[1] = payoffs_6_scenarios[2]

        payoffs_4_scenarios[2] = payoffs_6_scenarios[4]

        des_string = 'rational '
        intn_type = 'rational'

    else:

        payoffs_4_scenarios[1].append(payoffs_6_scenarios[1][0] * agent.prop_fight_back + payoffs_6_scenarios[2][0] * (1 - agent.prop_fight_back))
        payoffs_4_scenarios[1].append(payoffs_6_scenarios[1][1] * agent.prop_fight_back + payoffs_6_scenarios[2][1] * (1 - agent.prop_fight_back))

        payoffs_4_scenarios[2].append(payoffs_6_scenarios[3][0] * cp_agent.prop_fight_back + payoffs_6_scenarios[4][0] * (1 - cp_agent.prop_fight_back))
        payoffs_4_scenarios[2].append(payoffs_6_scenarios[3][1] * cp_agent.prop_fight_back + payoffs_6_scenarios[4][1] * (1 - cp_agent.prop_fight_back))

        des_string = 'heuristics '
        intn_type = 'heuristics'

    if print_fine_dets == 1:
        print('\n payoffs_4_scenarios\n\n [', payoffs_4_scenarios[0], payoffs_4_scenarios[1])
        print('  ', payoffs_4_scenarios[2], payoffs_4_scenarios[3], ']')

    a = payoffs_4_scenarios[0][0]
    b = payoffs_4_scenarios[0][1]
    c = payoffs_4_scenarios[1][0]
    d = payoffs_4_scenarios[1][1]
    e = payoffs_4_scenarios[2][0]
    f = payoffs_4_scenarios[2][1]
    g = payoffs_4_scenarios[3][0]
    h = payoffs_4_scenarios[3][1]

    game_bit_string = ''

    pairs = [[a, c], [a, e], [a, g], [e, c], [e, g], [c, g], [b, d], [b, f], [b, h], [f, d], [f, h], [d, h]]

    for pair in pairs:

        if pair[0] < pair[1]:

            game_bit_string += '0'

        elif pair[0] == pair[1]:

            game_bit_string += '1'

        elif pair[0] > pair[1]:

            game_bit_string += '2'

    es_dict = dict()

    es_dict['a'] = a
    es_dict['c'] = c
    es_dict['e'] = e
    es_dict['g'] = g

    sorted_str = ''
    sorted_array = []

    for key, value in sorted(es_dict.items(), key=lambda item: (item[1], item[0])):
        sorted_str += key
        sorted_array.append(value)

    des_string += sorted_str[0]

    oops = 0

    for iter_num in range(len(sorted_array) - 1):

        if sorted_array[iter_num] < sorted_array[iter_num + 1]:
            des_string += ' < '

        elif sorted_array[iter_num] == sorted_array[iter_num + 1]:
            des_string += ' = '

        elif sorted_array[iter_num] > sorted_array[iter_num + 1]:
            des_string += ' > '

            oops = 1

        des_string += sorted_str[iter_num + 1]

    des_string += '  |  '

    es_dict = dict()

    es_dict['b'] = b
    es_dict['d'] = d
    es_dict['f'] = f
    es_dict['h'] = h

    sorted_str = ''
    sorted_array = []

    for key, value in sorted(es_dict.items(), key=lambda item: (item[1], item[0])):
        sorted_str += key
        sorted_array.append(value)

    des_string += sorted_str[0]

    for iter_num in range(len(sorted_array) - 1):

        if sorted_array[iter_num] < sorted_array[iter_num + 1]:
            des_string += ' < '

        elif sorted_array[iter_num] == sorted_array[iter_num + 1]:
            des_string += ' = '

        elif sorted_array[iter_num] > sorted_array[iter_num + 1]:
            des_string += ' > '

            oops = 1

        des_string += sorted_str[iter_num + 1]

    if oops != 0:
        print('\n sorted_array =', sorted_array)
        print(' des_string ', des_string)
        pause()

    # there is a problem with numbers which are identical to many decimal places (and should be identical) but which the 'puter thinks are not identical... so I correct that here
    if game_bit_string == '000220222012':
        game_bit_string = '000210222012'

        des_string = 'a < c < g = e  |  f = h < d < b'

    if game_bit_string == '222111000012':
        game_bit_string = '222111000111'

        des_string = 'c = e = g < a  |  b < d = f = g'

    if game_bit_string == '000221222111':
        game_bit_string = '000111222111'

        des_string = 'a < c = e = g  |  d = f = g < b'

    if game_bit_string == '222221000002':
        game_bit_string = '222221000001'

        des_string = 'c = g < e < a  |  b < f < d = h'

    if des_string == 'c = e = g < a  |  d = f = h < b':

        if a == 0.0:

            des_string += '  |  a = 0'

        else:

            des_string += '  |  a > 0'

        if b == 0.0:

            des_string += ' b = 0'

        else:

            des_string += ' b > 0'

    if payoffs_6_scenarios[7] != 'Other':
        des_string += ' '
        des_string += payoffs_6_scenarios[7]

    if des_string in dbs.games_type_dict:

        dbs.games_type_dict[des_string][day] += 1

    else:

        dbs.games_type_dict[des_string] = np.zeros(shape=dbs.num_rounds, dtype=int)

        dbs.games_type_dict[des_string][day] += 1

    if strat_choice == 'heuristics':

        prob_scen_1 = (1 - agent.prop_steal) * (1 - cp_agent.prop_steal)
        prob_scen_2 = (1 - agent.prop_steal) * cp_agent.prop_steal
        prob_scen_3 = agent.prop_steal * (1 - cp_agent.prop_steal)
        prob_scen_4 = agent.prop_steal * cp_agent.prop_steal

        agent_prob_weighted_gain = prob_scen_1 * payoffs_4_scenarios[0][0] + prob_scen_2 * payoffs_4_scenarios[1][0] + prob_scen_3 * payoffs_4_scenarios[2][0] + prob_scen_4 * payoffs_4_scenarios[3][0]
        cp_agent_prob_weighted_gain = prob_scen_1 * payoffs_4_scenarios[0][1] + prob_scen_2 * payoffs_4_scenarios[1][1] + prob_scen_3 * payoffs_4_scenarios[2][1] + prob_scen_4 * payoffs_4_scenarios[3][1]

        scenario_name = des_string

        num_times_seen = 0

        one_or_both_agents_has_res = 1

        if agent.basket_array[0][0] == 0.0 and agent.basket_array[0][1] == 0.0 and cp_agent.basket_array[0][0] == 0.0 and cp_agent.basket_array[0][1] == 0.0:
            one_or_both_agents_has_res = 0

            #        if game_bit_string == '112122112122' or game_bit_string == '122022122022' or game_bit_string == '122012122012' or game_bit_string == '212222212222' or game_bit_string == '222022222022' or game_bit_string == '222122222122' or\
            #        game_bit_string == '222222222222' or game_bit_string == '222012222012' or game_bit_string == '212221212221' or game_bit_string == '222221222221' or game_bit_string == '222111222111':

            scenario_name = intn_type
            scenario_name += ': Neither agent has resources'

            num_times_seen += 1

        if one_or_both_agents_has_res and (game_bit_string[:6] == '000220' or game_bit_string[:6] == '000210' or game_bit_string[:6] == '000221' or game_bit_string[:6] == '000111' or \
                                           game_bit_string == '100220122002' or game_bit_string == '100210122012'):  # or (game_bit_string[:2] == '22' and game_bit_string[3:6] = '220' and game_bit_string[6:8] = '00' and game_bit_string[9:] == '002'):

            scenario_name = intn_type

            if agent.basket_array[0][0] == 0.0 and agent.basket_array[0][1] == 0.0:

                scenario_name += ': Agent with no res '

            elif agent.basket_array[0][0] > 0.0 or agent.basket_array[0][1] > 0.0:

                scenario_name += ': Agent with res '

            if payoffs_4_scenarios[0][0] == 0.0:

                scenario_name += 'expects to mug, no trading'

            else:

                if prob_scen_1 > 0.5:

                    scenario_name += 'expects to trade but mugging an option'

                else:

                    scenario_name += 'expects to mug but trading an option'

            num_times_seen += 1

        if one_or_both_agents_has_res and (
                game_bit_string == '200220022002' or game_bit_string == '200220222002' or game_bit_string == '200220020002' or game_bit_string == '200220000002' or game_bit_string == '200210022012' or game_bit_string == '200210222012' or \
                game_bit_string == '200210000012' or game_bit_string == '200220021002'):

            scenario_name = intn_type

            if agent.basket_array[0][0] == 0.0 and agent.basket_array[0][1] == 0.0:  # this is v unlikely in this familly

                scenario_name += ': Agent with no res '

            elif agent.basket_array[0][0] > 0.0 or agent.basket_array[0][1] > 0.0:

                scenario_name += ': Agent with res '

            if payoffs_4_scenarios[0][0] == 0.0:

                scenario_name += 'expects to mug, no trading'

            else:

                if prob_scen_1 > 0.5:

                    scenario_name += 'expects to trade but mugging an option'

                else:

                    scenario_name += 'expects to mug but trading an option'

            num_times_seen += 1

        #            scenario_name = 'Agent with res expects to mug cp with more'

        if one_or_both_agents_has_res and (
                game_bit_string == '202220222002' or game_bit_string == '202220022002' or game_bit_string == '202220020002' or game_bit_string == '202220000002' or game_bit_string == '202221222001' or game_bit_string == '202221020001' or \
                game_bit_string == '202221000001' or game_bit_string == '202220021002'):
            scenario_name = intn_type
            scenario_name += ': Risky Gamble: balance of probs, exp cp to acquiesce'

            num_times_seen += 1

        if one_or_both_agents_has_res and (game_bit_string == '222220000002' or game_bit_string == '222220020002' or \
                                           game_bit_string == '222220022002' or game_bit_string == '222220222002' or game_bit_string == '222210000012' or game_bit_string == '222210022012' or game_bit_string == '222210222012' or game_bit_string == '222221000001' or \
                                           game_bit_string == '222221020001' or game_bit_string == '222221222001' or game_bit_string == '222111000111' or game_bit_string == '222111222111'):
            scenario_name = intn_type
            scenario_name += ': Agent expects to trade'

            num_times_seen += 1

        if agent_prob_weighted_gain <= 0.0:  # then the agent has made a mistake - they should not be interacting with the cp

            scenario_name += ' (mistake!)'

    elif strat_choice == 'rational':  # then the choice is already determined - we simply express the strat choice

        agent_strat = payoffs_6_scenarios[8]

        cp_agent_strat = payoffs_6_scenarios[9]

        if stranger_int == 'acq' and cp_agent_strat == 'trade':
            cp_agent_strat = 'acquiesce'

        scenario_name = 'agent: '
        scenario_name += agent_strat
        scenario_name += '  |  cp: '
        scenario_name += cp_agent_strat

        if print_fine_dets:
            print('\n rational... scenario_name', scenario_name)

    if scenario_name in dbs.games_type_dict_2:

        dbs.games_type_dict_2[scenario_name][day] += agent.expected_gains_dict[str(cp_agent)][0]

    else:

        dbs.games_type_dict_2[scenario_name] = np.zeros(shape=dbs.num_rounds, dtype=np.float64)

        dbs.games_type_dict_2[scenario_name][day] += agent.expected_gains_dict[str(cp_agent)][0]

    if scenario_name in dbs.games_type_dict_3:

        dbs.games_type_dict_3[scenario_name][day] += 1

    else:

        dbs.games_type_dict_3[scenario_name] = np.zeros(shape=dbs.num_rounds, dtype=np.float64)

        dbs.games_type_dict_3[scenario_name][day] += 1

    #    print('\n payoffs_6_scenarios =', payoffs_6_scenarios)
    #
    #    pause()

    classic_game_type = payoffs_6_scenarios[7]

    if classic_game_type in dbs.classic_games_seen:

        dbs.classic_games_seen[classic_game_type][day] += 1

    else:

        dbs.classic_games_seen[classic_game_type] = np.zeros(shape=dbs.num_rounds, dtype=int)

        dbs.classic_games_seen[classic_game_type][day] += 1

    #    if print_fine_dets:
    #
    #        print('\n dbs.games_type_dict_2', dbs.games_type_dict_2)

    #    if len(scenario_name) == 12 or len(scenario_name) == 23 or num_times_seen > 1: #exp_rtns_matrix

    #    agent.exp_rtns_matrix[str(cp_agent)]

    if strat_choice == 'heuristics' and num_times_seen != 1:

        print('\n\n\n day ', day, 'game_bit_string =', game_bit_string, 'scenario_name =', scenario_name)
        print('\n num_times_seen =', num_times_seen)

        if str(cp_agent) in agent.reputations_dict:

            print('\n cp_agent KNOWN to agent')

        else:

            print('\n cp_agent NOT KNOWN to agent')

        if str(agent) in cp_agent.reputations_dict:

            print('\n agent KNOWN to cp_agent')

        else:

            print('\n agent NOT KNOWN to cp_agent')

        #        print('\n dbs.games_type_dict_2[scenario_name] =', dbs.games_type_dict_2[scenario_name])
        #        print('\n dbs.games_type_dict_2[scenario_name][day] =', dbs.games_type_dict_2[scenario_name][day])

        if agent.expected_gains_dict[str(cp_agent)][0] != agent_prob_weighted_gain:
            print('\n agent.expected_gains_dict[str(cp_agent)][0] != agent_prob_weighted_gain')

        print('\n payoffs_6_scenarios', payoffs_6_scenarios)
        print('\n agent.basket_array', agent.basket_array, 'agent.basket_array_start', agent.basket_array_start, 'agent.prop_fight_back', agent.prop_fight_back, 'agent.prop_steal', agent.prop_steal)
        print(' agent.agent_res_array:', agent.agent_res_array[0])

        agent_tot_res = agent.agent_res_array[0] + agent.basket_array[0]

        agent_MRS_array = generate_MRS_array([agent_tot_res], print_fine_dets=0)

        agent_lowest_res = int(0)

        if agent_tot_res[0] > agent_tot_res[1]:
            agent_lowest_res = int(1)

        cp_agent_tot_res = cp_agent.agent_res_array[0] + cp_agent.basket_array[0]

        cp_agent_MRS_array = generate_MRS_array([cp_agent_tot_res], print_fine_dets=0)

        cp_agent_lowest_res = int(0)

        if cp_agent_tot_res[0] > cp_agent_tot_res[1]:
            cp_agent_lowest_res = int(1)

        # convert to lowest-res equivalent
        agent_gain_from_cp = 0

        for res in range(num_res_founts):
            agent_gain_from_cp += cp_agent.basket_array[0][res] * agent_MRS_array[agent_lowest_res][res]

        cp_agent_gain_from_agent = 0

        for res in range(num_res_founts):
            cp_agent_gain_from_agent += agent.basket_array[0][res] * cp_agent_MRS_array[cp_agent_lowest_res][res]

        print('\n agent values cp_agent basket (reduced value):', agent_gain_from_cp)
        print(' agent.parents = ', agent.parents)
        print('\n cp_agent.basket_array', cp_agent.basket_array, 'cp_agent.basket_array_start', cp_agent.basket_array_start, 'cp_agent.prop_fight_back', cp_agent.prop_fight_back, 'cp_agent.prop_steal', cp_agent.prop_steal)
        print(' cp_agent.agent_res_array:', cp_agent.agent_res_array[0])
        print(' cp_agent.parents = ', cp_agent.parents)
        print('\n cp_agent values agent basket (reduced value):', cp_agent_gain_from_agent)
        print('\n payoffs_4_scenarios\n\n [', payoffs_4_scenarios[0], payoffs_4_scenarios[1])
        print('  ', payoffs_4_scenarios[2], payoffs_4_scenarios[3], ']')

        print('\n probs: trade = %1.6f  |  agent trades, cp steals = %1.6f  |  agent steals, cp trades = %1.6f  |  both steal = %1.6f' % (
        (1 - agent.prop_steal) * (1 - cp_agent.prop_steal), (1 - agent.prop_steal) * cp_agent.prop_steal, agent.prop_steal * (1 - cp_agent.prop_steal), agent.prop_steal * cp_agent.prop_steal))
        print('\n agent prob-weighted gains: scen 1 = %s  |  scen 2 = %s  |  scen 3 = %s  |  scen 4 = %s' % (
        prob_scen_1 * payoffs_4_scenarios[0][0], prob_scen_2 * payoffs_4_scenarios[1][0], prob_scen_3 * payoffs_4_scenarios[2][0], prob_scen_4 * payoffs_4_scenarios[3][0]))
        print('\n cp_agent prob-weighted gains: scen 1 = %s  |  scen 2 = %s  |  scen 3 = %s  |  scen 4 = %s' % (
        prob_scen_1 * payoffs_4_scenarios[0][1], prob_scen_2 * payoffs_4_scenarios[1][1], prob_scen_3 * payoffs_4_scenarios[2][1], prob_scen_4 * payoffs_4_scenarios[3][1]))

        print('\n expected prob-weighted gains / losses (no error): agent =', agent_prob_weighted_gain, 'cp_agent =', cp_agent_prob_weighted_gain)

        print('\n agent exp gain (including error) = ', agent.expected_gains_dict[str(cp_agent)][0], 'cp_agent exp gain', agent.expected_gains_dict[str(cp_agent)][1])

        print('\n prob weighted returns comparison:')
        print('\n cp_agent.home = ', cp_agent.home)

        if stranger_int == 'none':
            print(' gain_agent_low_res_1_prob_weighted (new 4)', payoffs_6_scenarios[5][0] * prob_scen_4)
            print(' gain_agent_low_res_2_prob_weighted (3F)', payoffs_6_scenarios[3][0] * agent.prop_steal * (1 - cp_agent.prop_steal) * cp_agent.prop_fight_back)
            print(' gain_agent_low_res_3_prob_weighted (2F)', payoffs_6_scenarios[1][0] * (1 - agent.prop_steal) * cp_agent.prop_steal * agent.prop_fight_back)
            print(' gain_agent_low_res_4_prob_weighted (3A)', payoffs_6_scenarios[4][0] * agent.prop_steal * (1 - cp_agent.prop_steal) * (1 - cp_agent.prop_fight_back))
            print(' gain_agent_low_res_5_prob_weighted (2A)', payoffs_6_scenarios[2][0] * (1 - agent.prop_steal) * cp_agent.prop_steal * (1 - agent.prop_fight_back))
            print(' gain_agent_low_res_6_prob_weighted (new 1)', payoffs_6_scenarios[0][0] * prob_scen_1)

        if stranger_int == 'none':
            print(' total = ', payoffs_6_scenarios[5][0] * prob_scen_4 + payoffs_6_scenarios[3][0] * agent.prop_steal * (1 - cp_agent.prop_steal) * cp_agent.prop_fight_back + \
                  payoffs_6_scenarios[1][0] * (1 - agent.prop_steal) * cp_agent.prop_steal * agent.prop_fight_back + payoffs_6_scenarios[4][0] * agent.prop_steal * (1 - cp_agent.prop_steal) * (1 - cp_agent.prop_fight_back) + \
                  payoffs_6_scenarios[2][0] * (1 - agent.prop_steal) * cp_agent.prop_steal * (1 - agent.prop_fight_back) + payoffs_6_scenarios[0][0] * prob_scen_1)

        print('\n probs: prob_scen_1', prob_scen_4, 'prob_scen_2', agent.prop_steal * (1 - cp_agent.prop_steal) * cp_agent.prop_fight_back, 'prob_scen_3', (1 - agent.prop_steal) * cp_agent.prop_steal * agent.prop_fight_back, \
              'prob_scen_4', agent.prop_steal * (1 - cp_agent.prop_steal) * (1 - cp_agent.prop_fight_back), 'prob_scen_5', (1 - agent.prop_steal) * cp_agent.prop_steal * (1 - agent.prop_fight_back), \
              'prob_scen_6', prob_scen_1)

        print('\n sum probs =', prob_scen_4 + agent.prop_steal * (1 - cp_agent.prop_steal) * cp_agent.prop_fight_back + (1 - agent.prop_steal) * cp_agent.prop_steal * agent.prop_fight_back + \
              agent.prop_steal * (1 - cp_agent.prop_steal) * (1 - cp_agent.prop_fight_back) + (1 - agent.prop_steal) * cp_agent.prop_steal * (1 - agent.prop_fight_back) + prob_scen_1)

        print('\n agent.prop_steal', agent.prop_steal, 'agent.prop_fight_back', agent.prop_fight_back)
        print(' cp_agent.prop_steal', cp_agent.prop_steal, 'cp_agent.prop_fight_back', cp_agent.prop_fight_back)

    if print_fine_dets:
        print('\n ending add_game_to_game_dict')
        pause()


#        pot_cp_prop_steal, pot_cp_prop_fight_back, num_interactions = find_cp_props(agent, cp_agent, day, len_reputations_mem=20, print_fine_dets=1)
#        print(' pot_cp_prop_steal =', pot_cp_prop_steal, 'pot_cp_prop_fight_back', pot_cp_prop_fight_back)
#        print('\n problem: agents shouldnt have trade surplus but they do')
#        print('\n agent.last_intn =', agent.last_intn)
#        if str(cp_agent) in agent.exp_int_gains_dict:
#            print('\n agent.exp_int_gains_dict[str(cp_agent)]:', agent.exp_int_gains_dict[str(cp_agent)])
#        else:
#            print('\n cp_agent not in agent.exp_int_gains_dict')
#        print('\n cp_agent.last_intn =', cp_agent.last_intn)

#    pause()


def check_vs_classic_games(payoffs):

    a = payoffs[0][0]
    b = payoffs[0][1]
    c = payoffs[1][0]
    d = payoffs[1][1]
    e = payoffs[2][0]
    f = payoffs[2][1]
    g = payoffs[3][0]
    h = payoffs[3][1]

    list_of_strats = []

    form = 'Other'

    if c < g < a < e and f < h < b < d:
        form = 'Prisoners Dilemma'
        list_of_strats.append(form)

    if a < e < g < c and b < d < h < f:
        form = 'Hawk-Dove'
        list_of_strats.append(form)

    aggr_payoffs = [a + b, c + d, e + f, g + h]

    if (e < a and c < g and d < b and f < h) or (a < e and g < c and b < d and h < f):

        form = 'Coordination Game (Other)'

        counter = 0

        if (c < g < e < a or c < g == e < a) and (f < h < d < b or f < h == d < b):
            form = 'Coordination Game: Stag Hunt'
            list_of_strats.append(form)

            counter += 1

        if (c == e < g < a and d == f < h < b) or (e < c < g < a and f < d < h < b):
            form = 'Coordination Game: Battle of the Sexes'
            list_of_strats.append(form)

            counter += 1

        if counter == 0:
            list_of_strats.append(form)

    if a < e and c < g and b < d and f < h and np.max(aggr_payoffs) == aggr_payoffs[3]:
        form = 'Strong Deadlock'
        list_of_strats.append(form)

    if a < e and c < g and d < b and h < f and np.max(aggr_payoffs) == aggr_payoffs[2]:
        form = 'Strong Deadlock'
        list_of_strats.append(form)

    if e < a and g < c and b < d and f < h and np.max(aggr_payoffs) == aggr_payoffs[1]:
        form = 'Strong Deadlock'
        list_of_strats.append(form)

    if e < a and g < c and d < b and h < f and np.max(aggr_payoffs) == aggr_payoffs[0]:
        form = 'Strong Deadlock'
        list_of_strats.append(form)

    if (a < e and c == g) or (a == e and c < g):

        if (b < d and f < h) or (b < d and f == h) or (b == d and f < h) and np.max(aggr_payoffs) == aggr_payoffs[3]:
            form = 'Weak Deadlock'
            list_of_strats.append(form)

        if (d < b and h < f) or (d < b and h == f) or (d == b and h < f) and np.max(aggr_payoffs) == aggr_payoffs[2]:
            form = 'Weak Deadlock'
            list_of_strats.append(form)

    if (e < a and g == c) or (e == a and g < c):

        if (b < d and f < h) or (b < d and f == h) or (b == d and f < h) and np.max(aggr_payoffs) == aggr_payoffs[1]:
            form = 'Weak Deadlock'
            list_of_strats.append(form)

        if (d < b and h < f) or (d < b and h == f) or (d == b and h < f) and np.max(aggr_payoffs) == aggr_payoffs[0]:
            form = 'Weak Deadlock'
            list_of_strats.append(form)

    if (e < a and c < g and b < d and h < f) or (a < e and g < c and d < b and f < h):
        form = 'Matching Pennies'
        list_of_strats.append(form)

    if c < g < a < e and h < f < b < d:
        form = 'Dominant / Subordinate Pigs'
        list_of_strats.append(form)

    if len(list_of_strats) > 1:
        print('\n payoffs ', payoffs)
        print('\n list_of_strats =', list_of_strats)
        pause()

    return form


def agents_trading_Walras_Style(KO_pop, town_grid, agent_population, print_dets, trade_moves, trade_movemnt, vision_len, day,
                   trade_loc, print_fine_dets, tracking_agent, wait_at_target_til_end, wait_at_tgt_moves, track_agent, trgt_sel,
                   dimen, trade_when_trgt, run_folder,
                   print_round_trans, df_daily, dbs, granular_mem, fountain_population, print_move_heat_maps, trade_prices,
                   rounds, gen_equ_thresh, gen_equ_wh_lps, SD_charts_freq, price_mean, force_prices, fixed_price,
                   keynesian_ratio, find_gen_equ_PQ, use_parallel_code, price_grid_dimen, test_par_code, print_plotly_charts,
                   print_MRS_std_charts, const_mkt_opens):

    # update MRS arrays to start and then save data if required
    for agent in agent_population.pop:

        agent.update_agent_MRS_array(print_dets, print_fine_dets, agent_population)

    # this line generates the supply & demand data for the 2d charts and it also finds the market clearing price and quantity when num_res_founts == 2
    if num_res_founts == 2:

        supply_demand_array = create_supply_demand_data(fountain_population, agent_population, print_dets, print_fine_dets, run_folder, day, dbs, gen_equ_thresh)

    for agent in agent_population.pop:

#        print('\nagent:', agent, 'home', agent.home, 'res_array =', agent.agent_res_array[0], 'basket:', agent.basket_array, 'optimal trans', agent.optimal_transs_systemic[day])

        for res in range(num_res_founts):

            agent.basket_array[0][res] -= agent.optimal_transs_systemic[day][res]

            if agent.basket_array[0][res] < 0:

                print('PROMBLEM: agent.basket_array[0][res] < 0')

                input("Press Enter to continue...")

#        print('resulting basket =', agent.basket_array)

#    input("Press Enter to continue...")


def write_trading_array_to_text(trading_db, data_folder):
    print('---> writing data to file: trading_array_data')

    filepath = data_folder
    filename = "trading_array_data"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
    fileHandle.write("Summary Trading Data\n\n")
    #    fileHandle.write("Mean\t\tSTD\t\tMin\tMax\tthreshold (mean + 5 x std)\tlocations above threshold\n")

    for i in range(len(trading_db)):
        if i == 0:

            outString = '\nPopulation\n'
            fileHandle.write(outString)

        elif i == 1:

            outString = '\nNumber of agents trying to trade\n'
            fileHandle.write(outString)

        elif i == 2:

            outString = '\nNumber of agents remaining on grid atfer trading\n'
            fileHandle.write(outString)

        elif i == 3:

            outString = '\nProportion of agents wanting to trade left on grid\n'
            fileHandle.write(outString)

        elif i == 4:

            outString = '\nTotal goods on sale\n'
            fileHandle.write(outString)

        elif i == 5:

            outString = '\nNumber of goods sold\n'
            fileHandle.write(outString)

        elif i == 6:

            outString = '\nProportion of goods on sale which are sold\n'
            fileHandle.write(outString)

        for l in np.arange(len(trading_db[i])):  # len varies
            outString = str(trading_db[i][l]) + " "
            fileHandle.write(outString)

    fileHandle.close()


def write_popn_data_to_txt(database, data_folder, start_pop):

    print('---> writing population data to data file: population_raw_data')

    filepath = data_folder
    filename = "population_raw_data"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
    fileHandle.write("Summary Population Data\n\n")
    fileHandle.write("Starting population = %d\n\n" % (start_pop))
    fileHandle.write("Round\tBirths\tDeaths\tPopulation")

    for i in range(len(database[0])):

        outString = "\n"
        fileHandle.write(outString)

        for l in np.arange(len(database)):     # len varies

            outString = str(database[l][i]) + "\t"
            fileHandle.write(outString)


def write_text_file_readme(data_folder, param_dict, scenario, readme_notes):

    print('---> creating readme file')

    param_key_list = sorted(param_dict, key=str.lower)

    filepath = data_folder
    filename = "1_read_me_file"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
    fileHandle.write("Parameters\n")

    fileHandle.write("\nScenario: %s  |  readme_notes: %s\n" % (scenario, readme_notes))

    for entry in param_key_list:

        fileHandle.write("\n%s = %s" % (entry, param_dict[entry]))

    fileHandle.close()


def write_daily_market_report(data_folder, dbs, fountain_population, day, start_round, end_round, print_fine_dets):
    #    print_fine_dets = 0

    filename = "daily_mkt_data"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d-%d-%d.txt' % (data_folder, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(),
                                                          dt.DateTime().hour(), dt.DateTime().minute(), dt.DateTime().second(), dt.DateTime().millis() / 100000), 'w')

    fileHandle.write("Daily Market Data\n\nThis file contains information about all of the market locations between days %d and %d.\n" % (start_round, end_round))

    #    # Unpack the day's transactions:
    #    days_transs = dbs.transs_daily_db[day]

    # Create an array to record which agents are at which market
    sign_mkt_locs_period = copy.copy(dbs.sign_mkt_locs[start_round])

    if print_fine_dets == 1:
        print('\n beginning sign_mkt_locs_period =', sign_mkt_locs_period)

    for d in np.arange(start_round + 1, end_round + 1):

        if print_fine_dets == 1:
            print('\n d =', d)

        for pot_mkt_loc in dbs.sign_mkt_locs[d]:

            if print_fine_dets == 1:
                print('\n pot_mkt_loc =', pot_mkt_loc)

            include_loc = 1

            for known_loc in sign_mkt_locs_period:

                if include_loc == 1:

                    if pot_mkt_loc[0] == known_loc[0] and pot_mkt_loc[1] == known_loc[1]:
                        include_loc = 0

            if include_loc == 1:

                if print_fine_dets == 1:
                    print('\n include_loc = 1')

                sign_mkt_locs_period.append(pot_mkt_loc)

    if print_fine_dets == 1:
        print('\n sign_mkt_locs_period =', sign_mkt_locs_period)

    agent_in_markets = [[] for i in range(len(sign_mkt_locs_period))]

    for d in np.arange(start_round, end_round + 1):

        if print_fine_dets == 1:
            print('\nd =', d)

        for trans_num in dbs.transs_daily_db[d]:

            trans = dbs.trans_db[trans_num]

            if print_fine_dets == 1:
                print('trans_num =', trans_num, 'location =', trans.location)

            for market_index in np.arange(len(sign_mkt_locs_period)):

                market_x = sign_mkt_locs_period[market_index][0]
                market_y = sign_mkt_locs_period[market_index][1]

                #            print '\nmarket_x =', market_x
                #            print 'trans.location =', trans.location

                if trans.location[0] == market_x and trans.location[1] == market_y:  # then we have matched a transaction to a market

                    # We add the two agents to the list of agents associated with that market
                    if trans.agent_a not in agent_in_markets[market_index]:
                        agent_in_markets[market_index].append(trans.agent_a)

                    if trans.agent_b not in agent_in_markets[market_index]:
                        agent_in_markets[market_index].append(trans.agent_b)

    if print_fine_dets == 1:
        print('\n agent_in_markets =', agent_in_markets)

    # By this point, agent_in_markets has all the agents that transacted at each market

    for market_index in np.arange(len(sign_mkt_locs_period)):

        market = sign_mkt_locs_period[market_index]

        fileHandle.write("\n\n\n\nMarket Location: %s" % (market))

        for agent in agent_in_markets[market_index]:

            total_for_start = np.zeros(shape=(num_res_founts), dtype=float)
            total_for_end = np.zeros(shape=(num_res_founts), dtype=float)

            for d in np.arange(start_round, end_round + 1):

                if print_fine_dets == 1:
                    print('\n agent.basket_array_start_hist[d] =\n', agent.basket_array_start_hist[d])
                    print('\n agent.basket_array_hist[d] =\n', agent.basket_array_hist[d])

                for res in np.arange(num_res_founts):
                    total_for_start[res] += agent.basket_array_start_hist[d][res]
                    total_for_end[res] += agent.basket_array_hist[d][res]

            total_for_start = total_for_start / float(end_round - start_round)
            total_for_end = total_for_end / float(end_round - start_round)

            if print_fine_dets == 1:
                print('\n total_for_start =', total_for_start)
                print('\n total_for_end =', total_for_end)

            sale_array = total_for_start - total_for_end

            fileHandle.write(
                "\n\nagent %s:\n\nhome is %s  |  Foraging Strat (last period) = %s  |  resources (last period) = %s  |  av. start_basket = %s  |  sale (purchase) = %s  |  birth = %s  |  \n\ntarget locations hist (last period) = %s\n\nlocations visited (last period) = %s\n" % (
                agent, agent.home, agent.for_strat_array, agent.agent_res_array, total_for_start, sale_array, agent.birth_date, agent.trgt_loc_rec, agent.trade_loc_rec))


def write_success_data(params, agent_population, dbs, print_dets, print_fine_dets, data_folder, rounds, fountain_population, for_spec_db1, for_spec_means, agent_res_init, cluster_lag, town_grid, \
                       for_strat_parts, printed_segment_size, allow_Keynes_Inst, KO_pop, constitutional_voting, constitutional_exp, num_experiments, respect_property_rights, file_type, black_shoop_exp,
                       fight_skill, two_tribes):
    """This data writes data to a file which is the main output data for each simulation."""

    print('---> writing data to file: Success Data')

    filepath = data_folder
    filename = "text_success_data"

    if file_type == 'html':

        fileHandle = open('%s/%s %d-%d-%d-%d-%d.html' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')

    else:

        fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')

    if file_type == 'html':
        #        fileHandle.write("<html>\n<head></head>\n<body><p>Hello World!</p></body>\n\n")
        fileHandle.write("<html>")

    if file_type == 'html':
        fileHandle.write("<h1>")
    fileHandle.write("Success Data For a Single Run\n\n\n")
    if file_type == 'html':
        fileHandle.write("</h1><body>")
        fileHandle.write("<p></p><p></p>")

    #        fileHandle.write("<style> p {margin : 0}")

    #    print("\n rounds =", rounds)
    #    print("\n type(rounds) =", type(rounds))

    ten_pct_rounds_array = np.arange(0, rounds, int(printed_segment_size), dtype=int)
    num_iters = len(ten_pct_rounds_array)
    ten_pct_gap = int(printed_segment_size)

    # Find Population Data
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("Population Data\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    population_data = []
    births_data = []
    deaths_data = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = ten_pct_rounds_array[iter] + ten_pct_gap
        mean_numb_agents = np.mean(dbs.main_db[3][start_round:end_round])
        std_numb_agents = np.std(dbs.main_db[3][start_round:end_round])

        num_births_in_iter = 0
        num_deaths_in_iter = 0

        for birth_day in dbs.birth_dates:
            if start_round <= birth_day < end_round:
                num_births_in_iter += 1

        births_data.append(num_births_in_iter)

        for death_day in dbs.death_dates:
            if start_round <= death_day < end_round:
                num_deaths_in_iter += 1

        deaths_data.append(num_deaths_in_iter)

        if two_tribes:
            mean_numb_sharks = np.mean(dbs.pop_sharks[start_round:end_round])
            std_numb_sharks = np.std(dbs.pop_sharks[start_round:end_round])
            mean_numb_jets = np.mean(dbs.pop_jets[start_round:end_round])
            std_numb_jets = np.std(dbs.pop_jets[start_round:end_round])

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")

        if two_tribes == 0:

            fileHandle.write("\nRounds %d to %d: mean num = %2.4f (%2.4f)" % (start_round, end_round - 1, mean_numb_agents, std_numb_agents))

        elif two_tribes:

            fileHandle.write("\nRounds %d to %d: mean num ags = %2.4f (%2.4f)  |  mean num sharks =  %2.4f (%2.4f)  |  mean num jets =  %2.4f (%2.4f)" % (
            start_round, end_round - 1, mean_numb_agents, std_numb_agents, mean_numb_sharks, std_numb_sharks, mean_numb_jets, std_numb_jets))

        if file_type == 'html':
            fileHandle.write("</p>")

        if two_tribes == 0:

            population_data.append(mean_numb_agents)

        elif two_tribes:

            population_data.append([mean_numb_agents, mean_numb_sharks, mean_numb_jets])

    # print('\n dbs.birth_dates =', dbs.birth_dates)
    # print('\n births_data =', births_data)
    # print('\n dbs.death_dates =', dbs.death_dates)
    # print('\n deaths_data =', deaths_data)
    # pause()

    # Find resources foraged in the last 10% of rounds (for each resource fountain and mean) and their stds

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\nForaging Data (total foraged from fountains in each round) - average per agent")
    if file_type == 'html':
        fileHandle.write("</h2>")

    end_foraging_data = []

    if print_fine_dets == 1:
        print('\n dbs.init_res_levels =', dbs.init_res_levels)  # note when two_tribes == 1 then this has 4 cells, not num_res_founts

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = ten_pct_rounds_array[iter] + ten_pct_gap
        mean_numb_agents = np.mean(dbs.main_db[3][start_round:end_round])

        if file_type == 'html':
            fileHandle.write("<h3>")
        fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
        if file_type == 'html':
            fileHandle.write("</h3>")

        for_data = []

        for i in np.arange(num_res_founts):

            if print_fine_dets == 1:
                print('\n start_round =', start_round)
                print(' end_round =', end_round)
                print('\n res =', i)
                print('\n [dbs.init_res_levels[d][i] for d in np.arange(start_round, end_round)] =', [dbs.init_res_levels[d][i] for d in np.arange(start_round, end_round)])
                print('\n np.mean(dbs.main_db[4 + i][start_round:end_round]) =', np.mean(dbs.main_db[4 + i][start_round:end_round]))

            if two_tribes == 0:

                initial_res_level = np.mean([dbs.init_res_levels[d][i] for d in np.arange(start_round, end_round)])

                if mean_numb_agents > 0:
                    mean_foraged = (initial_res_level - np.mean(dbs.main_db[4 + i][start_round:end_round])) / float(mean_numb_agents)
                    std_foraged = (np.std(dbs.main_db[4 + i][start_round:end_round])) / float(mean_numb_agents)

                elif mean_numb_agents == 0:
                    mean_foraged = 0
                    std_foraged = 0

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nResource %s Mean = %3.4f (%3.2f)" % (i, mean_foraged, std_foraged))
                if file_type == 'html':
                    fileHandle.write("</p>")

                for_data.append([i, mean_foraged, std_foraged])

            elif two_tribes:

                mean_numb_sharks = np.mean(dbs.pop_sharks[start_round:end_round])
                mean_numb_jets = np.mean(dbs.pop_jets[start_round:end_round])

                print('\n start_round =', start_round)
                print('\n end_round =', end_round)
                print('\n ten_pct_rounds_array =', ten_pct_rounds_array)
                print(' ten_pct_gap =', ten_pct_gap)
                print('\n printed_segment_size =', printed_segment_size)

                # do sharks' fountains first
                initial_res_level_sharks = np.mean([dbs.init_res_levels[d][i] for d in np.arange(start_round, end_round)])

                if mean_numb_sharks > 0:

                    mean_foraged_sharks = (initial_res_level_sharks - np.mean(dbs.res_founts_sharks[i][start_round:end_round])) / float(mean_numb_sharks)
                    std_foraged_sharks = np.std(dbs.res_founts_sharks[i][start_round:end_round]) / float(mean_numb_sharks)

                elif mean_numb_sharks == 0:

                    mean_foraged_sharks = 0
                    std_foraged_sharks = 0

                # now do jets
                initial_res_level_jets = np.mean([dbs.init_res_levels[d][2 + i] for d in np.arange(start_round, end_round)])

                if mean_numb_jets > 0:

                    mean_foraged_jets = (initial_res_level_jets - np.mean(dbs.res_founts_jets[i][start_round:end_round])) / float(mean_numb_jets)
                    std_foraged_jets = np.std(dbs.res_founts_jets[i][start_round:end_round]) / float(mean_numb_jets)

                elif mean_numb_jets == 0:

                    mean_foraged_jets = 0
                    std_foraged_jets = 0

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nResource %s Sharks Mean = %3.4f (%3.2f)  |  Jets Mean = %3.4f (%3.2f)" % (i, mean_foraged_sharks, std_foraged_sharks, mean_foraged_jets, std_foraged_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")

                for_data.append([i, mean_foraged_sharks, std_foraged_sharks, mean_foraged_jets, std_foraged_jets])

        end_foraging_data.append(for_data)

    if print_fine_dets == 1:
        print('\nend_foraging_data =\n', end_foraging_data)

    # Find degree of specialisation
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nSpecialisation Data (numbers of agents in specialisation buckets)")
    if file_type == 'html':
        fileHandle.write("</h2>")

    spec_degr_data = []
    mean_spec_array = []

    #    print('\n for_spec_db1 :\n\n', for_spec_db1)

    # find minimum value of max foraging value
    min_max_spec = int(for_strat_parts / float(num_res_founts))

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = ten_pct_rounds_array[iter] + ten_pct_gap
        mean_numb_agents = np.mean(dbs.main_db[3][start_round:end_round])

        if file_type == 'html':
            fileHandle.write("<h3>")
        fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
        if file_type == 'html':
            fileHandle.write("</h3>")

        ten_pct_data = []

        #        mean_spec_values = []

        for spec_degr in np.arange(for_strat_parts + 1):

            if mean_numb_agents >= 1:

                mean_specd = np.mean(for_spec_db1[spec_degr][start_round:end_round])
                std_specd = np.std(for_spec_db1[spec_degr][start_round:end_round])

            elif mean_numb_agents < 1:

                mean_specd = 0
                std_specd = 0

            if min_max_spec <= spec_degr <= for_strat_parts:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nSpecialisation degree %d Mean = %3.4f (%3.2f)" % (spec_degr, mean_specd, std_specd))
                if file_type == 'html':
                    fileHandle.write("</p>")

            ten_pct_data.append([spec_degr, mean_specd, std_specd])

        if mean_numb_agents >= 1:

            mean_mean_spec_value = np.mean(for_spec_means[start_round:end_round])
            std_mean_spec_value = np.std(for_spec_means[start_round:end_round])

        elif mean_numb_agents < 1:

            mean_mean_spec_value = None
            std_mean_spec_value = None

        #        print('start', start_round, 'end', end_round, '\n for_spec_means[start_round:end_round]:\n\n', for_spec_means[start_round:end_round])
        #        print('mean_mean_spec_value =', mean_mean_spec_value, 'std_mean_spec_value =', std_mean_spec_value)

        if file_type == 'html':
            fileHandle.write("<p> </p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\n\nOverall weighted mean specialisation value (mean of daily means) = %s" % (mean_mean_spec_value))
        if file_type == 'html':
            fileHandle.write("</p>")

        spec_degr_data.append(ten_pct_data)
        mean_spec_array.append([mean_mean_spec_value, std_mean_spec_value])

    if print_fine_dets == 1:
        print('\nspec_degr_data =\n', spec_degr_data)
        print('\nmean_spec_array =\n', mean_spec_array)

    # find the number of agents who specialised (skill prob > 0.99)
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nSpecialisation Data (numbers of agents in with one detection probability > 0.99)\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    num_spec_agents_array = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        av_num = np.mean(dbs.num_perfect_specs[2][start_round:end_round])
        std_num = np.std(dbs.num_perfect_specs[2][start_round:end_round])

        num_spec_agents_array.append([av_num, std_num])

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nRounds %d to %d - Average Num of Specialists: %3.4f (%3.2f)" % (start_round, end_round - 1, av_num, std_num))
        if file_type == 'html':
            fileHandle.write("</p>")

    # Find mean maximum probabilities of detection
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nDetection Probabilities Data (mean maximum probabilities of detection) at end of rounds\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    max_probs_data = []

    for iter in range(num_iters):

        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap - 1)

        max_probs_array = dbs.copy_ags_max_det_probs[end_round]

        #        print(end_round, 'dbs.copy_ags_max_det_probs[end_round] =', dbs.copy_ags_max_det_probs[end_round])

        #        dbs.copy_ags_res_arrays[round] = agents_res_array

        #        for agent in dbs.live_agents[end_round]:
        #
        #            max_probs_array.append(np.max(agent.detect_skills_array_hist[end_round]))
        #
        #            if print_fine_dets == 1:
        #                print('\nend_round =', end_round)
        #                print('agent.detect_skills_array_hist[end_round] =', agent.detect_skills_array_hist[end_round])

        if len(max_probs_array) > 0:

            mean_max_probs = np.mean(max_probs_array)
            std_max_probs = np.std(max_probs_array)

        elif len(max_probs_array) == 0:

            mean_max_probs = None
            std_max_probs = None

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nEnd of Round %d Mean = %s (%s)" % (end_round, mean_max_probs, std_max_probs))
        if file_type == 'html':
            fileHandle.write("</p>")

        max_probs_data.append([mean_max_probs, std_max_probs])

    if print_fine_dets == 1:
        print('\nmax_probs_data =\n', max_probs_data)

    # Generate Resource Stocks Data
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nAgent Personal Resource Levels Data at end of rounds\n\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    if file_type == 'html':
        fileHandle.write("<p>")
    fileHandle.write("Resource starting value = %s" % (agent_res_init))
    if file_type == 'html':
        fileHandle.write("</p>")

    res_array_data = []

    for iter in range(num_iters):

        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap - 1)

        min_ress_array = []
        mean_ress_array = []
        max_ress_array = []

        #        print(end_round, 'dbs.copy_ags_res_arrays[end_round] =', dbs.copy_ags_res_arrays[end_round])

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'></p>")

        for agent_line in dbs.copy_ags_res_arrays[end_round]:  # dbs.live_agents[end_round]:

            min_res = np.min(agent_line)
            mean_res = np.mean(agent_line)
            max_res = np.max(agent_line)

            min_ress_array.append(min_res)
            mean_ress_array.append(mean_res)
            max_ress_array.append(max_res)

        if len(min_ress_array) > 0:

            mean_min_res = np.mean(min_ress_array)
            std_min_res = np.std(min_ress_array)

            mean_mean_res = np.mean(mean_ress_array)
            std_mean_res = np.std(mean_ress_array)

            mean_max_res = np.mean(max_ress_array)
            std_max_res = np.std(max_ress_array)

        elif len(min_ress_array) == 0:

            mean_min_res = std_min_res = mean_max_res = std_max_res = mean_mean_res = std_mean_res = 0

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\n\nEnd of Round %d Mean Min Resource = %3.4f (%3.2f)" % (end_round, mean_min_res, std_min_res))
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nEnd of Round %d Mean Max Resource = %3.4f (%3.2f)" % (end_round, mean_max_res, std_max_res))
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nEnd of Round %d Mean Mean Resource = %3.4f (%3.2f)" % (end_round, mean_mean_res, std_mean_res))
        if file_type == 'html':
            fileHandle.write("</p><p></p>")

        res_array_data.append([[mean_min_res, std_min_res], [mean_max_res, std_max_res], [mean_mean_res, std_mean_res]])

    if print_fine_dets == 1:
        print('\nres_array_data =\n', res_array_data)

    # Generate Turnover data
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nTurnover Data (volume of transactions of each resource)")
    if file_type == 'html':
        fileHandle.write("</h2>")

    actual_turnover_array = []
    optimal_turnover_array = []
    ratio_turnover_array = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        act_to_array = []
        opt_to_array = []
        rat_to_array = []

        if file_type == 'html':
            fileHandle.write("<h3>")
        fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
        if file_type == 'html':
            fileHandle.write("</h3>")

        for res in np.arange(num_res_founts):

            gross_to_array = [dbs.net_net_transs_db[x][res] for x in np.arange(start_round, end_round)]

            mean_to = np.mean(gross_to_array)
            std_to = np.std(gross_to_array)

            optimal_to_array = [dbs.optimal_bskt_turnover[x][res] for x in np.arange(start_round, end_round)]

            mean_opt_to = np.mean(optimal_to_array)
            std_opt_to = np.std(optimal_to_array)

            #            turnover_ratio_array = [dbs.net_net_transs_db[x][res] / float(dbs.optimal_bskt_turnover[x][res]) for x in np.arange(start_round, end_round)]
            #
            #            mean_turn_rat = np.mean(turnover_ratio_array)
            #            std_opt_turn_rat = np.std(turnover_ratio_array)

            if mean_opt_to > 0:
                mean_to_ratio = mean_to / float(mean_opt_to)
            else:
                mean_to_ratio = 0

            if std_opt_to > 0:
                std_to_ratio = std_to / float(std_opt_to)
            else:
                std_to_ratio = 0

            if two_tribes == 0:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n\nResource %s - Actual Turnover: %3.4f (%3.2f)" % (res, mean_to, std_to))
                if file_type == 'html':
                    fileHandle.write("</p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nResource %s - Optimal Turnover: %3.4f (%3.2f)" % (res, mean_opt_to, std_opt_to))
                if file_type == 'html':
                    fileHandle.write("</p>")
                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nPercent: %3.4f (%3.3f)" % (mean_to_ratio * 100, std_to_ratio * 100))
                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'><p></p>")

                act_to_array.append([mean_to, std_to])
                opt_to_array.append([mean_opt_to, std_opt_to])
                rat_to_array.append([mean_to_ratio, std_to_ratio])

            elif two_tribes:

                gross_to_array_sharks = [dbs.net_net_transs_db_sharks[x][res] for x in np.arange(start_round, end_round)]

                mean_to_sharks = np.mean(gross_to_array_sharks)
                std_to_sharks = np.std(gross_to_array_sharks)

                optimal_to_array_sharks = [dbs.optimal_bskt_turnover_sharks[x][res] for x in np.arange(start_round, end_round)]

                mean_opt_to_sharks = np.mean(optimal_to_array_sharks)
                std_opt_to_sharks = np.std(optimal_to_array_sharks)

                if mean_opt_to_sharks > 0:
                    mean_to_ratio_sharks = mean_to_sharks / float(mean_opt_to_sharks)
                else:
                    mean_to_ratio_sharks = 0

                if std_opt_to_sharks > 0:
                    std_to_ratio_sharks = std_to_sharks / float(std_opt_to_sharks)
                else:
                    std_to_ratio_sharks = 0

                gross_to_array_jets = [dbs.net_net_transs_db_jets[x][res] for x in np.arange(start_round, end_round)]

                mean_to_jets = np.mean(gross_to_array_jets)
                std_to_jets = np.std(gross_to_array_jets)

                optimal_to_array_jets = [dbs.optimal_bskt_turnover_jets[x][res] for x in np.arange(start_round, end_round)]

                mean_opt_to_jets = np.mean(optimal_to_array_jets)
                std_opt_to_jets = np.std(optimal_to_array_jets)

                if mean_opt_to_jets > 0:
                    mean_to_ratio_jets = mean_to_jets / float(mean_opt_to_jets)
                else:
                    mean_to_ratio_jets = 0

                if std_opt_to_jets > 0:
                    std_to_ratio_jets = std_to_jets / float(std_opt_to_jets)
                else:
                    std_to_ratio_jets = 0

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n\nResource %s - Actual Turnover: Total %3.4f (%3.2f)  |  Sharks %3.4f (%3.2f)  |  Jets %3.4f (%3.2f)" % (res, mean_to, std_to, mean_to_sharks, std_to_sharks, mean_to_jets, std_to_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nResource %s - Optimal Turnover: Total %3.4f (%3.2f)  |  Sharks %3.4f (%3.2f)  |  Jets %3.4f (%3.2f)" % (res, mean_opt_to, std_opt_to, mean_opt_to_sharks, std_opt_to_sharks, mean_opt_to_jets, std_opt_to_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")
                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nPercent: Total %3.4f (%3.3f)  |  Sharks %3.4f (%3.2f)  |  Jets %3.4f (%3.2f)" % (
                mean_to_ratio * 100, std_to_ratio * 100, mean_to_ratio_sharks * 100, std_to_ratio_sharks * 100, mean_to_ratio_jets * 100, std_to_ratio_jets * 100))
                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'><p></p>")

                act_to_array.append([mean_to, std_to, mean_to_sharks, std_to_sharks, mean_to_jets, std_to_jets])
                opt_to_array.append([mean_opt_to, std_opt_to, mean_opt_to_sharks, std_opt_to_sharks, mean_opt_to_jets, std_opt_to_jets])
                rat_to_array.append([mean_to_ratio, std_to_ratio, mean_to_ratio_sharks, std_to_ratio_sharks, mean_to_ratio_jets, std_to_ratio_jets])

        actual_turnover_array.append(act_to_array)
        optimal_turnover_array.append(opt_to_array)
        ratio_turnover_array.append(rat_to_array)

    if print_fine_dets == 1:
        print('\nactual_turnover_array =\n', actual_turnover_array)
        print('\noptimal_turnover_array =\n', optimal_turnover_array)

    # Generate Average Age data
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nAverage Age Data\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    all_age_arry = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        if np.any(dbs.ag_age_db[1][start_round:end_round] == 0) == False:

            av_age = np.mean(dbs.ag_age_db[1][start_round:end_round])
            std_age = np.std(dbs.ag_age_db[1][start_round:end_round])

        elif np.any(dbs.ag_age_db[1][start_round:end_round] == 0):

            av_age = None
            std_age = None

        all_age_arry.append([av_age, std_age])

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nRounds %d to %d - Average Age: %s (%s)" % (start_round, end_round - 1, av_age, std_age))
        if file_type == 'html':
            fileHandle.write("</p>")

    if print_fine_dets == 1:
        print('\nall_age_arry = \n', all_age_arry)
    #
    #    # Generate Clustering Coefficient Data
    #    fileHandle.write("\n\n\n\nCustering Coefficient Data\n")
    #
    #    cc_array = []
    #
    #    for iter in range(num_iters):
    #
    #        start_round = ten_pct_rounds_array[iter]
    #        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)
    #
    #        if start_round > cluster_lag - 1:
    #
    #            # Note here, dbs.clustering_db[1] starts at round cluster_lag - 1 (default = 4)
    #            av_cc = np.mean(dbs.clustering_db[1][start_round:end_round])
    #            std_cc = np.std(dbs.clustering_db[1][start_round:end_round])
    #
    #            cc_array.append([start_round, end_round - 1, av_cc, std_cc])
    #
    #            fileHandle.write("\nRounds %d to %d - Clustering Coefficient = %3.4f (%3.2f)" % (start_round, end_round - 1, av_cc, std_cc))
    #
    #    if print_fine_dets == 1:
    #        print('\ncc_array = \n', cc_array)

    # Generate data showing the number of squares with transactions
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nNumber of Squares with Transactions Data\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    num_sq_array = []
    trading_prop_array = []
    trading_gini_array = []

    #    # generate and process the gini coefficient data
    #
    #    # create array to save daily gini coefficients
    #    ginis = np.zeros(shape=(rounds), dtype=np.float)
    #
    #    for day in range(rounds):
    #
    #        gini_coeff_daily = gini(town_grid.all_trans_array[day])
    #
    #        ginis[day] = gini_coeff_daily
    #
    #        print('day = ', day, '- gini_coeff_daily =', gini_coeff_daily)
    #
    #    print('\n ginis:\n\n', ginis)

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        # this array record the transactions in each square if there was a transaction
        ginis = []

        # We want to find a weighted average number of squares where there were transactions
        tot_sqs = 0

        trading_prop_one_sq = []

        segment_grid = np.zeros(shape=(town_grid.dimen, town_grid.dimen))

        for xdi in np.arange(town_grid.dimen):
            for ydi in np.arange(town_grid.dimen):

                # We only want to know if there has been any transaction on each grid square
                if np.sum(dbs.transactions_record[xdi][ydi][start_round:end_round]) > 0:
                    tot_sqs += 1

                # add volumes up for each grid square in each day, for whole segment
                for day in range(start_round, end_round):
                    segment_grid[xdi][ydi] += town_grid.all_trans_array[day][xdi][ydi]

                if segment_grid[xdi][ydi] > 0.0:
                    ginis.append(segment_grid[xdi][ydi])

        if len(ginis) > 0:

            segment_gini = gini(np.array(ginis))

        else:

            segment_gini = 0.0

        trading_gini_array.append(segment_gini)

        #        print('\n\n iter = ', iter, ' ginis =\n\n', ginis, '\n segment_gini coefficient=', segment_gini)

        #        trading_gini_array.append(mean_ginis)

        #        print('\n iter ', iter, 'segment grid:\n')
        #
        #        for row in segment_grid:
        #
        #            print(row)

        total_volume = np.sum(segment_grid)

        max_volume = np.max(segment_grid)

        if total_volume > 0:

            one_squ_ratio = max_volume / float(total_volume)

        else:

            one_squ_ratio = 0.0

        trading_prop_one_sq.append(one_squ_ratio)

        #        print('\n total_volume =', total_volume)
        #        print(' max_volume =', max_volume)
        #        print(' one_squ_ratio =', one_squ_ratio)

        num_sq_array.append(tot_sqs)

        trading_prop_array.append(one_squ_ratio)

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write(
            "\nRounds %d to %d - Number of Squares with transactions = %d  |  Proportion of Transaction Volumes on One Square = %1.4f  |  gini coeff (segment) = %1.4f" % (start_round, end_round - 1, tot_sqs, one_squ_ratio, segment_gini))
        if file_type == 'html':
            fileHandle.write("</p>")

    #    print('num_sq_array =', num_sq_array)

    if print_fine_dets == 1:
        print('\nnum_sq_array =\n', num_sq_array)

    # If a market emerged, by what round did it?  Here we look at dbs.mkt_emerged_round, which has 3 elements: [0] = 90% 10 day moving average turnover ratio, [1] = 95%, [3] = 99%
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nWhen Did the Market Emerge?\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    #    print('\n dbs.mkt_emerged_round =', dbs.mkt_emerged_round)

    if dbs.mkt_emerged_round[0] > 0:

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\n10-round Moving Average of Turnover Ratio exceeded 90pct (for any resource) in Round %d\n" % (dbs.mkt_emerged_round[0]))
        if file_type == 'html':
            fileHandle.write("</p>")

        if dbs.mkt_emerged_round[1] > 0:

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("10-round Moving Average of Turnover Ratio exceeded 95pct (for any resource) in Round %d\n" % (dbs.mkt_emerged_round[1]))
            if file_type == 'html':
                fileHandle.write("</p>")

            if dbs.mkt_emerged_round[2] > 0:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("10-round Moving Average of Turnover Ratio exceeded 99pct (for any resource) in Round %d\n" % (dbs.mkt_emerged_round[2]))
                if file_type == 'html':
                    fileHandle.write("</p>")

            else:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n10-round Moving Average of Turnover Ratio never exceeded 99pct (for any resource)")
                if file_type == 'html':
                    fileHandle.write("</p>")

        else:

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n10-round Moving Average of Turnover Ratio never exceeded 95pct (for any resource)")
            if file_type == 'html':
                fileHandle.write("</p>")

    else:

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\n10-round Moving Average of Turnover Ratio never exceeded 90pct (for any resource)")
        if file_type == 'html':
            fileHandle.write("</p>")

    # Now we turn to the locations targetted by each agent. The question is when did all the agents go to the same location?

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nOne Location Visited by Agents? If so, when?\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    if file_type == 'html':
        fileHandle.write("<p style='margin:0;'>")
    if dbs.round_all_ags_one_trgt == None:
        fileHandle.write("\n\n The agents never converged on a single square")
    else:
        fileHandle.write("\n\n The agents converged on a single square in round %d" % dbs.round_all_ags_one_trgt)
    if file_type == 'html':
        fileHandle.write("</p>")

    # Generate data showing the difference between mean actual transactions and optimal price, for each resource pair
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nPricing Data\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    act_prices_data = []
    act_std_prices_data = []
    opt_prices_data = []
    diff_prices_data = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        if file_type == 'html':
            fileHandle.write("<h3>")
        fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
        if file_type == 'html':
            fileHandle.write("</h3>")

        if two_tribes == 0:

            act_prices_iter = [[[None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            act_std_prices_iter = [[[None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            opt_prices_iter = [[[None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            diff_prices_iter = [[[None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]

        elif two_tribes:

            act_prices_iter = [[[None, None, None, None, None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            act_std_prices_iter = [[[None, None, None, None, None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            opt_prices_iter = [[[None, None, None, None, None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]
            diff_prices_iter = [[[None, None, None, None, None, None] for i in np.arange(num_res_founts)] for j in np.arange(num_res_founts)]

        for res_1 in np.arange(num_res_founts):
            for res_2 in np.arange(num_res_founts):

                if res_1 != res_2:

                    if print_fine_dets == 1:
                        print('\ndbs.mean_price_history[res_1][res_2] =\n', dbs.mean_price_history[res_1][res_2])
                        print('start_round =', start_round)
                        print('end_round =', end_round)
                        print('np.array(dbs.mean_price_history[res_1][res_2][start_round:end_round] =', np.array(dbs.mean_price_history[res_1][res_2][start_round:end_round]))
                        print('1 / =', 1.0 / np.array(dbs.mean_price_history[res_1][res_2][start_round:end_round]))
                        print('list...', list(1.0 / np.array(dbs.mean_price_history[res_1][res_2][start_round:end_round])))
                        print('\n[dbs.optimal_price_array[i][res_1][res_2] for i in np.arange(start_round:end_round)] =\n', [dbs.optimal_price_array[i][res_1][res_2] for i in np.arange(start_round, end_round)])

                    # Unpack the relevant price data, which is in working price form
                    act_chart_prices_array = np.array(dbs.mean_price_history[res_1][res_2][start_round:end_round])
                    act_chart_prs_stds_array = np.array(dbs.price_history_std[res_1][res_2][start_round:end_round])

                    if two_tribes:
                        act_chart_prices_array_sharks = np.array(dbs.mean_price_history_sharks[res_1][res_2][start_round:end_round])
                        act_chart_prs_stds_array_sharks = np.array(dbs.price_history_std_sharks[res_1][res_2][start_round:end_round])

                        act_chart_prices_array_jets = np.array(dbs.mean_price_history_jets[res_1][res_2][start_round:end_round])
                        act_chart_prs_stds_array_jets = np.array(dbs.price_history_std_jets[res_1][res_2][start_round:end_round])

                    # These are recorded as working prices at this stage, so inversion necessary
                    opt_prices_array = [1 / dbs.optimal_price_array[i][res_1][res_2] for i in np.arange(start_round, end_round)]

                    if two_tribes:
                        opt_prices_array_sharks = [1 / dbs.optimal_price_array_sharks[i][res_1][res_2] for i in np.arange(start_round, end_round)]
                        opt_prices_array_jets = [1 / dbs.optimal_price_array_jets[i][res_1][res_2] for i in np.arange(start_round, end_round)]

                    # We have to crop this data to remove the days when there were no transactions i.e. dbs.mean_price_history[res_1][res_2][day] == None

                    # Create databases to capture the cropped data
                    cropped_chart_prices_array = []
                    cropped_chart_prices_std_array = []
                    cropped_opt_prices_array = []

                    if two_tribes:
                        cropped_chart_prices_array_sharks = []
                        cropped_chart_prices_std_array_sharks = []
                        cropped_opt_prices_array_sharks = []

                        cropped_chart_prices_array_jets = []
                        cropped_chart_prices_std_array_jets = []
                        cropped_opt_prices_array_jets = []

                    price_day = 0

                    # If there were no transactions in a particular day, we must ignore price data - we search through
                    # dbs.mean_price_history[res_1][res_2] and ignore days where == None
                    for day_mean_wkg_price in act_chart_prices_array:

                        if day_mean_wkg_price != 1000 and day_mean_wkg_price != 0.0:
                            cropped_chart_prices_array.append(day_mean_wkg_price)
                            cropped_chart_prices_std_array.append(act_chart_prs_stds_array[price_day])

                            cropped_opt_prices_array.append(opt_prices_array[price_day])

                        price_day += 1

                    if two_tribes:

                        # sharks
                        price_day = 0

                        for day_mean_wkg_price in act_chart_prices_array_sharks:

                            if day_mean_wkg_price != 1000 and day_mean_wkg_price != 0.0:
                                cropped_chart_prices_array_sharks.append(day_mean_wkg_price)
                                cropped_chart_prices_std_array_sharks.append(act_chart_prs_stds_array_sharks[price_day])

                                cropped_opt_prices_array_sharks.append(opt_prices_array_sharks[price_day])

                            price_day += 1

                        # jets
                        price_day = 0

                        for day_mean_wkg_price in act_chart_prices_array_jets:

                            if day_mean_wkg_price != 1000 and day_mean_wkg_price != 0.0:
                                cropped_chart_prices_array_jets.append(day_mean_wkg_price)
                                cropped_chart_prices_std_array_jets.append(act_chart_prs_stds_array_jets[price_day])

                                cropped_opt_prices_array_jets.append(opt_prices_array_jets[price_day])

                            price_day += 1

                    # convert to np
                    cropped_opt_prices_array = np.array(cropped_opt_prices_array)

                    if two_tribes:
                        cropped_opt_prices_array_sharks = np.array(cropped_opt_prices_array_sharks)
                        cropped_opt_prices_array_jets = np.array(cropped_opt_prices_array_jets)

                    if len(cropped_chart_prices_array) > 0:
                        act_prices_mean = np.mean(cropped_chart_prices_array)
                        act_prices_std = np.std(cropped_chart_prices_array)

                    else:
                        act_prices_mean = None
                        act_prices_std = None

                    if two_tribes:

                        # sharks
                        if len(cropped_chart_prices_array_sharks) > 0:
                            act_prices_mean_sharks = np.mean(cropped_chart_prices_array_sharks)
                            act_prices_std_sharks = np.std(cropped_chart_prices_array_sharks)

                        else:
                            act_prices_mean_sharks = None
                            act_prices_std_sharks = None

                        # jets
                        if len(cropped_chart_prices_array_jets) > 0:
                            act_prices_mean_jets = np.mean(cropped_chart_prices_array_jets)
                            act_prices_std_jets = np.std(cropped_chart_prices_array_jets)

                        else:
                            act_prices_mean_jets = None
                            act_prices_std_jets = None

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\n\nResource %s vs Resource %s - Mean Actual Price = %s (%s)" % (res_1, res_2, act_prices_mean, act_prices_std))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        act_prices_iter[res_1][res_2] = [act_prices_mean, act_prices_std]

                    elif two_tribes:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\n\nResource %s vs Resource %s - Mean Actual Price (all) = %s (%s)  |  Sharks %s (%s)  |  Jets %s (%s)" % (
                        res_1, res_2, act_prices_mean, act_prices_std, act_prices_mean_sharks, act_prices_std_sharks, act_prices_mean_jets, act_prices_std_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        act_prices_iter[res_1][res_2] = [act_prices_mean, act_prices_std, act_prices_mean_sharks, act_prices_std_sharks, act_prices_mean_jets, act_prices_std_jets]

                    if len(cropped_chart_prices_std_array) > 0:
                        mean_std_of_daily_prices = np.mean(cropped_chart_prices_std_array)
                        std_std_of_daily_prices = np.std(cropped_chart_prices_std_array)

                    else:
                        mean_std_of_daily_prices = None
                        std_std_of_daily_prices = None

                    if two_tribes:

                        # sharks
                        if len(cropped_chart_prices_std_array_sharks) > 0:
                            mean_std_of_daily_prices_sharks = np.mean(cropped_chart_prices_std_array_sharks)
                            std_std_of_daily_prices_sharks = np.std(cropped_chart_prices_std_array_sharks)

                        else:
                            mean_std_of_daily_prices_sharks = None
                            std_std_of_daily_prices_sharks = None

                        # jets
                        if len(cropped_chart_prices_std_array_jets) > 0:
                            mean_std_of_daily_prices_jets = np.mean(cropped_chart_prices_std_array_jets)
                            std_std_of_daily_prices_jets = np.std(cropped_chart_prices_std_array_jets)

                        else:
                            mean_std_of_daily_prices_jets = None
                            std_std_of_daily_prices_jets = None

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Average Daily Standard Deviation of Prices = %s (%s)" % (res_1, res_2, mean_std_of_daily_prices, std_std_of_daily_prices))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        act_std_prices_iter[res_1][res_2] = [mean_std_of_daily_prices, std_std_of_daily_prices]

                    elif two_tribes:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Average Daily Standard Deviation of Prices (all) = %s (%s)  |  Sharks %s (%s)  |  Jets %s (%s)" % (
                        res_1, res_2, mean_std_of_daily_prices, std_std_of_daily_prices, mean_std_of_daily_prices_sharks, std_std_of_daily_prices_sharks, mean_std_of_daily_prices_jets, std_std_of_daily_prices_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        act_std_prices_iter[res_1][res_2] = [mean_std_of_daily_prices, std_std_of_daily_prices, mean_std_of_daily_prices_sharks, std_std_of_daily_prices_sharks, mean_std_of_daily_prices_jets, std_std_of_daily_prices_jets]

                    if len(cropped_opt_prices_array) > 0:
                        opt_prices_mean = np.mean(cropped_opt_prices_array)
                        opt_prices_std = np.std(cropped_opt_prices_array)

                    else:
                        opt_prices_mean = None
                        opt_prices_std = None

                    if two_tribes:

                        # sharks
                        if len(cropped_opt_prices_array_sharks) > 0:
                            opt_prices_mean_sharks = np.mean(cropped_opt_prices_array_sharks)
                            opt_prices_std_sharks = np.std(cropped_opt_prices_array_sharks)

                        else:
                            opt_prices_mean_sharks = None
                            opt_prices_std_sharks = None

                        # jets
                        if len(cropped_opt_prices_array_jets) > 0:
                            opt_prices_mean_jets = np.mean(cropped_opt_prices_array_jets)
                            opt_prices_std_jets = np.std(cropped_opt_prices_array_jets)

                        else:
                            opt_prices_mean_jets = None
                            opt_prices_std_jets = None

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Mean Optimal Price (all) = %s (%s)" % (res_1, res_2, opt_prices_mean, opt_prices_std))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        opt_prices_iter[res_1][res_2] = [opt_prices_mean, opt_prices_std]

                    elif two_tribes:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Mean Optimal Price (all) = %s (%s)  |  Sharks %s (%s)  |  Jets %s (%s)" % (
                        res_1, res_2, opt_prices_mean, opt_prices_std, opt_prices_mean_sharks, opt_prices_std_sharks, opt_prices_mean_jets, opt_prices_std_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        opt_prices_iter[res_1][res_2] = [opt_prices_mean, opt_prices_std, opt_prices_mean_sharks, opt_prices_std_sharks, opt_prices_mean_jets, opt_prices_std_jets]

                    price_differences = np.zeros(shape=(len(cropped_chart_prices_array)))

                    for cell_num in range(len(price_differences)):
                        price_differences[cell_num] = math.fabs(cropped_chart_prices_array[cell_num] - cropped_opt_prices_array[cell_num])

                    if two_tribes:

                        # sharks
                        price_differences_sharks = np.zeros(shape=(len(cropped_chart_prices_array_sharks)))

                        for cell_num in range(len(price_differences_sharks)):
                            price_differences_sharks[cell_num] = math.fabs(cropped_chart_prices_array_sharks[cell_num] - cropped_opt_prices_array_sharks[cell_num])

                        # jets
                        price_differences_jets = np.zeros(shape=(len(cropped_chart_prices_array_jets)))

                        for cell_num in range(len(price_differences_jets)):
                            price_differences_jets[cell_num] = math.fabs(cropped_chart_prices_array_jets[cell_num] - cropped_opt_prices_array_jets[cell_num])

                    #                    price_differences = act_chart_prices_array - cropped_opt_prices_array

                    if len(price_differences) > 0:
                        diff_prices_mean = np.mean(price_differences)
                        diff_prices_std = np.std(price_differences)

                    elif len(price_differences) == 0:
                        diff_prices_mean = None
                        diff_prices_std = None

                    if two_tribes:

                        # sharks
                        if len(price_differences_sharks) > 0:
                            diff_prices_mean_sharks = np.mean(price_differences_sharks)
                            diff_prices_std_sharks = np.std(price_differences_sharks)

                        elif len(price_differences_sharks) == 0:
                            diff_prices_mean_sharks = None
                            diff_prices_std_sharks = None

                        # jets
                        if len(price_differences_jets) > 0:
                            diff_prices_mean_jets = np.mean(price_differences_jets)
                            diff_prices_std_jets = np.std(price_differences_jets)

                        elif len(price_differences_jets) == 0:
                            diff_prices_mean_jets = None
                            diff_prices_std_jets = None

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Mean Abs (Actual - Optimal Price) = %s (%s)" % (res_1, res_2, diff_prices_mean, diff_prices_std))
                        if file_type == 'html':
                            fileHandle.write("</p>")
                            fileHandle.write("<p></p>")

                        diff_prices_iter[res_1][res_2] = [diff_prices_mean, diff_prices_std]

                    elif two_tribes:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s vs Resource %s - Mean Abs (Actual - Optimal Price) all = %s (%s)  |  Sharks %s (%s)  |  Jets %s (%s)" % (
                        res_1, res_2, diff_prices_mean, diff_prices_std, diff_prices_mean_sharks, diff_prices_std_sharks, diff_prices_mean_jets, diff_prices_std_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")
                            fileHandle.write("<p></p>")

                        diff_prices_iter[res_1][res_2] = [diff_prices_mean, diff_prices_std, diff_prices_mean_sharks, diff_prices_std_sharks, diff_prices_mean_jets, diff_prices_std_jets]

        act_prices_data.append(act_prices_iter)
        act_std_prices_data.append(act_std_prices_iter)
        opt_prices_data.append(opt_prices_iter)
        diff_prices_data.append(diff_prices_iter)

    if print_fine_dets == 1:
        print('\nact_prices_data =\n', act_prices_data)
        print('\nopt_prices_data =\n', opt_prices_data)
        print('\ndiff_prices_data =\n', diff_prices_data)

    # Here we find the mean and std of the optimal prices for the whole simulation Turnover

    if file_type == 'html':
        fileHandle.write("<p></p>")
        fileHandle.write("<p style='margin:0;'>")
    fileHandle.write("\n\nOptimal Prices: Mean and STD (Resource 0 vs Resource 1 - chart prices): \n")
    #    if file_type == 'html':
    #        fileHandle.write("</p>")

    all_opt_prices = [1 / dbs.optimal_price_array[i][0][1] for i in np.arange(rounds) if dbs.optimal_price_array[i][0][1] != 0.0]

    mean_opt_prices = np.mean(all_opt_prices)
    std_opt_prices = np.std(all_opt_prices)

    whole_sim_opt_prices_array = [mean_opt_prices, std_opt_prices]

    #    if file_type == 'html':
    #        fileHandle.write("<p style='margin:0;'>")
    fileHandle.write("\nMean = %2.4f  |  STD = %2.4f" % (mean_opt_prices, std_opt_prices))
    if file_type == 'html':
        fileHandle.write("</p>")

    # Here we look at the number of home locations which are serviced by markets (recorded in dbs.serviced_locations)
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nPercentage of Agent Homes Covered by Markets\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    serviced_locs_data = []

    for iter in range(num_iters):

        start_round = ten_pct_rounds_array[iter]
        end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

        serv_iter_data = [dbs.serviced_locations[i] for i in np.arange(start_round, end_round)]

        mean_iter = np.mean(serv_iter_data)
        std_iter = np.std(serv_iter_data)

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nRounds %4.0f to %4.0f - Percent of agents within market catchment area = %3.2f (std %3.2f percent)" % (start_round, end_round - 1, mean_iter * 100, std_iter * 100))
        if file_type == 'html':
            fileHandle.write("</p>")

        serviced_locs_data.append([mean_iter, std_iter])

    # if there is a Keynesian Institution, we look at that here

    KI_data = []

    if allow_Keynes_Inst == 'total':

        Keynes_Object = KO_pop.pop[0]
        loc_x = Keynes_Object.loc[0]
        loc_y = Keynes_Object.loc[1]

        #        print('\n\n loc_x =', loc_x, 'loc_y', loc_y)

        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\n\nKeynesian Institution Data (location [%d %d])\n" % (loc_x, loc_y))
        if file_type == 'html':
            fileHandle.write("</h2>")

        for iter in range(num_iters):

            start_round = ten_pct_rounds_array[iter]
            end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

            tot_vol_trade = 0.0
            vol_on_KI = 0.0

            #            print('dbs.trans_db =', dbs.trans_db)
            #            print('len(dbs.trans_db) =', len(dbs.trans_db))

            for trans_numb in range(len(dbs.trans_db)):

                #                print('trans_numb =', trans_numb)

                transaction = dbs.trans_db[trans_numb]

                #                print('transaction =', transaction)
                #                print('transaction.day =', transaction.day)
                #                print('transaction.good_a =', transaction.good_a)
                #                print('transaction.tot_trans_ag_sell =', transaction.tot_trans_ag_sell)
                #                print('transaction.location =', transaction.location)

                if start_round <= transaction.day < end_round:

                    if transaction.good_a == 0:

                        tot_vol_trade += transaction.tot_trans_ag_sell

                        if transaction.location[0] == loc_x and transaction.location[1] == loc_y:
                            vol_on_KI += transaction.tot_trans_ag_sell

                    elif transaction.good_b == 0:

                        tot_vol_trade += transaction.tot_trans_ag_buy

                        if transaction.location[0] == loc_x and transaction.location[1] == loc_y:
                            vol_on_KI += transaction.tot_trans_ag_buy

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nRounds %4.0f to %4.0f - Total Volume of Transaction = %4.4f  |  Total Volume on Keynesian Institution = %4.4f  |  Proportion of transactions on KI = %0.4f" % (
            start_round, end_round - 1, tot_vol_trade, vol_on_KI, float(vol_on_KI / tot_vol_trade)))
            if file_type == 'html':
                fileHandle.write("</p>")

            KI_data.append([tot_vol_trade, vol_on_KI, float(vol_on_KI / tot_vol_trade)])

            # print out live agents' resource arrays and birth date and distance from last mkt visited
    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\n\nAgent Resource Data: Resource Arrays at end of Simulation")
    if file_type == 'html':
        fileHandle.write("</h2>")

    if file_type == 'html':
        fileHandle.write("<p style='margin:0;'>")
    fileHandle.write("\n\nNumber of Agents Alive = %d\n\n" % (len(agent_population.pop)))
    if file_type == 'html':
        fileHandle.write("</p>")
        fileHandle.write("<p></p>")

    agent_num = 0

    mean_res_array = []
    dist_to_target_array = []

    mean_res_array_0 = []
    mean_res_array_1 = []
    dist_to_target_array_0 = []
    dist_to_target_array_1 = []

    X_array_all_agents = []

    save_res_array = []

    slope_data = []

    for agent in agent_population.pop:

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\n Agent %d: \t Birth Date %d  |  Resource Array: [" % (agent_num, agent.birth_date))

        for res in range(num_res_founts):
            fileHandle.write(" %2.2f " % (agent.agent_res_array[0][res]))

        if agent.grid_trgt[0] != None:

            dist_from_last_trgt_x = math.fabs(agent.grid_trgt[0] - agent.home[0])

            if dist_from_last_trgt_x > town_grid.dimen / 2.0:
                dist_from_last_trgt_x = town_grid.dimen - dist_from_last_trgt_x

            dist_from_last_trgt_y = math.fabs(agent.grid_trgt[1] - agent.home[1])

            if dist_from_last_trgt_y > town_grid.dimen / 2.0:
                dist_from_last_trgt_y = town_grid.dimen - dist_from_last_trgt_y

            max_dist = np.max([dist_from_last_trgt_x, dist_from_last_trgt_y])

            moves_to_target = math.ceil(max_dist / float(agent.agent_vision))

            fileHandle.write("]  |  last target location = [ %d %d ]  |  Moves to Target from Home = %d" % (agent.grid_trgt[0], agent.grid_trgt[1], moves_to_target))

        else:

            moves_to_target = None
            fileHandle.write("]  |  last target location = [ None None ]  |  Moves to Target from Home = n/a")

        agent_num += 1

        if agent.birth_date == 0:

            min_res = np.min(agent.agent_res_array[0])

            mean_res_array.append(min_res)
            dist_to_target_array.append(moves_to_target)

            if agent.for_strat_array[0][-1] == 0:
                mean_res_array_0.append(agent.agent_res_array[0][0])
                dist_to_target_array_0.append(moves_to_target)
                save_res_array.append(0)

            if agent.for_strat_array[0][-1] == 1:
                mean_res_array_1.append(agent.agent_res_array[0][1])
                dist_to_target_array_1.append(moves_to_target)
                save_res_array.append(1)

            X_array = [1.0, moves_to_target, agent.for_strat_array[0][-1]]

            X_array_all_agents.append(X_array)

        if file_type == 'html':
            fileHandle.write("</p>")

    #    if len(mean_res_array) > 1:
    #
    #        plot_scatter_2d(dist_to_target_array, mean_res_array, 'Distance to Target / Resources Scatter - All Res', data_folder, filename='distance_resource_scatter_all_res', dpi='high')
    #
    #        # we convert array to np and add an intercept term
    #        dist_to_target_array = np.array(dist_to_target_array)
    ##        dist_to_target_array = sm.add_constant(dist_to_target_array)
    #
    #        X_array_all_agents = np.array(X_array_all_agents)
    #
    #        print('\n X_array_all_agents =', X_array_all_agents)
    ##        print('\n dist_to_target_array=', dist_to_target_array)
    #
    #        results = sm.OLS(mean_res_array, X_array_all_agents).fit()
    #
    #        print('\n all res results of OLS:\n\n', results.summary())
    #
    #        fileHandle.write("\n\n All Results: \n\n%s" % (results.summary()))
    #
    #        slope_data = [results.params[1], results.bse[1], results.pvalues[1]]
    #
    ##        slope_data.append(slope_array)
    #
    #    if len(mean_res_array_0) > 1:
    #
    #        plot_scatter_2d(dist_to_target_array_0, mean_res_array_0, 'Distance to Target / Resources Scatter Res 0', data_folder, filename='distance_resource_scatter_res_0', dpi='low')
    #
    #        # we convert array to np and add an intercept term
    #        dist_to_target_array_0 = np.array(dist_to_target_array_0)
    #        dist_to_target_array_0 = sm.add_constant(dist_to_target_array_0)
    #
    #        results = sm.OLS(mean_res_array_0, dist_to_target_array_0).fit()
    #
    #        print('\n res_0 results of OLS:\n\n', results.summary())
    #
    #        fileHandle.write("\n\n Results 0: \n\n%s" % (results.summary()))
    #
    #    if len(mean_res_array_1) > 1:
    #
    #        plot_scatter_2d(dist_to_target_array_1, mean_res_array_1, 'Distance to Target / Resources Scatter Res 1', data_folder, filename='distance_resource_scatter_res_1', dpi='low')
    #
    #        # we convert array to np and add an intercept term
    #        dist_to_target_array_1 = np.array(dist_to_target_array_1)
    #        dist_to_target_array_1 = sm.add_constant(dist_to_target_array_1)
    #
    #        results = sm.OLS(mean_res_array_1, dist_to_target_array_1).fit()
    #
    #        print('\n res_1 results of OLS:\n\n', results.summary())
    #
    #        fileHandle.write("\n\n Results 1: \n\n%s" % (results.summary()))

    #    input("Press Enter to continue")

    if file_type == 'html':
        fileHandle.write("<h2>")
    fileHandle.write("\n\n\nSignificant Market Locations (last round):\n")
    if file_type == 'html':
        fileHandle.write("</h2>")

    if len(dbs.sign_mkt_locs[rounds - 1]) > 0:

        for loc in dbs.sign_mkt_locs[rounds - 1]:

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nLocation [ %d, %d ] : volume %6.2f" % (loc[0], loc[1], dbs.last_round_trans_data[loc[0]][loc[1]]))
            if file_type == 'html':
                fileHandle.write("</p>")

    else:

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nThere was no trading")
        if file_type == 'html':
            fileHandle.write("</p>")

    # Now we turn to constitutional matters

    # create matrix to record agents' res accumulations during each experiment ([0] is agent, etc) - these are returned in the function so must always exist
    const_record_res_accum = [[] for i in range(num_experiments + 1)]

    # create array to count votes
    agents_aggr_votes = np.zeros(shape=(num_experiments + 1))

    if constitutional_voting == 1:

        print_fine_dets = 1

        if file_type == 'html':
            fileHandle.write("<h1>")
        fileHandle.write("\n\n\nConstitutional Voting:\n\n")
        if file_type == 'html':
            fileHandle.write("</h1>")

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nNotes:\n\nExperiment 1 is floating prices and market start = 0")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nExperiment 2 is floating prices and market start = 20")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nExperiment 4 is optimal prices and market start = 0")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nExperiment 3 is optimal prices and market start = 20")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nExperiment 5 is pure Walrasian Prices and Quantities")
        if file_type == 'html':
            fileHandle.write("</p>")

        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\nAgent\tExperiment ")
        if file_type == 'html':
            fileHandle.write("</h2>")

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        for experiment in range(1, num_experiments + 1):
            fileHandle.write("%d\t\t" % (experiment))

        fileHandle.write("\n\n")

        # only agents alive at the end of the constitutional process and who were alive throughout can vote...
        for agent in dbs.constitutional_agents[num_experiments]:

            agent_in_all_exps = 1

            for exp in range(1, num_experiments):

                if agent not in dbs.constitutional_agents[exp]:
                    agent_in_all_exps = 0

            if agent_in_all_exps == 1:

                preferred_system = 0  # this is the system the agent votes for
                best_res_gain = -10000000.0  # make this an absurdly low number which cannot be reached in any experiment

                if print_fine_dets == 1:
                    print('\n\n agent =', agent, 'home', agent.home)

                fileHandle.write("\n%s\t\t" % (agent.home))

                const_record_res_accum[0].append(agent.home)

                for experiment in range(1, num_experiments + 1):

                    if print_fine_dets == 1:
                        print('\n experiment ', experiment, ':')

                    iter_counter = 0

                    for ag in dbs.constitutional_agents[experiment - 1]:

                        if agent is ag:

                            res_start = dbs.constitutional_min_ress[experiment - 1][iter_counter]

                            if print_fine_dets == 1:
                                print('res_start =', res_start)

                        else:

                            iter_counter += 1

                    iter_counter = 0

                    for ag in dbs.constitutional_agents[experiment]:

                        if agent is ag:

                            res_end = dbs.constitutional_min_ress[experiment][iter_counter]

                            if print_fine_dets == 1:
                                print('res_end =', res_end)

                        else:

                            iter_counter += 1

                    new_res_gain = res_end - res_start

                    const_record_res_accum[experiment].append(new_res_gain)

                    if new_res_gain > best_res_gain:
                        best_res_gain = new_res_gain
                        preferred_system = experiment

                    fileHandle.write("%3.2f\t\t" % (new_res_gain))

                    if print_fine_dets == 1:
                        print('new_res_gain =', new_res_gain)
                        print('best_res_gain =', best_res_gain)
                        print('preferred_system =', preferred_system)

                agents_aggr_votes[preferred_system] += 1

                if print_fine_dets == 1:
                    print('\n agents_aggr_votes so far =', agents_aggr_votes)

        if print_fine_dets == 1:
            print('\n\n agents_aggr_votes =', agents_aggr_votes)
            print('\n const_record_res_accum:\n\n', const_record_res_accum)

        fileHandle.write("\n\n\n\n")
        if file_type == 'html':
            fileHandle.write("</p>")

    # Now we move on to data corresponding to the agents respecting property rights or not

    # these databases get returned below
    prop_steal_data = []
    prop_fb_data = []
    num_trans_data = []
    num_fights_data = []
    num_scen_1_data = []
    num_scen_23_data = []
    num_scen_45_data = []

    black_shoop_array = []

    # Record game type data here
    game_type_dict = dict()
    game_type_dict_seen = dict()
    games_type_dict_2 = dict()
    games_type_dict_3 = dict()
    classic_games_considered_sums = dict()
    classic_games_seen_sums = dict()

    if respect_property_rights == 0:

        # We start by looking at Propensity to Steal and Fight Back
        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\n\nPropensity to Steal Data\n")
        if file_type == 'html':
            fileHandle.write("</h2>")

        #        print('\n dbs.prop_steal_std_db_sharks =\n', dbs.prop_steal_std_db_sharks)

        #        pause()

        for iter in range(num_iters):

            start_round = ten_pct_rounds_array[iter]
            end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

            prop_steal_mean_iter_data = [dbs.prop_steal_mean_db[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_mean_db[i] is not None]
            prop_steal_std_iter_data = [dbs.prop_steal_std_db[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_std_db[i] is not None]

            if len(prop_steal_mean_iter_data) > 0:

                mean_iter_steal = np.mean(prop_steal_mean_iter_data)
                std_iter_steal = np.mean(prop_steal_std_iter_data)

            else:

                mean_iter_steal = None
                std_iter_steal = None

            if two_tribes:

                prop_steal_mean_iter_data_sharks = [dbs.prop_steal_mean_db_sharks[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_mean_db_sharks[i] is not None]
                prop_steal_std_iter_data_sharks = [dbs.prop_steal_std_db_sharks[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_std_db_sharks[i] is not None]

                prop_steal_mean_iter_data_jets = [dbs.prop_steal_mean_db_jets[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_mean_db_jets[i] is not None]
                prop_steal_std_iter_data_jets = [dbs.prop_steal_std_db_jets[i] for i in np.arange(start_round, end_round) if dbs.prop_steal_std_db_jets[i] is not None]

                # sharks
                if len(prop_steal_mean_iter_data_sharks) > 0:

                    mean_iter_steal_sharks = np.mean(prop_steal_mean_iter_data_sharks)
                    std_iter_steal_sharks = np.mean(prop_steal_std_iter_data_sharks)

                else:

                    mean_iter_steal_sharks = None
                    std_iter_steal_sharks = None

                # jets
                if len(prop_steal_mean_iter_data_jets) > 0:

                    mean_iter_steal_jets = np.mean(prop_steal_mean_iter_data_jets)
                    std_iter_steal_jets = np.mean(prop_steal_std_iter_data_jets)

                else:

                    mean_iter_steal_jets = None
                    std_iter_steal_jets = None

            prop_fb_mean_iter_data = [dbs.prop_fb_mean_db[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_mean_db[i] is not None]
            prop_fb_std_iter_data = [dbs.prop_fb_std_db[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_std_db[i] is not None]

            if two_tribes:
                prop_fb_mean_iter_data_sharks = [dbs.prop_fb_mean_db_sharks[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_mean_db_sharks[i] is not None]
                prop_fb_std_iter_data_sharks = [dbs.prop_fb_std_db_sharks[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_std_db_sharks[i] is not None]

                prop_fb_mean_iter_data_jets = [dbs.prop_fb_mean_db_jets[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_mean_db_jets[i] is not None]
                prop_fb_std_iter_data_jets = [dbs.prop_fb_std_db_jets[i] for i in np.arange(start_round, end_round) if dbs.prop_fb_std_db_jets[i] is not None]

            if len(prop_fb_mean_iter_data) > 0:

                mean_iter_fb = np.mean(prop_fb_mean_iter_data)
                std_iter_fb = np.mean(prop_fb_std_iter_data)

            else:

                mean_iter_fb = None
                std_iter_fb = None

            if two_tribes:

                # sharks
                if len(prop_fb_mean_iter_data_sharks) > 0:

                    mean_iter_fb_sharks = np.mean(prop_fb_mean_iter_data_sharks)
                    std_iter_fb_sharks = np.mean(prop_fb_std_iter_data_sharks)

                else:

                    mean_iter_fb_sharks = None
                    std_iter_fb_sharks = None

                # jets
                if len(prop_fb_mean_iter_data_jets) > 0:

                    mean_iter_fb_jets = np.mean(prop_fb_mean_iter_data_jets)
                    std_iter_fb_jets = np.mean(prop_fb_std_iter_data_jets)

                else:

                    mean_iter_fb_jets = None
                    std_iter_fb_jets = None

                if file_type == 'html':
                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Sharks Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % (
                start_round, end_round - 1, mean_iter_steal_sharks, std_iter_steal_sharks, mean_iter_fb_sharks, std_iter_fb_sharks))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Jets Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % (
                start_round, end_round - 1, mean_iter_steal_jets, std_iter_steal_jets, mean_iter_fb_jets, std_iter_fb_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nRounds %4d to %4d - All Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % (start_round, end_round - 1, mean_iter_steal, std_iter_steal, mean_iter_fb, std_iter_fb))
            if file_type == 'html':
                fileHandle.write("</p>")

            if two_tribes == 0:

                prop_steal_data.append([mean_iter_steal, std_iter_steal])
                prop_fb_data.append([mean_iter_fb, std_iter_fb])

            elif two_tribes:

                prop_steal_data.append([mean_iter_steal, std_iter_steal, mean_iter_steal_sharks, std_iter_steal_sharks, mean_iter_steal_jets, std_iter_steal_jets])
                prop_fb_data.append([mean_iter_fb, std_iter_fb, mean_iter_fb_sharks, std_iter_fb_sharks, mean_iter_fb_jets, std_iter_fb_jets])

        # Now we look at the number of transactions and fights
        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\n\nNumber of Transactions and Fights In Each Round\n")
        if file_type == 'html':
            fileHandle.write("</h2>")

        for iter in range(num_iters):

            start_round = ten_pct_rounds_array[iter]
            end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

            num_trans_iter = [dbs.num_ints_each_round[6][i] for i in np.arange(start_round, end_round) if dbs.num_ints_each_round[6][i] is not None]
            num_fights_iter = [dbs.num_fight_each_round[i] for i in np.arange(start_round, end_round) if dbs.num_fight_each_round[i] is not None]

            if two_tribes:
                num_trans_iter_sharks = [dbs.num_ints_each_round_sharks[6][i] for i in np.arange(start_round, end_round) if dbs.num_ints_each_round_sharks[6][i] is not None]
                num_fights_iter_sharks = [dbs.num_fight_each_round_sharks[i] for i in np.arange(start_round, end_round) if dbs.num_fight_each_round_sharks[i] is not None]

                num_trans_iter_jets = [dbs.num_ints_each_round_jets[6][i] for i in np.arange(start_round, end_round) if dbs.num_ints_each_round_jets[6][i] is not None]
                num_fights_iter_jets = [dbs.num_fight_each_round_jets[i] for i in np.arange(start_round, end_round) if dbs.num_fight_each_round_jets[i] is not None]

                num_trans_iter_inter = [dbs.num_ints_each_round_inter[6][i] for i in np.arange(start_round, end_round) if dbs.num_ints_each_round_inter[6][i] is not None]
                num_fights_iter_inter = [dbs.num_fight_each_round_inter[i] for i in np.arange(start_round, end_round) if dbs.num_fight_each_round_inter[i] is not None]

            if len(num_trans_iter) > 0:
                mean_iter_trans = np.mean(num_trans_iter)
                std_iter_trans = np.std(num_trans_iter)

            else:
                mean_iter_trans = 0
                std_iter_trans = 0

            if len(num_fights_iter) > 0:
                mean_iter_fights = np.mean(num_fights_iter)
                std_iter_fights = np.std(num_fights_iter)

            else:
                mean_iter_fights = 0
                std_iter_fights = 0

            if two_tribes:

                # sharks
                if len(num_trans_iter_sharks) > 0:
                    mean_iter_trans_sharks = np.mean(num_trans_iter_sharks)
                    std_iter_trans_sharks = np.std(num_trans_iter_sharks)

                else:
                    mean_iter_trans_sharks = 0
                    std_iter_trans_sharks = 0

                if len(num_fights_iter_sharks) > 0:
                    mean_iter_fights_sharks = np.mean(num_fights_iter_sharks)
                    std_iter_fights_sharks = np.std(num_fights_iter_sharks)

                else:
                    mean_iter_fights_sharks = 0
                    std_iter_fights_sharks = 0

                # jets
                if len(num_trans_iter_jets) > 0:
                    mean_iter_trans_jets = np.mean(num_trans_iter_jets)
                    std_iter_trans_jets = np.std(num_trans_iter_jets)

                else:
                    mean_iter_trans_jets = 0
                    std_iter_trans_jets = 0

                if len(num_fights_iter_jets) > 0:
                    mean_iter_fights_jets = np.mean(num_fights_iter_jets)
                    std_iter_fights_jets = np.std(num_fights_iter_jets)

                else:
                    mean_iter_fights_jets = 0
                    std_iter_fights_jets = 0

                if len(num_trans_iter_inter) > 0:
                    mean_iter_trans_inter = np.mean(num_trans_iter_inter)
                    std_iter_trans_inter = np.std(num_trans_iter_inter)

                else:
                    mean_iter_trans_inter = 0
                    std_iter_trans_inter = 0

                if len(num_fights_iter_inter) > 0:
                    mean_iter_fights_inter = np.mean(num_fights_iter_inter)
                    std_iter_fights_inter = np.std(num_fights_iter_inter)

                else:
                    mean_iter_fights_inter = 0
                    std_iter_fights_inter = 0

            if two_tribes:

                if file_type == 'html':
                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Sharks Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % (
                start_round, end_round - 1, mean_iter_trans_sharks, std_iter_trans_sharks, mean_iter_fights_sharks, std_iter_fights_sharks))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Jets Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % (
                start_round, end_round - 1, mean_iter_trans_jets, std_iter_trans_jets, mean_iter_fights_jets, std_iter_fights_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Inter Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % (
                start_round, end_round - 1, mean_iter_trans_inter, std_iter_trans_inter, mean_iter_fights_inter, std_iter_fights_inter))
                if file_type == 'html':
                    fileHandle.write("</p>")

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nRounds %4d to %4d - All Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % (start_round, end_round - 1, mean_iter_trans, std_iter_trans, mean_iter_fights, std_iter_fights))
            if file_type == 'html':
                fileHandle.write("</p>")

            if two_tribes == 0:

                num_trans_data.append([mean_iter_trans, std_iter_trans])
                num_fights_data.append([mean_iter_fights, std_iter_fights])

            elif two_tribes:

                num_trans_data.append([mean_iter_trans, std_iter_trans, mean_iter_trans_sharks, std_iter_trans_sharks, mean_iter_trans_jets, std_iter_trans_jets, mean_iter_trans_inter, std_iter_trans_inter])
                num_fights_data.append([mean_iter_fights, std_iter_fights, mean_iter_fights_sharks, std_iter_fights_sharks, mean_iter_fights_jets, std_iter_fights_jets, mean_iter_fights_inter, std_iter_fights_inter])

        # Now we break down the 'fights' in to their 3 types
        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\n\nBreakdown of Fights by Type\n")
        if file_type == 'html':
            fileHandle.write("</h2>")

        if file_type == 'html':
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nScenario 1 is: both agents attempted to steal.")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nScenarios 2 & 3 is: one agent attempted to steal, the other wanted to trade but then fought back.")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nScenarios 4 & 5 is: one agent attempted to steal, the other wanted to trade but then acquiesced.")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p style='margin:0;'>")
        fileHandle.write("\nNote: pct data below gives scenario 1, 2 & 3, and 4 & 5 fights as proportion of the mean number of fights during the period.\n")
        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")

        for iter in range(num_iters):

            start_round = ten_pct_rounds_array[iter]
            end_round = int(ten_pct_rounds_array[iter] + ten_pct_gap)

            scen_1_iter = [dbs.num_ints_each_round[1][i] for i in np.arange(start_round, end_round)]

            no_nones = 1

            if len(scen_1_iter) > 0:
                mean_scen_1 = np.mean(scen_1_iter)
                std_scen_1 = np.std(scen_1_iter)
            else:
                mean_scen_1 = 0
                std_scen_1 = 0
                no_nones = 0

            scen_23_iter = [dbs.num_ints_each_round[2][i] for i in np.arange(start_round, end_round)]

            if len(scen_23_iter) > 0:
                mean_scen_23 = np.mean(scen_23_iter)
                std_scen_23 = np.std(scen_23_iter)
            else:
                mean_scen_23 = 0
                std_scen_23 = 0
                no_nones = 0

            scen_45_iter = [dbs.num_ints_each_round[4][i] for i in np.arange(start_round, end_round)]

            if len(scen_45_iter) > 0:
                mean_scen_45 = np.mean(scen_45_iter)
                std_scen_45 = np.std(scen_45_iter)
            else:
                mean_scen_45 = 0
                std_scen_45 = 0
                no_nones = 0

            if no_nones == 1:

                prop_1_fights = (100 * mean_scen_1) / float(mean_scen_1 + mean_scen_23 + mean_scen_45)
                prop_23_fights = (100 * mean_scen_23) / float(mean_scen_1 + mean_scen_23 + mean_scen_45)
                prop_45_fights = (100 * mean_scen_45) / float(mean_scen_1 + mean_scen_23 + mean_scen_45)

            else:

                prop_1_fights = 0
                prop_23_fights = 0
                prop_45_fights = 0

            if two_tribes:

                # sharks
                scen_1_iter_sharks = [dbs.num_ints_each_round_sharks[1][i] for i in np.arange(start_round, end_round)]

                no_nones_sharks = 1

                if len(scen_1_iter_sharks) > 0:
                    mean_scen_1_sharks = np.mean(scen_1_iter_sharks)
                    std_scen_1_sharks = np.std(scen_1_iter_sharks)
                else:
                    mean_scen_1_sharks = 0
                    std_scen_1_sharks = 0
                    no_nones_sharks = 0

                scen_23_iter_sharks = [dbs.num_ints_each_round_sharks[2][i] for i in np.arange(start_round, end_round)]

                if len(scen_23_iter_sharks) > 0:
                    mean_scen_23_sharks = np.mean(scen_23_iter_sharks)
                    std_scen_23_sharks = np.std(scen_23_iter_sharks)
                else:
                    mean_scen_23_sharks = 0
                    std_scen_23_sharks = 0
                    no_nones_sharks = 0

                scen_45_iter_sharks = [dbs.num_ints_each_round_sharks[4][i] for i in np.arange(start_round, end_round)]

                if len(scen_45_iter_sharks) > 0:
                    mean_scen_45_sharks = np.mean(scen_45_iter_sharks)
                    std_scen_45_sharks = np.std(scen_45_iter_sharks)
                else:
                    mean_scen_45_sharks = 0
                    std_scen_45_sharks = 0
                    no_nones_sharks = 0

                if no_nones_sharks == 1:

                    prop_1_fights_sharks = (100 * mean_scen_1_sharks) / float(mean_scen_1_sharks + mean_scen_23_sharks + mean_scen_45_sharks)
                    prop_23_fights_sharks = (100 * mean_scen_23_sharks) / float(mean_scen_1_sharks + mean_scen_23_sharks + mean_scen_45_sharks)
                    prop_45_fights_sharks = (100 * mean_scen_45_sharks) / float(mean_scen_1_sharks + mean_scen_23_sharks + mean_scen_45_sharks)

                else:

                    prop_1_fights_sharks = 0
                    prop_23_fights_sharks = 0
                    prop_45_fights_sharks = 0

                # jets
                scen_1_iter_jets = [dbs.num_ints_each_round_jets[1][i] for i in np.arange(start_round, end_round)]

                no_nones_jets = 1

                if len(scen_1_iter_jets) > 0:
                    mean_scen_1_jets = np.mean(scen_1_iter_jets)
                    std_scen_1_jets = np.std(scen_1_iter_jets)
                else:
                    mean_scen_1_jets = 0
                    std_scen_1_jets = 0
                    no_nones_jets = 0

                scen_23_iter_jets = [dbs.num_ints_each_round_jets[2][i] for i in np.arange(start_round, end_round)]

                if len(scen_23_iter_jets) > 0:
                    mean_scen_23_jets = np.mean(scen_23_iter_jets)
                    std_scen_23_jets = np.std(scen_23_iter_jets)
                else:
                    mean_scen_23_jets = 0
                    std_scen_23_jets = 0
                    no_nones_jets = 0

                scen_45_iter_jets = [dbs.num_ints_each_round_jets[4][i] for i in np.arange(start_round, end_round)]

                if len(scen_45_iter_jets) > 0:
                    mean_scen_45_jets = np.mean(scen_45_iter_jets)
                    std_scen_45_jets = np.std(scen_45_iter_jets)
                else:
                    mean_scen_45_jets = 0
                    std_scen_45_jets = 0
                    no_nones_jets = 0

                if no_nones_jets == 1:

                    prop_1_fights_jets = (100 * mean_scen_1_jets) / float(mean_scen_1_jets + mean_scen_23_jets + mean_scen_45_jets)
                    prop_23_fights_jets = (100 * mean_scen_23_jets) / float(mean_scen_1_jets + mean_scen_23_jets + mean_scen_45_jets)
                    prop_45_fights_jets = (100 * mean_scen_45_jets) / float(mean_scen_1_jets + mean_scen_23_jets + mean_scen_45_jets)

                else:

                    prop_1_fights_jets = 0
                    prop_23_fights_jets = 0
                    prop_45_fights_jets = 0

                # inter
                scen_1_iter_inter = [dbs.num_ints_each_round_inter[1][i] for i in np.arange(start_round, end_round)]

                no_nones_inter = 1

                if len(scen_1_iter_inter) > 0:
                    mean_scen_1_inter = np.mean(scen_1_iter_inter)
                    std_scen_1_inter = np.std(scen_1_iter_inter)
                else:
                    mean_scen_1_inter = 0
                    std_scen_1_inter = 0
                    no_nones_inter = 0

                scen_23_iter_inter = [dbs.num_ints_each_round_inter[2][i] for i in np.arange(start_round, end_round)]

                if len(scen_23_iter_inter) > 0:
                    mean_scen_23_inter = np.mean(scen_23_iter_inter)
                    std_scen_23_inter = np.std(scen_23_iter_inter)
                else:
                    mean_scen_23_inter = 0
                    std_scen_23_inter = 0
                    no_nones_inter = 0

                scen_45_iter_inter = [dbs.num_ints_each_round_inter[4][i] for i in np.arange(start_round, end_round)]

                if len(scen_45_iter_inter) > 0:
                    mean_scen_45_inter = np.mean(scen_45_iter_inter)
                    std_scen_45_inter = np.std(scen_45_iter_inter)
                else:
                    mean_scen_45_inter = 0
                    std_scen_45_inter = 0
                    no_nones_inter = 0

                if no_nones_inter == 1:

                    prop_1_fights_inter = (100 * mean_scen_1) / float(mean_scen_1_inter + mean_scen_23_inter + mean_scen_45_inter)
                    prop_23_fights_inter = (100 * mean_scen_23_inter) / float(mean_scen_1_inter + mean_scen_23_inter + mean_scen_45_inter)
                    prop_45_fights_inter = (100 * mean_scen_45_inter) / float(mean_scen_1_inter + mean_scen_23_inter + mean_scen_45_inter)

                else:

                    prop_1_fights_inter = 0
                    prop_23_fights_inter = 0
                    prop_45_fights_inter = 0

            if two_tribes:

                if file_type == 'html':
                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Sharks Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                                 (start_round, end_round - 1, mean_scen_1_sharks, prop_1_fights_sharks, std_scen_1_sharks, mean_scen_23_sharks, prop_23_fights_sharks, std_scen_23_sharks, mean_scen_45_sharks, prop_45_fights_sharks,
                                  std_scen_45_sharks))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Jets Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                                 (start_round, end_round - 1, mean_scen_1_jets, prop_1_fights_jets, std_scen_1_jets, mean_scen_23_jets, prop_23_fights_jets, std_scen_23_jets, mean_scen_45_jets, prop_45_fights_jets, std_scen_45_jets))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %4d to %4d - Inter Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                                 (start_round, end_round - 1, mean_scen_1_inter, prop_1_fights_inter, std_scen_1_inter, mean_scen_23_inter, prop_23_fights_inter, std_scen_23_inter, mean_scen_45_inter, prop_45_fights_inter,
                                  std_scen_45_inter))
                if file_type == 'html':
                    fileHandle.write("</p>")

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\nRounds %4d to %4d - All Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                             (start_round, end_round - 1, mean_scen_1, prop_1_fights, std_scen_1, mean_scen_23, prop_23_fights, std_scen_23, mean_scen_45, prop_45_fights, std_scen_45))
            if file_type == 'html':
                fileHandle.write("</p>")

            if two_tribes == 0:

                num_scen_1_data.append([mean_scen_1, std_scen_1])
                num_scen_23_data.append([mean_scen_23, std_scen_23])
                num_scen_45_data.append([mean_scen_45, std_scen_45])

            elif two_tribes:

                num_scen_1_data.append([mean_scen_1, std_scen_1, mean_scen_1_sharks, std_scen_1_sharks, mean_scen_1_jets, std_scen_1_jets, mean_scen_1_inter, std_scen_1_inter])
                num_scen_23_data.append([mean_scen_23, std_scen_23, mean_scen_23_sharks, std_scen_23_sharks, mean_scen_23_jets, std_scen_23_jets, mean_scen_23_inter, std_scen_23_inter])
                num_scen_45_data.append([mean_scen_45, std_scen_45, mean_scen_45_sharks, std_scen_45_sharks, mean_scen_45_jets, std_scen_45_jets, mean_scen_45_inter, std_scen_45_inter])

        if params.track_game_types and (len(dbs.games_type_considered_dict) > 0 or len(dbs.games_type_dict) > 0):

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nGame Type Data\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            total_sum_cons = 0
            total_sum_seen = 0
            total_sum_2 = 0
            total_sum_3 = 0
            total_classic_cons = 0
            total_classic_seen = 0

            print('\n game_type_dict considered:\n')

            for game_type in dbs.games_type_considered_dict:
                game_type_dict[game_type] = sum(dbs.games_type_considered_dict[game_type])

                total_sum_cons += sum(dbs.games_type_considered_dict[game_type])

                print(' game_type', game_type, 'sum', sum(dbs.games_type_considered_dict[game_type]))

            print('\n game_type_dict_seen:\n')

            for game_type in dbs.games_type_dict:
                game_type_dict_seen[game_type] = sum(dbs.games_type_dict[game_type])

                total_sum_seen += sum(dbs.games_type_dict[game_type])

                print(' game_type', game_type, 'sum', sum(dbs.games_type_dict[game_type]))

            print('\n dbs.games_type_dict_2:\n')

            for game_type in dbs.games_type_dict_2:
                games_type_dict_2[game_type] = sum(dbs.games_type_dict_2[game_type])

                total_sum_2 += sum(dbs.games_type_dict_2[game_type])

                print(' game_type', game_type, 'sum', sum(dbs.games_type_dict_2[game_type]))

            print('\n games_type_dict_3:\n')

            for game_type in dbs.games_type_dict_3:
                games_type_dict_3[game_type] = sum(dbs.games_type_dict_3[game_type])

                total_sum_3 += sum(dbs.games_type_dict_3[game_type])

                print(' game_type', game_type, 'sum', sum(dbs.games_type_dict_3[game_type]))

            for classic_game_type in dbs.classic_games_considered:
                classic_games_considered_sums[classic_game_type] = sum(dbs.classic_games_considered[classic_game_type])

                total_classic_cons += sum(dbs.classic_games_considered[classic_game_type])

            for classic_game_type in dbs.classic_games_seen:
                classic_games_seen_sums[classic_game_type] = sum(dbs.classic_games_seen[classic_game_type])

                total_classic_seen += sum(dbs.classic_games_seen[classic_game_type])

            print('\n classic_games_seen_sums =', classic_games_seen_sums)

            print(' game_type_dict', game_type_dict)

            game_type_array = sorted(game_type_dict.items(), key=lambda item: (item[1], item[0]), reverse=True)
            games_type_array_3 = sorted(games_type_dict_3.items(), key=lambda item: (item[1], item[0]), reverse=True)

            classic_games_considered_sums_array = sorted(classic_games_considered_sums.items(), key=lambda item: (item[1], item[0]), reverse=True)
            classic_games_seen_sums_array = sorted(classic_games_seen_sums.items(), key=lambda item: (item[1], item[0]), reverse=True)

            #            game_type_dict_seen = sorted(game_type_dict_seen.items(), key=lambda item: (item[1], item[0]), reverse=True)

            print('\n game_type_array ', game_type_array)
            print('\n games_type_array_3 ', games_type_array_3)
            print('\n classic_games_considered_sums_array ', classic_games_considered_sums_array)
            print('\n classic_games_seen_sums_array ', classic_games_seen_sums_array)
            print(' total_sum_cons', total_sum_cons)
            print('\n game_type_dict_seen ', game_type_dict_seen)
            print(' total_sum_seen ', total_sum_seen)
            print(' total_classic_cons =', total_classic_cons)
            print(' total_classic_seen =', total_classic_seen)

            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nRaw Considered Game Types (number of games in total)")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

                counter = 1

                for game_type in game_type_array:

                    #                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")

                    print('\n game_type =', game_type)

                    if game_type[0] in game_type_dict_seen:

                        seen_num = game_type_dict_seen[game_type[0]]

                    else:

                        seen_num = 0

                    print('\n seen_num =', seen_num)

                    #                    print("\n considered %s : %s (%s pct)  |  seen %s (%s pct)") % (game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen))

                    fileHandle.write("\n%2d considered %s : %d (%1.6f pct)  |  seen %d (%1.6f pct)" % (counter, game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen)))

                    counter += 1

                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nTotal considered = %d, total seen = %d" % (total_sum_cons, total_sum_seen))
                fileHandle.write("</p>")

            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nSeen Game Types (number of game types seen (unweighted) and volume (benefit to instigating agent))")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

                counter = 1

                for game_type in games_type_array_3:

                    #                    fileHandle.write("<p></p>")
                    fileHandle.write("<p style='margin:0;'>")

                    print('\n game_type =', game_type)

                    if game_type[0] in games_type_dict_2:

                        seen_num = games_type_dict_2[game_type[0]]

                    else:

                        seen_num = 0

                    print('\n seen_num =', seen_num)

                    #                    print("\n considered %s : %s (%s pct)  |  seen %s (%s pct)") % (game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen))

                    fileHandle.write("\n%2d %s : %d (%1.6f pct)  |  volume %1.6f (%1.6f pct)" % (counter, game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_3), seen_num, 100 * seen_num / float(total_sum_2)))

                    counter += 1

                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nAggregated number of games = %d, total volume = %s" % (total_sum_3, total_sum_2))
                fileHandle.write("</p>")

            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nClassic Games Considered")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

                for classic_game_type in classic_games_considered_sums_array:
                    fileHandle.write("<p style='margin:0;'>")

                    print('\n classic_game_type =', classic_game_type)

                    num = classic_game_type[1]

                    fileHandle.write("\n%s : total %d (%1.6f pct)" % (classic_game_type[0], num, 100 * num / float(total_classic_cons)))

                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nAggregated number of classic games considered = %d" % (total_classic_cons))
                fileHandle.write("</p>")

            print('\n classic_games_seen_sums_array =', classic_games_seen_sums_array)

            if file_type == 'html':
                fileHandle.write("<h3>")
            fileHandle.write("\n\nClassic Games Seen")
            if file_type == 'html':
                fileHandle.write("</h3>")

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")

                for classic_game_type in classic_games_seen_sums_array:
                    fileHandle.write("<p style='margin:0;'>")

                    print('\n seen classic_game_type =', classic_game_type)

                    fileHandle.write("\n%s : %d (%1.6f pct)" % (classic_game_type[0], classic_game_type[1], 100 * classic_game_type[1] / float(total_classic_seen)))

                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nAggregated number of classic games seen = %d" % (total_classic_seen))
                fileHandle.write("</p>")

        if file_type == 'html':
            fileHandle.write("<h2>")
        fileHandle.write("\n\n\n\nurls for plotly charts (if used):\n")
        if file_type == 'html':
            fileHandle.write("</h2>")

        if file_type == 'html':
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n individual agents' prop_steals: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.agents_prop_steal_url, dbs.agents_prop_steal_url))
        else:
            fileHandle.write("\n individual agents' prop_steals: \t\t\t\t%s" % dbs.agents_prop_steal_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n individual agents' prop_fight_back: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.agents_prop_fb_url, dbs.agents_prop_fb_url))
        else:
            fileHandle.write("\n individual agents' prop_fight_back: \t\t\t\t%s" % dbs.agents_prop_fb_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n individual agents' prop_steals >= and < 0.5: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.prop_steal_above_below_50_url, dbs.prop_steal_above_below_50_url))
        else:
            fileHandle.write("\n individual agents' prop_steals >= and < 0.5: \t\t%s" % dbs.prop_steal_above_below_50_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n individual agents' prop_fight_backs >= and < 0.5: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.prop_fb_above_below_50_url, dbs.prop_fb_above_below_50_url))
        else:
            fileHandle.write("\n individual agents' prop_fight_backs >= and < 0.5: \t\t%s" % dbs.prop_fb_above_below_50_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n prop_means (steal and fb): \t\t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.props_means_url, dbs.props_means_url))
        else:
            fileHandle.write("\n prop_means (steal and fb): \t\t\t\t\t%s" % dbs.props_means_url)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n number of transactions and fights per round - all: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.trans_and_fights_url, dbs.trans_and_fights_url))
        else:
            fileHandle.write("\n number of transactions and fights per round - all: \t\t%s" % dbs.trans_and_fights_url)

        if two_tribes:

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of transactions and fights per round - sharks: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.trans_and_fights_url_sharks, dbs.trans_and_fights_url_sharks))
            else:
                fileHandle.write("\n number of transactions and fights per round - sharks: \t\t%s" % dbs.trans_and_fights_url_sharks)

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of transactions and fights per round - jets: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.trans_and_fights_url_jets, dbs.trans_and_fights_url_jets))
            else:
                fileHandle.write("\n number of transactions and fights per round - jets: \t\t%s" % dbs.trans_and_fights_url_jets)

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of transactions and fights per round - inter: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.trans_and_fights_url_inter, dbs.trans_and_fights_url_inter))
            else:
                fileHandle.write("\n number of transactions and fights per round - inter: \t\t%s" % dbs.trans_and_fights_url_inter)

        if file_type == 'html':
            fileHandle.write("</p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n number of fight types per round - all: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.fight_types_url, dbs.fight_types_url))
        else:
            fileHandle.write("\n number of fight types per round: \t\t\t\t%s" % dbs.fight_types_url)

        if two_tribes:

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of fight types per round - sharks: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.fight_types_url_sharks, dbs.fight_types_url_sharks))
            else:
                fileHandle.write("\n number of fight types per round - sharks: \t\t\t\t%s" % dbs.fight_types_url_sharks)

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of fight types per round - jets: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.fight_types_url_jets, dbs.fight_types_url_jets))
            else:
                fileHandle.write("\n number of fight types per round - jets: \t\t\t\t%s" % dbs.fight_types_url_jets)

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n number of fight types per round - inter: \t\t\t\t<a href='%s' target='_blank'>%s</a>" % (dbs.fight_types_url_inter, dbs.fight_types_url_inter))
            else:
                fileHandle.write("\n number of fight types per round - inter: \t\t\t\t%s" % dbs.fight_types_url_inter)

        # if the agent's fight_skill was allowed to vary:
        if fight_skill is not None:

            if file_type == 'html':
                fileHandle.write("</p>")
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n evolution of fight skills: \t\t<a href='%s' target='_blank'>%s</a>" % (dbs.fight_skill_url, dbs.fight_skill_url))
            else:
                fileHandle.write("\n evolution of fight skills: \t\t%s" % dbs.fight_skill_url)

        if file_type == 'html':
            fileHandle.write("</p>")

        # here we generate the results of the black_shoop_exp if there was one run
        if black_shoop_exp:

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nBlack Shoop Experiment Results\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            black_shoop_num = 0
            num_dead_black_shoops = 0
            black_shoop_aggr_birth_date = 0
            black_shoop_aggr_death_date = 0

            for black_shoop in agent_population.black_shoop_list:

                black_shoop_num += 1

                if black_shoop.death_date < rounds:

                    black_shoop_aggr_birth_date += black_shoop.birth_date
                    black_shoop_aggr_death_date += black_shoop.death_date

                    num_dead_black_shoops += 1

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\nBlack Shoop %d was born on day %d and died on day %d (life = %d days)\n" % (black_shoop_num, black_shoop.birth_date, black_shoop.death_date, black_shoop.death_date - black_shoop.birth_date))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                else:

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\nBlack Shoop %d was born on day %d and was alive at the end of the sim\n" % (black_shoop_num, black_shoop.birth_date))
                    if file_type == 'html':
                        fileHandle.write("</p>")

            mean_black_shoop_birth_date = 0
            mean_black_shoop_death_date = 0
            mean_age = 0

            if num_dead_black_shoops > 0:
                mean_black_shoop_birth_date = black_shoop_aggr_birth_date / float(num_dead_black_shoops)
                mean_black_shoop_death_date = black_shoop_aggr_death_date / float(num_dead_black_shoops)
                mean_age = mean_black_shoop_death_date - mean_black_shoop_birth_date

            if file_type == 'html':
                fileHandle.write("<p>")
                fileHandle.write("</p>")
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n\nShoops who lived and died: mean birth = %4.3f, mean death = %4.3f (mean life = %3.3f days)\n" % (mean_black_shoop_birth_date, mean_black_shoop_death_date, mean_age))
            if file_type == 'html':
                fileHandle.write("</p>")

            black_shoop_array.append(mean_black_shoop_birth_date)
            black_shoop_array.append(mean_black_shoop_death_date)

        fileHandle.write("\n\n\n\n\n\n")

        if file_type == 'html':
            fileHandle.write("<p></p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p></p>")
            fileHandle.write("<p></p>")
            fileHandle.write("</body>\n\n</html>")

        fileHandle.close()

    return population_data, births_data, deaths_data, end_foraging_data, spec_degr_data, mean_spec_array, num_spec_agents_array, max_probs_data, res_array_data, actual_turnover_array, optimal_turnover_array, ratio_turnover_array, \
           all_age_arry, num_sq_array, trading_prop_array, trading_gini_array, act_prices_data, act_std_prices_data, opt_prices_data, whole_sim_opt_prices_array, diff_prices_data, serviced_locs_data, dbs.mkt_emerged_round, \
           KI_data, agents_aggr_votes, const_record_res_accum, slope_data, prop_steal_data, prop_fb_data, num_trans_data, num_fights_data, num_scen_1_data, num_scen_23_data, num_scen_45_data, \
           dbs.agents_prop_steal_url, dbs.agents_prop_fb_url, dbs.prop_steal_above_below_50_url, dbs.prop_fb_above_below_50_url, dbs.props_means_url, dbs.trans_and_fights_url, dbs.trans_and_fights_url_sharks, dbs.trans_and_fights_url_jets, \
           dbs.trans_and_fights_url_inter, dbs.fight_types_url, dbs.fight_types_url_sharks, dbs.fight_types_url_jets, dbs.fight_types_url_inter, black_shoop_array, dbs.prop_steal_mean_db, dbs.prop_fb_mean_db, dbs.num_ints_each_round, \
           dbs.num_fight_each_round, dbs.fight_skill_url, game_type_dict, game_type_dict_seen, games_type_dict_2, games_type_dict_3, classic_games_considered_sums, classic_games_seen_sums, dbs.round_all_ags_one_trgt


def write_turnover_acc_report(data_folder, rounds, dbs, gen_equ_thresh):
    """This function write a report to show the accuracy of the turnover data."""

    filepath = data_folder
    filename = "text_turnover_acc_report"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
    fileHandle.write("Turnover Accuracy Report\n\n")

    fileHandle.write("Day\tIterations\tErrors\n\n")

    for i in np.arange(rounds):

        if np.any(np.abs(dbs.optimal_bskt_errors[i]) > gen_equ_thresh):

            fileHandle.write('\n%3.0f\t%2.0d\t\t%s \t\t********' % (i, dbs.optimal_bskt_iters[i], dbs.optimal_bskt_errors[i]))

        else:

            fileHandle.write('\n%3.0f\t%2.0d\t\t%s' % (i, dbs.optimal_bskt_iters[i], dbs.optimal_bskt_errors[i]))


def write_succ_trans_data(dbs, day, town_grid, print_dets, data_folder, daily, daily_db):
    print('\n---> writing successful transaction data')

    if daily == 0:

        filepath = data_folder
        filename = "text_succ_trans"

        fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
        fileHandle.write("Agent Successful Transactions Data\n\n\n")

        #        print '\ndbs.trans_db =\n'
        #        for n in np.arange(len(dbs.trans_db)):
        #            print dbs.trans_db[n]

        outString = "  num\t  day\tmove\tlocation\tcp_sell\tcp_buy\ttrans\tagent_home\tcp agent home\n\n"
        fileHandle.write(outString)

        # create 2d array to record number of transactions
        grid = []
        row = []
        for k in np.arange(town_grid.dimen):
            row.append([])
        for l in np.arange(town_grid.dimen):
            grid.append(copy.deepcopy(row))

        for num in np.arange(len(dbs.trans_db)):

            inst = dbs.trans_db[num]

            #            if print_dets == 1:
            #            print '\ninst =', inst
            #            print 'inst.location =', inst.location

            if inst.good_a is not None:
                loc_x = inst.location[0]
                loc_y = inst.location[1]
                day = inst.day
                cp_ag = inst.agent_b
                subj_agent = inst.agent_a
                cp_sell_good = inst.good_b
                cp_buy_good = inst.good_a
                move_num = inst.move_num

                num_trans = inst.tot_trans_ag_sell

                grid[loc_x][loc_y].append(num)

                outString = "%5.0f" % (num) + "\t%5.0f\t" % (day) + str(move_num) + "\t[%2.0f" % (loc_x) + ", %2.0f" % (loc_y) + "]\t" + str(cp_sell_good) + "\t" + str(cp_buy_good) + "\t" + str(num_trans) + "\t[%2.0f" % (
                subj_agent.home[0]) + ", %2.0f" % (subj_agent.home[1]) + "]\t[%2.0f" % (cp_ag.home[0]) + ", %2.0f" % (cp_ag.home[1]) + "]\n"
                fileHandle.write(outString)

        # create an array to show transaction pairings:
        trans_pairs = []
        for fount in np.arange(num_res_founts - 1):
            remain_array = np.arange(fount + 1, num_res_founts)
            for el in remain_array:
                pair = np.array([fount, el])
                trans_pairs.append(pair)

        num_res_pairs = len(trans_pairs)

        if print_dets == 1:
            print('\ntrans_pairs =\n', trans_pairs)
            print('\nnum_res_pairs =', num_res_pairs)
            print('\n\n\nday =', day)

        grid_decomp = np.zeros(shape=(num_res_pairs, town_grid.dimen, town_grid.dimen))

        if print_dets == 1:
            print('\ngrid =\n\n')
            for p in np.arange(len(grid)):
                print(grid[p])

        for row in np.arange(len(grid)):
            for col in np.arange(len(grid[row])):
                if len(grid[row][col]) > 0:

                    outString = "\nLocation [" + str(row) + ", " + str(col) + "]\n\n"
                    fileHandle.write(outString)

                    data = grid[row][col]

                    if print_dets == 1:
                        print('\n\nrow =', row, 'col =', col, ' | data_array =', data)

                    tally_matrix = np.zeros(shape=(num_res_founts, num_res_founts), dtype=float)

                    for numb in data:

                        trans = dbs.trans_db[numb]

                        if print_dets == 1:
                            print('\ntrans =', trans, ' | numb =', numb)

                        for i in np.arange(num_res_founts):
                            for j in np.arange(num_res_founts):

                                if (trans.good_a == i and trans.good_b == j) or (trans.good_b == i and trans.good_a == j):

                                    if print_dets == 1:
                                        print('\ni =', i, 'j = ', j, 'tot_trans =', trans.tot_trans_ag_sell)

                                    tally_matrix[i][j] = tally_matrix[i][j] + trans.tot_trans_ag_sell

                                    if print_dets == 1:
                                        print('tally_matrix[i][j] =', tally_matrix[i][j])

                            if print_dets == 1:
                                print('\ntally_matrix =\n\n', tally_matrix)

                    for i in np.arange(num_res_founts - 1):
                        for j in np.arange(i + 1, num_res_founts):

                            if tally_matrix[i][j] > 0:
                                outString = "Pair: " + str(i) + " & " + str(j) + " (buy or sell) = " + str(tally_matrix[i][j]) + "\n"
                                fileHandle.write(outString)

        for row in np.arange(len(grid)):
            for col in np.arange(len(grid[row])):
                if len(grid[row][col]) > 0:

                    for p in np.arange(num_res_pairs):

                        pair = trans_pairs[p]
                        i = pair[0]
                        j = pair[1]

                        data = grid[row][col]

                        if print_dets == 1:
                            print('\n\nrow =', row, 'col =', col, ' | data_array =', data)

                        for numb in data:

                            trans = dbs.trans_db[numb]

                            if print_dets == 1:
                                print('\ntrans =', trans, ' | numb =', numb)

                            if (trans.good_a == i and trans.good_b == j) or (trans.good_b == i and trans.good_a == j):

                                if print_dets == 1:
                                    print('\ni =', i, 'j = ', j, 'tot_trans =', trans.tot_trans_ag_sell)

                                grid_decomp[p][row][col] += trans.tot_trans_ag_sell

        # create a colors array
        heatmap_cols = ['Reds', 'Purples', 'Greens', 'BuGn', 'BuPu', 'GnBu', 'Greys', 'OrRd', 'PuBu', 'PuBuGn', 'PuRd',
                        'Oranges', 'RdPu', 'YlGn', 'YlGnBu', 'YlOrBr', 'YlOrRd']

        for ar in np.arange(num_res_pairs):

            if print_dets == 1:
                print('\ngrid_decomp[ar] =', grid_decomp[ar])

            col = heatmap_cols[ar]
            title = 'Transaction Pair : %s - %s' % (trans_pairs[ar][0], trans_pairs[ar][1])
            create_heat_map(town_grid.dimen, grid_decomp[ar], data_folder, col, title, 'transs_pairs', dpi='low')

    elif daily == 1:

        filepath = data_folder
        filename = "text_succ_trans_daily_%s" % (day)

        fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
        fileHandle.write("Agent Successful Transactions Daily Data\n\n\n")

        #        print '\ndbs.trans_db =\n'
        #        for n in np.arange(len(dbs.trans_db)):
        #            print dbs.trans_db[n]

        outString = "  num\t  day\tmove\tlocation\tcp_sell\tcp_buy\ttrans\tagent_home\tcp agent home\n\n"
        fileHandle.write(outString)

        # create 2d array to record number of transactions
        grid = []
        row = []
        for k in np.arange(town_grid.dimen):
            row.append([])
        for l in np.arange(town_grid.dimen):
            grid.append(copy.deepcopy(row))

        for num in daily_db:

            inst = dbs.trans_db[num]

            if inst.good_a is not None:
                loc_x = inst.location[0]
                loc_y = inst.location[1]
                day = inst.day
                cp_ag = inst.agent_b
                subj_agent = inst.agent_a
                cp_sell_good = inst.good_b
                cp_buy_good = inst.good_a
                move_num = inst.move_num
                num_trans = inst.tot_trans_ag_sell

                grid[loc_x][loc_y].append(num)

                outString = "%5.0f" % (num) + "\t%5.0f\t" % (day) + str(move_num) + "\t[%2.0f" % (loc_x) + ", %2.0f" % (loc_y) + "]\t" + str(cp_sell_good) + "\t" + str(cp_buy_good) + "\t" + str(num_trans) + "\t[%2.0f" % (
                subj_agent.home[0]) + ", %2.0f" % (subj_agent.home[1]) + "]\t[%2.0f" % (cp_ag.home[0]) + ", %2.0f" % (cp_ag.home[1]) + "]\n"
                fileHandle.write(outString)

        outString = "\n\n\nData by Grid Location\n"
        fileHandle.write(outString)

        if print_dets == 1:
            print('\n\n\nday =', day)
            print('\ngrid =\n\n')
            for p in np.arange(len(grid)):
                print(grid[p])

        for row in np.arange(len(grid)):
            for col in np.arange(len(grid[row])):
                if len(grid[row][col]) > 0:

                    outString = "\nLocation [" + str(row) + ", " + str(col) + "]\n\n"
                    fileHandle.write(outString)

                    data = grid[row][col]

                    if print_dets == 1:
                        print('\n\nrow =', row, 'col =', col, ' | data_array =', data)

                    tally_matrix = np.zeros(shape=(num_res_founts, num_res_founts), dtype=int)

                    for numb in data:

                        trans = dbs.trans_db[numb]

                        if print_dets == 1:
                            print('\ntrans =', trans, ' | numb =', numb)

                        for i in np.arange(num_res_founts):
                            for j in np.arange(num_res_founts):

                                if (trans.good_a == i and trans.good_b == j) or (trans.good_b == i and trans.good_a == j):

                                    if print_dets == 1:
                                        print('\ni =', i, 'j = ', j, 'tot_trans =', trans.tot_trans_ag_sell)

                                    tally_matrix[i][j] = tally_matrix[i][j] + trans.tot_trans_ag_sell

                                    if print_dets == 1:
                                        print('tally_matrix[i][j] =', tally_matrix[i][j])

                    if print_dets == 1:
                        print('\ntally_matrix =\n\n', tally_matrix)

                    for i in np.arange(num_res_founts - 1):
                        for j in np.arange(i + 1, num_res_founts):

                            if tally_matrix[i][j] > 0:
                                outString = "Pair: " + str(i) + " & " + str(j) + " (buy or sell) = " + str(tally_matrix[i][j]) + "\n"
                                fileHandle.write(outString)


def write_for_strat_data(print_dets, print_fine_dets, dbs, fountain_population, agent_population, data_folder, rounds, two_tribes):
    """This function processes foraging strategy data and prints the data to a file, which is saved."""

    print('---> writing data to file: Foraging Strategy Data')

    filepath = data_folder
    filename = "text_foraging_strat"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
    fileHandle.write("Foraging Strategy Data\n\n")

    fileHandle.write("Total Number of foraging slots by resource:\n\n")

    if two_tribes == 0:

        outString = "round\t\t"

        total_forag_slots_array = np.zeros(shape=(rounds, num_res_founts))

        for day in np.arange(rounds):
            for for_strat_array in dbs.for_strat_db[day]:
                for strat in for_strat_array:
                    total_forag_slots_array[day][strat] += 1

        for res in np.arange(num_res_founts):
            outString = outString + 'res ' + str(res) + '\t\t'

        outString = outString + '\n\n'

        fileHandle.write(outString)

        for day in np.arange(rounds):

            fileHandle.write('%5.0f' % (day) + '\t\t')

            for res in np.arange(num_res_founts):
                fileHandle.write('%4.0f' % (total_forag_slots_array[day][res]) + '\t\t')

            fileHandle.write('\n')

    elif two_tribes:

        total_forag_slots_array_sharks = np.zeros(shape=(rounds, 2))
        total_forag_slots_array_jets = np.zeros(shape=(rounds, 2))

        for day in np.arange(rounds):
            for for_strat_array in dbs.for_strat_db_sharks[day]:
                for strat in for_strat_array:
                    total_forag_slots_array_sharks[day][strat] += 1

            for for_strat_array in dbs.for_strat_db_jets[day]:
                for strat in for_strat_array:
                    total_forag_slots_array_jets[day][strat] += 1

        outString = "round\t\tsharks\t\tjets\n\n"
        fileHandle.write(outString)

        outString = "\t\tres 0\tres 1\tres 0\tres 1\n\n"
        fileHandle.write(outString)

        for day in np.arange(rounds):
            fileHandle.write('%5.0f' % (day) + '\t\t')

            fileHandle.write('%4.0f\t%4.0f\t%4.0f\t%4.0f\n' % (total_forag_slots_array_sharks[day][0], total_forag_slots_array_sharks[day][1], total_forag_slots_array_jets[day][0], total_forag_slots_array_jets[day][1]))

    # Now write agent-by-agent data

    fileHandle.write('\n\nAgent-by-Agent Foraging Strategy Data:\n\nStart with agents alive at the end of the simulation\n')

    for agent in agent_population.pop:

        fileHandle.write('\nAgent: ' + str(agent) + ' tribe' + agent.tribe + '\n\n')

        for day in np.arange(rounds):

            if agent.birth_date <= day <= agent.death_date:
                fileHandle.write('Day %5.0f' % (day) + ':\t' + str(agent.for_strat_hist[day]) + '\n')

    fileHandle.write('\n\nAgents who sadly died during the simulation ****************************************************\n\n')

    for agent in agent_population.dead_agent_array:

        fileHandle.write('\nAgent: ' + str(agent) + ' tribe' + agent.tribe + '\n\n')

        for day in np.arange(rounds):

            if agent.birth_date <= day <= agent.death_date:
                fileHandle.write('Day %5.0f' % (day) + ':\t' + str(agent.for_strat_hist[day]) + '\n')


def write_agreed_locs(dbs, data_folder, rounds):
    """This function writes the agreed location information when agree_loction is 'strong' or 'super_strong'"""

    print('---> writing data to file: agreed locations')

    filepath = data_folder
    filename = "text_agreed_locations"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
    fileHandle.write("Locations Where Agents Organised to Meet\n\n")

    for day in range(rounds):

        fileHandle.write("\n%5d \t" % day)

        if len(dbs.agreed_locs[day]) == 0:

            fileHandle.write("None")

        else:

            tot_agents = 0

            for loc in dbs.agreed_locs[day]:
                tot_agents += loc[2]

            fileHandle.write("tot locs %2d  tot org'd ags %2d  mean  %2.3f\t\t" % (len(dbs.agreed_locs[day]), tot_agents, float(tot_agents) / float(len(dbs.agreed_locs[day]))))

            for loc in dbs.agreed_locs[day]:
                fileHandle.write("loc [%2d, %2d] num %2d \t" % (loc[0], loc[1], loc[2]))

    fileHandle.close()


def write_key_agent_data(dbs, agent_population, fountain_population, data_folder, vision_len, town_grid, rounds):
    print('---> writing data to file: Important Agent Data')

    filepath = data_folder
    filename = "text_agent_raw_data"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
    fileHandle.write("Important Agent Data\n\n")
    fileHandle.write("Ag Num\tBirth\tForaging Strat\tAgent Res Arr\tLoc\t\t\t\tHome\t\tDist\t\tMoves to loc\tDet Skills\n\n")

    #    for i in np.arange(len(agent_population.pop)):
    #
    #        agent = agent_population.pop[i]
    #
    #        x_dist = agent.location[0] - agent.home[0]
    #
    #        if x_dist > 32:
    #            x_dist = 64 - x_dist
    #        elif 0 > x_dist > -32:
    #            x_dist = x_dist * -1
    #        elif -63 <= x_dist <= -32:
    #            x_dist = 64 + x_dist
    #
    #        y_dist = agent.location[1] - agent.home[1]
    #
    #        if y_dist > 32:
    #            y_dist = 64 - y_dist
    #        elif 0 > y_dist > -32:
    #            y_dist = y_dist * -1
    #        elif -63 <= y_dist <= -32:
    #            y_dist = 64 + y_dist
    #
    #        dist = np.array([[x_dist, y_dist]])
    #
    #        moves_to_loc = math.ceil(np.max(dist[0]) / vision_len)
    #
    #        outString = str(i) + "\t" + str(agent.birth_date) + '\t' + str(agent.for_strat_array) + '\t' + str(agent.agent_res_array) + '\t' + str(agent.location) + '\t' + str(agent.home) + '\t' + str(dist) + '\t' + str(moves_to_loc) + '\t\t' + str(agent.detect_skills_array) + '\t' + '\n'
    #        fileHandle.write(outString)
    #
    #    outString = "\n\n\nTransactions Data per Agent (surviving after the final round)\n"
    #    fileHandle.write(outString)
    #
    #    for j in np.arange(len(agent_population.pop)):
    #
    #        agent = agent_population.pop[j]
    #
    #        outString = "\n\nAgent " + str(j) + " | name :" + str(agent) + "  |  birth date: " + str(agent.birth_date)
    #        fileHandle.write(outString)
    #        outString = "\n\n day\tmove\thome\t\ttarget\t\ttrans loc\ttravel\tsale\tbuy\ttype\tcp home\t\tno trs\t\tfor_strat_array\t\tloc rec\n"
    #        fileHandle.write(outString)
    #
    #        agent_trans_array = []
    #
    #        for day in np.arange(rounds):
    #            for res_1 in np.arange(num_res_founts):
    #                for res_2 in np.arange(num_res_founts):
    #                    for trans_num in agent.loc_mems_array[day][res_1][res_2]:
    #                        agent_trans_array.append(trans_num)
    #
    #        for trans_num in agent_trans_array:
    #
    #            trans = dbs.trans_db[trans_num]
    #
    #            if trans.agent_a == agent:
    #                ag_type = 'inst'
    #                sell_good = trans.good_a
    #                buy_good = trans.good_b
    #                trgt = trans.agent_a_trgt
    #                loc_rec = trans.a_loc_rec
    #                cp = trans.agent_b
    #                for_strat_array = trans.ag_for_strat_array
    #
    #            else:
    #                ag_type = 'c/p'
    #                sell_good = trans.good_b
    #                buy_good = trans.good_a
    #                trgt = trans.agent_b_trgt
    #                loc_rec = trans.b_loc_rec
    #                cp = trans.agent_a
    #                for_strat_array = trans.cp_for_strat_array
    #
    #            # work out distance to trading point
    #            x_dist = trans.location[0] - agent.home[0]
    #
    #            if x_dist > 32:
    #                x_dist = 64 - x_dist
    #            elif 0 > x_dist > -32:
    #                x_dist = x_dist * -1
    #            elif -63 <= x_dist <= -32:
    #                x_dist = 64 + x_dist
    #
    #            y_dist = trans.location[1] - agent.home[1]
    #
    #            if y_dist > 32:
    #                y_dist = 64 - y_dist
    #            elif 0 > y_dist > -32:
    #                y_dist = y_dist * -1
    #            elif -63 <= y_dist <= -32:
    #                y_dist = 64 + y_dist
    #
    #            travel_time = np.max([x_dist, y_dist]) / float(vision_len)
    #            travel_time = int(math.ceil(travel_time))
    #
    #            loc_rec_flat = []
    #            for i in np.arange(len(loc_rec)):
    #                loc_rec_flat.append(list(loc_rec[i]))
    #
    #            outString = "\n" + "%4.0f" % (trans.day) + "\t" + str(trans.move_num) + "\t" + "[%3.0f," % (agent.home[0]) + " %3.0f]" % (agent.home[1]) + "\t" + "[%3.0f," % (trgt[0]) + " %3.0f]" % (trgt[1]) + "\t" + "[%3.0f," % (trans.location[0]) + " %3.0f]" % (trans.location[1]) + "\t" + str(travel_time) + "\t" + str(sell_good) + "\t" + str(buy_good)  + "\t" + str(ag_type) + "\t" + "[%3.0f," % (cp.home[0]) + " %3.0f]" % (cp.home[1]) + "\t" + str(trans.tot_trans_ag_sell) + "\t" + str(for_strat_array) + "\t" + "\t" + str(loc_rec_flat)
    #            fileHandle.write(outString)

    # overview of foraging and transacting

    if num_res_founts == 2:

        outString = "\n\n\nForaging, Trading & Specialisation - Some Key Data\n\n"
        fileHandle.write(outString)

        for agent in agent_population.pop:

            outString = "\n\n\nAgent " + str(agent) + "\tHome:" + str(agent.home) + "\t tribe: " + str(agent.tribe) + "\t birth " + str(agent.birth_date) + "\t death date " + str(agent.death_date) + "\n\n"
            fileHandle.write(outString)

            outString = "\nday\tfor_str_st\tstart_ress\tbskt_st\ttrans\tactual\tratio\toptimal\t\tend bskt\tdet_skills\tpr_stl\tpr_f_b\tslot\tr_min\tf_0\tf_1\tprice\tEy_0\tEy_1\tLast Loc\n"
            fileHandle.write(outString)

            start_date = np.min([agent.birth_date, rounds - 2])

            for day in range(start_date, rounds):

                #                print('agent.hist_trade_loc_rec =', agent.hist_trade_loc_rec)

                if len(agent.hist_trade_loc_rec[day]) > 0:

                    outString = "\n" + str(day) + "\t[%d %d %d %d]" % (agent.for_strat_hist[day][0], agent.for_strat_hist[day][1], agent.for_strat_hist[day][2], agent.for_strat_hist[day][3]) + "\t[%3.2f %3.2f]" % (
                    agent.agent_res_array_hist[day - 1][0], agent.agent_res_array_hist[day - 1][1]) + "\t[%d %d]" % (agent.basket_array_start_hist[day][0], agent.basket_array_start_hist[day][1]) + "\t%d" % (
                                agent.num_act_transs[day]) + "\t%1.2f" % (agent.total_actual_agent_sales[day]) + "\t%1.2f" % (agent.personal_turnover_ratio[day]) + "\t[%1.2f %1.2f]" % (
                                agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1]) + "\t[%1.2f %1.2f]" % (agent.basket_array_hist[day][0], agent.basket_array_hist[day][1]) + "\t[%1.3f %1.3f]" % (
                                agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1]) + "\t%1.4f" % (agent.prop_steal_history[day]) + "\t%1.4f" % (agent.prop_fight_back_history[day]) + "\t%d" % (
                                agent.foraging_strat_data[day][0]) + "\t%d" % (agent.foraging_strat_data[day][1]) + "\t%2.2f" % (agent.foraging_strat_data[day][2]) + "\t%2.2f" % (agent.foraging_strat_data[day][3]) + "\t%2.4f" % (
                                agent.foraging_strat_data[day][4]) + "\t%2.4f" % (agent.foraging_strat_data[day][5]) + "\t%2.4f" % (agent.foraging_strat_data[day][6]) + "\t%s" % (agent.hist_trade_loc_rec[day][-1])

                else:

                    outString = "\n" + str(day) + "\t[%d %d %d %d]" % (agent.for_strat_hist[day][0], agent.for_strat_hist[day][1], agent.for_strat_hist[day][2], agent.for_strat_hist[day][3]) + "\t[%3.2f %3.2f]" % (
                    agent.agent_res_array_hist[day - 1][0], agent.agent_res_array_hist[day - 1][1]) + "\t[%d %d]" % (agent.basket_array_start_hist[day][0], agent.basket_array_start_hist[day][1]) + "\t%d" % (
                                agent.num_act_transs[day]) + "\t%1.2f" % (agent.total_actual_agent_sales[day]) + "\t%1.2f" % (agent.personal_turnover_ratio[day]) + "\t[%1.2f %1.2f]" % (
                                agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1]) + "\t[%1.2f %1.2f]" % (agent.basket_array_hist[day][0], agent.basket_array_hist[day][1]) + "\t[%1.3f %1.3f]" % (
                                agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1]) + "\t%1.4f" % (agent.prop_steal_history[day]) + "\t%1.4f" % (agent.prop_fight_back_history[day]) + "\t%d" % (
                                agent.foraging_strat_data[day][0]) + "\t%d" % (agent.foraging_strat_data[day][1]) + "\t%2.2f" % (agent.foraging_strat_data[day][2]) + "\t%2.2f" % (agent.foraging_strat_data[day][3]) + "\t%2.4f" % (
                                agent.foraging_strat_data[day][4]) + "\t%2.4f" % (agent.foraging_strat_data[day][5]) + "\t%2.4f" % (agent.foraging_strat_data[day][6]) + "\tNone"

                fileHandle.write(outString)


#    here = 0

#    # focus on transactions & turnover
#    if num_res_founts == 2:
#
#        outString = "\n\n\nPersonal Turnover Ratio Data (Actual / Optimal Transactions)\n\n"
#        fileHandle.write(outString)
#
#        outString = "Notes: 'trans' is the number of transactions the agent was involved in, whether they traded or not.\n\n"
#        fileHandle.write(outString)
#
#        outString = "\n\nday\t"
#        fileHandle.write(outString)
#
#        for agent in agent_population.pop:
#
#            outString = str(agent.home) + "\t\t\t\t\t"
#            fileHandle.write(outString)
#
#        outString = "\n"
#        fileHandle.write(outString)
#
#        for agent in agent_population.pop:
#
#            outString = "\ttrans\tactual\tratio\toptimal\t"
#            fileHandle.write(outString)
#
#        outString = "\n"
#        fileHandle.write(outString)
#
#        for day in range(rounds):
#
#            outString = "\n" + str(day) + "\t"
#            fileHandle.write(outString)
#
#            for agent in agent_population.pop:
#
#    #            print('agent.num_act_transs[day] =', agent.num_act_transs[day], 'agent.optimal_transs_systemic[day] =', agent.optimal_transs_systemic[day], 'agent.personal_turnover_ratio[day] =', agent.personal_turnover_ratio[day])
#                outString = "%d" % (agent.num_act_transs[day]) + "\t%1.2f" % (agent.total_actual_agent_sales[day]) + "\t%1.2f" % (agent.personal_turnover_ratio[day]) + "\t[%1.2f %1.2f]\t" % (agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1])
#                fileHandle.write(outString)


def write_key_dead_agent_data(dbs, agent_population, fountain_population, data_folder, vision_len, town_grid, rounds):
    print('---> writing data to file: Important Dead Agent Data')

    filepath = data_folder
    filename = "text_agent_dead_raw_data"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
    fileHandle.write("Important Dead Agent Data\n\n")
    fileHandle.write("Ag Name\t\t\t\t\t\tBirth\tForaging Strat\tAgent Res Arr\tLoc\t\tHome\t\tDist\t\tMoves to loc\tDet Skills\t\t\t\tStrat Array\t\t\t\t\t\t\t\t\t\t\t\tdeath\n\n")

    #    for agent in agent_population.dead_agent_array:
    #
    #        x_dist = agent.location[0] - agent.home[0]
    #
    #        if x_dist > 32:
    #            x_dist = 64 - x_dist
    #        elif 0 > x_dist > -32:
    #            x_dist = x_dist * -1
    #        elif -63 <= x_dist <= -32:
    #            x_dist = 64 + x_dist
    #
    #        y_dist = agent.location[1] - agent.home[1]
    #
    #        if y_dist > 32:
    #            y_dist = 64 - y_dist
    #        elif 0 > y_dist > -32:
    #            y_dist = y_dist * -1
    #        elif -63 <= y_dist <= -32:
    #            y_dist = 64 + y_dist
    #
    #        dist = np.array([[x_dist, y_dist]])
    #
    #        moves_to_loc = math.ceil(np.max(dist[0]) / vision_len)
    #
    #        outString = str(agent) + "\t" + str(agent.birth_date) + '\t' + str(agent.for_strat_array) + '\t' + str(agent.agent_res_array) + '\t' + str(agent.location) + '\t' + str(agent.home) + '\t' + str(dist) + '\t' + str(moves_to_loc) + '\t\t' + str(agent.detect_skills_array) + '\t' + '\t' + str(agent.death_date) + '\n'
    #        fileHandle.write(outString)
    #
    #    outString = "\n\n\nTransactions Data per Dead Agent\n"
    #    fileHandle.write(outString)
    #
    #    for agent in agent_population.dead_agent_array:
    #
    #        outString = "\n\nAgent name" + str(agent) + "  |  home =" + str(agent.home) + "  |  birth date: " + str(agent.birth_date) + "  |  death date: " + str(agent.death_date)
    #        fileHandle.write(outString)
    #        outString = "\n\n day\tmove\thome\t\ttarget\t\ttrans loc\ttravel\tsale\tbuy\ttype\tcp home\t\tno trs\t\tfor_strat_array\ttrad_bskt\tloc rec\n"
    #        fileHandle.write(outString)
    #
    #        agent_trans_array = []
    #
    #        for day in np.arange(rounds):
    #            for res_1 in np.arange(num_res_founts):
    #                for res_2 in np.arange(num_res_founts):
    #                    for trans_num in agent.loc_mems_array[day][res_1][res_2]:
    #                        agent_trans_array.append(trans_num)
    #
    #        for trans_num in agent_trans_array:
    #
    #            trans = dbs.trans_db[trans_num]
    #
    #            if trans.agent_a == agent:
    #                ag_type = 'inst'
    #                sell_good = trans.good_a
    #                buy_good = trans.good_b
    #                trgt = trans.agent_a_trgt
    #                tb = trans.a_tb         # trading basket
    #                loc_rec = trans.a_loc_rec
    #                cp = trans.agent_b
    #                for_strat_array = trans.ag_for_strat_array
    #
    #            else:
    #                ag_type = 'c/p'
    #                sell_good = trans.good_b
    #                buy_good = trans.good_a
    #                trgt = trans.agent_b_trgt
    #                tb = trans.b_tb
    #                loc_rec = trans.b_loc_rec
    #                cp = trans.agent_a
    #                for_strat_array = trans.cp_for_strat_array
    #
    #            # work out distance to trading point
    #            x_dist = trans.location[0] - agent.home[0]
    #
    #            if x_dist > 32:
    #                x_dist = 64 - x_dist
    #            elif 0 > x_dist > -32:
    #                x_dist = x_dist * -1
    #            elif -63 <= x_dist <= -32:
    #                x_dist = 64 + x_dist
    #
    #            y_dist = trans.location[1] - agent.home[1]
    #
    #            if y_dist > 32:
    #                y_dist = 64 - y_dist
    #            elif 0 > y_dist > -32:
    #                y_dist = y_dist * -1
    #            elif -63 <= y_dist <= -32:
    #                y_dist = 64 + y_dist
    #
    #            travel_time = np.max([x_dist, y_dist]) / float(vision_len)
    #            travel_time = int(math.ceil(travel_time))
    #
    #            loc_rec_flat = []
    #            for i in np.arange(len(loc_rec)):
    #                loc_rec_flat.append(list(loc_rec[i]))
    #
    #            outString = "\n" + "%4.0f" % (trans.day) + "\t" + str(trans.move_num) + "\t" + "[%3.0f," % (agent.home[0]) + " %3.0f]" % (agent.home[1]) + "\t" + "[%3.0f," % (trgt[0]) + " %3.0f]" % (trgt[1]) + "\t" + "[%3.0f," % (trans.location[0]) + " %3.0f]" % (trans.location[1]) + "\t" + str(travel_time) + "\t" + str(sell_good) + "\t" + str(buy_good)  + "\t" + str(ag_type) + "\t" + "[%3.0f," % (cp.home[0]) + " %3.0f]" % (cp.home[1]) + "\t" + str(trans.tot_trans_ag_sell) + "\t" + str(for_strat_array) + "\t" + "\t" + str(tb) + "\t" + str(loc_rec_flat)
    #            fileHandle.write(outString)

    if num_res_founts == 2:

        outString = "\n\n\nPersonal Turnover Ratio Data (Actual / Optimal Transactions)\n\n"
        fileHandle.write(outString)

        for agent in agent_population.dead_agent_array:

            outString = "\n\n\nAgent " + str(agent) + "\tHome:" + str(agent.home) + "\t tribe: " + str(agent.tribe) + "\t birth " + str(agent.birth_date) + "\t death date " + str(agent.death_date) + "\n\n"
            fileHandle.write(outString)

            outString = "\nday\tfor_str_st\tstart_ress\tbskt_st\ttrans\tactual\tratio\toptimal\t\tend bskt\tdet_skills\tpr_stl\tpr_f_b\tslot\tr_min\tf_0\tf_1\tprice\tEy_0\tEy_1\tLast Loc\n"
            fileHandle.write(outString)

            for day in range(agent.birth_date + 1, agent.death_date + 1):

                if len(agent.hist_trade_loc_rec[day]) > 0:

                    outString = "\n" + str(day) + "\t[%d %d %d %d]" % (agent.for_strat_hist[day][0], agent.for_strat_hist[day][1], agent.for_strat_hist[day][2], agent.for_strat_hist[day][3]) + "\t[%3.2f %3.2f]" % (
                    agent.agent_res_array_hist[day - 1][0], agent.agent_res_array_hist[day - 1][1]) + "\t[%d %d]" % (agent.basket_array_start_hist[day][0], agent.basket_array_start_hist[day][1]) + "\t%d" % (
                                agent.num_act_transs[day]) + "\t%1.2f" % (agent.total_actual_agent_sales[day]) + "\t%1.2f" % (agent.personal_turnover_ratio[day]) + "\t[%1.2f %1.2f]" % (
                                agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1]) + "\t[%1.2f %1.2f]" % (agent.basket_array_hist[day][0], agent.basket_array_hist[day][1]) + "\t[%1.3f %1.3f]" % (
                                agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1]) + "\t%1.4f" % (agent.prop_steal_history[day]) + "\t%1.4f" % (agent.prop_fight_back_history[day]) + "\t%d" % (
                                agent.foraging_strat_data[day][0]) + "\t%d" % (agent.foraging_strat_data[day][1]) + "\t%2.2f" % (agent.foraging_strat_data[day][2]) + "\t%2.2f" % (agent.foraging_strat_data[day][3]) + "\t%2.4f" % (
                                agent.foraging_strat_data[day][4]) + "\t%2.4f" % (agent.foraging_strat_data[day][5]) + "\t%2.4f" % (agent.foraging_strat_data[day][6]) + "\t%s" % (agent.hist_trade_loc_rec[day][-1])

                else:

                    outString = "\n" + str(day) + "\t[%d %d %d %d]" % (agent.for_strat_hist[day][0], agent.for_strat_hist[day][1], agent.for_strat_hist[day][2], agent.for_strat_hist[day][3]) + "\t[%3.2f %3.2f]" % (
                    agent.agent_res_array_hist[day - 1][0], agent.agent_res_array_hist[day - 1][1]) + "\t[%d %d]" % (agent.basket_array_start_hist[day][0], agent.basket_array_start_hist[day][1]) + "\t%d" % (
                                agent.num_act_transs[day]) + "\t%1.2f" % (agent.total_actual_agent_sales[day]) + "\t%1.2f" % (agent.personal_turnover_ratio[day]) + "\t[%1.2f %1.2f]" % (
                                agent.optimal_transs_systemic[day][0], agent.optimal_transs_systemic[day][1]) + "\t[%1.2f %1.2f]" % (agent.basket_array_hist[day][0], agent.basket_array_hist[day][1]) + "\t[%1.3f %1.3f]" % (
                                agent.detect_skills_array_hist[day][0], agent.detect_skills_array_hist[day][1]) + "\t%1.4f" % (agent.prop_steal_history[day]) + "\t%1.4f" % (agent.prop_fight_back_history[day]) + "\t%d" % (
                                agent.foraging_strat_data[day][0]) + "\t%d" % (agent.foraging_strat_data[day][1]) + "\t%2.2f" % (agent.foraging_strat_data[day][2]) + "\t%2.2f" % (agent.foraging_strat_data[day][3]) + "\t%2.4f" % (
                                agent.foraging_strat_data[day][4]) + "\t%2.4f" % (agent.foraging_strat_data[day][5]) + "\t%2.4f" % (agent.foraging_strat_data[day][6]) + "\tNone"

                fileHandle.write(outString)


def write_key_agent_data_round(dbs, agent_population, data_folder, vision_len, day, peak_locs_array, town_grid):
    filepath = data_folder
    filename = "daily_data_%s" % (day)

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
    fileHandle.write("Daily Agent Data - Round %s\n\n" % (day))
    #    fileHandle.write("Ag Num\tBirth\tForaging Strat\tAgent Res Arr\tLoc\t\tHome\t\tDist\t\tMoves to loc\tDet Skills\t\t\t\tStrat Array\n\n")

    outString = "\npeak_locs_array =" + str(peak_locs_array) + "\n"
    fileHandle.write(outString)

    for loc in peak_locs_array:
        outString = "\npeak loc =" + str(loc) + "\n"
        fileHandle.write(outString)

        for agent in agent_population.pop:

            # note that trans_loc_mat_new2 records other-agent data i.e. what counterparty sold and bought, not agent so we must flip the good_sell and good_buy numbers:
            for good_sell in agent.buy_array:
                for good_buy in agent.sell_array:
                    for trans_loc_num in agent.trans_loc_mat_new2[good_sell][good_buy]:  # warning - this database no longer exists - re-write when needing this data

                        trans_loc = dbs.trans_db[trans_loc_num].location

                        if loc[0] == trans_loc[0][0] and loc[1] == trans_loc[0][1]:
                            # if this condition is true then the agent transacted at this location with these sell & buy goods

                            x_dist = agent.location[0] - agent.home[0]

                            if x_dist > 32:
                                x_dist = 64 - x_dist
                            elif 0 > x_dist > -32:
                                x_dist = x_dist * -1
                            elif -63 <= x_dist <= -32:
                                x_dist = 64 + x_dist

                            y_dist = agent.location[1] - agent.home[1]

                            if y_dist > 32:
                                y_dist = 64 - y_dist
                            elif 0 > y_dist > -32:
                                y_dist = y_dist * -1
                            elif -63 <= y_dist <= -32:
                                y_dist = 64 + y_dist

                            travel_time = np.max([x_dist, y_dist]) / float(vision_len)
                            travel_time = int(math.ceil(travel_time))

                            outString = "agent transacted here: home is " + str(agent.home) + "  |  dist = " + str(int(x_dist)) + ", " + str(int(y_dist)) + "  |  Travel Time = " + str(travel_time) + " moves\n"
                            fileHandle.write(outString)


#    fileHandle.close()


def write_ag_age_data(dbs, data_folder):
    filepath = data_folder
    filename = "population_age_written"

    fileHandle = open('%s/%s %d-%d-%d-%d-%d.txt' % (filepath, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(), dt.DateTime().minute()), 'w')
    fileHandle.write("Average Age of Agents\n\n")
    fileHandle.write("Round\tAv Age\n")

    for day in dbs.ag_age_db[0]:
        outString = str(dbs.ag_age_db[0][day]) + "\t" + str(dbs.ag_age_db[1][day]) + "\n"
        fileHandle.write(outString)


class Parameters_Object():

    def __init__(self, params_dict, ststst, fount_dep, applied_constitutions):

        for item in params_dict:

            # print('item =', item, 'params_dict[item] =', params_dict[item], 'type(params_dict[item]) =', type(params_dict[item]))

            if type(params_dict[item]) is int:

                exec('self.%s = %d' % (item, params_dict[item]))

            if type(params_dict[item]) is float:

                exec('self.%s = %f' % (item, params_dict[item]))

            elif type(params_dict[item]) is str:

                exec('self.%s = "%s"' % (item, params_dict[item]))

            elif params_dict[item] is None:

                exec('self.%s = None' % item)

            elif item == 'ststst':

                self.ststst = ststst

            elif item == 'fount_dep':

                self.fount_dep = fount_dep

            elif item == 'applied_constitutions':

                self.applied_constitutions = applied_constitutions

            # if type(params_dict[item]) is not int and type(params_dict[item]) is not float and type(params_dict[item]) is not str and params_dict[item] is not None:
            #
            #     print('\n ****** PROBLEM ******')
            #     pause()

        # print('\n resulting self.ststst', self.ststst, 'self.fount_dep', self.fount_dep, 'self.applied_constitutions', self.applied_constitutions)
        #
        # pause()


class Sim_Suite_Object():

    def __init__(self, allow_Keynes_Inst, print_voting_only, print_local_policy_data, num_experiments,
                 applied_constitutions, popn_ch, total_num_sims, track_game_types):

        self.total_num_sims = total_num_sims
        self.track_game_types = track_game_types
        self.numb_of_sims = 0

        self.allow_Keynes_Inst = allow_Keynes_Inst
        self.print_voting_only = print_voting_only
        self.print_local_policy_data = print_local_policy_data
        self.num_experiments = num_experiments
        self.applied_constitutions = applied_constitutions
        self.popn_ch = popn_ch
        self.results_to_email = ''  # this is a file which is copied from the last results txt file, so it can be emailed

        self.population_data = []
        self.births_data = []
        self.deaths_data = []
        self.foraging_data = []
        self.spec_data = []
        self.mean_spec_data = []
        self.num_spec_agents_data = []
        self.max_probability_data = []
        self.resource_array_data = []
        self.actual_turnover_data = []
        self.optimal_turnover_data = []
        self.ratio_turnover_data = []
        self.all_age_data = []
        self.num_sq_data = []
        self.trading_prop_data = []
        self.trading_gini_data = []
        self.act_prices_data = []
        self.act_std_prices_data = []
        self.opt_prices_data = []
        self.whole_sim_opt_prices_data = []
        self.diff_prices_data = []
        self.serviced_locs_data = []
        self.mkt_emerged_round = []
        self.KI_data_all = []
        self.agents_aggr_votes_data = []
        self.const_record_res_accum_data = []
        self.slope_data = []
        self.prop_steal_data = []
        self.prop_fb_data = []
        self.num_trans_data = []
        self.num_fights_data = []
        self.num_scen_1_data = []
        self.num_scen_23_data = []
        self.num_scen_45_data = []

        self.agents_prop_steal_urls = []
        self.agents_prop_fb_urls = []
        self.prop_steal_above_below_50_urls = []
        self.prop_fb_above_below_50_urls = []
        self.props_means_urls = []
        self.trans_and_fights_urls = []
        self.trans_and_fights_urls_sharks = []
        self.trans_and_fights_urls_jets = []
        self.trans_and_fights_urls_inter = []
        self.fight_skills_urls = []

        self.prop_steal_mean_db = []
        self.prop_fb_mean_db = []
        self.num_ints_each_round = []
        self.num_fight_each_round = []

        self.fight_types_urls = []
        self.fight_types_urls_sharks = []
        self.fight_types_urls_jets = []
        self.fight_types_urls_inter = []

        self.black_shoop_data = []

        self.dbss = []

        self.game_type_dict = dict()
        self.game_type_dict_seen = dict()
        self.games_type_dict_2 = dict()
        self.games_type_dict_3 = dict()

        self.classic_games_considered_sums = dict()
        self.classic_games_seen_sums = dict()

        self.round_all_ags_one_trgt = []

    def add_sub_folder(self, sub_folder):

        self.sub_folder = sub_folder

    def add_segment_size(self, segment_size):

        self.segment_size = segment_size

    def add_to_dbs(self, single_sim_data):

        # unpack single_sim_data
        pop_data, births_data, deaths_data, end_foraging_data, spec_degr_data, mean_spec_array, num_spec_agents_array, max_probs_data, res_array_data, actual_turnover_array, optimal_turnover_array, ratio_turnover_array, all_age_arry, \
        num_sq_array, trading_prop_array, trading_gini_array, act_prices_array, act_std_prices_array, opt_prices_array, whole_sim_opt_prices_array, diff_prices_array, serviced_locs_data, mkt_emerged_round, \
        KI_data, agents_aggr_votes, const_record_res_accum, slope_data, prop_steal_data, prop_fb_data, num_trans_data, num_fights_data, num_scen_1_data, num_scen_23_data, num_scen_45_data, \
        agents_prop_steal_url, agents_prop_fb_url, prop_steal_above_below_50_url, prop_fb_above_below_50_url, props_means_url, trans_and_fights_url, trans_and_fights_url_sharks, trans_and_fights_url_jets, \
        trans_and_fights_url_inter, fight_types_url, fight_types_url_sharks, fight_types_url_jets, fight_types_url_inter, black_shoop_array, prop_steal_mean_db, prop_fb_mean_db, num_ints_each_round, \
        num_fight_each_round, fight_skill_url, game_type_dict, game_type_dict_seen, games_type_dict_2, games_type_dict_3, classic_games_considered_sums, classic_games_seen_sums, round_all_ags_one_trgt = single_sim_data
        #        mkt_emerged_round = run_dbs.mkt_emerged_round

        if self.print_voting_only == 0:

            self.foraging_data.append(end_foraging_data)
            self.spec_data.append(spec_degr_data)
            self.mean_spec_data.append(mean_spec_array)
            self.num_spec_agents_data.append(num_spec_agents_array)
            self.max_probability_data.append(max_probs_data)
            self.resource_array_data.append(res_array_data)
            self.actual_turnover_data.append(actual_turnover_array)
            self.optimal_turnover_data.append(optimal_turnover_array)
            self.ratio_turnover_data.append(ratio_turnover_array)
            self.all_age_data.append(all_age_arry)
            self.num_sq_data.append(num_sq_array)
            self.trading_prop_data.append(trading_prop_array)
            self.trading_gini_data.append(trading_gini_array)
            self.serviced_locs_data.append(serviced_locs_data)
            self.mkt_emerged_round.append(mkt_emerged_round)
            self.KI_data_all.append(KI_data)
            self.slope_data.append(slope_data)
            self.prop_steal_data.append(prop_steal_data)
            self.prop_fb_data.append(prop_fb_data)
            self.num_trans_data.append(num_trans_data)
            self.num_fights_data.append(num_fights_data)
            self.num_scen_1_data.append(num_scen_1_data)
            self.num_scen_23_data.append(num_scen_23_data)
            self.num_scen_45_data.append(num_scen_45_data)
            self.round_all_ags_one_trgt.append(round_all_ags_one_trgt)

            self.agents_prop_steal_urls.append(agents_prop_steal_url)
            self.agents_prop_fb_urls.append(agents_prop_fb_url)
            self.prop_steal_above_below_50_urls.append(prop_steal_above_below_50_url)
            self.prop_fb_above_below_50_urls.append(prop_fb_above_below_50_url)
            self.props_means_urls.append(props_means_url)
            self.trans_and_fights_urls.append(trans_and_fights_url)
            self.trans_and_fights_urls_sharks.append(trans_and_fights_url_sharks)
            self.trans_and_fights_urls_jets.append(trans_and_fights_url_jets)
            self.trans_and_fights_urls_inter.append(trans_and_fights_url_inter)
            self.fight_types_urls.append(fight_types_url)
            self.fight_types_urls_sharks.append(fight_types_url_sharks)
            self.fight_types_urls_jets.append(fight_types_url_jets)
            self.fight_types_urls_inter.append(fight_types_url_inter)

            self.prop_steal_mean_db.append(prop_steal_mean_db)
            self.prop_fb_mean_db.append(prop_fb_mean_db)
            self.num_ints_each_round.append(num_ints_each_round)
            self.num_fight_each_round.append(num_fight_each_round)

            self.fight_skills_urls.append(fight_skill_url)

            self.black_shoop_data.append(black_shoop_array)

            if len(game_type_dict) > 0:

                for game_type in game_type_dict:

                    if game_type in self.game_type_dict:

                        self.game_type_dict[game_type] += game_type_dict[game_type]

                    else:

                        self.game_type_dict[game_type] = game_type_dict[game_type]

            if len(game_type_dict_seen) > 0:

                for game_type in game_type_dict_seen:

                    if game_type in self.game_type_dict_seen:

                        self.game_type_dict_seen[game_type] += game_type_dict_seen[game_type]

                    else:

                        self.game_type_dict_seen[game_type] = game_type_dict_seen[game_type]

            if len(games_type_dict_2) > 0:

                for game_type in games_type_dict_2:

                    if game_type in self.games_type_dict_2:

                        self.games_type_dict_2[game_type] += games_type_dict_2[game_type]

                    else:

                        self.games_type_dict_2[game_type] = games_type_dict_2[game_type]

            if len(games_type_dict_3) > 0:

                for game_type in games_type_dict_3:

                    if game_type in self.games_type_dict_3:

                        self.games_type_dict_3[game_type] += games_type_dict_3[game_type]

                    else:

                        self.games_type_dict_3[game_type] = games_type_dict_3[game_type]

            if len(classic_games_considered_sums) > 0:

                for classic_game_type in classic_games_considered_sums:

                    if classic_game_type in self.classic_games_considered_sums:

                        self.classic_games_considered_sums[classic_game_type] += classic_games_considered_sums[
                            classic_game_type]

                    else:

                        self.classic_games_considered_sums[classic_game_type] = classic_games_considered_sums[
                            classic_game_type]

            if len(classic_games_seen_sums) > 0:

                for classic_game_type in classic_games_seen_sums:

                    if classic_game_type in self.classic_games_seen_sums:

                        self.classic_games_seen_sums[classic_game_type] += classic_games_seen_sums[classic_game_type]

                    else:

                        self.classic_games_seen_sums[classic_game_type] = classic_games_seen_sums[classic_game_type]

        if self.popn_ch != 'fixed':
            self.population_data.append(pop_data)

        self.births_data.append(births_data)
        self.deaths_data.append(deaths_data)

        self.agents_aggr_votes_data.append(agents_aggr_votes)
        self.const_record_res_accum_data.append(const_record_res_accum)

        if self.print_local_policy_data == 0 or self.print_voting_only == 1:
            self.act_prices_data.append(act_prices_array)
            self.act_std_prices_data.append(act_std_prices_array)
            self.opt_prices_data.append(opt_prices_array)
            self.diff_prices_data.append(diff_prices_array)
            self.whole_sim_opt_prices_data.append(whole_sim_opt_prices_array)

    #        self.dbss.append(run_dbs)

    def remove_run_data(self, run_num):

        """In the event of one of the runs having bad data, we can remove it with this function.  We just need a run
        number."""

        del self.foraging_data[run_num]
        del self.spec_data[run_num]
        del self.mean_spec_data[run_num]
        del self.max_probability_data[run_num]
        del self.resource_array_data[run_num]
        del self.actual_turnover_data[run_num]
        del self.optimal_turnover_data[run_num]
        del self.all_age_data[run_num]
        del self.cc_data[run_num]
        del self.num_sq_data[run_num]
        del self.act_prices_data[run_num]
        del self.opt_prices_data[run_num]
        del self.diff_prices_data[run_num]

        del self.dbss[run_num]

        self.numb_of_sims -= 1

    def save_sim_set_data(self, sub_folder, rounds, for_strat_parts, constitutional_voting,
                          start_const_proces, const_proc_test_period, constitutional_exp, respect_property_rights,
                          file_type, black_shoop_exp, two_tribes, fight_skill, plotly_online, print_fine_dets=0):

        """This function writes all of the relevant sim set data to file."""

        #        print_fine_dets = 1

        print('---> writing data to file: Sim Set Data')

        filename = "sim_set_data_%d" % (self.numb_of_sims)

        if file_type == 'html':

            new_file = '%s/%s %d-%d-%d-%d-%d-%d.html' % (
            self.sub_folder, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(),
            dt.DateTime().hour(), dt.DateTime().minute(), dt.DateTime().second())

        else:

            new_file = '%s/%s %d-%d-%d-%d-%d-%d.txt' % (
            self.sub_folder, filename, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(),
            dt.DateTime().hour(), dt.DateTime().minute(), dt.DateTime().second())

        fileHandle = open(new_file, 'w')

        if file_type == 'html':
            fileHandle.write("<html>")
            fileHandle.write("<h1>")
        fileHandle.write("Data For a Single Sim Set\n\n")
        if file_type == 'html':
            fileHandle.write("</h1>")

        if file_type == 'html':
            fileHandle.write("<p>")
        fileHandle.write("Number of Runs in the Simulation Suite = %d\n\n\n" % (self.numb_of_sims))
        if file_type == 'html':
            fileHandle.write("</p>")

        # this is in order to identify the set of results to email

        self.results_to_email = new_file

        ten_pct_rounds_array = list(range(0, rounds, int(self.segment_size)))
        ten_pct_gap = int(self.segment_size)

        data_segments = int(rounds / self.segment_size)

        if self.print_voting_only == 0:

            # Population Data
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("Population Data (agents per round) and Births and Deaths\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.population_data =\n', self.population_data)

            if self.popn_ch == 'fixed':

                fileHandle.write("\nThe population was fixed at %d agents in all simulations" % (num_agents))

            else:

                for segment in range(data_segments):

                    if print_fine_dets == 1:
                        print('\n\nsegment =', segment)

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    if two_tribes == 0:

                        mean_array = [run[segment] for run in self.population_data]
                        mean_array_births = [run[segment] for run in self.births_data]
                        mean_array_deaths = [run[segment] for run in self.deaths_data]

                        mean_pop = np.mean(mean_array)
                        std_pop = np.std(mean_array)

                        mean_births = np.mean(mean_array_births)
                        std_births = np.std(mean_array_births)

                        mean_deaths = np.mean(mean_array_deaths)
                        std_deaths = np.std(mean_array_deaths)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nRounds %d to %d: mean popn = %2.4f (%2.4f)  |  mean births = %2.4f (%2.4f)  |  mean deaths = %2.4f (%2.4f)" % (
                        start_round, end_round - 1, mean_pop, std_pop, mean_births, std_births, mean_deaths, std_deaths))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    elif two_tribes:

                        mean_array = [run[segment][0] for run in self.population_data]

                        mean_pop = np.mean(mean_array)
                        std_pop = np.std(mean_array)

                        mean_array_sharks = [run[segment][1] for run in self.population_data]

                        mean_pop_sharks = np.mean(mean_array_sharks)
                        std_pop_sharks = np.std(mean_array_sharks)

                        mean_array_jets = [run[segment][2] for run in self.population_data]

                        mean_pop_jets = np.mean(mean_array_jets)
                        std_pop_jets = np.std(mean_array_jets)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %d to %d: mean popn (all) = %2.4f (%2.4f)  |  sharks  %2.4f (%2.4f)  |  jets %2.4f (%2.4f)" % (
                            start_round, end_round - 1, mean_pop, std_pop, mean_pop_sharks, std_pop_sharks,
                            mean_pop_jets, std_pop_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

            # Foraging Data
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\nForaging Data (total foraged from fountains in each round)")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.foraging_data =\n', self.foraging_data)

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
                if file_type == 'html':
                    fileHandle.write("</h3>")

                # create array to record all means
                all_means = []
                all_stds = []

                for res in range(num_res_founts):

                    if print_fine_dets == 1:
                        print('\nres =', res)

                    mean_array = [run[segment][res][1] for run in self.foraging_data]
                    std_array = [run[segment][res][2] for run in self.foraging_data]

                    mean_mean = np.mean(mean_array)
                    mean_std = np.mean(std_array)

                    if two_tribes == 0:

                        if print_fine_dets == 1:
                            print('\nmean_array =', mean_array)
                            print('\nstd_array =', std_array)

                            print('mean mean = ', np.mean(mean_array))
                            print('mean std = ', np.mean(std_array))

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s Mean = %3.4f (%3.2f)" % (res, mean_mean, mean_std))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    if two_tribes:

                        mean_array_sharks = [run[segment][res][1] for run in self.foraging_data]
                        std_array_sharks = [run[segment][res][2] for run in self.foraging_data]

                        mean_mean_sharks = np.mean(mean_array_sharks)
                        mean_std_sharks = np.mean(std_array_sharks)

                        mean_array_jets = [run[segment][res][3] for run in self.foraging_data]
                        std_array_jets = [run[segment][res][4] for run in self.foraging_data]

                        mean_mean_jets = np.mean(mean_array_jets)
                        mean_std_jets = np.mean(std_array_jets)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nResource %s Mean Sharks = %3.4f (%3.2f)  |  Jets = %3.4f (%3.2f)" % (
                        res, mean_mean_sharks, mean_std_sharks, mean_mean_jets, mean_std_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    if segment == data_segments - 1:
                        all_means.append(mean_mean)
                        all_stds.append(mean_std)

                    # now find table data
                    tab_for_mean = np.mean(all_means)
                    tab_for_std = np.mean(all_stds)

            # Specialisation Data
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nSpecialisation Data (numbers of agents in specialisation buckets)")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.spec_data =\n', self.spec_data)
                print('\nself.mean_spec_data =\n', self.mean_spec_data)

            # find minimum value of max foraging value
            min_max_spec = int(for_strat_parts / float(num_res_founts))

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nRounds %d to %d:" % (start_round, end_round - 1))
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for spec_value in np.arange(min_max_spec, for_strat_parts + 1, dtype=int):

                    if print_fine_dets == 1:
                        print('\nspec_value =', spec_value)

                    mean_array = [run[segment][spec_value][1] for run in self.spec_data]
                    std_array = [run[segment][spec_value][2] for run in self.spec_data]

                    mean_mean = np.mean(mean_array)
                    mean_std = np.mean(std_array)

                    # Note: the mean_mean and mean_std values are in units of no. of agents with these spec_values, so the data shows the average number of agents with these values in each segment

                    if print_fine_dets == 1:
                        print('\nmean_array =', mean_array)
                        print('\nstd_array =', std_array)

                        print('mean mean = ', np.mean(mean_array))
                        print('mean std = ', np.mean(std_array))

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nSpecialisation Bucket %d Mean = %3.4f (%3.2f)" % (spec_value, mean_mean, mean_std))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                #            print(' segment ', segment, '[run[segment][0] for run in self.mean_spec_data]:\n\n', [run[segment][0] for run in self.mean_spec_data])
                #            print('\n segment ', segment, '[run[segment][1] for run in self.mean_spec_data]:\n\n', [run[segment][1] for run in self.mean_spec_data])

                mean_specs_array = [run[segment][0] for run in self.mean_spec_data if run[segment][0] is not None]

                if len(mean_specs_array) > 0:

                    mean_of_mean_specs = np.mean(mean_specs_array)

                else:

                    mean_of_mean_specs = None

                std_specs_array = [run[segment][1] for run in self.mean_spec_data if run[segment][1] is not None]

                if len(std_specs_array) > 0:

                    mean_of_std_specs = np.mean(std_specs_array)

                else:

                    mean_of_std_specs = None

                # Note: the values of mean_of_mean_specs and mean_of_std_specs are in units of no. of rousure fountains visited, showing mean (and std) of mean_max_spec value in each segment
                # so if we run 1000 rounds in each sim, each segment will be 100 rounds.  In each of these 100 rounds we find a mean_max_spec value over all agents; we then find the mean and std of that value
                # over the 100 rounds.  We then find the means of these two values, which are mean_of_mean_specs and mean_of_std_specs

                if file_type == 'html':
                    fileHandle.write("<p>")
                fileHandle.write("\n\nOverall Mean Specialisation = %s (%s)" % (mean_of_mean_specs, mean_of_std_specs))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if segment == data_segments - 1:
                    tab_spec_mean = mean_of_mean_specs
                    tab_spec_std = mean_of_std_specs

            # Number of Specialists
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write(
                "\n\n\n\nSpecialisation Data (number of agents fully specialised (detection prob > 0.99))\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            # print('\n self.num_spec_agents_data =\n\n', self.num_spec_agents_data)

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\nsegment =', segment)

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                mean_of_segment = np.mean([run[segment][0] for run in self.num_spec_agents_data])
                mean_of_std = np.mean([run[segment][1] for run in self.num_spec_agents_data])
                std_of_means = np.std([run[segment][0] for run in self.num_spec_agents_data])

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nRounds %d to %d: mean num = %2.4f (%2.4f)  |  std of means = %2.4f" % (
                start_round, end_round - 1, mean_of_segment, mean_of_std, std_of_means))
                if file_type == 'html':
                    fileHandle.write("</p>")

            # Max probability data
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write(
                "\n\n\n\nDetection Probabilities Data (mean maximum probabilities of detection) at end of rounds\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.max_probability_data =\n', self.max_probability_data)

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                mean_array = [run[segment][0] for run in self.max_probability_data if run[segment][0] is not None]
                std_array = [run[segment][1] for run in self.max_probability_data if run[segment][1] is not None]

                if len(mean_array) > 0:

                    mean_mean = np.mean(mean_array)

                else:

                    mean_mean = None

                if len(std_array) > 0:

                    mean_std = np.mean(std_array)

                else:

                    mean_std = None

                if print_fine_dets == 1:
                    print('\nmean_array =', mean_array)
                    print('\nstd_array =', std_array)

                    print('mean mean = ', mean_mean)
                    print('mean std = ', mean_std)

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nEnd of Round %d Mean = %s (%s)" % (end_round - 1, mean_mean, mean_std))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if segment == data_segments - 1:
                    tab_det_prob_mean = mean_mean
                    tab_det_prob_std = mean_std

            # Agent Resource Data
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nAgent Personal Resource Levels Data at end of rounds")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.resource_array_data =\n', self.resource_array_data)

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nEnd Round %d" % (end_round - 1))
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for var_index in range(3):

                    var_array = ['Min', 'Max', 'Mean']

                    var = var_array[var_index]

                    if print_fine_dets == 1:
                        print('\nvar =', var)

                    mean_array = [run[segment][var_index][0] for run in self.resource_array_data]
                    std_array = [run[segment][var_index][1] for run in self.resource_array_data]

                    mean_mean = np.mean(mean_array)
                    mean_std = np.mean(std_array)

                    if print_fine_dets == 1:
                        print('\nmean_array =', mean_array)
                        print('\nstd_array =', std_array)

                        print('mean mean = ', np.mean(mean_array))
                        print('mean std = ', np.mean(std_array))

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write("\n%s Mean = %3.4f (%3.2f)" % (var, mean_mean, mean_std))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                if segment == data_segments - 1:
                    tab_min_res_mean = mean_mean
                    tab_min_res_std = mean_std

                    # Turnover Data
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nTurnover Data (volume of transactions of each resource)")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nactual_turnover_data =\n', self.actual_turnover_data)
                print('\noptimal_turnover_data =\n', self.optimal_turnover_data)

            # for table data:
            saved_means = []
            saved_stds = []

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nRounds %d to %d" % (start_round, end_round - 1))
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for res in range(num_res_founts):

                    if print_fine_dets == 1:
                        print('\nres =', res)

                    mean_array = [run[segment][res][0] for run in self.actual_turnover_data]
                    std_array = [run[segment][res][1] for run in self.actual_turnover_data]

                    mean_mean_act = np.mean(mean_array)
                    mean_std_act = np.mean(std_array)

                    if print_fine_dets == 1:
                        print('\nmean_array =', mean_array)
                        print('\nstd_array =', std_array)

                        print('mean_mean_act = ', mean_mean_act)
                        print('mean_std_act = ', mean_std_act)

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\n\nResource %d Actual Mean = %3.4f (%3.2f)" % (res, mean_mean_act, mean_std_act))
                        if file_type == 'html':
                            fileHandle.write("</p'>")

                    if two_tribes:

                        mean_array_sharks = [run[segment][res][2] for run in self.actual_turnover_data]
                        std_array_sharks = [run[segment][res][3] for run in self.actual_turnover_data]

                        mean_mean_act_sharks = np.mean(mean_array_sharks)
                        mean_std_act_sharks = np.mean(std_array_sharks)

                        mean_array_jets = [run[segment][res][4] for run in self.actual_turnover_data]
                        std_array_jets = [run[segment][res][5] for run in self.actual_turnover_data]

                        mean_mean_act_jets = np.mean(mean_array_jets)
                        mean_std_act_jets = np.mean(std_array_jets)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\n\nResource %d Actual Mean all = %3.4f (%3.2f)  |  Sharks = %3.4f (%3.2f)  |  Jets = %3.4f (%3.2f)" % (
                            res, mean_mean_act, mean_std_act, mean_mean_act_sharks, mean_std_act_sharks,
                            mean_mean_act_jets, mean_std_act_jets))
                        if file_type == 'html':
                            fileHandle.write("</p'>")

                    mean_array = [run[segment][res][0] for run in self.optimal_turnover_data]
                    std_array = [run[segment][res][1] for run in self.optimal_turnover_data]

                    mean_mean_opt = np.mean(mean_array)
                    mean_std_opt = np.mean(std_array)

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nResource %d Optimal Mean = %3.4f (%3.2f)" % (res, mean_mean_opt, mean_std_opt))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    if print_fine_dets == 1:
                        print('\nmean_array =', mean_array)
                        print('\nstd_array =', std_array)

                        print('mean_mean_opt = ', mean_mean_opt)
                        print('mean_std_opt = ', mean_std_opt)

                    if two_tribes:

                        mean_array_sharks = [run[segment][res][2] for run in self.optimal_turnover_data]
                        std_array_sharks = [run[segment][res][3] for run in self.optimal_turnover_data]

                        mean_mean_opt_sharks = np.mean(mean_array_sharks)
                        mean_std_opt_sharks = np.mean(std_array_sharks)

                        mean_array_jets = [run[segment][res][4] for run in self.optimal_turnover_data]
                        std_array_jets = [run[segment][res][5] for run in self.optimal_turnover_data]

                        mean_mean_opt_jets = np.mean(mean_array_jets)
                        mean_std_opt_jets = np.mean(std_array_jets)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nResource %d Optimal Mean all = %3.4f (%3.2f)  |  Sharks = %3.4f (%3.2f)  |  Jets = %3.4f (%3.2f)" % (
                            res, mean_mean_opt, mean_std_opt, mean_mean_opt_sharks, mean_std_opt_sharks,
                            mean_mean_opt_jets, mean_std_opt_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    mean_array = [run[segment][res][0] for run in self.ratio_turnover_data]
                    std_array = [run[segment][res][1] for run in self.ratio_turnover_data]

                    mean_mean_rat = np.mean(mean_array)
                    mean_std_rat = np.mean(std_array)

                    if two_tribes == 0:

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nRatio: %3.4f (%3.3f)" % (mean_mean_rat, mean_std_rat))
                        if file_type == 'html':
                            fileHandle.write("</p>")
                            fileHandle.write("<p> </p>")

                    if two_tribes:

                        mean_array_sharks = [run[segment][res][2] for run in self.ratio_turnover_data]
                        std_array_sharks = [run[segment][res][3] for run in self.ratio_turnover_data]

                        mean_mean_rat_sharks = np.mean(mean_array_sharks)
                        mean_std_rat_sharks = np.mean(std_array_sharks)

                        mean_array_jets = [run[segment][res][4] for run in self.ratio_turnover_data]
                        std_array_jets = [run[segment][res][5] for run in self.ratio_turnover_data]

                        mean_mean_rat_jets = np.mean(mean_array_jets)
                        mean_std_rat_jets = np.mean(std_array_jets)

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRatio all: %3.4f (%3.3f)  |  Sharks: %3.4f (%3.3f)  |  Jets: %3.4f (%3.3f)" % (
                            mean_mean_rat, mean_std_rat, mean_mean_rat_sharks, mean_std_rat_sharks, mean_mean_rat_jets,
                            mean_std_rat_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")
                            fileHandle.write("<p> </p>")

                    if segment == data_segments - 1:
                        saved_means.append(mean_mean_rat)
                        saved_stds.append(mean_std_rat)

                tab_turnover_mean = np.mean(saved_means)
                tab_turnover_std = np.mean(saved_stds)

            # Age Data
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nAverage Age Data\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.all_age_data =\n', self.all_age_data)

            for segment in range(data_segments):

                if print_fine_dets == 1:
                    print('\n\nsegment =', segment)

                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                mean_array = [run[segment][0] for run in self.all_age_data if run[segment][0] is not None]
                std_array = [run[segment][1] for run in self.all_age_data if run[segment][0] is not None]

                if len(mean_array) > 0:

                    mean_mean = np.mean(mean_array)

                else:

                    mean_mean = None

                if len(std_array) > 0:

                    mean_std = np.mean(std_array)

                else:

                    mean_std = None

                if print_fine_dets == 1:
                    print('\nmean_array =', mean_array)
                    print('\nstd_array =', std_array)

                    print('mean mean = ', np.mean(mean_array))
                    print('mean std = ', np.mean(std_array))

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nEnd of Round %d Mean = %s (%s)" % (end_round - 1, mean_mean, mean_std))
                if file_type == 'html':
                    fileHandle.write("</p>")

            #        # Clustering Coefficient
            #
            #        fileHandle.write("\n\n\n\nCustering Coefficient Data\n")
            #
            #        if print_fine_dets == 1:
            #            print('\nself.cc_data =\n', self.cc_data)
            #
            #        for segment in range(len(self.cc_data[0])):
            #
            #            mean_array = [run[segment][2] for run in self.cc_data]
            #            std_array = [run[segment][3] for run in self.cc_data]
            #
            #            mean_mean = np.mean(mean_array)
            #            mean_std = np.mean(std_array)
            #
            #            if print_fine_dets == 1:
            #                print('\nmean_array =', mean_array)
            #                print('\nstd_array =', std_array)
            #
            #                print('mean mean = ', np.mean(mean_array))
            #                print('mean std = ', np.mean(std_array))
            #
            #            start_round = self.cc_data[0][segment][0]
            #            end_round = self.cc_data[0][segment][1]
            #
            #            fileHandle.write("\nRounds %d to %d - Clustering Coefficient = %3.4f (%3.2f)" % (start_round, end_round, mean_mean, mean_std))

            # Number of Squares with transactions

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nNumber of Squares with Transactions Data\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\nself.num_sq_data =\n', self.num_sq_data)

            for segment in range(data_segments):

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                mean_array = [run[segment] for run in self.num_sq_data]

                mean_mean = np.mean(mean_array)
                std_mean = np.std(mean_array)

                if print_fine_dets == 1:
                    print('\nmean_array =', mean_array)
                    print('\nstd_array =', std_array)

                    print('mean mean = ', mean_mean)
                    print('std_mean = ', std_mean)

                # now deal with proportion of trading on one square
                mean_array = [run[segment] for run in self.trading_prop_data]

                mean_mean_prop = np.mean(mean_array)
                std_mean_prop = np.std(mean_array)

                mean_gini_array = [run[segment] for run in self.trading_gini_data]

                mean_mean_gini = np.mean(mean_gini_array)
                std_mean_gini = np.std(mean_gini_array)

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nRounds %d to %d - Number of Squares with transactions = %3.4f (%3.4f)  |  Proportion of Transactions on One Square = %1.4f (%1.4f)  |  Mean Gini = %1.4f (%1.4f)" % (
                    start_round, end_round - 1, mean_mean, std_mean, mean_mean_prop, std_mean_prop, mean_mean_gini,
                    std_mean_gini))
                if file_type == 'html':
                    fileHandle.write("</p>")

                if segment == data_segments - 1:
                    tab_num_sqs_mean = mean_mean
                    tab_num_sqs_std = std_mean

                    tab_mean_mean_prop = mean_mean_prop
                    tab_mean_std_prop = std_mean_prop

            #                tab_mean_mean_gini = mean_mean_gini
            #                tab_std_mean_gini = std_mean_gini

            #            print('\nsegment', segment, '[run[segment][0] for run in self.num_sq_data] :', [run[segment][0] for run in self.num_sq_data])

            # By what stage did a market emerge?  If at all?
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nWhen Did a Market Emerge (if at all)?\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            #        print("\n\nWhen Did a Market Emerge (if at all)?\n")
            #        print("\n self.mkt_emerged_round =", self.mkt_emerged_round)

            above_90_pct_array = []
            above_95_pct_array = []
            above_99_pct_array = []

            #            print('\n self.mkt_emerged_round =', self.mkt_emerged_round)

            for sim in range(self.numb_of_sims):

                #            print("\n self.mkt_emerged_round[sim] =", self.mkt_emerged_round[sim])

                if self.mkt_emerged_round[sim][0] > 0:
                    above_90_pct_array.append(self.mkt_emerged_round[sim][0])

                if self.mkt_emerged_round[sim][1] > 0:
                    above_95_pct_array.append(self.mkt_emerged_round[sim][1])

                if self.mkt_emerged_round[sim][2] > 0:
                    above_99_pct_array.append(self.mkt_emerged_round[sim][2])

            if len(above_90_pct_array) > 0:  # then the MA moved above 90% in at least 1 sim

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nTurnover exceeeded 90pct in at least 1 round in %d of %d simulations. Of those, mean = %2.2f (std = %2.2f)" % (
                    len(above_90_pct_array), self.numb_of_sims, np.mean(above_90_pct_array),
                    np.std(above_90_pct_array)))
                if file_type == 'html':
                    fileHandle.write("</p>")

            else:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nTurnover never exceeeded 90pct in at least 1 round in any simulation")
                if file_type == 'html':
                    fileHandle.write("</p>")

            if len(above_95_pct_array) > 0:  # then the MA moved above 90% in at least 1 sim

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nTurnover exceeeded 95pct in at least 1 round in %d of %d simulations. Of those, mean = %2.2f (std = %2.2f)" % (
                    len(above_95_pct_array), self.numb_of_sims, np.mean(above_95_pct_array),
                    np.std(above_95_pct_array)))
                if file_type == 'html':
                    fileHandle.write("</p>")

            else:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nTurnover never exceeeded 95pct in at least 1 round in any simulation")
                if file_type == 'html':
                    fileHandle.write("</p>")

            if len(above_99_pct_array) > 0:  # then the MA moved above 90% in at least 1 sim

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nTurnover exceeeded 99pct in at least 1 round in %d of %d simulations. Of those, mean = %2.2f (std = %2.2f)" % (
                    len(above_99_pct_array), self.numb_of_sims, np.mean(above_99_pct_array),
                    np.std(above_99_pct_array)))
                if file_type == 'html':
                    fileHandle.write("</p>")

            else:

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nTurnover never exceeeded 90pct in at least 1 round in any simulation")
                if file_type == 'html':
                    fileHandle.write("</p>")

            # Now we turn to the locations targetted by each agent. The question is when did all the agents go to the same location?
            round_all_ags_one_trgt_Nones_removed = []

            for sim_datum in self.round_all_ags_one_trgt:
                if sim_datum != None:
                    round_all_ags_one_trgt_Nones_removed.append(sim_datum)

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nOne Location Visited by Agents? If so, when?\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write("\n Raw data: %s" % (self.round_all_ags_one_trgt))
            if file_type == 'html':
                fileHandle.write("</p>")
            fileHandle.write("\n Number of times agents converge on one locations = %d of %d sims" % (len(round_all_ags_one_trgt_Nones_removed), len(self.round_all_ags_one_trgt)))
            if file_type == 'html':
                fileHandle.write("</p>")
            if len(round_all_ags_one_trgt_Nones_removed) == 0:
                fileHandle.write("\n The agents never converged on a single square")
            else:
                fileHandle.write("\n Mean round when this happened = %3.2f (std %3.2f)" % (np.mean(round_all_ags_one_trgt_Nones_removed), np.std(round_all_ags_one_trgt_Nones_removed)))
            if file_type == 'html':
                fileHandle.write("</p>")

            # Now to prices and price differences
            if self.print_local_policy_data == 0:

                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nPrice and Price Difference Data\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                    # Pricing Data
                for segment in range(data_segments):

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\nRounds %d to %d" % (start_round, end_round - 1))
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    for res_1 in np.arange(num_res_founts):
                        for res_2 in np.arange(num_res_founts):

                            if res_1 != res_2:

                                act_mean_array = [run[segment][res_1][res_2][0] for run in self.act_prices_data if
                                                  run[segment][res_1][res_2][0] is not None]
                                act_std_array = [run[segment][res_1][res_2][1] for run in self.act_prices_data if
                                                 run[segment][res_1][res_2][1] is not None]

                                if len(act_mean_array) > 0:

                                    act_mean_mean = np.mean(act_mean_array)

                                else:

                                    act_mean_mean = None

                                if len(act_std_array) > 0:

                                    act_mean_std = np.mean(act_std_array)

                                else:

                                    act_mean_std = None

                                if two_tribes == 0:

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write("\n\nResource %s vs Resource %s - Mean Actual Price = %s (%s)" % (
                                    res_1, res_2, act_mean_mean, act_mean_std))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                if two_tribes:

                                    # sharks
                                    act_mean_array_sharks = [run[segment][res_1][res_2][2] for run in
                                                             self.act_prices_data if
                                                             run[segment][res_1][res_2][2] is not None]
                                    act_std_array_sharks = [run[segment][res_1][res_2][3] for run in
                                                            self.act_prices_data if
                                                            run[segment][res_1][res_2][3] is not None]

                                    if len(act_mean_array_sharks) > 0:

                                        act_mean_mean_sharks = np.mean(act_mean_array_sharks)

                                    else:

                                        act_mean_mean_sharks = None

                                    if len(act_std_array_sharks) > 0:

                                        act_mean_std_sharks = np.mean(act_std_array_sharks)

                                    else:

                                        act_mean_std_sharks = None

                                    # jets
                                    act_mean_array_jets = [run[segment][res_1][res_2][4] for run in self.act_prices_data
                                                           if run[segment][res_1][res_2][4] is not None]
                                    act_std_array_jets = [run[segment][res_1][res_2][5] for run in self.act_prices_data
                                                          if run[segment][res_1][res_2][5] is not None]

                                    if len(act_mean_array_jets) > 0:

                                        act_mean_mean_jets = np.mean(act_mean_array_jets)

                                    else:

                                        act_mean_mean_jets = None

                                    if len(act_std_array_jets) > 0:

                                        act_mean_std_jets = np.mean(act_std_array_jets)

                                    else:

                                        act_mean_std_jets = None

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\n\nResource %s vs Resource %s - Mean Actual Price (all) = %s (%s)  |  Sharks %s (%s)  |  Jets %s (%s)" % (
                                        res_1, res_2, act_mean_mean, act_mean_std, act_mean_mean_sharks,
                                        act_mean_std_sharks, act_mean_mean_jets, act_mean_std_jets))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                act_std_mean_array = [run[segment][res_1][res_2][0] for run in self.act_std_prices_data
                                                      if run[segment][res_1][res_2][0] is not None]
                                act_std_std_array = [run[segment][res_1][res_2][1] for run in self.act_std_prices_data
                                                     if run[segment][res_1][res_2][1] is not None]

                                if len(act_std_mean_array) > 0:

                                    act_std_mean = np.mean(act_std_mean_array)

                                else:

                                    act_std_mean = None

                                if len(act_std_std_array) > 0:

                                    act_std_std = np.mean(act_std_std_array)

                                else:

                                    act_std_std = None

                                if two_tribes == 0:

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\nResource %s vs Resource %s - Mean Daily STD of Actual Price = %s (%s)" % (
                                        res_1, res_2, act_std_mean, act_std_std))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                if two_tribes:

                                    # sharks
                                    act_std_mean_array_sharks = [run[segment][res_1][res_2][2] for run in
                                                                 self.act_std_prices_data if
                                                                 run[segment][res_1][res_2][2] is not None]
                                    act_std_std_array_sharks = [run[segment][res_1][res_2][3] for run in
                                                                self.act_std_prices_data if
                                                                run[segment][res_1][res_2][3] is not None]

                                    if len(act_std_mean_array_sharks) > 0:

                                        act_std_mean_sharks = np.mean(act_std_mean_array_sharks)

                                    else:

                                        act_std_mean_sharks = None

                                    if len(act_std_std_array_sharks) > 0:

                                        act_std_std_sharks = np.mean(act_std_std_array_sharks)

                                    else:

                                        act_std_std_sharks = None

                                    # jets
                                    act_std_mean_array_jets = [run[segment][res_1][res_2][4] for run in
                                                               self.act_std_prices_data if
                                                               run[segment][res_1][res_2][4] is not None]
                                    act_std_std_array_jets = [run[segment][res_1][res_2][5] for run in
                                                              self.act_std_prices_data if
                                                              run[segment][res_1][res_2][5] is not None]

                                    if len(act_std_mean_array_jets) > 0:

                                        act_std_mean_jets = np.mean(act_std_mean_array_jets)

                                    else:

                                        act_std_mean_jets = None

                                    if len(act_std_std_array_jets) > 0:

                                        act_std_std_jets = np.mean(act_std_std_array_jets)

                                    else:

                                        act_std_std_jets = None

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\nResource %s vs Resource %s - Mean Daily STD of Actual Price (all) = %s (%s)  |  Sharks = %s (%s)  |  Jets = %s (%s)" % (
                                        res_1, res_2, act_std_mean, act_std_std, act_std_mean_sharks,
                                        act_std_std_sharks, act_std_mean_jets, act_std_std_jets))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                opt_mean_array = [run[segment][res_1][res_2][0] for run in self.opt_prices_data if
                                                  run[segment][res_1][res_2][0] is not None]
                                opt_std_array = [run[segment][res_1][res_2][1] for run in self.opt_prices_data if
                                                 run[segment][res_1][res_2][1] is not None]

                                if len(opt_mean_array) > 0:

                                    opt_mean_mean = np.mean(opt_mean_array)

                                else:

                                    opt_mean_mean = None

                                if len(opt_std_array) > 0:

                                    opt_mean_std = np.mean(opt_std_array)

                                else:

                                    opt_mean_std = None

                                if two_tribes == 0:

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write("\nResource %s vs Resource %s - Mean Optimal Price = %s (%s)" % (
                                    res_1, res_2, opt_mean_mean, opt_mean_std))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                if two_tribes:

                                    # sharks
                                    opt_mean_array_sharks = [run[segment][res_1][res_2][2] for run in
                                                             self.opt_prices_data if
                                                             run[segment][res_1][res_2][2] is not None]
                                    opt_std_array_sharks = [run[segment][res_1][res_2][3] for run in
                                                            self.opt_prices_data if
                                                            run[segment][res_1][res_2][3] is not None]

                                    if len(opt_mean_array_sharks) > 0:

                                        opt_mean_mean_sharks = np.mean(opt_mean_array_sharks)

                                    else:

                                        opt_mean_mean_sharks = None

                                    if len(opt_std_array_sharks) > 0:

                                        opt_mean_std_sharks = np.mean(opt_std_array_sharks)

                                    else:

                                        opt_mean_std_sharks = None

                                    # jets
                                    opt_mean_array_jets = [run[segment][res_1][res_2][4] for run in self.opt_prices_data
                                                           if run[segment][res_1][res_2][4] is not None]
                                    opt_std_array_jets = [run[segment][res_1][res_2][5] for run in self.opt_prices_data
                                                          if run[segment][res_1][res_2][5] is not None]

                                    if len(opt_mean_array_jets) > 0:

                                        opt_mean_mean_jets = np.mean(opt_mean_array_jets)

                                    else:

                                        opt_mean_mean_jets = None

                                    if len(opt_std_array_jets) > 0:

                                        opt_mean_std_jets = np.mean(opt_std_array_jets)

                                    else:

                                        opt_mean_std_jets = None

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\nResource %s vs Resource %s - Mean Optimal Price (all) = %s (%s)  |  Sharks = %s (%s)  |  Jets = %s (%s)" % (
                                        res_1, res_2, opt_mean_mean, opt_mean_std, opt_mean_mean_sharks,
                                        opt_mean_std_sharks, opt_mean_mean_jets, opt_mean_std_jets))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")

                                diff_mean_array = [run[segment][res_1][res_2][0] for run in self.diff_prices_data if
                                                   run[segment][res_1][res_2][0] is not None]
                                diff_std_array = [run[segment][res_1][res_2][1] for run in self.diff_prices_data if
                                                  run[segment][res_1][res_2][1] is not None]

                                if len(diff_mean_array) > 0:

                                    diff_mean_mean = np.mean(diff_mean_array)

                                else:

                                    diff_mean_mean = None

                                if len(diff_std_array) > 0:

                                    diff_mean_std = np.mean(diff_std_array)

                                else:

                                    diff_mean_std = None

                                if two_tribes == 0:

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\nResource %s vs Resource %s - Mean Absolute Price Difference = %s (%s)" % (
                                        res_1, res_2, diff_mean_mean, diff_mean_std))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")
                                        fileHandle.write("<p> </p>")

                                if two_tribes:

                                    # sharks
                                    diff_mean_array_sharks = [run[segment][res_1][res_2][2] for run in
                                                              self.diff_prices_data if
                                                              run[segment][res_1][res_2][2] is not None]
                                    diff_std_array_sharks = [run[segment][res_1][res_2][3] for run in
                                                             self.diff_prices_data if
                                                             run[segment][res_1][res_2][3] is not None]

                                    if len(diff_mean_array_sharks) > 0:

                                        diff_mean_mean_sharks = np.mean(diff_mean_array_sharks)

                                    else:

                                        diff_mean_mean_sharks = None

                                    if len(diff_std_array_sharks) > 0:

                                        diff_mean_std_sharks = np.mean(diff_std_array_sharks)

                                    else:

                                        diff_mean_std_sharks = None

                                    # jets
                                    diff_mean_array_jets = [run[segment][res_1][res_2][4] for run in
                                                            self.diff_prices_data if
                                                            run[segment][res_1][res_2][4] is not None]
                                    diff_std_array_jets = [run[segment][res_1][res_2][5] for run in
                                                           self.diff_prices_data if
                                                           run[segment][res_1][res_2][5] is not None]

                                    if len(diff_mean_array_jets) > 0:

                                        diff_mean_mean_jets = np.mean(diff_mean_array_jets)

                                    else:

                                        diff_mean_mean_jets = None

                                    if len(diff_std_array_jets) > 0:

                                        diff_mean_std_jets = np.mean(diff_std_array_jets)

                                    else:

                                        diff_mean_std_jets = None

                                    if file_type == 'html':
                                        fileHandle.write("<p style='margin:0;'>")
                                    fileHandle.write(
                                        "\nResource %s vs Resource %s - Mean Absolute Price Difference (all) = %s (%s)  |  Sharks = %s (%s)  |  Jets = %s (%s)" % (
                                        res_1, res_2, diff_mean_mean, diff_mean_std, diff_mean_mean_sharks,
                                        diff_mean_std_sharks, diff_mean_mean_jets, diff_mean_std_jets))
                                    if file_type == 'html':
                                        fileHandle.write("</p>")
                                        fileHandle.write("<p> </p>")

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nOptimal Prices over Sims:\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                means_array = []
                stds_array = []

                #        print('\n self.whole_sim_opt_prices_data =', self.whole_sim_opt_prices_data)

                for sim in range(self.numb_of_sims):

                    means_array.append(self.whole_sim_opt_prices_data[sim][0])
                    stds_array.append(self.whole_sim_opt_prices_data[sim][1])

                    if len(means_array) > 0:

                        whole_sim_mean = np.mean(means_array)

                    else:

                        whole_sim_mean = None

                    if len(stds_array) > 0:

                        whole_sim_std = np.mean(stds_array)

                    else:

                        whole_sim_std = None

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nAverage Mean and Standard Deviation of Prices Over Whole Simulations (Chart Price of Res 0 in Res 1 Units): Mean = %2.5f  |  STD = %2.5f\n" % (
                    whole_sim_mean, whole_sim_std))
                if file_type == 'html':
                    fileHandle.write("</p>")

            # Here we look at the number of home locations which are serviced by markets (dbs.serviced_locations)
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nPercentage of Agent Squares Covered by Markets\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if print_fine_dets == 1:
                print('\n self.serviced_locs_data =\n', self.serviced_locs_data)

            for segment in range(data_segments):

                start_round = ten_pct_rounds_array[segment]
                end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                mean_array = [run[segment][0] for run in self.serviced_locs_data]
                pct_array = [run[segment][1] for run in self.serviced_locs_data]

                mean_mean = np.mean(mean_array)
                mean_pct = np.mean(pct_array)

                if print_fine_dets == 1:
                    print('\nmean_array =', mean_array)
                    print('\nmean_pct =', mean_pct)

                    print('mean mean = ', mean_mean)
                    print('mean_pct = ', mean_pct)

                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nRounds %4.0f to %4.0f - Percent of agents within market catchment area = %3.2f (std %3.2f pct)" % (
                    start_round, end_round - 1, mean_mean * 100, mean_pct * 100))
                if file_type == 'html':
                    fileHandle.write("</p>")

            #        # Here we look at slope data
            #        fileHandle.write("\n\n\n\nThe Relationship Between Distance from Market and Resource Holdings at The End of Simulations\n")
            #
            #        fileHandle.write("\nSim \tSlope Coeff \tSt Error\tp value\n")
            #
            #        print('self.slope_data =', self.slope_data)
            #
            #        for sim in range(self.numb_of_sims):
            #
            #            if len(self.slope_data[sim]) > 0:
            #
            #                fileHandle.write("\n%d \t %3.2f \t\t %3.2f \t\t %3.2f" % (sim, self.slope_data[sim][0], self.slope_data[sim][1], self.slope_data[sim][2]))
            #
            #        # slope_array = [results.params[1], results.bse[1], results.pvalues[1]]
            #        slopes_array = [run[0] for run in self.slope_data]
            #        mean_slope = np.mean(slopes_array)
            #        std_slope = np.std(slopes_array)
            #
            #        std_errors_array = [run[1] for run in self.slope_data]
            #        mean_std_err = np.mean(std_errors_array)
            #        std_std_err = np.std(std_errors_array)
            #
            #        p_ratio_array = [run[2] for run in self.slope_data]
            #        mean_p_ratio = np.mean(p_ratio_array)
            #        std_p_ratio = np.std(p_ratio_array)
            #
            #        fileHandle.write("\n\n\nMean Slope = %3.2f (%3.2f)  |  Mean St Err = %3.2f (%3.2f)  |  Mean P Ratio = %3.2f (%3.2f)" % (mean_slope, std_slope, mean_std_err, std_std_err, mean_p_ratio, std_p_ratio))

            # Keynesian Institution Data, if any

            if self.allow_Keynes_Inst == 'total':

                #            print('\n\n self.KI_data_all\n\n', self.KI_data_all)
                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nKeynesian Institution Data\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                for segment in range(data_segments):

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    tot_vol_array = [run[segment][0] for run in self.KI_data_all]
                    KI_vol_array = [run[segment][1] for run in self.KI_data_all]
                    prop_array = [run[segment][2] for run in self.KI_data_all]

                    mean_tot_vol = np.mean(tot_vol_array)
                    std_tot_vol = np.std(tot_vol_array)

                    mean_KI_vol = np.mean(KI_vol_array)
                    std_KI_vol = np.std(KI_vol_array)

                    mean_prop = np.mean(prop_array)
                    std_prop = np.std(prop_array)

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nRounds %4.0f to %4.0f - Volume of Transactions (res 0 only) = %4.4f (%4.4f)  |  Volume on KI = %4.4f (%4.4f)  |  Proportion on KI = %4.4f (%4.4f)" % (
                        start_round, end_round - 1, mean_tot_vol, std_tot_vol, mean_KI_vol, std_KI_vol, mean_prop,
                        std_prop))
                    if file_type == 'html':
                        fileHandle.write("</p>")

            #                if segment == data_segments - 1 and mean_prop > 0:
            #
            #                    print('\n POSITIVE VALUE: market moved in this round')
            #
            #                    input("Press Enter to continue...")

            if respect_property_rights == 0:

                # there are 3 sets of data to look at: props steal and fb; num trans and fights; and breakdown of fights
                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nPropensity to Steal and Fight Back Data\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                if print_fine_dets == 1:
                    print('\n self.prop_steal_data =\n', self.prop_steal_data)
                    print('\n self.prop_fb_data =\n', self.prop_fb_data)

                for segment in range(data_segments):

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    if two_tribes:

                        # sharks
                        mean_steal_array_sharks = [run[segment][2] for run in self.prop_steal_data if
                                                   run[segment][2] is not None]
                        std_steal_array_sharks = [run[segment][3] for run in self.prop_steal_data if
                                                  run[segment][3] is not None]

                        if len(mean_steal_array_sharks) > 0:

                            mean_mean_steal_sharks = np.mean(mean_steal_array_sharks)

                        else:

                            mean_mean_steal_sharks = None

                        if len(std_steal_array_sharks) > 0:

                            mean_std_steal_sharks = np.mean(std_steal_array_sharks)

                        else:

                            mean_std_steal_sharks = None

                        mean_fb_array_sharks = [run[segment][2] for run in self.prop_fb_data if
                                                run[segment][2] is not None]
                        std_fb_array_sharks = [run[segment][3] for run in self.prop_fb_data if
                                               run[segment][3] is not None]

                        if len(mean_fb_array_sharks) > 0:

                            mean_mean_fb_sharks = np.mean(mean_fb_array_sharks)

                        else:

                            mean_mean_fb_sharks = None

                        if len(std_fb_array_sharks) > 0:

                            mean_std_fb_sharks = np.mean(std_fb_array_sharks)

                        else:

                            mean_std_fb_sharks = None

                        # jets
                        mean_steal_array_jets = [run[segment][2] for run in self.prop_steal_data if
                                                 run[segment][2] is not None]
                        std_steal_array_jets = [run[segment][3] for run in self.prop_steal_data if
                                                run[segment][3] is not None]

                        if len(mean_steal_array_jets) > 0:

                            mean_mean_steal_jets = np.mean(mean_steal_array_jets)

                        else:

                            mean_mean_steal_jets = None

                        if len(std_steal_array_jets) > 0:

                            mean_std_steal_jets = np.mean(std_steal_array_jets)

                        else:

                            mean_std_steal_jets = None

                        mean_fb_array_jets = [run[segment][4] for run in self.prop_fb_data if
                                              run[segment][4] is not None]
                        std_fb_array_jets = [run[segment][5] for run in self.prop_fb_data if
                                             run[segment][5] is not None]

                        if len(mean_fb_array_jets) > 0:

                            mean_mean_fb_jets = np.mean(mean_fb_array_jets)

                        else:

                            mean_mean_fb_jets = None

                        if len(std_fb_array_jets) > 0:

                            mean_std_fb_jets = np.mean(std_fb_array_jets)

                        else:

                            mean_std_fb_jets = None

                        if file_type == 'html':
                            fileHandle.write("<p></p>")
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Sharks Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % \
                            (start_round, end_round - 1, mean_mean_steal_sharks, mean_std_steal_sharks,
                             mean_mean_fb_sharks, mean_std_fb_sharks))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Jets Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % \
                            (start_round, end_round - 1, mean_mean_steal_jets, mean_std_steal_jets, mean_mean_fb_jets,
                             mean_std_fb_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    mean_steal_array = [run[segment][0] for run in self.prop_steal_data if run[segment][0] is not None]
                    std_steal_array = [run[segment][1] for run in self.prop_steal_data if run[segment][1] is not None]

                    if len(mean_steal_array) > 0:

                        mean_mean_steal = np.mean(mean_steal_array)

                    else:

                        mean_mean_steal = None

                    if len(std_steal_array) > 0:

                        mean_std_steal = np.mean(std_steal_array)

                    else:

                        mean_std_steal = None

                    mean_fb_array = [run[segment][0] for run in self.prop_fb_data if run[segment][0] is not None]
                    std_fb_array = [run[segment][1] for run in self.prop_fb_data if run[segment][1] is not None]

                    if len(mean_fb_array) > 0:

                        mean_mean_fb = np.mean(mean_fb_array)

                    else:

                        mean_mean_fb = None

                    if len(std_fb_array) > 0:

                        mean_std_fb = np.mean(std_fb_array)

                    else:

                        mean_std_fb = None

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nRounds %4d to %4d - Mean Propensity to Steal = %s (std %s)  |  Mean Propensity to Fight Back = %s (std %s)" % \
                        (start_round, end_round - 1, mean_mean_steal, mean_std_steal, mean_mean_fb, mean_std_fb))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nNumber of Transactions and Fights\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                if print_fine_dets == 1:
                    print('\n self.num_trans_data =\n', self.num_trans_data)
                    print('\n self.num_fights_data =\n', self.num_fights_data)

                for segment in range(data_segments):

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    if two_tribes:

                        # sharks
                        mean_trans_array_sharks = [run[segment][2] for run in self.num_trans_data if
                                                   run[segment][2] is not None]
                        std_trans_array_sharks = [run[segment][3] for run in self.num_trans_data if
                                                  run[segment][3] is not None]

                        if len(mean_trans_array_sharks) > 0:

                            mean_mean_trans_sharks = np.mean(mean_trans_array_sharks)

                        else:

                            mean_mean_trans_sharks = None

                        if len(std_trans_array_sharks) > 0:

                            mean_std_trans_sharks = np.mean(std_trans_array_sharks)

                        else:

                            mean_std_trans_sharks = None

                        mean_fights_array_sharks = [run[segment][2] for run in self.num_fights_data if
                                                    run[segment][2] is not None]
                        std_fights_array_sharks = [run[segment][3] for run in self.num_fights_data if
                                                   run[segment][3] is not None]

                        if len(mean_fights_array_sharks) > 0:

                            mean_mean_fights_sharks = np.mean(mean_fights_array_sharks)

                        else:

                            mean_mean_fights_sharks = None

                        if len(std_fights_array_sharks) > 0:

                            mean_std_fights_sharks = np.mean(std_fights_array_sharks)

                        else:

                            mean_std_fights_sharks = None

                        # jets
                        mean_trans_array_jets = [run[segment][4] for run in self.num_trans_data if
                                                 run[segment][4] is not None]
                        std_trans_array_jets = [run[segment][5] for run in self.num_trans_data if
                                                run[segment][5] is not None]

                        if len(mean_trans_array_jets) > 0:

                            mean_mean_trans_jets = np.mean(mean_trans_array_jets)

                        else:

                            mean_mean_trans_jets = None

                        if len(std_trans_array_jets) > 0:

                            mean_std_trans_jets = np.mean(std_trans_array_jets)

                        else:

                            mean_std_trans_jets = None

                        mean_fights_array_jets = [run[segment][4] for run in self.num_fights_data if
                                                  run[segment][4] is not None]
                        std_fights_array_jets = [run[segment][5] for run in self.num_fights_data if
                                                 run[segment][5] is not None]

                        if len(mean_fights_array_jets) > 0:

                            mean_mean_fights_jets = np.mean(mean_fights_array_jets)

                        else:

                            mean_mean_fights_jets = None

                        if len(std_fights_array_jets) > 0:

                            mean_std_fights_jets = np.mean(std_fights_array_jets)

                        else:

                            mean_std_fights_jets = None

                        # inter
                        mean_trans_array_inter = [run[segment][6] for run in self.num_trans_data if
                                                  run[segment][6] is not None]
                        std_trans_array_inter = [run[segment][7] for run in self.num_trans_data if
                                                 run[segment][7] is not None]

                        if len(mean_trans_array_inter) > 0:

                            mean_mean_trans_inter = np.mean(mean_trans_array_inter)

                        else:

                            mean_mean_trans_inter = None

                        if len(std_trans_array_inter) > 0:

                            mean_std_trans_inter = np.mean(std_trans_array_inter)

                        else:

                            mean_std_trans_inter = None

                        mean_fights_array_inter = [run[segment][6] for run in self.num_fights_data if
                                                   run[segment][6] is not None]
                        std_fights_array_inter = [run[segment][7] for run in self.num_fights_data if
                                                  run[segment][7] is not None]

                        if len(mean_fights_array_inter) > 0:

                            mean_mean_fights_inter = np.mean(mean_fights_array_inter)

                        else:

                            mean_mean_fights_inter = None

                        if len(std_fights_array_inter) > 0:

                            mean_std_fights_inter = np.mean(std_fights_array_inter)

                        else:

                            mean_std_fights_inter = None

                        if file_type == 'html':
                            fileHandle.write("<p></p'>")
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Sharks Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % \
                            (start_round, end_round - 1, mean_mean_trans_sharks, mean_std_trans_sharks,
                             mean_mean_fights_sharks, mean_std_fights_sharks))
                        if file_type == 'html':
                            fileHandle.write("</p'>")

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Jets Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % \
                            (start_round, end_round - 1, mean_mean_trans_jets, mean_std_trans_jets,
                             mean_mean_fights_jets, mean_std_fights_jets))
                        if file_type == 'html':
                            fileHandle.write("</p'>")

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Inter-Tribe Mean Number of Transactions = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % \
                            (start_round, end_round - 1, mean_mean_trans_inter, mean_std_trans_inter,
                             mean_mean_fights_inter, mean_std_fights_inter))
                        if file_type == 'html':
                            fileHandle.write("</p'>")

                    mean_trans_array = [run[segment][0] for run in self.num_trans_data if run[segment][0] is not None]
                    std_trans_array = [run[segment][1] for run in self.num_trans_data if run[segment][1] is not None]

                    if len(mean_trans_array) > 0:

                        mean_mean_trans = np.mean(mean_trans_array)

                    else:

                        mean_mean_trans = None

                    if len(std_trans_array) > 0:

                        mean_std_trans = np.mean(std_trans_array)

                    else:

                        mean_std_trans = None

                    mean_fights_array = [run[segment][0] for run in self.num_fights_data if run[segment][0] is not None]
                    std_fights_array = [run[segment][1] for run in self.num_fights_data if run[segment][1] is not None]

                    if len(mean_fights_array) > 0:

                        mean_mean_fights = np.mean(mean_fights_array)

                    else:

                        mean_mean_fights = None

                    if len(std_fights_array) > 0:

                        mean_std_fights = np.mean(std_fights_array)

                    else:

                        mean_std_fights = None

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nRounds %4d to %4d - Mean Number of Transaction = %s (std %s)  |  Mean Number of Fights = %s (std %s)" % \
                        (
                        start_round, end_round - 1, mean_mean_trans, mean_std_trans, mean_mean_fights, mean_std_fights))
                    if file_type == 'html':
                        fileHandle.write("</p'>")

                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nTypes of Fights\n")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                # define fight types:
                if file_type == 'html':
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\nScenario 1 is: both agents attempted to steal.")
                if file_type == 'html':
                    fileHandle.write("</p'>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nScenarios 2 & 3 is: one agent attempted to steal, the other wanted to trade but then fought back.")
                if file_type == 'html':
                    fileHandle.write("</p'>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nScenarios 4 & 5 is: one agent attempted to steal, the other wanted to trade but then acquiesced.")
                if file_type == 'html':
                    fileHandle.write("</p'>")
                    fileHandle.write("<p style='margin:0;'>")
                fileHandle.write(
                    "\nNote: pct data below give scenario 1, 2 & 3, and 4 & 5 fights as proportion of the mean number of fights during the period.\n")
                if file_type == 'html':
                    fileHandle.write("</p>")
                    fileHandle.write("<p> </p>")

                if print_fine_dets == 1:
                    print('\n self.num_scen_1_data =\n', self.num_scen_1_data)
                    print('\n self.num_scen_23_data =\n', self.num_scen_23_data)
                    print('\n self.num_scen_45_data =\n', self.num_scen_45_data)

                for segment in range(data_segments):

                    start_round = ten_pct_rounds_array[segment]
                    end_round = ten_pct_rounds_array[segment] + ten_pct_gap

                    if two_tribes:

                        # sharks
                        # scen 1
                        mean_scen_1_array_sharks = [run[segment][2] for run in self.num_scen_1_data if
                                                    run[segment][2] is not None]
                        std_scen_1_array_sharks = [run[segment][3] for run in self.num_scen_1_data if
                                                   run[segment][3] is not None]

                        if len(mean_scen_1_array_sharks) > 0:

                            mean_mean_scen_1_sharks = np.mean(mean_scen_1_array_sharks)

                        else:

                            mean_mean_scen_1_sharks = 0

                        if len(std_scen_1_array_sharks) > 0:

                            mean_std_scen_1_sharks = np.mean(std_scen_1_array_sharks)

                        else:

                            mean_std_scen_1_sharks = 0

                        # scen 2 & 3
                        mean_scen_23_array_sharks = [run[segment][2] for run in self.num_scen_23_data if
                                                     run[segment][2] is not None]
                        std_scen_23_array_sharks = [run[segment][3] for run in self.num_scen_23_data if
                                                    run[segment][3] is not None]

                        if len(mean_scen_23_array_sharks) > 0:

                            mean_mean_scen_23_sharks = np.mean(mean_scen_23_array_sharks)

                        else:

                            mean_mean_scen_23_sharks = 0

                        if len(std_scen_23_array_sharks) > 0:

                            mean_std_scen_23_sharks = np.mean(std_scen_23_array_sharks)

                        else:

                            mean_std_scen_23_sharks = 0

                        # scen 4 & 5
                        mean_scen_45_array_sharks = [run[segment][2] for run in self.num_scen_45_data if
                                                     run[segment][2] is not None]
                        std_scen_45_array_sharks = [run[segment][3] for run in self.num_scen_45_data if
                                                    run[segment][3] is not None]

                        if len(mean_scen_45_array_sharks) > 0:

                            mean_mean_scen_45_sharks = np.mean(mean_scen_45_array_sharks)

                        else:

                            mean_mean_scen_45_sharks = 0

                        if len(std_scen_45_array_sharks) > 0:

                            mean_std_scen_45_sharks = np.mean(std_scen_45_array_sharks)

                        else:

                            mean_std_scen_45_sharks = 0

                        if (mean_mean_scen_1_sharks + mean_mean_scen_23_sharks + mean_mean_scen_45_sharks) > 0:

                            prop_1 = (100 * mean_mean_scen_1_sharks) / float(
                                mean_mean_scen_1_sharks + mean_mean_scen_23_sharks + mean_mean_scen_45_sharks)
                            prop_23 = (100 * mean_mean_scen_23_sharks) / float(
                                mean_mean_scen_1_sharks + mean_mean_scen_23_sharks + mean_mean_scen_45_sharks)
                            prop_45 = (100 * mean_mean_scen_45_sharks) / float(
                                mean_mean_scen_1_sharks + mean_mean_scen_23_sharks + mean_mean_scen_45_sharks)

                        else:

                            prop_1 = 0
                            prop_23 = 0
                            prop_45 = 0

                        if file_type == 'html':
                            fileHandle.write("<p></p>")
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Sharks Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                            (start_round, end_round - 1, mean_mean_scen_1_sharks, prop_1, mean_std_scen_1_sharks,
                             mean_mean_scen_23_sharks, prop_23, mean_std_scen_23_sharks, mean_mean_scen_45_sharks,
                             prop_45, mean_std_scen_45_sharks))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        # jets
                        # scen 1
                        mean_scen_1_array_jets = [run[segment][4] for run in self.num_scen_1_data if
                                                  run[segment][4] is not None]
                        std_scen_1_array_jets = [run[segment][5] for run in self.num_scen_1_data if
                                                 run[segment][5] is not None]

                        if len(mean_scen_1_array_jets) > 0:

                            mean_mean_scen_1_jets = np.mean(mean_scen_1_array_jets)

                        else:

                            mean_mean_scen_1_jets = 0

                        if len(std_scen_1_array_jets) > 0:

                            mean_std_scen_1_jets = np.mean(std_scen_1_array_jets)

                        else:

                            mean_std_scen_1_jets = 0

                        # scen 2 & 3
                        mean_scen_23_array_jets = [run[segment][4] for run in self.num_scen_23_data if
                                                   run[segment][4] is not None]
                        std_scen_23_array_jets = [run[segment][5] for run in self.num_scen_23_data if
                                                  run[segment][5] is not None]

                        if len(mean_scen_23_array_jets) > 0:

                            mean_mean_scen_23_jets = np.mean(mean_scen_23_array_jets)

                        else:

                            mean_mean_scen_23_jets = 0

                        if len(std_scen_23_array_jets) > 0:

                            mean_std_scen_23_jets = np.mean(std_scen_23_array_jets)

                        else:

                            mean_std_scen_23_jets = 0

                        # scen 4 & 5
                        mean_scen_45_array_jets = [run[segment][4] for run in self.num_scen_45_data if
                                                   run[segment][4] is not None]
                        std_scen_45_array_jets = [run[segment][5] for run in self.num_scen_45_data if
                                                  run[segment][5] is not None]

                        if len(mean_scen_45_array_jets) > 0:

                            mean_mean_scen_45_jets = np.mean(mean_scen_45_array_jets)

                        else:

                            mean_mean_scen_45_jets = 0

                        if len(std_scen_45_array_jets) > 0:

                            mean_std_scen_45_jets = np.mean(std_scen_45_array_jets)

                        else:

                            mean_std_scen_45_jets = 0

                        if (mean_mean_scen_1_jets + mean_mean_scen_23_jets + mean_mean_scen_45_jets) > 0:

                            prop_1 = (100 * mean_mean_scen_1_jets) / float(
                                mean_mean_scen_1_jets + mean_mean_scen_23_jets + mean_mean_scen_45_jets)
                            prop_23 = (100 * mean_mean_scen_23_jets) / float(
                                mean_mean_scen_1_jets + mean_mean_scen_23_jets + mean_mean_scen_45_jets)
                            prop_45 = (100 * mean_mean_scen_45_jets) / float(
                                mean_mean_scen_1_jets + mean_mean_scen_23_jets + mean_mean_scen_45_jets)

                        else:

                            prop_1 = 0
                            prop_23 = 0
                            prop_45 = 0

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Jets Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                            (start_round, end_round - 1, mean_mean_scen_1_jets, prop_1, mean_std_scen_1_jets,
                             mean_mean_scen_23_jets, prop_23, mean_std_scen_23_jets, mean_mean_scen_45_jets, prop_45,
                             mean_std_scen_45_jets))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                        # inter
                        # scen 1
                        mean_scen_1_array_inter = [run[segment][6] for run in self.num_scen_1_data if
                                                   run[segment][6] is not None]
                        std_scen_1_array_inter = [run[segment][7] for run in self.num_scen_1_data if
                                                  run[segment][7] is not None]

                        if len(mean_scen_1_array_inter) > 0:

                            mean_mean_scen_1_inter = np.mean(mean_scen_1_array_inter)

                        else:

                            mean_mean_scen_1_inter = 0

                        if len(std_scen_1_array_inter) > 0:

                            mean_std_scen_1_inter = np.mean(std_scen_1_array_inter)

                        else:

                            mean_std_scen_1_inter = 0

                        # scen 2 & 3
                        mean_scen_23_array_inter = [run[segment][6] for run in self.num_scen_23_data if
                                                    run[segment][6] is not None]
                        std_scen_23_array_inter = [run[segment][7] for run in self.num_scen_23_data if
                                                   run[segment][7] is not None]

                        if len(mean_scen_23_array_inter) > 0:

                            mean_mean_scen_23_inter = np.mean(mean_scen_23_array_inter)

                        else:

                            mean_mean_scen_23_inter = 0

                        if len(std_scen_23_array_inter) > 0:

                            mean_std_scen_23_inter = np.mean(std_scen_23_array_inter)

                        else:

                            mean_std_scen_23_inter = 0

                        # scen 4 & 5
                        mean_scen_45_array_inter = [run[segment][6] for run in self.num_scen_45_data if
                                                    run[segment][6] is not None]
                        std_scen_45_array_inter = [run[segment][7] for run in self.num_scen_45_data if
                                                   run[segment][7] is not None]

                        if len(mean_scen_45_array_inter) > 0:

                            mean_mean_scen_45_inter = np.mean(mean_scen_45_array_inter)

                        else:

                            mean_mean_scen_45_inter = 0

                        if len(std_scen_45_array_inter) > 0:

                            mean_std_scen_45_inter = np.mean(std_scen_45_array_inter)

                        else:

                            mean_std_scen_45_inter = 0

                        if (mean_mean_scen_1_inter + mean_mean_scen_23_inter + mean_mean_scen_45_inter) > 0:

                            prop_1 = (100 * mean_mean_scen_1_inter) / float(
                                mean_mean_scen_1_inter + mean_mean_scen_23_inter + mean_mean_scen_45_inter)
                            prop_23 = (100 * mean_mean_scen_23_inter) / float(
                                mean_mean_scen_1_inter + mean_mean_scen_23_inter + mean_mean_scen_45_inter)
                            prop_45 = (100 * mean_mean_scen_45_inter) / float(
                                mean_mean_scen_1_inter + mean_mean_scen_23_inter + mean_mean_scen_45_inter)

                        else:

                            prop_1 = 0
                            prop_23 = 0
                            prop_45 = 0

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nRounds %4d to %4d - Inter-Tribe Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                            (start_round, end_round - 1, mean_mean_scen_1_inter, prop_1, mean_std_scen_1_inter,
                             mean_mean_scen_23_inter, prop_23, mean_std_scen_23_inter, mean_mean_scen_45_inter, prop_45,
                             mean_std_scen_45_inter))
                        if file_type == 'html':
                            fileHandle.write("</p>")

                    # scen 1
                    mean_scen_1_array = [run[segment][0] for run in self.num_scen_1_data if run[segment][0] is not None]
                    std_scen_1_array = [run[segment][1] for run in self.num_scen_1_data if run[segment][1] is not None]

                    if len(mean_scen_1_array) > 0:

                        mean_mean_scen_1 = np.mean(mean_scen_1_array)

                    else:

                        mean_mean_scen_1 = 0

                    if len(std_scen_1_array) > 0:

                        mean_std_scen_1 = np.mean(std_scen_1_array)

                    else:

                        mean_std_scen_1 = 0

                    # scen 2 & 3
                    mean_scen_23_array = [run[segment][0] for run in self.num_scen_23_data if
                                          run[segment][0] is not None]
                    std_scen_23_array = [run[segment][1] for run in self.num_scen_23_data if
                                         run[segment][1] is not None]

                    if len(mean_scen_23_array) > 0:

                        mean_mean_scen_23 = np.mean(mean_scen_23_array)

                    else:

                        mean_mean_scen_23 = 0

                    if len(std_scen_23_array) > 0:

                        mean_std_scen_23 = np.mean(std_scen_23_array)

                    else:

                        mean_std_scen_23 = 0

                    # scen 4 & 5
                    mean_scen_45_array = [run[segment][0] for run in self.num_scen_45_data if
                                          run[segment][0] is not None]
                    std_scen_45_array = [run[segment][1] for run in self.num_scen_45_data if
                                         run[segment][1] is not None]

                    if len(mean_scen_45_array) > 0:

                        mean_mean_scen_45 = np.mean(mean_scen_45_array)

                    else:

                        mean_mean_scen_45 = 0

                    if len(std_scen_45_array) > 0:

                        mean_std_scen_45 = np.mean(std_scen_45_array)

                    else:

                        mean_std_scen_45 = 0

                    if (mean_mean_scen_1 + mean_mean_scen_23 + mean_mean_scen_45) > 0:

                        prop_1 = (100 * mean_mean_scen_1) / float(
                            mean_mean_scen_1 + mean_mean_scen_23 + mean_mean_scen_45)
                        prop_23 = (100 * mean_mean_scen_23) / float(
                            mean_mean_scen_1 + mean_mean_scen_23 + mean_mean_scen_45)
                        prop_45 = (100 * mean_mean_scen_45) / float(
                            mean_mean_scen_1 + mean_mean_scen_23 + mean_mean_scen_45)

                    else:

                        prop_1 = 0
                        prop_23 = 0
                        prop_45 = 0

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                    fileHandle.write(
                        "\nRounds %4d to %4d - Mean Scen. 1 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 2 & 3 Fights = %s (or %s pct) (std %s)  |  Mean Scen. 4 & 5 Fights = %s (or %s pct) (std %s)" % \
                        (start_round, end_round - 1, mean_mean_scen_1, prop_1, mean_std_scen_1, mean_mean_scen_23,
                         prop_23, mean_std_scen_23, mean_mean_scen_45, prop_45, mean_std_scen_45))
                    if file_type == 'html':
                        fileHandle.write("</p>")

                if self.track_game_types:

                    if file_type == 'html':
                        fileHandle.write("<h2>")
                    fileHandle.write("\n\n\n\nGame Type Data\n")
                    if file_type == 'html':
                        fileHandle.write("</h2>")

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\nRaw Considered Game Types (number of games in total)")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    if file_type == 'html':
                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                        total_sum_cons = 0
                        total_sum_seen = 0
                        total_sum_2 = 0
                        total_sum_3 = 0
                        total_sum_classics_cons = 0
                        total_sum_classics_seen = 0

                        for game_type in self.game_type_dict:
                            total_sum_cons += self.game_type_dict[game_type]

                        game_type_dict_run = sorted(self.game_type_dict.items(), key=lambda item: (item[1], item[0]),
                                                    reverse=True)

                        for game_type in self.game_type_dict_seen:
                            total_sum_seen += self.game_type_dict_seen[game_type]

                        for game_type in self.games_type_dict_2:
                            total_sum_2 += self.games_type_dict_2[game_type]

                        for game_type in self.games_type_dict_3:
                            total_sum_3 += self.games_type_dict_3[game_type]

                        games_type_dict_3_seen = sorted(self.games_type_dict_3.items(), key=lambda item: (item[1], item[0]),
                                                        reverse=True)

                        for classic_game_type in self.classic_games_considered_sums:
                            total_sum_classics_cons += self.classic_games_considered_sums[classic_game_type]

                        for classic_game_type in self.classic_games_seen_sums:
                            total_sum_classics_seen += self.classic_games_seen_sums[classic_game_type]

                        classic_games_considered_sums_array = sorted(self.classic_games_considered_sums.items(),
                                                                     key=lambda item: (item[1], item[0]), reverse=True)
                        classic_games_seen_sums_array = sorted(self.classic_games_seen_sums.items(),
                                                               key=lambda item: (item[1], item[0]), reverse=True)

                        counter = 1

                        for game_type in game_type_dict_run:

                            #                    fileHandle.write("<p></p>")
                            fileHandle.write("<p style='margin:0;'>")

                            print('\n game_type =', game_type)

                            if game_type[0] in self.game_type_dict_seen:

                                seen_num = self.game_type_dict_seen[game_type[0]]

                            else:

                                seen_num = 0

                            print('\n seen_num =', seen_num)

                            #                   Serviced print("\n considered %s : %s (%s pct)  |  seen %s (%s pct)") % (game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen))

                            fileHandle.write("\n%2d considered %s : %d (%1.6f pct)  |  seen %d (%1.6f pct)" % (
                            counter, game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num,
                            100 * seen_num / float(total_sum_seen)))

                            counter += 1

                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nTotal considered = %d (mean per sim = %1.3f), total seen = %d (mean per sim = %1.3f)" % (
                            total_sum_cons, total_sum_cons / float(self.numb_of_sims), total_sum_seen,
                            total_sum_seen / float(self.numb_of_sims)))
                        fileHandle.write("</p>")

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write(
                        "\n\nSeen Game Types (number of game types seen (unweighted) and volume (benefit to instigating agent))")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    if file_type == 'html':
                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                        counter = 1

                        for game_type in games_type_dict_3_seen:

                            #                    fileHandle.write("<p></p>")
                            fileHandle.write("<p style='margin:0;'>")

                            print('\n game_type =', game_type)

                            if game_type[0] in self.games_type_dict_2:

                                seen_num = self.games_type_dict_2[game_type[0]]

                            else:

                                seen_num = 0

                            print('\n seen_num =', seen_num)

                            #                    print("\n considered %s : %s (%s pct)  |  seen %s (%s pct)") % (game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_cons), seen_num, 100 * seen_num / float(total_sum_seen))

                            fileHandle.write("\n%2d %s : total %d (%1.6f pct)  |  volume %1.6f (%1.6f pct)" % (
                            counter, game_type[0], game_type[1], 100 * game_type[1] / float(total_sum_3), seen_num,
                            100 * seen_num / float(total_sum_2)))

                            counter += 1

                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write(
                            "\nAggregated number of games = %d (mean per sim = %1.3f), total volume = %1.3f (mean per sim = %1.3f)" % (
                            total_sum_3, total_sum_3 / float(self.numb_of_sims), total_sum_2,
                            total_sum_2 / float(self.numb_of_sims)))
                        fileHandle.write("</p>")

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\nClassic Games Considered")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    if file_type == 'html':
                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                        for classic_game_type in classic_games_considered_sums_array:
                            fileHandle.write("<p style='margin:0;'>")

                            fileHandle.write("\n%s : %d (%1.6f pct)" % (classic_game_type[0], classic_game_type[1],
                                                                        100 * classic_game_type[1] / float(
                                                                            total_sum_classics_cons)))

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\nClassic Games Seen")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    if file_type == 'html':
                        fileHandle.write("<p></p>")
                        fileHandle.write("<p style='margin:0;'>")

                        for classic_game_type in classic_games_seen_sums_array:
                            fileHandle.write("<p style='margin:0;'>")

                            fileHandle.write("\n%s : %d (%1.6f pct)" % (classic_game_type[0], classic_game_type[1],
                                                                        100 * classic_game_type[1] / float(
                                                                            total_sum_classics_seen)))

                # now we write the urls for the plotly charts
                if file_type == 'html':
                    fileHandle.write("<h2>")
                fileHandle.write("\n\n\n\nurls for plotly charts by chart category")
                if file_type == 'html':
                    fileHandle.write("</h2>")

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nagents' prop_steals\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.agents_prop_steal_urls[sim], self.agents_prop_steal_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.agents_prop_steal_urls[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nagents' prop_fight_backs\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.agents_prop_fb_urls[sim], self.agents_prop_fb_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.agents_prop_fb_urls[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nprop_steals >= 0.5 and < 0.5\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.prop_steal_above_below_50_urls[sim], self.prop_steal_above_below_50_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.prop_steal_above_below_50_urls[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nprop_fight_backs >= 0.5 and < 0.5\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.prop_fb_above_below_50_urls[sim], self.prop_fb_above_below_50_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.prop_fb_above_below_50_urls[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nprop means\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.props_means_urls[sim], self.props_means_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.props_means_urls[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\ntransactions and fights\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.trans_and_fights_urls[sim], self.trans_and_fights_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.trans_and_fights_urls[sim]))

                if two_tribes:

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nSharks\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.trans_and_fights_urls_sharks[sim], self.trans_and_fights_urls_sharks[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.trans_and_fights_urls_sharks[sim]))

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nJets\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.trans_and_fights_urls_jets[sim], self.trans_and_fights_urls_jets[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.trans_and_fights_urls_jets[sim]))

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nInter-Tribe\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.trans_and_fights_urls_inter[sim], self.trans_and_fights_urls_inter[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.trans_and_fights_urls_inter[sim]))

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\n\nfight types\n")
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for sim in range(self.numb_of_sims):

                    if file_type == 'html':
                        fileHandle.write("<p style='margin:0;'>")
                        fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                        sim + 1, self.fight_types_urls[sim], self.fight_types_urls[sim]))
                        fileHandle.write("</p>")
                    else:
                        fileHandle.write("\nsim %2d: %s" % (sim + 1, self.fight_types_urls[sim]))

                if two_tribes:

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nSharks\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.fight_types_urls_sharks[sim], self.fight_types_urls_sharks[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.fight_types_urls_sharks[sim]))

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nJets\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.fight_types_urls_jets[sim], self.fight_types_urls_jets[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.fight_types_urls_jets[sim]))

                    if file_type == 'html':
                        fileHandle.write("<h4>")
                    fileHandle.write("\n\n\nInter-Tribe\n")
                    if file_type == 'html':
                        fileHandle.write("</h4>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.fight_types_urls_inter[sim], self.fight_types_urls_inter[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.fight_types_urls_inter[sim]))

                if fight_skill:

                    if file_type == 'html':
                        fileHandle.write("<h3>")
                    fileHandle.write("\n\n\nfight skills:\n")
                    if file_type == 'html':
                        fileHandle.write("</h3>")

                    for sim in range(self.numb_of_sims):

                        if file_type == 'html':
                            fileHandle.write("<p style='margin:0;'>")
                            fileHandle.write("\nsim %2d: <a href='%s' target='_blank'>%s</a>" % (
                            sim + 1, self.fight_skills_urls[sim], self.fight_skills_urls[sim]))
                            fileHandle.write("</p>")
                        else:
                            fileHandle.write("\nsim %2d: %s" % (sim + 1, self.fight_skills_urls[sim]))

                            # if we conduct a constitutional experiment:
        if constitutional_voting == 1:

            # Now to prices and price differences
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nPrice and Price Difference Data for Voting\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            # Pricing Data
            for experiment in range(self.num_experiments):

                if experiment == 0:

                    start_round = 0
                    end_round = start_const_proces

                else:

                    start_round = start_const_proces + ((experiment - 1) * const_proc_test_period)
                    end_round = start_const_proces + (experiment * const_proc_test_period)

                if file_type == 'html':
                    fileHandle.write("<h3>")
                fileHandle.write("\n\nRounds %d to %d" % (start_round, end_round - 1))
                if file_type == 'html':
                    fileHandle.write("</h3>")

                for res_1 in np.arange(num_res_founts):
                    for res_2 in np.arange(num_res_founts):

                        if res_1 != res_2:
                            act_mean_array = [run[experiment][res_1][res_2][0] for run in self.act_prices_data]
                            act_std_array = [run[experiment][res_1][res_2][1] for run in self.act_prices_data]

                            act_mean_mean = np.mean(act_mean_array)
                            act_mean_std = np.mean(act_std_array)

                            fileHandle.write("\n\nResource %s vs Resource %s - Mean Actual Price = %3.5f (%3.5f)" % (
                            res_1, res_2, act_mean_mean, act_mean_std))

                            act_std_mean_array = [run[experiment][res_1][res_2][0] for run in self.act_std_prices_data]
                            act_std_std_array = [run[experiment][res_1][res_2][1] for run in self.act_std_prices_data]

                            act_std_mean = np.mean(act_std_mean_array)
                            act_std_std = np.mean(act_std_std_array)

                            fileHandle.write(
                                "\nResource %s vs Resource %s - Mean Daily STD of Actual Price = %3.5f (%3.5f)" % (
                                res_1, res_2, act_std_mean, act_std_std))

                            opt_mean_array = [run[experiment][res_1][res_2][0] for run in self.opt_prices_data]
                            opt_std_array = [run[experiment][res_1][res_2][1] for run in self.opt_prices_data]

                            opt_mean_mean = np.mean(opt_mean_array)
                            opt_mean_std = np.mean(opt_std_array)

                            fileHandle.write("\nResource %s vs Resource %s - Mean Optimal Price = %3.5f (%3.5f)" % (
                            res_1, res_2, opt_mean_mean, opt_mean_std))

                            diff_mean_array = [run[experiment][res_1][res_2][0] for run in self.diff_prices_data]
                            diff_std_array = [run[experiment][res_1][res_2][1] for run in self.diff_prices_data]

                            diff_mean_mean = np.mean(diff_mean_array)
                            diff_mean_std = np.mean(diff_std_array)

                            fileHandle.write(
                                "\nResource %s vs Resource %s - Mean Absolute Price Difference = %3.5f (%3.5f)" % (
                                res_1, res_2, diff_mean_mean, diff_mean_std))

            if file_type == 'html':
                fileHandle.write("<p>")
            fileHandle.write("\n\nOptimal Prices over Sims:\n")
            if file_type == 'html':
                fileHandle.write("</p>")

            means_array = np.zeros(shape=(self.numb_of_sims))
            stds_array = np.zeros(shape=(self.numb_of_sims))

            #        print('\n self.whole_sim_opt_prices_data =', self.whole_sim_opt_prices_data)

            for sim in range(self.numb_of_sims):
                means_array[sim] = self.whole_sim_opt_prices_data[sim][0]
                stds_array[sim] = self.whole_sim_opt_prices_data[sim][1]

            if file_type == 'html':
                fileHandle.write("<p>")
            fileHandle.write(
                "\nAverage Mean and Standard Deviation of Prices Over Whole Simulations (Chart Price of Res 0 in Res 1 Units): Mean = %2.5f  |  STD = %2.5f\n" % (
                np.mean(means_array), np.mean(stds_array)))
            if file_type == 'html':
                fileHandle.write("</p>")

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nConstitutional Voting: Constitution %d | Applied Constitutions = %s" % (
            constitutional_exp, self.applied_constitutions))
            if file_type == 'html':
                fileHandle.write("<h2>")

            if file_type == 'html':
                fileHandle.write("<p>")
            fileHandle.write("\n\nNotes:\n\nExperiment 1 is floating prices and market start = 0")
            fileHandle.write("\nExperiment 2 is floating prices and market start = 20")
            fileHandle.write("\nExperiment 4 is optimal prices and market start = 0")
            fileHandle.write("\nExperiment 3 is optimal prices and market start = 20")
            fileHandle.write("\nExperiment 5 is pure Walrasian Prices and Quantities")
            if file_type == 'html':
                fileHandle.write("</p>")

            fileHandle.write(
                "\n\nConstitution Process Starts = %d  |  Test Period Length = %d  |  Number of Experiments = %d" % (
                start_const_proces, const_proc_test_period, self.num_experiments))

            total_votes = np.zeros(shape=(self.num_experiments + 1), dtype=np.float64)
            num_times_won_vote_array = np.zeros(shape=(self.num_experiments + 1), dtype=np.float64)

            fileHandle.write("\n\nVoting in Each Sim:")
            fileHandle.write("\n\nExperiment \t\t ")

            for exp in range(self.num_experiments):
                fileHandle.write("%d\t" % (exp))

            fileHandle.write("\n")

            for sim in range(self.numb_of_sims):

                print('\n sim', sim)

                print(' self.agents_aggr_votes_data[sim] =', self.agents_aggr_votes_data[sim])

                fileHandle.write("\nSim no. %2d:\t\t" % (sim))

                for experiment in range(1, self.num_experiments + 1):
                    fileHandle.write("%3d\t" % (self.agents_aggr_votes_data[sim][experiment]))

                total_votes += self.agents_aggr_votes_data[sim]

                # we also want to find how many times each constitutional system was voted for
                max_votes = np.max(self.agents_aggr_votes_data[sim])

                print('\n max_votes', max_votes)

                max_votes_array = []

                for experiment in range(1, self.num_experiments + 1):

                    if max_votes == self.agents_aggr_votes_data[sim][experiment]:
                        max_votes_array.append(experiment)

                print('\n max_votes_array =', max_votes_array)

                for voted_experiment in max_votes_array:
                    num_times_won_vote_array[voted_experiment] += 1 / float(len(max_votes_array))

            print('\n num_times_won_vote_array =', num_times_won_vote_array)

            fileHandle.write("\n\nNumber of Times Each Constitution Voted For\n")

            for experiment in range(1, self.num_experiments + 1):
                fileHandle.write("\nExperiment %d: %2.2f" % (experiment, num_times_won_vote_array[experiment]))

            total_votes_prop = total_votes / float(np.sum(total_votes))

            print('\n total_votes_prop =', total_votes_prop)

            fileHandle.write("\n\nTotal Votes (in percentage terms):\n")

            for experiment in range(1, self.num_experiments + 1):
                fileHandle.write(
                    "\nExperiment %d: Percentage of Votes = %3.2f" % (experiment, total_votes_prop[experiment] * 100))

            print('\n self.const_record_res_accum_data =\n\n', self.const_record_res_accum_data)

            # Now I want to find the average gain in each experiment and the std
            fileHandle.write(
                "\n\nMean and Standard Deviations of Resources Accumulated During the Constitutional Experiment\n")

            means_array = np.zeros(shape=(self.numb_of_sims, self.num_experiments + 1))
            stds_array = np.zeros(shape=(self.numb_of_sims, self.num_experiments + 1))

            for experiment in range(1, self.num_experiments + 1):

                print('\n\n experiment ', experiment, 'self.numb_of_sims =', self.numb_of_sims)

                experiment_array = []
                sim_means = []

                for sim in range(self.numb_of_sims):

                    print('\n sim =', sim)

                    print('len(self.const_record_res_accum_data[sim][experiment]) =',
                          len(self.const_record_res_accum_data[sim][experiment]))

                    agent_data_array = np.zeros(shape=(len(self.const_record_res_accum_data[sim][experiment])))

                    for agent_num in range(len(self.const_record_res_accum_data[sim][experiment])):
                        print('\n agent_num =', agent_num)
                        print(' self.const_record_res_accum_data[sim][experiment][agent_num]=',
                              self.const_record_res_accum_data[sim][experiment][agent_num])

                        experiment_array.append(self.const_record_res_accum_data[sim][experiment][agent_num])

                        agent_data_array[agent_num] = self.const_record_res_accum_data[sim][experiment][agent_num]

                    print('\n agent_data_array =', agent_data_array)

                    mean = np.mean(agent_data_array)
                    std = np.std(agent_data_array)

                    means_array[sim][experiment] = mean
                    stds_array[sim][experiment] = std

                    sim_means.append(mean)

                print('\n experiment_array \n\n', experiment_array)

                exp_mean = np.mean(experiment_array)
                std_of_sim_means = np.std(sim_means)
                exp_std = np.std(experiment_array)

                print('\n exp_mean', exp_mean)
                print('\n exp_std', exp_std)

                fileHandle.write("\nExperiment %d: Mean = %4.4f (std of sim means %4.4f) [mean of stds %4.4f]" % (
                experiment, exp_mean, std_of_sim_means, exp_std))

            fileHandle.write("\n\nMean and STD of Agents' Accumulated Resources for Each Sim")
            fileHandle.write("\n\nExperiment\t\t")

            for exp in range(self.num_experiments):
                fileHandle.write("%d\t\t" % (exp))

            fileHandle.write("\n")

            print('\n means_array :', means_array)
            print('\n stds_array :', stds_array)

            for sim in range(self.numb_of_sims):

                print('\n sim', sim)
                #
                print(' self.agents_aggr_votes_data[sim] =', self.agents_aggr_votes_data[sim])

                fileHandle.write("\nSim no. %d:\t" % (sim))

                for experiment in range(1, self.num_experiments + 1):
                    fileHandle.write("%4.2f (%4.2f)\t" % (means_array[sim][experiment], stds_array[sim][experiment]))

        if black_shoop_exp:

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nBlack Shoop Experiment Results\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            birth_date_array = [run[0] for run in self.black_shoop_data]
            death_date_array = [run[1] for run in self.black_shoop_data]

            mean_birth_date = np.mean(birth_date_array)
            mean_death_date = np.mean(death_date_array)

            mean_life_span = mean_death_date - mean_birth_date

            if file_type == 'html':
                fileHandle.write("<p style='margin:0;'>")
            fileHandle.write(
                "\nBlack Shoops were born on (mean) day %4.3f and died on (mean) day %4.3f (mean life span = %4.3f days)\n" % (
                mean_birth_date, mean_death_date, mean_life_span))
            if file_type == 'html':
                fileHandle.write("</p>")

        # print some aggregated charts
        if respect_property_rights == 0:

            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\nSimulation Means Charts:\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            props_means_url = ''
            fight_types_url = ''

            # create files which will be sent to plotly
            prop_steal_means = np.zeros(shape=rounds)
            prop_fb_means = np.zeros(shape=rounds)

            proport_fights = np.zeros(shape=rounds)
            proport_fight_back = np.zeros(shape=rounds)
            proport_acqu = np.zeros(shape=rounds)
            proport_trans = np.zeros(shape=rounds)

            for day in range(rounds):

                aggr_prop_steal = 0
                aggr_prop_fb = 0

                num_sim_count = 0

                for sim in range(self.numb_of_sims):

                    if self.prop_steal_mean_db[sim][day] is not None:
                        aggr_prop_steal += self.prop_steal_mean_db[sim][day]
                        aggr_prop_fb += self.prop_fb_mean_db[sim][day]

                        num_sim_count += 1

                if num_sim_count != 0 and aggr_prop_steal > 0:

                    prop_steal_means[day] = aggr_prop_steal / num_sim_count

                else:

                    prop_steal_means[day] = None

                if num_sim_count != 0 and aggr_prop_fb > 0:

                    prop_fb_means[day] = aggr_prop_fb / num_sim_count

                else:

                    prop_fb_means[day] = None

            # now generate charts
            data_prop_means = []

            data_prop_means.append(
                go.Scatter(x=np.arange(rounds), y=prop_steal_means, connectgaps=False, name='Mean Propensity to Steal'))
            data_prop_means.append(
                go.Scatter(x=np.arange(rounds), y=prop_fb_means, connectgaps=False, name='Mean Propensity to Fight Back'))

            filename_prop_steal = '%s/prop_means_%d-%d-%d-%d-%d.html' % (
            self.sub_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(),
            dt.DateTime().minute())
            props_means_url = plotly.offline.plot(data_prop_means, filename=filename_prop_steal, auto_open=False)

            if plotly_online:

                filename_prop_steal = '%s/prop_means_%d-%d-%d-%d-%d' % (
                self.sub_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(),
                dt.DateTime().hour(), dt.DateTime().minute())

                try:

                    props_means_url = py.plot(data_prop_means, filename=filename_prop_steal, auto_open=False,
                                              sharing='private')

                except:

                    print('\n *** There was a problem connecting to plotly so place chart on local drive ***\n')

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n prop_means (steal and fb): \t\t\t\t\t<a href='%s' target='_blank'>%s</a>" % (
                props_means_url, props_means_url))
                fileHandle.write("</p>")
            else:
                fileHandle.write("\n prop_means (steal and fb): \t\t\t\t\t%s" % props_means_url)

            for day in range(rounds):

                aggr_both_steal = 0
                aggr_fb = 0
                aggr_acq = 0
                aggr_trade = 0

                for sim in range(self.numb_of_sims):
                    aggr_both_steal += self.num_ints_each_round[sim][1][day]
                    aggr_fb += self.num_ints_each_round[sim][2][day]
                    aggr_acq += self.num_ints_each_round[sim][4][day]
                    aggr_trade += self.num_ints_each_round[sim][6][day]

                tot_ints = aggr_both_steal + aggr_fb + aggr_acq + aggr_trade

                if tot_ints > 0 and aggr_both_steal > 0:

                    proport_fights[day] = aggr_both_steal / float(tot_ints)

                else:

                    proport_fights[day] = None

                if tot_ints > 0 and aggr_fb > 0:

                    proport_fight_back[day] = aggr_fb / float(tot_ints)

                else:

                    proport_fight_back[day] = None

                if tot_ints > 0 and aggr_acq > 0:

                    proport_acqu[day] = aggr_acq / float(tot_ints)

                else:

                    proport_acqu[day] = None

                if tot_ints > 0 and aggr_trade > 0:

                    proport_trans[day] = aggr_trade / float(tot_ints)

                else:

                    proport_trans[day] = None

            #        proport_fights = generate_MA_array(proport_fights, 10)
            #        proport_fight_back = generate_MA_array(proport_fight_back, 10)
            #        proport_acqu = generate_MA_array(proport_acqu, 10)
            #        proport_trans = generate_MA_array(proport_trans, 10)

            # now send data to plotly:
            fight_types = []

            fight_types.append(go.Scatter(x=np.arange(rounds), y=proport_fights, connectgaps=False, name='Both Steal'))
            fight_types.append(go.Scatter(x=np.arange(rounds), y=proport_fight_back, connectgaps=False,
                                          name='One Steals, Other Fights Back'))
            fight_types.append(
                go.Scatter(x=np.arange(rounds), y=proport_acqu, connectgaps=False, name='One Steals, Other Acquiesces'))
            fight_types.append(go.Scatter(x=np.arange(rounds), y=proport_trans, connectgaps=False, name='Transactions'))

            filename_fight_types = '%s/fight_types_%d-%d-%d-%d-%d.html' % (
            self.sub_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(), dt.DateTime().hour(),
            dt.DateTime().minute())
            fight_types_url = plotly.offline.plot(fight_types, filename=filename_fight_types, auto_open=False)

            if plotly_online:

                filename_fight_types = '%s/fight_types_%d-%d-%d-%d-%d' % (
                self.sub_folder, dt.DateTime().year(), dt.DateTime().month(), dt.DateTime().day(),
                dt.DateTime().hour(), dt.DateTime().minute())

                try:

                    fight_types_url = py.plot(fight_types, filename=filename_fight_types, auto_open=False,
                                              sharing='private')

                except:

                    print('\n *** There was a problem connecting to plotly so place chart on local drive ***\n')

            if file_type == 'html':
                fileHandle.write("<p></p>")
                fileHandle.write("<p style='margin:0;'>")
                fileHandle.write("\n Interaction Types: \t\t\t\t\t<a href='%s' target='_blank'>%s</a>" % (
                fight_types_url, fight_types_url))
                fileHandle.write("</p>")
            else:
                fileHandle.write("\n Interaction Types: \t\t\t\t\t%s" % fight_types_url)

        if self.print_voting_only == 0:

            # now we print out the data for the tables in the paper
            if file_type == 'html':
                fileHandle.write("<h2>")
            fileHandle.write("\n\n\n\nTable Data (re table in the paper)\n\n")
            if file_type == 'html':
                fileHandle.write("</h2>")

            if file_type == 'html':
                fileHandle.write("<table style='width:100%'>")

                fileHandle.write("<tr>")

                fileHandle.write("<th style = 'text-align: left;'>Mean Foragd (all res)</th>")
                fileHandle.write("<th style = 'text-align: left;'>Mean Spec Val</th>")
                fileHandle.write("<th style = 'text-align: left;'>Mean Max Det Prob</th>")
                fileHandle.write("<th style = 'text-align: left;'>Mean Min Res</th>")
                fileHandle.write("<th style = 'text-align: left;'>Num Sqs w trans</th>")
                fileHandle.write("<th style = 'text-align: left;'>Prop One Squared</th>")
                fileHandle.write("<th style = 'text-align: left;'>Turnover Mean</th>")

                fileHandle.write("</tr>")

                fileHandle.write("<tr>")

                fileHandle.write("<td>%s (%s)</td>" % (tab_for_mean, tab_for_std))
                fileHandle.write("<td>%s (%s)</td>" % (tab_spec_mean, tab_spec_std))
                fileHandle.write("<td>%s (%s)</td>" % (tab_det_prob_mean, tab_det_prob_std))
                fileHandle.write("<td>%s (%s)</td>" % (tab_min_res_mean, tab_min_res_std))
                fileHandle.write("<td>%s (%s)</td>" % (tab_num_sqs_mean, tab_num_sqs_std))
                fileHandle.write("<td>%s (%s)</td>" % (tab_mean_mean_prop, tab_mean_std_prop))
                fileHandle.write("<td>%s (%s)</td>" % (tab_turnover_mean, tab_turnover_std))

                fileHandle.write("</tr>")
                fileHandle.write("</table>")

            if file_type != 'html':
                fileHandle.write(
                    "\n Mean Foragd (all res) \t Mean Spec Val \t\t Mean Max Detection Prob \t Mean Min Res \t\t Num Sqs w\ Trans \t\t Proportion one square \t\t Turnover Mean \n")
                fileHandle.write(
                    "\n %s (%s)\t\t %s (%s) \t %s (%s) \t\t %s (%s) \t %s (%s) \t\t %s (%s) \t\t %s (%s)\n\n\n\n" % (
                    tab_for_mean, tab_for_std, tab_spec_mean, tab_spec_std, tab_det_prob_mean, tab_det_prob_std,
                    tab_min_res_mean, tab_min_res_std, tab_num_sqs_mean, tab_num_sqs_std, tab_mean_mean_prop,
                    tab_mean_std_prop, tab_turnover_mean, tab_turnover_std))

            if file_type == 'html':
                fileHandle.write("<p>")
            fileHandle.write(
                "\n\nNotes on data: each simulation is divided in to segments (default 10).  We find the mean and std of each metric in each segment in each run,\nso by default this gives us 10 x 2 pieces of data.\nWe then find the mean across each segment in all of the simulations.\nSo the mean is a mean of means and the std is the mean of a stds.\nFor the specialisation data, each measure in each round is a mean across agents.")
            fileHandle.write(
                "\nIn addition, the data re number of squares with transactions adds up the number of squares with transactions in each segment.  The mean is the mean of these values and the standard deviation is the std of these so it is not a mean of a std but a std of a mean...")
            fileHandle.write(
                "\n For proportion of transaction volume on one square, there is a single value for each run, for each segment so the mean is a mean of means and the std a std of means.\n\n\n")
            if file_type == 'html':
                fileHandle.write("</p>")

        if file_type == 'html':
            if file_type == 'html':
                fileHandle.write("<p> </p>")
                fileHandle.write("<p> </p>")
            fileHandle.write("</html>")


class Agent():
    """A class for instantiating agents."""

    def __init__(self, birth_date, death_date, for_strat_array, agent_res_array, detect_skills_array, basket_array,
                 location, agent_vision, grid_trgt, trading_basket, home,
                 neighs, goods_2_mkt, trade_proby,
                 trans_loc_mat, trade_loc_rec, trgt_loc_rec, sell_array, buy_array, can_trade, ag_trans_array,
                 sell_good,
                 buy_good, loc_mems_array, loc_mems_array_cp, thresh_probs_array, agent_mem_length, cp_trans_weight,
                 wait_at_tgt_moves, reached_trgt, MRS_array, aggr_res_array,
                 dummy_basket_array, for_strat_hist, equil_price_SD_exps,
                 num_act_transs, MRS_history, agent_res_array_hist, detect_skills_array_hist, optimal_transs_systemic,
                 optimal_transs_local, wkg_prices_memory, personal_turnover_ratio, basket_array_hist,
                 basket_array_start_hist,
                 total_actual_agent_sales, total_optimal_agent_sales, cognition_factor, over_sell_counter,
                 didnt_over_sell_counter, trade_movemnt,
                 foraging_strat_data, resources_to_children, hist_trade_loc_rec,
                 prop_steal, prop_fight_back, reputations_dict, fights_array, loc_fights_array, loc_fights_array_cp,
                 prop_steal_history, prop_fight_back_history, agreed_meeting_point, meeting_point_cps, tribe,
                 fight_skill, agents_die_old_age,
                 fight_skill_history):

        if type(agents_die_old_age) == int:

            self.age = random.randint(0,
                                      agents_die_old_age - 250)  # we create a variable to record the agent's age - note we don't use birth_date (which is really an instantiation date)
            # to track age this is used in the code to start certain charts

        else:

            self.age = 0

        self.birth_date = birth_date  # record agent's date of birth
        self.death_date = death_date
        self.for_strat_array = for_strat_array  # forriaging strategy array
        self.agent_res_array = agent_res_array  # agent personal resource levels
        self.detect_skills_array = detect_skills_array  # an array of probabilities: prob of detecting each resource
        self.basket_array = basket_array  # a 'basket' for holding collected resources
        self.basket_array_start = copy.copy(basket_array)  # to record the basket array prior to trading, after foraging
        self.location = location  # the location of an agent on the town_grid (assuming they seek to trade)
        self.agent_vision = agent_vision  # the distance an agent can see in the town_grid
        self.grid_trgt = grid_trgt
        self.trading_basket = trading_basket
        self.home = home
        self.neighs = neighs
        self.goods_2_mkt = goods_2_mkt
        self.trade_proby = trade_proby
        self.trans_loc_mat = trans_loc_mat
        self.trade_loc_rec = trade_loc_rec
        self.trgt_loc_rec = trgt_loc_rec
        self.sell_array = sell_array
        self.buy_array = buy_array
        # can_trade: the default of this value is 1, which means the agent can trade.  It is only set to 0 when the agent is heading straight to target without trading on the way
        self.can_trade = can_trade
        self.ag_trans_array = ag_trans_array
        self.sell_good = sell_good
        self.buy_good = buy_good
        self.loc_mems_array = loc_mems_array
        self.loc_mems_array_cp = loc_mems_array_cp
        self.thresh_probs_array = thresh_probs_array
        self.agent_mem_length = agent_mem_length
        self.cp_trans_weight = cp_trans_weight
        self.wait_at_tgt_moves = wait_at_tgt_moves
        self.reached_trgt = reached_trgt
        self.MRS_array = MRS_array
        self.aggr_res_array = aggr_res_array  # this records the total resources 'held' by the agent, which is the summation of agent_res_array and basket_array
        self.dummy_basket_array = dummy_basket_array
        self.for_strat_hist = for_strat_hist
        self.equil_price_SD_exps = equil_price_SD_exps
        self.num_act_transs = num_act_transs
        self.MRS_history = MRS_history
        self.agent_res_array_hist = agent_res_array_hist
        self.detect_skills_array_hist = detect_skills_array_hist
        self.optimal_transs_systemic = optimal_transs_systemic
        self.optimal_transs_local = optimal_transs_local
        self.wkg_prices_memory = wkg_prices_memory
        self.personal_turnover_ratio = personal_turnover_ratio
        self.basket_array_hist = basket_array_hist
        self.basket_array_start_hist = basket_array_start_hist
        self.total_actual_agent_sales = total_actual_agent_sales
        self.total_optimal_agent_sales = total_optimal_agent_sales
        self.cognition_factor = cognition_factor
        self.over_sell_counter = over_sell_counter
        self.didnt_over_sell_counter = didnt_over_sell_counter
        self.reached_tgt_on_move = 0
        self.last_transaction = 0
        self.wait_at_tgt_moves_pro_rata = wait_at_tgt_moves
        self.ignore_agents_array = []
        self.trade_movemnt = trade_movemnt
        self.number_of_children = 0
        self.resources_to_children = resources_to_children
        self.foraging_strat_data = foraging_strat_data
        self.hist_trade_loc_rec = hist_trade_loc_rec
        self.prop_steal = prop_steal
        self.prop_fight_back = prop_fight_back
        self.reputations_dict = reputations_dict
        self.fights_array = fights_array
        self.trades_array = []
        self.trans_known_about = []
        self.loc_fights_array = loc_fights_array
        self.loc_fights_array_cp = loc_fights_array_cp
        self.prop_steal_history = prop_steal_history
        self.prop_fight_back_history = prop_fight_back_history
        self.agreed_meeting_point = agreed_meeting_point
        self.meeting_point_cps = meeting_point_cps
        self.agent_last_traded_with = None  # this helps prevent agents trading repeatedly
        self.exp_returns_dict = dict()  # this records the expected returns each agent has if interacting with another agent
        self.previous_trgt = []
        self.exp_int_gains_dict = dict()
        self.exp_int_gains_dict_strangers = dict()
        self.last_intn = None
        self.tribe = tribe
        self.fight_skill = fight_skill
        self.fight_skill_history = fight_skill_history

        if fight_skill is not None:
            self.num_fights_today = 0

        self.black_shoop_file = None

        # useful data for updating black_shoop_file
        self.trans = []
        self.fights = []
        self.move_nums = []

        # create a dictionary which records the 6 expected outcomes in an interaction between 2 agents
        self.exp_rtns_matrix = dict()

        # create a dictionary to record expected returns for agent pairs
        self.expected_gains_dict = dict()

        self.parents = [None, None]

        self.agent_knows_cp_dict = dict()

        # create 2 dictionaries for last known reputations - for when agents don't have information in memory but they have had in the past
        self.last_known_rep_ps_dict = dict()
        self.last_known_rep_pfb_dict = dict()

        self.location_memories_dict = dict()
        self.location_memories_habits_dict = dict()

        self.need_to_update_reps = dict()
        self.latest_cps_dict = dict()

        self.locations_weights_hist_dict = {}

    def add_tracking_agent_data(self):

        """This method adds two variables to the tracking agent."""

        self.pre_basket_array = np.zeros(shape=(1, num_res_founts), dtype=int)
        self.pre_trading_basket = np.zeros(shape=(1, num_res_founts), dtype=int)

    def moves_randomly(self, print_fine_dets, town_grid):

        """This method moves the agent on the grid, both horizontally and vertically."""

        rand_move_vert = random.choice(np.arange(self.agent_vision * -1, (self.agent_vision * 1) + 1))

        if print_fine_dets == 1:
            print('rand_move_vert =', rand_move_vert)

        rand_move_hor = random.choice(np.arange(self.agent_vision * -1, (self.agent_vision * 1) + 1))

        if print_fine_dets == 1:
            print('rand_move_hor =', rand_move_hor)
            print('\npre agent.location[0] =', self.location[0])

        self.location[0] = (self.location[0] + rand_move_vert) % town_grid.dimen
        self.location[1] = (self.location[1] + rand_move_hor) % town_grid.dimen

        if print_fine_dets == 1:
            print('\npost agent.location =', self.location)

    def choose_new_loc(self, town_grid, print_dets, print_fine_dets, trade_movemnt, move, day, trade_when_trgt,
                       trade_moves, wait_at_tgt_moves, dbs, respect_property_rights, trade_at_trgt_precise):

        """This function selects for an individual agent a grid square to move to, which is nearest its target but not full."""

        # if trade_movemnt != 'random' and self.trade_movemnt != 'random':
        #     print_fine_dets = 1

        if print_fine_dets == 1:
            print('\n move', move)
            print('trade_movemnt =', trade_movemnt)
            print('self.trade_movemnt =', self.trade_movemnt)
            print('self.home', self.home)
            print('\n trade_moves', trade_moves)
            print(' wait_at_tgt_moves', wait_at_tgt_moves)
            print(' trade_moves - wait_at_tgt_moves', trade_moves - wait_at_tgt_moves)
            print(' trade_when_trgt =', trade_when_trgt)
            print(' self.grid_trgt =', self.grid_trgt)

            print('\n agent.home =', self.home)
            print('\n agent.trade_loc_rec =\n')
            for mo in np.arange(len(self.trade_loc_rec)):
                print(self.trade_loc_rec[mo])

            print(self.location, '<-- agent.location')
            print('\n agent.trgt_loc_rec =\n')

            for mo in np.arange(len(self.trgt_loc_rec)):
                print(self.trgt_loc_rec[mo])

            print(self.grid_trgt, '<-- agent.grid_trgt')

        if trade_movemnt == 'random' or self.trade_movemnt == 'random':

            if print_fine_dets == 1:
                print('\n Agent is moving randomly')
                print(' Old loc =', self.location)

            # create random movements:
            random_move_x = np.random.randint(-1 * self.agent_vision, self.agent_vision + 1)
            random_move_y = np.random.randint(-1 * self.agent_vision, self.agent_vision + 1)

            proposed_x = (self.location[0] + random_move_x) % town_grid.dimen
            proposed_y = (self.location[1] + random_move_y) % town_grid.dimen

            x_dist_to_home_x = math.fabs(proposed_x - self.home[0])
            x_dist_to_home_y = math.fabs(proposed_y - self.home[1])

            if x_dist_to_home_x > town_grid.dimen / 2.0:
                x_dist_to_home_x -= town_grid.dimen / 2.0

            if x_dist_to_home_y > town_grid.dimen / 2.0:
                x_dist_to_home_y -= town_grid.dimen / 2.0

            if print_fine_dets == 1:
                print('\n random_move_x', random_move_x)
                print(' random_move_y', random_move_y)
                print('x_dist_to_home_x =', x_dist_to_home_x)
                print('x_dist_to_home_y =', x_dist_to_home_y)
                print('propsed loc =', self.location[0] + random_move_x, self.location[1] + random_move_y)

            # only allow the agent to move randomly in each dimension if it is within travel bounds ((trade_moves - wait_at_tgt_moves))
            if x_dist_to_home_x <= (trade_moves - wait_at_tgt_moves):
                self.location[0] = proposed_x

            if x_dist_to_home_y <= (trade_moves - wait_at_tgt_moves):
                self.location[1] = proposed_y

            if print_fine_dets == 1:
                print('New loc =', self.location)

        elif trade_movemnt == 'set' and self.trade_movemnt == 'set':

            if trade_when_trgt == 1:

                #                self.location
                #                self.agent_vision
                #                self.grid_trgt

                x_dist = self.grid_trgt[0] - self.location[0]
                y_dist = self.grid_trgt[1] - self.location[1]

                if print_fine_dets == 1:
                    print('\n Start loc =', self.location)
                    print('self.grid_trgt =', self.grid_trgt)
                    print('self.agent_vision =', self.agent_vision)
                    print('start x_dist =', x_dist)
                    print('start y_dist =', y_dist)

                # x_dist correct distances given the grid is a torus so agents will travel shortest distance
                if x_dist >= (town_grid.dimen / 2.0):

                    x_dist = -1 * (town_grid.dimen - x_dist)

                elif x_dist < -1 * (town_grid.dimen / 2.0):

                    x_dist = town_grid.dimen + x_dist

                # Now the agents move an appropriate amount
                if x_dist >= self.agent_vision:

                    self.location[0] = (self.location[0] + self.agent_vision) % town_grid.dimen

                elif 0 < x_dist < self.agent_vision:

                    self.location[0] = (self.location[0] + x_dist) % town_grid.dimen

                elif x_dist <= -1 * self.agent_vision:

                    self.location[0] = (self.location[0] - self.agent_vision) % town_grid.dimen

                elif -1 * self.agent_vision < x_dist < 0:

                    self.location[0] = (self.location[0] - x_dist) % town_grid.dimen

                # y_dist: correct distances given the grid is a torus so agents will travel shortest distance
                if y_dist >= (town_grid.dimen / 2.0):

                    y_dist = -1 * (town_grid.dimen - y_dist)

                elif y_dist < -1 * (town_grid.dimen / 2.0):

                    y_dist = town_grid.dimen + y_dist

                # Now the agents move an appropriate amount
                if y_dist >= self.agent_vision:

                    self.location[1] = (self.location[1] + self.agent_vision) % town_grid.dimen

                elif 0 < y_dist < self.agent_vision:

                    self.location[1] = (self.location[1] + y_dist) % town_grid.dimen

                elif y_dist <= -1 * self.agent_vision:

                    self.location[1] = (self.location[1] - self.agent_vision) % town_grid.dimen

                elif -1 * self.agent_vision < y_dist < 0:

                    self.location[1] = (self.location[1] - y_dist) % town_grid.dimen

                if print_fine_dets == 1:
                    #                    print('\n end x_dist =', x_dist)
                    #                    print(' end y_dist =', y_dist)
                    print('\n Final loc =', self.location)

                # update x_dist and y_dist post-move
                x_dist_post_move = self.grid_trgt[0] - self.location[0]
                y_dist_post_move = self.grid_trgt[1] - self.location[1]

                # x_dist correct distances given the grid is a torus so agents will travel shortest distance
                if x_dist_post_move > (town_grid.dimen / 2.0):
                    x_dist_post_move = town_grid.dimen - x_dist_post_move

                if y_dist_post_move > (town_grid.dimen / 2.0):
                    y_dist_post_move = town_grid.dimen - y_dist_post_move

                if print_fine_dets == 1:
                    print('\n x_dist_post_move =', x_dist_post_move)
                    print(' y_dist_post_move =', y_dist_post_move)

                # if the agent respects property rights then it doesn't trade until it reaches its target
                if respect_property_rights == 1 and x_dist_post_move == 0 and y_dist_post_move == 0:

                    if print_fine_dets == 1:
                        print('\n setting can_trade = 1, reached_trgt = 1, reached_tgt_on_move =', move)

                    self.can_trade = 1
                    self.reached_trgt = 1
                    self.reached_tgt_on_move = move

                else:

                    if print_fine_dets == 1:
                        print('\n self.can_trade =', self.can_trade, 'self.reached_trgt =', self.reached_trgt)

                # agents can trade when they are next to the market when they do not respect property rights -
                # this prevents them going on to a location blindly and getting mugged: then they are 1 step away so they evaluate whether to go on it
                if respect_property_rights == 0:

                    if trade_at_trgt_precise == 0 and np.abs(x_dist_post_move) <= 1 and np.abs(y_dist_post_move) <= 1:

                        if print_fine_dets == 1:
                            print(
                                '\n respect_property_rights == 0 and x_dist <= 1 and y_dist <= 1 so setting can_trade = 1, reached_trgt = 1, reached_tgt_on_move =',
                                move)

                        self.can_trade = 1
                        self.reached_trgt = 1
                        self.reached_tgt_on_move = move

                    elif trade_at_trgt_precise == 1 and x_dist_post_move == 0 and y_dist_post_move == 0:

                        if print_fine_dets == 1:
                            print(
                                '\n trade_at_trgt_precise == 0 and x_dist_post_move == 0 and y_dist_post_move == 0 so setting can_trade = 1, reached_trgt = 1, reached_tgt_on_move =',
                                move)

                        self.can_trade = 1
                        self.reached_trgt = 1
                        self.reached_tgt_on_move = move

            # we only want to use this more complicated approach if the agents are trading on their way to the target
            elif trade_when_trgt == 0:

                poss_locs_dimen = (self.agent_vision * 2) + 1

                if print_dets == 1:
                    print('\n*** starting choose_new_loc function ***')
                    print('\nagent.location =', self.location)
                    print('agent.grid_trgt =', self.grid_trgt)
                    print('\nposs_locs_dimen =', poss_locs_dimen)

                poss_locs_array = np.zeros(shape=(poss_locs_dimen, poss_locs_dimen), dtype=float)
                # e.g. if agent_vision = 3 then it can choose among a 7 x 7 grid.

                agent_tally_array = np.zeros(shape=(poss_locs_dimen, poss_locs_dimen), dtype=float)

                #        if print_fine_dets == 1:
                #            print '\ntown_grid.grid_agents:\n', town_grid.grid_agents

                for poss_locs_x_coord in np.arange(poss_locs_dimen):

                    grid_equiv_x = (poss_locs_x_coord + self.location[0] - self.agent_vision) % town_grid.dimen

                    x_dist = math.fabs(self.grid_trgt[0] - grid_equiv_x)

                    if x_dist > town_grid.dimen / 2.0:
                        x_dist = town_grid.dimen - x_dist

                    for poss_locs_y_coord in np.arange(poss_locs_dimen):

                        grid_equiv_y = (poss_locs_y_coord + self.location[1] - self.agent_vision) % town_grid.dimen

                        y_dist = math.fabs(self.grid_trgt[1] - grid_equiv_y)

                        if y_dist > town_grid.dimen / 2.0:
                            y_dist = town_grid.dimen - y_dist

                        #                if print_fine_dets == 1:
                        #                    print '\nposs_locs_x_coord =', poss_locs_x_coord
                        #                    print 'poss_locs_y_coord =', poss_locs_y_coord
                        #                    print 'grid_equiv_x =', grid_equiv_x
                        #                    print 'x_dist =', x_dist
                        #                    print 'grid_equiv_y =', grid_equiv_y
                        #                    print 'y_dist =', y_dist
                        #                    print 'town_grid.grid_agents[grid_equiv_x][grid_equiv_y] =', town_grid.grid_agents[grid_equiv_x][grid_equiv_y]
                        #                    print 'grid_equiv_x, grid_equiv_y', grid_equiv_x, grid_equiv_y, 'len =', len(town_grid.grid_agents[grid_equiv_x][grid_equiv_y])

                        # Here we set agent.can_trade = 1 if one of the agent's possible locations (full or not) is its grid_trgt
                        if x_dist == 0 and y_dist == 0:
                            self.can_trade = 1
                            self.reached_trgt = 1
                            self.reached_tgt_on_move = move

                            # we set ignore_agents_array to blank - agent can now trade with whomever
                            self.ignore_agents_array = []

                        # Now we work out how many moves to target from current location
                        moves_to_trgt = int(
                            math.ceil(np.max([np.fabs(x_dist), np.fabs(y_dist)]) / float(self.agent_vision)))

                        # For monitoring:
                        if len(town_grid.grid_agents[grid_equiv_x][grid_equiv_y]) > 0:
                            #                        print 'poss_locs_x_coord, poss_locs_y_coord', poss_locs_x_coord, poss_locs_y_coord, 'len =', len(town_grid.grid_agents[grid_equiv_x][grid_equiv_y])
                            agent_tally_array[poss_locs_x_coord][poss_locs_y_coord] = len(
                                town_grid.grid_agents[grid_equiv_x][grid_equiv_y])

                        # We have removed the agent from town_grid.grid_agents prior to running this function so we add 1 manually to agent_tally_array
                        if grid_equiv_x == self.location[0] and grid_equiv_y == self.location[1]:
                            agent_tally_array[poss_locs_x_coord][poss_locs_y_coord] += 1

                        poss_locs_array[poss_locs_x_coord][poss_locs_y_coord] = moves_to_trgt

                if print_dets == 1:
                    print('\nagent_tally_array:\n')
                    for array in agent_tally_array:
                        print(array)

                    print('\nposs_locs_array:\n')
                    for array in poss_locs_array:
                        print(array)

                # Now we need to find the minimum of poss_locs_array: this is the square we want to move on to.

                min_crow_dist = np.min(poss_locs_array)
                if print_dets == 1:
                    print('\nmin_crow_dist =', min_crow_dist, '\n')

                # Now find out which square(s) for which this is true
                # In case there is more than one, create an array to record all of the possible new locations

                new_locs_choices_array = []

                for x_coord in np.arange(poss_locs_dimen):
                    for y_coord in np.arange(poss_locs_dimen):

                        #                if print_fine_dets == 1:
                        #                    print 'x, y =', (x_coord + self.location[0] - self.agent_vision) % town_grid.dimen, ',', (y_coord + self.location[1] - self.agent_vision) % town_grid.dimen, '=', poss_locs_array[x_coord][y_coord]

                        if poss_locs_array[x_coord][y_coord] == min_crow_dist:

                            if print_dets == 1:
                                print('min_distance at [', x_coord, ',', y_coord, ']')

                            new_locs_choices_array.append(np.array(
                                [(x_coord + self.location[0] - self.agent_vision) % town_grid.dimen,
                                 (y_coord + self.location[1] - self.agent_vision) % town_grid.dimen]))

                        if poss_locs_array[x_coord][y_coord] == town_grid.dimen ** 2:

                            if print_dets == 1:
                                print('----> grid square', x_coord, y_coord, 'is full <----')

                if print_dets == 1:
                    print('\n new_locs_choices_array =', new_locs_choices_array)

                # There is a possibility (v minor with default parameters) that all of the potential new locations are full - if this is
                # the case the then agent remains in its current location

                # We will know all the squares are not full if this condition holds (if all full then all array values will be the same):
                if min_crow_dist != np.max(poss_locs_array):
                    # If this is true, we choose a location from new_locs_choices_array randomly
                    self.location = random.choice(new_locs_choices_array)

                if print_dets == 1:
                    print('\nagent.home =', self.home)
                    print('\nagent.trade_loc_rec =\n')
                    for mo in np.arange(len(self.trade_loc_rec)):
                        print(self.trade_loc_rec[mo])

                    print(self.location, '<-- agent.location')
                    print('\nagent.trgt_loc_rec =\n')

                    for mo in np.arange(len(self.trgt_loc_rec)):
                        print(self.trgt_loc_rec[mo])

                    print(self.grid_trgt, '<-- agent.grid_trgt')

        if print_fine_dets == 1:
            print('\n END of choose_new_loc method: self.can_trade =', self.can_trade, 'self.reached_trgt =', self.reached_trgt)

        # if trade_movemnt != 'random' and self.trade_movemnt != 'random':
        #     pause()

    #        if print_fine_dets == 1:
    #
    #            input("Press Enter to continue...")

    def update_agent_MRS_array(self, print_dets, print_fine_dets, agent_population):

        """This method updates the agent's MRS_array."""

        # if print_dets == 1:
        #     print('\n\n\n*** starting update_agent_MRS_array ***')

        # First find the agents' total amounts of each resource
        self.aggr_res_array = self.agent_res_array + self.basket_array

        # if print_fine_dets == 1:
        #     print('\n--> ag =', self)
        #     print('ag.agent_res_array =', self.agent_res_array)
        #     print('ag.basket_array =', self.basket_array)
        #     print('ag.aggr_res_array =', self.aggr_res_array)

        self.MRS_array = generate_MRS_array(self.aggr_res_array, print_fine_dets)

        # if print_dets == 1:
        #     print('\nagent.MRS_array:\n', self.MRS_array)
        #     print('\n*** ENDING update_agent_MRS_array ***')

    def find_exp_returns_intn(self, params, pot_cp, agent_population, print_dets, price_mean, force_prices, fixed_price, day, dbs, fountain_population, fight_cost, len_reputations_mem, intn_error_std, print_fine_dets, fight_balance,
                              adjust_props_r, agent_intn_beta, move, formal_inst, prob_fine, fine, simulated_int, fight_skill, fix_ps_fb_0, stranger_int, strat_choice, strangers_if_unknown):

        """This method calculates the expected gains from interaction given the agents' prop_steal and prop_fight_back; and each other's perception of those two values."""

        if params.calc_timings:
            start_find_exp_rtnn_time = dt.DateTime()

        # if str(pot_cp) in self.exp_int_gains_dict and (self.exp_int_gains_dict[str(pot_cp)][0] is not pot_cp.last_intn or self.exp_int_gains_dict[str(pot_cp)][1] is not self.last_intn):
        # if str(pot_cp) in self.exp_int_gains_dict and (self.exp_int_gains_dict[str(pot_cp)][0] is pot_cp.last_intn or self.exp_int_gains_dict[str(pot_cp)][1] is self.last_intn):
        # if simulated_int:
        #     print_dets = print_fine_dets = 1

        # print_fine_dets = 1

        if print_fine_dets:

            print('\n\n\n -------------------------- starting agent.find_exp_returns_intn (move = ', move, ') ----------------------------\n')

            if str(pot_cp) in self.exp_int_gains_dict:
                print('\n self.exp_int_gains_dict[str(pot_cp)] =', self.exp_int_gains_dict[str(pot_cp)])
            print('\n pot_cp.last_intn', pot_cp.last_intn)
            print('\n self.last_intn', self.last_intn)
            print('\n simulated_int', simulated_int)

        # we first use a short cut - if neither agent has interacted since the last time 'self' evaluated this pot_cp agent then we can use the previous evaluation's agent_total_exp_gain
        # and pot_cp_total_exp_gain (before any variation).  This means we don't process more code than we need to.  Note this does not mean, conceptually, that the agents are omniscient, it's
        # just a coding short cut.

        # we assume a new evaluation is required unless certain criteria met
        new_eval_requd = 1

        if str(pot_cp) in self.exp_int_gains_dict and simulated_int == 0:

            known_cp_int_data = self.exp_int_gains_dict[str(pot_cp)]

            # if this condition is true then neither the cp_agent nor the agent have interacted since the last time the agent evaluated the outcomes for cp_agent so we can use the previous evaluation
            if known_cp_int_data[0] == pot_cp.last_intn and known_cp_int_data[1] == self.last_intn:

                if print_fine_dets:
                    print('\n we are using a previous evaluation as a short cut')

                agent_total_exp_gain, pot_cp_total_exp_gain = known_cp_int_data[2]

                if params.track_game_types:
                    des_string = known_cp_int_data[3]
                    classic_game_type = known_cp_int_data[4]

                new_eval_requd = 0

        if new_eval_requd:

            if print_fine_dets:
                print('\n A new evaluation is required')

            # the first thing we do is to estimate the pot_cp's propensities to steal and fight back
            pot_cp_prop_steal, pot_cp_prop_fight_back, num_interactions = find_cp_props(self, pot_cp, day, len_reputations_mem, print_fine_dets)

            if print_fine_dets == 1:
                print('\n estimated pot_cp_prop_steal', pot_cp_prop_steal, '\t\t actual =', pot_cp.prop_steal)
                print(' estimated pot_cp_prop_fight_back', pot_cp_prop_fight_back, '\t actual =', pot_cp.prop_fight_back)

            # we run a function, form_exps_rtns_props()
            agent_total_exp_gain, pot_cp_total_exp_gain, exp_rtns_matrix = \
                form_exps_rtns_props(params, self, pot_cp, pot_cp_prop_steal, pot_cp_prop_fight_back, agent_population, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, simulated_int, adjust_props_r,
                                     agent_intn_beta, fight_balance, fight_cost, formal_inst, prob_fine, fine, print_fine_dets, fight_skill, stranger_int, strat_choice, strangers_if_unknown)

            # update self.exp_int_gains_dict[str(pot_cp)] so we might shortcut later
            self.exp_int_gains_dict[str(pot_cp)] = [pot_cp.last_intn, self.last_intn, [agent_total_exp_gain, pot_cp_total_exp_gain]]

            # apply exp_rtns_matrix to agent's own self.exp_rtns_matrix - if this cp_agent is selected to interact with the agent, this matrix will be used to record what type of 'game' it is
            self.exp_rtns_matrix[str(pot_cp)] = exp_rtns_matrix

            # if we are recording game types:
            if simulated_int == 0 and params.track_game_types:

                self.exp_int_gains_dict[str(pot_cp)].append(exp_rtns_matrix[6])
                self.exp_int_gains_dict[str(pot_cp)].append(exp_rtns_matrix[7])

                des_string = exp_rtns_matrix[6]
                classic_game_type = exp_rtns_matrix[7]

        # add to dictionaries if not simulating the interaction
        if simulated_int == 0 and params.track_game_types:

            if des_string in dbs.games_type_considered_dict:

                dbs.games_type_considered_dict[des_string][day] += 1

            else:

                dbs.games_type_considered_dict[des_string] = np.zeros(shape=dbs.num_rounds, dtype=int)

                dbs.games_type_considered_dict[des_string][day] += 1

            if classic_game_type in dbs.classic_games_considered:

                dbs.classic_games_considered[classic_game_type][day] += 1

            else:

                dbs.classic_games_considered[classic_game_type] = np.zeros(shape=dbs.num_rounds, dtype=int)

                dbs.classic_games_considered[classic_game_type][day] += 1

        if str(pot_cp) in self.exp_int_gains_dict and print_fine_dets == 1:
            print('\n New Evaluation: self.exp_int_gains_dict[str(pot_cp)] =', self.exp_int_gains_dict[str(pot_cp)], '\n')

        if print_fine_dets:
            print('\n self.exp_rtns_matrix[str(pot_cp)]', self.exp_rtns_matrix[str(pot_cp)])

        # Now we add an error value to the expected gains / losses
        # if we are testing code or printing code then we do this long hand; otherwise, go straight for shorthand
        if params.run_code_tests or print_fine_dets:

            ag_gain_no_error = copy.copy(agent_total_exp_gain)
            cp_gain_no_error = copy.copy(pot_cp_total_exp_gain)

            if np.sum(pot_cp.basket_array) > 0:

                agent_intn_error = random.normalvariate(0, intn_error_std)
                pot_cp_intn_error = random.normalvariate(0, intn_error_std)

            else:

                agent_intn_error = 0.0
                pot_cp_intn_error = 0.0

            agent_total_exp_gain += agent_intn_error
            pot_cp_total_exp_gain += pot_cp_intn_error

        else:

            if np.sum(pot_cp.basket_array) > 0:

                agent_total_exp_gain += random.normalvariate(0, intn_error_std)
                pot_cp_total_exp_gain += random.normalvariate(0, intn_error_std)

        if print_fine_dets:

            print('\n agent_intn_error %4.3f' % agent_intn_error, 'ag_gain_no_error %4.3f => post-error %4.3f ' % (ag_gain_no_error, agent_total_exp_gain))
            print(' pot_cp_intn_error %4.3f' % pot_cp_intn_error, 'cp_gain_no_error %4.3f => post-error %4.3f ' % (cp_gain_no_error, pot_cp_total_exp_gain))

            print('\n self.agent_res_array', self.agent_res_array, 'pot_cp.agent_res_array', pot_cp.agent_res_array)
            print(' self.basket_array', self.basket_array, 'pot_cp.basket_array', pot_cp.basket_array, '\n')

            # pause()

        if params.run_code_tests:

            # a test to ensure code working ok - this test the returns matrix, specifically the values regarding acquiescing
            if (simulated_int and agent_basket_array[0][0] > 0.0 and agent_basket_array[0][1] > 0.0 and self.exp_rtns_matrix[str(pot_cp)][2][0] == 0.0) or\
                (simulated_int == 0 and self.basket_array[0][0] > 0.0 and self.basket_array[0][1] > 0.0 and self.exp_rtns_matrix[str(pot_cp)][2][0] == 0.0):

                print('\n ok euston we have a problem... in Agent.find_exp_returns_intn method')
                print('\n agent_basket_array =', agent_basket_array)
                print('\n cp_agent_basket_array =', cp_agent_basket_array)
                print('\n self.exp_rtns_matrix[str(pot_cp)] =', self.exp_rtns_matrix[str(pot_cp)])
                print('\n self.exp_int_gains_dict[str(pot_cp)] =', self.exp_int_gains_dict[str(pot_cp)])
                pause()

            # Another tet of the code
            if (simulated_int == 0 and (pot_cp.basket_array[0][0] == 0 and pot_cp.basket_array[0][1] == 0) and (self.basket_array[0][0] > 0 or self.basket_array[0][1] > 0)) or \
                    (simulated_int and (cp_agent_basket_array[0][0] == 0 and cp_agent_basket_array[0][1] == 0) and (agent_basket_array[0][0] > 0 or agent_basket_array[0][1] > 0)):

                if ag_gain_no_error > 0 and cp_gain_no_error < 0:
                    print('\n BIIIIG PROBLEM in find_exp_returns_intn - day ', day, 'move', move)
                    print('\n self.home', self.home, 'self.basket_array', self.basket_array)
                    print('\n pot_cp.home', pot_cp.home, 'pot_cp.basket_array', pot_cp.basket_array)
                    print('\n agent_total_exp_gain', agent_total_exp_gain)
                    print(' pot_cp_total_exp_gain', pot_cp_total_exp_gain)
                    print(' new_eval_requd', new_eval_requd)
                    print(' simulated_int', simulated_int)
                    print(' ag_gain_no_error', ag_gain_no_error)
                    print(' cp_gain_no_error', cp_gain_no_error)

                    print('\n New Evaluation: self.exp_int_gains_dict[str(pot_cp)] =', self.exp_int_gains_dict[str(pot_cp)],
                          '\n')

                    print('\n self.exp_rtns_matrix[str(pot_cp)] =', self.exp_rtns_matrix[str(pot_cp)])

                    pause()

        if params.calc_timings:
            dbs.timings_dict['trading_move_agent_bilat_eval'][day] += dt.DateTime() - start_find_exp_rtnn_time

        return agent_total_exp_gain, pot_cp_total_exp_gain

    def evaluate_exp_rtns_all_grid_sqs(self, params, town_grid, own_loc_exp_rtn, exp_cp_returns_array, agent_population,
                                       print_dets, price_mean, force_prices, fixed_price,
                                       day, move, dbs, fountain_population, fight_cost, len_reputations_mem,
                                       intn_error_std, print_fine_dets, agent_avoid_muggers, fight_balance,
                                       adjust_props_r, agent_intn_beta, two_tribes, formal_inst, prob_fine, fine,
                                       fight_skill, fix_ps_fb_0, two_tribes_inst, strat_choice,
                                       stranger_int, strangers_if_unknown, respect_property_rights, trade_when_trgt,
                                       track_agent):

        """This method looks at all the grid squares around the agent and evaluates the expected return from interacting with any of the agents, and provides a mean expected
        return for each of the grid squares"""

        no_neighs = 0
        tracking_agent_here = 0

        # if track_agent is not None and agent_population.tracking_agent == self:
        #     print_fine_dets = 1

        # if track_agent is not None:
        #
        #     for i in [-1, 0, 1]:
        #
        #         for j in [-1, 0, 1]:
        #
        #             x_coord = (self.location[0] + i) % town_grid.dimen
        #             y_coord = (self.location[1] + j) % town_grid.dimen
        #
        #             if i == 0 and j == 0 and len(town_grid.grid_agents[x_coord][y_coord]) > 1:
        #
        #                 for ag in town_grid.grid_agents[x_coord][y_coord]:
        #                     if ag not in agent_population.tracking_agent.ignore_agents_array:
        #
        #                         no_neighs += 1
        #
        #             if (i == 0 and j == 0) == False and len(town_grid.grid_agents[x_coord][y_coord]) > 0:
        #
        #                 for ag in town_grid.grid_agents[x_coord][y_coord]:
        #                     if ag not in agent_population.tracking_agent.ignore_agents_array:
        #
        #                         no_neighs += 1
        #
        #             if agent_population.tracking_agent in town_grid.grid_agents[x_coord][y_coord]:
        #                 tracking_agent_here = 1
        #
        #             if self is not agent_population.tracking_agent and agent_population.tracking_agent in \
        #                     town_grid.grid_agents[x_coord][y_coord]:
        #                 print('\n evaluate_exp_rtns_all_grid_sqs: our tracking agent is in the vicinity of another agent')
        #
        #     if no_neighs >= 1 and tracking_agent_here:
        #
        #         print_fine_dets = 1

        if track_agent is not None and self == agent_population.tracking_agent:
            print_fine_dets = 1

        if print_fine_dets == 1:
            print('\n\n\n **** Starting evaluate_exp_rtns_all_grid_sqs (day = %d, move = %d)' % (day, move))

            print('\n agent.trade_loc_rec =\n')
            print(self.home, '<-- agent.home')
            for mo in np.arange(len(self.trade_loc_rec)):
                print('end of move', mo, '\t', self.trade_loc_rec[mo])

            print(self.location, '<-- self.location')

            print('\n   self.basket_array', self.basket_array)
            print('  self.agent_res_array', self.agent_res_array)

            for i in range(-1, 2):

                for j in range(-1, 2):

                    x_coord = (self.location[0] + i) % town_grid.dimen
                    y_coord = (self.location[1] + j) % town_grid.dimen

                    if len(town_grid.grid_agents[x_coord][y_coord]) > 0:

                        print('\n grid loc', x_coord, y_coord, 'i', i, 'j', j,
                              'len(town_grid.grid_agents[x_coord][y_coord]) ',
                              len(town_grid.grid_agents[x_coord][y_coord]))

                        for ag in town_grid.grid_agents[x_coord][y_coord]:

                            if ag is not self:

                                print('\n   ag.basket_array', ag.basket_array)
                                print(' ag.agent_res_array', ag.agent_res_array)

                                print('\n ag.trade_loc_rec =\n')
                                print(ag.home, '<-- ag.home')
                                for mo in np.arange(len(ag.trade_loc_rec)):
                                    print('end of move', mo, '\t', ag.trade_loc_rec[mo])

                                print(ag.location, '<-- ag.location')

            #                        no_neighs = 1

            # if no_neighs:
            #     pause()

        neigh_exp_returns_array = np.zeros(shape=(3, 3))

        # and own expected return at current square
        neigh_exp_returns_array[1][1] = own_loc_exp_rtn

        line = [[] for i in range(3)]
        neigh_cp_exp_returns_array = [copy.deepcopy(line) for j in range(3)]

        # place own square cp_returns in neigh_cp_exp_returns_array
        neigh_cp_exp_returns_array[1][1] = exp_cp_returns_array

        if print_fine_dets == 1:
            print('\n self.home', self.home)
            print(' self.location', self.location)
            #            print('\n neigh_exp_returns_array\n\n', neigh_exp_returns_array)
            print(' own_loc_exp_rtn', own_loc_exp_rtn)
            print(' exp_cp_returns_array', exp_cp_returns_array)
            print(' self.ignore_agents_array:', self.ignore_agents_array)
            print(' strangers_if_unknown', strangers_if_unknown, '\n')

        # these values default to the current location
        max_mean_exp_return = own_loc_exp_rtn
        max_grid_square = copy.copy(self.location)

        # we start with number of neighbours equal to the number of pot_cps on current square
        number_neighbours = len(neigh_cp_exp_returns_array[1][1])

        head_to_target = 1

        # we have to record the squares where there are no agents and the expected return is zero - if the max_mean_exp_return ends up as zero then we choose one of these randomly
        squares_w_zero_exp_rtn = []

        for i in [-1, 0, 1]:

            for j in [-1, 0, 1]:

                if (i == 0 and j == 0) == False:

                    x_coord = (self.location[0] + i) % town_grid.dimen
                    y_coord = (self.location[1] + j) % town_grid.dimen

                    # if len(town_grid.grid_agents[x_coord][y_coord]) > 5:
                    #     print_fine_dets = 1

                    if print_fine_dets == 1:
                        print('\n i ', i, 'j ', j)
                        print(' x_coord', x_coord, 'y_coord', y_coord)

                    # agents_on_squ = copy.copy(town_grid.grid_agents[x_coord][y_coord])
                    agent_list = []

                    # start with iter of zero - this will help iterate through agents on square
                    iter = 0
                    # one condition for ending while loop is finished_iter = 1 (last agent)
                    finished_iter = 0

                    if len(town_grid.grid_agents[x_coord][y_coord]) > 0:

                        # we create a while loop which works whether params.limit_agent_interaction is positive or None.  If positive, the while loop continues until the number of selected agents equals the limit; and
                        # if None, agents are selected based on the criteria below - there is no limit
                        while (params.limit_agent_interaction and len(agent_list) < params.limit_agent_interaction and finished_iter == 0) or \
                              (params.limit_agent_interaction == None and finished_iter == 0):

                            pot_cp = town_grid.grid_agents[x_coord][y_coord][iter]

                            if print_fine_dets:
                                print('\n iter =', iter)
                                print(' pot_cp: ', pot_cp)

                            accept_agent = 1

                            if respect_property_rights and pot_cp.can_trade == 0:
                                accept_agent = 0

                                if print_fine_dets:
                                    print('\n respect_property_rights == 1 and pot_cp.can_trade == 0')

                            elif self.agent_last_traded_with is pot_cp and pot_cp.agent_last_traded_with is self:
                                accept_agent = 0

                                if print_fine_dets:
                                    print('\n agent.agent_last_traded_with is pot_cp and pot_cp.agent_last_traded_with is agent')

                            elif any(res < 0.0 for res in pot_cp.agent_res_array[0]):
                                accept_agent = 0

                                if print_fine_dets:
                                    print('\n any(res < 0.0 for res in pot_cp.agent_res_array[0])')

                            elif trade_when_trgt == 0 and self.reached_trgt == 0 and pot_cp in self.ignore_agents_array:
                                accept_agent = 0

                                if print_fine_dets:
                                    print('\n trade_when_trgt == 0 and agent.reached_trgt == 0 and pot_cp in agent.ignore_agents_array')

                            elif two_tribes == 1 and agent_population.ignore_strangers == 1 and pot_cp.tribe != agent.tribe:
                                accept_agent = 0

                                if print_fine_dets:
                                    print('\n two_tribes == 1 and agent_population.ignore_strangers == 1 and pot_cp.tribe != agent.tribe')

                            # if none of the above conditions are true, add pot_cp to agent_crop_list
                            if accept_agent == 1:
                                agent_list.append(pot_cp)

                                if print_fine_dets:
                                    print('\n agent passed all tests - added to agent_crop_list')

                            # add 1 to iter
                            if iter < len(town_grid.grid_agents[x_coord][y_coord]) - 1:
                                iter += 1

                            # unless we have come to the end of the iterations
                            else:
                                finished_iter = 1
                                if print_fine_dets:
                                    print('\n this was the last iteration')

                        if print_fine_dets:
                            print('\n END agent_list:', agent_list)
                            # pause()
                            # print_fine_dets = 0

                    exp_returns_array = []

                    for pot_cp in agent_list:

                        number_neighbours += 1

                        if print_fine_dets:
                            print('\n strat_choice', strat_choice)
                            print(' strangers_if_unknown', strangers_if_unknown)
                            print(' self.agent_knows_cp_dict[str(pot_cp)]', self.agent_knows_cp_dict[str(pot_cp)])
                            print(' pot_cp.agent_knows_cp_dict[str(self)]', pot_cp.agent_knows_cp_dict[str(self)])

                        if self.tribe == pot_cp.tribe and strat_choice == 'heuristics' and (
                                strangers_if_unknown == 0 or (
                                strangers_if_unknown and self.agent_knows_cp_dict[str(pot_cp)] and
                                pot_cp.agent_knows_cp_dict[str(self)])):

                            #                            if no_neighs:
                            #                                print_fine_dets = 0
                            agent_exp_rtn, pot_cp_exp_rtn = self.find_exp_returns_intn(params, pot_cp, agent_population,
                                                                                       print_dets, price_mean,
                                                                                       force_prices, fixed_price, day,
                                                                                       dbs, fountain_population,
                                                                                       fight_cost, len_reputations_mem,
                                                                                       intn_error_std, print_fine_dets,
                                                                                       fight_balance, adjust_props_r,
                                                                                       agent_intn_beta,
                                                                                       move, formal_inst, prob_fine,
                                                                                       fine, simulated_int=0,
                                                                                       fight_skill=fight_skill,
                                                                                       fix_ps_fb_0=fix_ps_fb_0,
                                                                                       stranger_int=stranger_int,
                                                                                       strat_choice=strat_choice,
                                                                                       strangers_if_unknown=strangers_if_unknown)

                            exp_returns_array.append(agent_exp_rtn)
                            neigh_cp_exp_returns_array[i + 1][j + 1].append(pot_cp_exp_rtn)
                        #                            if no_neighs:
                        #                                print_fine_dets = 1

                        # if they are strangers
                        elif (agent_population.ignore_strangers == 0 and self.tribe != pot_cp.tribe) or \
                              strat_choice == 'rational' or \
                              strat_choice == 'heuristics' and strangers_if_unknown and (self.agent_knows_cp_dict[str(pot_cp)] == 0 or pot_cp.agent_knows_cp_dict[str(self)] == 0):

                            use_start_basket = 0
                            agent_dec, cp_agent_dec, agent_exp_rtn, pot_cp_exp_rtn = strangers_interact(
                                params, agent_population.min_trans_Q, price_mean,
                                force_prices, fixed_price, day, dbs, fountain_population,
                                print_dets, print_fine_dets, use_start_basket, self, pot_cp,
                                agent_population.stranger_int, formal_inst, prob_fine, fine, two_tribes_inst,
                                fight_cost)

                            # we only include them is there is a clear dominant strategy from both
                            if agent_dec != 'none' and cp_agent_dec != 'none':
                                exp_returns_array.append(agent_exp_rtn)
                                neigh_cp_exp_returns_array[i + 1][j + 1].append(pot_cp_exp_rtn)

                        else:

                            print(
                                '\n PROBLEM in agent.evaluate_exp_rtns_all_grid_sqs - neither condition held above but one of them must')
                            print_fine_dets = 1

                        #                        pause()

                        if print_fine_dets == 1:
                            print('\n agent.prop_steal', self.prop_steal, 'self.prop_fight_back', self.prop_fight_back)
                            print(' agent.agent_res_array', self.agent_res_array[0])
                            print(' agent.basket_array', self.basket_array[0])
                            print(' agent.tribe', self.tribe)

                            print('\n pot_cp.home', pot_cp.home, 'pot_cp.prop_steal', pot_cp.prop_steal,
                                  'pot_cp.prop_fight_back', pot_cp.prop_fight_back)
                            print(' pot_cp.agent_res_array', pot_cp.agent_res_array[0])
                            print(' pot_cp.basket_array', pot_cp.basket_array[0])
                            print(' pot_cp.tribe', pot_cp.tribe)

                            print('\n pot_cp', pot_cp, 'agent_exp_rtn', agent_exp_rtn, 'pot_cp_exp_rtn', pot_cp_exp_rtn)

                    if print_fine_dets:
                        print(' exp_returns_array', exp_returns_array)

                    if len(exp_returns_array) > 0:

                        mean_exp_return = np.mean(exp_returns_array)

                        # if this is true, we definitely don't want to head back to target (assuming agent isn't wondering around randomly)
                        if mean_exp_return > 0.0:
                            head_to_target = 0

                    elif len(exp_returns_array) == 0:

                        mean_exp_return = 0

                    if mean_exp_return == 0:
                        squares_w_zero_exp_rtn.append(np.array([x_coord, y_coord], dtype=int))

                    if mean_exp_return != 0 and print_fine_dets == 1:
                        print(' mean_exp_return', mean_exp_return)

                    if mean_exp_return > max_mean_exp_return:

                        max_mean_exp_return = mean_exp_return
                        max_grid_square = np.array([x_coord, y_coord], dtype=int)

                        if print_fine_dets == 1:
                            print('\n max_mean_exp_return', max_mean_exp_return)
                            print(' max_grid_square', max_grid_square)

                    neigh_exp_returns_array[i + 1][j + 1] = mean_exp_return

        # here we account for avoidance: if the mean exp gain is negative on a particular square and any one of the cp_agents has an expected positive gain then I will move
        # away from that cp_agent
        min_mean_exp_rtn = np.min(neigh_exp_returns_array)
        max_mean_exp_rtn = np.max(neigh_exp_returns_array)

        if print_fine_dets == 1:
            print('\n min_mean_exp_rtn =', min_mean_exp_rtn)
            print(' max_mean_exp_rtn =', max_mean_exp_rtn)
            print('\n\n neigh_exp_returns_array: \n\n', neigh_exp_returns_array)
            print('\n neigh_cp_exp_returns_array: \n')
            for line in neigh_cp_exp_returns_array:
                print(line)
            print('\n len(squares_w_zero_exp_rtn) =', len(squares_w_zero_exp_rtn))

        # By this stage, if there is a 'good' square for the agent to head toward (it has a positive value, so max_mean_exp_rtn > 0) then we are essentially finished with this
        # function.  If, however, the max_mean_exp_rtn is zero then we must choose the least-bad square to move toward.  If max_mean_exp_rtn == 0 then we choose from any of
        # the 8 squares in squares_w_zero_exp_rtn if the length of this array is 8.  If max_mean_exp_rtn = 0 and the length of squares_w_zero_exp_rtn < 8 then we have to
        # find the square the agent dislikes least.  We do this by looking at every grid square the agent could move to: we add the values from neigh_cp_exp_returns_array
        # which are within striking distance from each square (provided it is negative and there is at least one positive value in neigh_cp_exp_returns_array).  The agent then
        # chooses the square with the least negative value.

        # we only proceed if agent_avoid_muggers and if max_mean_exp_rtn <= 0
        if agent_avoid_muggers and max_mean_exp_rtn <= 0:

            # find the maximum value of neigh_cp_exp_returns_array
            max_cp_exp_rtn = 0.0

            for line in neigh_cp_exp_returns_array:
                for cell in line:
                    if len(cell) > 0:
                        for el in cell:
                            if el > max_cp_exp_rtn:
                                max_cp_exp_rtn = el

            # if min_mean_exp_rtn < 0 or max_cp_exp_rtn > 0.0:
            #     print_fine_dets = 1
            #     no_neighs = 1

            if print_fine_dets:
                # print('\n min_mean_exp_rtn =', min_mean_exp_rtn)
                # print(' max_mean_exp_rtn =', max_mean_exp_rtn)
                # print('\n\n neigh_exp_returns_array: \n\n', neigh_exp_returns_array)
                # print('\n neigh_cp_exp_returns_array: \n')
                # for line in neigh_cp_exp_returns_array:
                #     print(line)
                # print('\n len(squares_w_zero_exp_rtn) =', len(squares_w_zero_exp_rtn))

                print('\n agent_avoid_muggers and max_mean_exp_rtn <= 0')
                print(' max_cp_exp_rtn', max_cp_exp_rtn)

            # in the simpler situation, when min_mean_exp_rtn <= 0 and max_cp_exp_rtn <= 0, the agent will move to a zero square if there is one (it will ignore any agents)
            if min_mean_exp_rtn <= 0 and max_cp_exp_rtn <= 0 and len(squares_w_zero_exp_rtn) > 0:

                if print_fine_dets:
                    print('\n min_mean_exp_rtn <= 0 and max_cp_exp_rtn <= 0 and len(squares_w_zero_exp_rtn) > 0')

                # here the agent chooses the square closest to its target (if it's not wandering around randomly)
                if self.trade_movemnt == 'set':

                    if print_fine_dets:
                        print('\n self.trade_movemnt == set')
                        print(' self.grid_trgt', self.grid_trgt)

                    # if the agent is already at its target - we keep it there
                    if self.reached_trgt and self.location[0] == self.grid_trgt[0] and self.location[1] == self.grid_trgt[1]:

                        max_grid_square = self.grid_trgt
                        head_to_target = 1

                    else:

                        # print_fine_dets = 1

                        # if print_fine_dets:
                        #
                        #     print('\n squares_w_zero_exp_rtn:', squares_w_zero_exp_rtn)
                        #     print('\n self.location', self.location, 'self.grid_trgt =', self.grid_trgt)

                        best_grid_locations_array = []
                        min_dist_to_trgt = town_grid.dimen

                        for grid_locn in squares_w_zero_exp_rtn:

                            dist_to_trgt_2d = abs_dist_on_torus(grid_locn, self.grid_trgt, town_grid.dimen)

                            dist_to_trgt = np.max(dist_to_trgt_2d)

                            if print_fine_dets:
                                print('\n grid_locn', grid_locn)
                                print(' dist_to_trgt_2d', dist_to_trgt_2d)
                                print(' dist_to_trgt', dist_to_trgt)
                                print(' current min_dist_to_trgt', min_dist_to_trgt)

                            if dist_to_trgt < min_dist_to_trgt:

                                min_dist_to_trgt = dist_to_trgt

                                best_grid_locations_array = [grid_locn]

                            elif dist_to_trgt == min_dist_to_trgt:

                                best_grid_locations_array.append(grid_locn)

                            if print_fine_dets:
                                print('\n Resulting min_dist_to_trgt =', min_dist_to_trgt)

                        max_grid_square = random.choice(best_grid_locations_array)

                        if print_fine_dets:
                            print('\n best_grid_locations_array: ', best_grid_locations_array)
                            print('\n End max_grid_square', max_grid_square)
                            # pause()

                        head_to_target = 0

                else:

                    max_grid_square = random.choice(squares_w_zero_exp_rtn)  # we do this for when min_mean_exp_rtn < 0 and it gets over-ridden if pot_cp has postive return (agent runs)

                    head_to_target = 1

                if print_fine_dets:
                    print(' \n min_mean_exp_rtn <= 0 and len(squares_w_zero_exp_rtn) > 0')
                    print(' max_grid_square =', max_grid_square)

            # this is the more complicated situation - the agent needs to work out which square is the least bad to move to
            else:

                # we start by creating a 3 x 3 matrix with extreme negative values and a variable which tracks the least negative value in the matrix
                sum_negs_array = np.full(shape=(3, 3), fill_value=-999.0)
                max_neg = -999.0

                for i in [0, 1, 2]:
                    for j in [0, 1, 2]:

                        # we are only interested in squares where any counterpart has a positive exp return
                        max_cp_value_current_sq = 0.0

                        if len(neigh_cp_exp_returns_array[i][j]) > 0:
                            max_cp_value_current_sq = np.max(neigh_cp_exp_returns_array[i][j])

                        if max_cp_value_current_sq <= 0.0:

                            sum_counter = 0.0

                            for k in [-1, 0, 1]:
                                for l in [-1, 0, 1]:

                                    if i + k >= 0 and i + k < 3 and j + l >= 0 and j + l < 3:

                                        max_cp_value = 0.0

                                        if len(neigh_cp_exp_returns_array[i + k][j + l]) > 0:
                                            max_cp_value = np.max(neigh_cp_exp_returns_array[i + k][j + l])

                                        if max_cp_value > 0.0:
                                            sum_counter += neigh_exp_returns_array[i + k][j + l]

                            if sum_counter > max_neg:
                                max_neg = sum_counter

                            sum_negs_array[i][j] = sum_counter

                best_locations_array = []

                for i in [0, 1, 2]:
                    for j in [0, 1, 2]:
                        if sum_negs_array[i][j] == max_neg:
                            best_locations_array.append([i - 1, j - 1])

                if print_fine_dets:
                    print('\n sum_negs_array: \n')
                    for line in sum_negs_array:
                        print('[%5.2f, %5.2f, %5.2f]' % (line[0], line[1], line[2]))
                    print('\n max_neg', max_neg)
                    print('\n best_locations_array: \n', best_locations_array)

                # here the agent chooses the square closest to its target (if it's not wandering around randomly)
                if self.trade_movemnt == 'set':

                    if print_fine_dets:
                        print('\n self.trade_movemnt == set')
                        print(' self.grid_trgt', self.grid_trgt)

                    # if print_fine_dets:
                    #
                    #     print('\n best_locations_array:', best_locations_array)
                    #     print('\n self.location', self.location, 'self.grid_trgt =', self.grid_trgt)

                    best_grid_locations_array = []
                    min_dist_to_trgt = town_grid.dimen

                    for rel_locn in best_locations_array:

                        grid_locn = [(self.location[0] + rel_locn[0]) % town_grid.dimen, (self.location[1] + rel_locn[1]) % town_grid.dimen]

                        dist_to_trgt_2d = abs_dist_on_torus(grid_locn, self.grid_trgt, town_grid.dimen)

                        dist_to_trgt = np.max(dist_to_trgt_2d)

                        if print_fine_dets:
                            print('\n rel_locn', rel_locn, 'grid_locn', grid_locn)
                            print(' dist_to_trgt_2d', dist_to_trgt_2d)
                            print(' dist_to_trgt', dist_to_trgt)
                            print(' current min_dist_to_trgt', min_dist_to_trgt)

                        if dist_to_trgt < min_dist_to_trgt:

                            min_dist_to_trgt = dist_to_trgt

                            best_grid_locations_array = [grid_locn]

                        elif dist_to_trgt == min_dist_to_trgt:

                            best_grid_locations_array.append(grid_locn)

                        if print_fine_dets:
                            print('\n Resulting min_dist_to_trgt =', min_dist_to_trgt)

                    max_grid_square = random.choice(best_grid_locations_array)

                    if print_fine_dets:
                        print('\n best_grid_locations_array: ', best_grid_locations_array)
                        print('\n End max_grid_square', max_grid_square)
                        # pause()

                else:

                    best_location_choice = random.choice(best_locations_array)

                    max_grid_square = [(self.location[0] + best_location_choice[0]) % town_grid.dimen, (self.location[1] + best_location_choice[1]) % town_grid.dimen]

                if print_fine_dets:
                    print('\n self.location =', self.location)
                    print('\n resulting max_grid_square', max_grid_square)
                    # pause()

                # in this situation, the agent will want to avoid a potentially bad interaction so it will not head toward target
                head_to_target = 0

        if print_fine_dets == 1:
            print('\n squares_w_zero_exp_rtn', squares_w_zero_exp_rtn)

            if params.track_agent and self == agent_population.tracking_agent:
                print('\n checking agent is tracking agent')
            else:
                print('\n checking agent is NOT tracking agent')

            print('\n checking agent res =', self.basket_array)
            print(' tracking_agent res =', agent_population.tracking_agent.basket_array)
            print(' agent_population.tracking_agent.location', agent_population.tracking_agent.location)
            print('\n self.location', self.location)
            print(' self.grid_trgt', self.grid_trgt)
            print(' self.reached_trgt =', self.reached_trgt)
            print('\n max_mean_exp_return', max_mean_exp_return)
            print(' max_grid_square', max_grid_square)
            print(' number_neighbours', number_neighbours)
            print(' move ', move)
            print('\n head_to_target =', head_to_target)

        if print_fine_dets: # and no_neighs > 0:
            pause()

        return neigh_exp_returns_array, max_mean_exp_return, max_grid_square, number_neighbours, neigh_cp_exp_returns_array, head_to_target


class Agent_Population():
    """This is a class for managing a population of agents."""

    # the class is initiated with a starting population:
    def __init__(self, start_population, trade_prices, min_trans_Q, homes_array, for_strat_parts,
                 black_shoop_exp, stranger_int, corruption_prop_charge, must_update_neighs):

        self.pop = start_population
        self.dead_agent_array = []
        self.trade_prices = trade_prices
        self.min_trans_Q = min_trans_Q
        self.homes_array = homes_array
        self.for_strat_parts = for_strat_parts

        # choose an agent at random from the population so we can track it over its life:
        ag_numb = np.random.randint(0, len(self.pop))
        self.tracking_agent = self.pop[ag_numb]
        self.KI_stiffs = []
        # this variable means agents from different tribes will simply ignore each other
        self.ignore_strangers = 1

        #        if black_shoop_exp:

        self.black_shoop_list = []
        self.black_shoop_seen = 0

        # when not respecting property rights, in one experiment we keep all props the same except for one agent:
        self.change_agent = None

        self.stranger_int = stranger_int

        # variable which corresponds to corruptability of officials imposing any fine
        self.corruption_prop_charge = corruption_prop_charge

        self.must_update_neighs = must_update_neighs

        # variable which tracks the population's mean propensity to steal
        self.mean_ps = 0.0

    def remove_agent(self, agent_num):

        """A method for removing an agent from the population."""

        self.pop = np.delete(self.pop, agent_num)

    def add_agent(self, new_agent):

        """A method for adding a new agent to the population."""

        self.pop = np.append(self.pop, new_agent)

    def agents_interact(self, params, fountain_population, agent, cp_agent, day, town_grid, move, dbs, price_mean, force_prices,
                        fixed_price,
                        print_dets, respect_property_rights, adjust_props_r, fight_cost, agent_intn_beta, num_rounds,
                        print_fine_dets,
                        prop_steal_ceil, prop_steal_floor, prop_fight_back_ceil, prop_fight_back_floor, fight_balance,
                        len_reputations_mem, intn_error_std, KO_pop, agent_population, keynesian_ratio, trade_prices,
                        trade_movemnt,
                        trade_when_trgt, track_agent, trgt_sel, trade_moves, granular_mem, wait_at_tgt_moves, ststst,
                        agree_location,
                        formal_inst, prob_fine, fine, print_agents_interact, fight_skill, fix_ps_fb_0, two_tribes_inst,
                        strat_choice,
                        stranger_int, strangers_if_unknown):

        """A method for managing the interaction and potential trading of two agents (designated agent & cp_agent)."""

        # First of all, let us record what type of game this is
        if params.track_game_types and respect_property_rights == 0:

            add_game_to_game_dict(self, fountain_population, agent, cp_agent, agent.exp_rtns_matrix[str(cp_agent)], dbs,
                                  day, print_fine_dets, strat_choice, stranger_int, strangers_if_unknown)

        if track_agent is not None and (agent_population.tracking_agent == agent or agent_population.tracking_agent == cp_agent):

            print_dets = 1
            print_fine_dets = 1

        else:

            print_dets = 0
            print_fine_dets = 0

        if print_agents_interact:
            print_fine_dets = 1

        # print_dets = 1
        # print_fine_dets = 1

        # When 2 agents interact each agents has to first decide if they want to try to steal from the other, or if they want to trade.  If both want to trade then they simply trade.  If
        # both want to steal then they end up fighting each other.  However, if one wants to steal and the other trade, the agent wishing to trade can then decide to fight back or not once
        # the interaction starts - if they fight back then the two are in a fight; whereas if the agents acquiesces (chooses not to fight) then the fighting agent steal all its resources.

        #        if agent == agent_population.pop[0] or cp_agent == agent_population.pop[0]:
        #            print_fine_dets = 1

        if print_fine_dets == 1:
            print(
                '\n ********************************************** Agents start interacting **********************************************')

            print('\nday =', day)
            print('move =', move)

            print('\n agent.home =', agent.home)
            print(' cp_agent.home =', cp_agent.home)

            print('\n agent.grid_trgt =', agent.grid_trgt)
            print(' cp_agent.grid_trgt =', cp_agent.grid_trgt)

            print('\n agent.location =', agent.location)
            print(' cp_agent.location =', cp_agent.location)

            print('\n agent.agent_res_array ', agent.agent_res_array)
            print(' agent.basket_array =', agent.basket_array)

            print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array)
            print(' cp_agent.basket_array =', cp_agent.basket_array)

            print('\n self.stranger_int =', self.stranger_int)

            print('\n agent.tribe', agent.tribe)
            print('\n cp_agent.tribe', cp_agent.tribe)

            print('\n agent_population.mean_ps =', agent_population.mean_ps)
            print(' agent_population.corruption_prop_charge =', agent_population.corruption_prop_charge)

        # used for testing:
        #        agent.agent_res_array[0] = [100, 50]
        #        cp_agent.agent_res_array[0] = [50, 100]
        #
        #        agent.basket_array[0] = [1, 1]
        #        cp_agent.basket_array[0] = [1, 1]
        #
        #        print_fine_dets = 1

        ########

        fight_num = None

        agent_start_res = copy.copy(agent.agent_res_array[0])
        cp_agent_start_res = copy.copy(cp_agent.agent_res_array[0])

        agent_start_basket = copy.copy(agent.basket_array)
        cp_agent_start_basket = copy.copy(cp_agent.basket_array)

        initiator_start_prop_steal = copy.copy(agent.prop_steal)
        initiator_start_prop_fight_back = copy.copy(agent.prop_fight_back)

        counterpart_start_prop_steal = copy.copy(cp_agent.prop_steal)
        counterpart_start_prop_fight_back = copy.copy(cp_agent.prop_fight_back)

        agents_trade_peacefully = 0  # we assume this unless agents decide otherwise

        if print_fine_dets == 1:
            print_model_2_dets = 1

        else:
            print_model_2_dets = 0

        if print_fine_dets == 1 or print_model_2_dets == 1:
            print('\n\n\n\n ------- Agents start interacting ----------\n')

            print('\n day =', day)
            print(' move =', move)

            print('\n agent.location', agent.location)

            print('\n agent.agent_res_array ', agent.agent_res_array)
            print(' agent.basket_array =', agent.basket_array)

            print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array)
            print(' cp_agent.basket_array =', cp_agent.basket_array)

            print('\n formal_inst ', formal_inst, 'prob_fine ', prob_fine, 'fine ', fine)

        # record agents' total resources to start
        start_agent_tot_ress = agent.basket_array[0] + agent.agent_res_array[0]
        start_cp_agent_tot_ress = cp_agent.basket_array[0] + cp_agent.agent_res_array[0]

        if respect_property_rights == 0:

            # # record agents' total resources to start
            # start_agent_tot_ress = agent.basket_array[0] + agent.agent_res_array[0]
            # start_cp_agent_tot_ress = cp_agent.basket_array[0] + cp_agent.agent_res_array[0]

            # and find out which resource most defficient in
            agent_min_res_value = np.min(start_agent_tot_ress)
            cp_agent_min_res_value = np.min(start_cp_agent_tot_ress)

            agent_min_res = 0
            cp_agent_min_res = 0

            for res in range(num_res_founts):

                if start_agent_tot_ress[res] == agent_min_res_value:
                    agent_min_res = res

                if start_cp_agent_tot_ress[res] == cp_agent_min_res_value:
                    cp_agent_min_res = res

            #           for testing
            #            agent.tribe = 'sharks'
            #            cp_agent.tribe = 'jets'

            #            print('\n agent.tribe =', agent.tribe, 'cp_agent.tribe', cp_agent.tribe)
            #            print(' strat_choice =', strat_choice)
            #            print(' strangers_if_unknown = ', strangers_if_unknown)
            #            print(' agent.agent_knows_cp_dict[str(cp_agent)]', agent.agent_knows_cp_dict[str(cp_agent)])
            #            print(' cp_agent.agent_knows_cp_dict[str(agent)] =', cp_agent.agent_knows_cp_dict[str(agent)])
            #            print(' agent.exp_rtns_matrix[str(cp_agent)]', agent.exp_rtns_matrix[str(cp_agent)])

            # we start by asking each agent if they want to attempt to steal or trade.  Note that if the agents are strangers then by default both their
            # prop steals == 1
            if agent.tribe != cp_agent.tribe or strat_choice == 'rational' or (
                    strat_choice == 'heuristics' and strangers_if_unknown and (
                    agent.agent_knows_cp_dict[str(cp_agent)] == 0 or cp_agent.agent_knows_cp_dict[str(agent)] == 0)):
                #
                #                print('\n agent.exp_rtns_matrix[str(cp_agent)]', agent.exp_rtns_matrix[str(cp_agent)])
                #                print(' agent_dec, cp_agent_dec, ag_gain, cp_gain', agent.exp_rtns_matrix[str(cp_agent)][8:])

                #                use_start_basket = 0
                #                agent_dec, cp_agent_dec, ag_gain, cp_gain = strangers_interact(self.min_trans_Q, price_mean, force_prices, fixed_price, day, dbs, fountain_population, print_dets, print_fine_dets,
                #                                                                               use_start_basket, agent, cp_agent, self.stranger_int, formal_inst, prob_fine, fine, two_tribes_inst, fight_cost)

                # we can use the data we already have to determine agent and cp_agent's decisions
                return_data = agent.exp_rtns_matrix[str(cp_agent)]

                agent_dec, cp_agent_dec, ag_gain, cp_gain = return_data[8:]

                if print_fine_dets:
                    print('\n strangers_interact completed: agent_dec ', agent_dec, ' cp_agent_dec ', cp_agent_dec,
                          ' ag_gain ', ag_gain, ' cp_gain ', cp_gain)

            # if the agents are the same tribe then the interaction is dictated by the prop steals
            elif agent.tribe == cp_agent.tribe and strat_choice == 'heuristics' and (strangers_if_unknown == 0 or (
                    strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and cp_agent.agent_knows_cp_dict[
                str(agent)])):

                agent_ran_num = random.random()

                # prop_steals can be above 1 or below 0 so we truncate them:
                cropped_ag_prop_steal = np.min([1.0, np.max([0, agent.prop_steal])])
                cropped_cp_prop_steal = np.min([1.0, np.max([0, cp_agent.prop_steal])])

                if agent_ran_num < cropped_ag_prop_steal:

                    agent_dec = 'steal'

                else:       # so >= then trade

                    agent_dec = 'trade'

                cp_agent_ran_num = random.random()

                if cp_agent_ran_num < cropped_cp_prop_steal:

                    cp_agent_dec = 'steal'

                else:

                    cp_agent_dec = 'trade'

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n agent_ran_num = %1.3f' % (agent_ran_num),
                          ' agent.prop_steal = %1.3f' % (agent.prop_steal), 'agent decision:', agent_dec)
                    print('\n cp_agent_ran_num = %1.3f' % (cp_agent_ran_num),
                          ' cp_agent.prop_steal = %1.3f' % (cp_agent.prop_steal), 'cp_agent decision:', cp_agent_dec)

            #            pause()

            fight_winner = None

            # if they both choose to trade then
            if agent_dec == 'trade' and cp_agent_dec == 'trade':

                agents_trade_peacefully = 1  # and we head to the code which organises the trading

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n => agents_trade_peacefully')

            # if one agent wants to fight and the other trade, they trader gets the chance to fight back
            # there are two cases: one where agent tries to steal and vice versa
            if agent_dec == 'steal' and cp_agent_dec == 'trade':

                if agent.tribe == cp_agent.tribe and strat_choice == 'heuristics':

                    fight_back_random_num = random.random()

                    # prop_fight_backs can be above 1 or below 0 so we truncate them:
                    cropped_cp_prop_fb = np.min([1.0, np.max([0, cp_agent.prop_fight_back])])

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n fight_back_random_num: %1.3f' % (fight_back_random_num))
                        print(' cropped_cp_prop_fb: %1.3f' % (cropped_cp_prop_fb))

                    if fight_back_random_num < cropped_cp_prop_fb:  # then the cp_agent decides to fight back

                        cp_agent_dec = 'fight_back'

                        if print_fine_dets == 1 or print_model_2_dets == 1:
                            print('\n cp_agent decides to fight')

                # if the agents' choices remain the same
                if agent_dec == 'steal' and cp_agent_dec == 'trade':

                    agent.basket_array += cp_agent.basket_array
                    cp_agent.basket_array = np.zeros(shape=(1, num_res_founts), dtype=float)

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n cp_agent is a wimp')

                    fight_winner = agent
                    fight_loser = cp_agent

                    #                    # if the agent has successfully stolen from cp_agent then it will ignore cp_agent from now on (no upside to interaction); and
                    #                    # the cp_agent, being bruised fomr the encounter, will ignore the agent
                    #                    agent.ignore_agents_array.append(cp_agent)
                    #                    cp_agent.ignore_agents_array.append(agent)

                    # if there is a formal institution and policing of fights then we include that here
                    if formal_inst:

                        if random.random() < prob_fine:  # then the fight was detected and the agent is punished (from agent_res_array - agent might not have any res in basket)

                            if random.random() < agent_population.mean_ps:  # then there is corruption and the agent pays a bribe

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n corruption!')
                                    print(' agent pays bribe of fine * agent_population.corruption_prop_charge =',
                                          fine * agent_population.corruption_prop_charge)

                                agent.agent_res_array[0] += np.array([fine * agent_population.corruption_prop_charge,
                                                                      fine * agent_population.corruption_prop_charge])

                            else:  # then there is no corruption

                                agent.agent_res_array[0] += np.array([fine, fine])

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n agent fought and was fined by the police')
                                    print(' agent.agent_res_array ', agent.agent_res_array)

                                if formal_inst == 'compensate':
                                    cp_agent.agent_res_array[0] -= np.array([fine, fine])

                                    if print_fine_dets == 1 or print_model_2_dets == 1:
                                        print('\n cp_agent was compensated by ', np.array([fine, fine]) * -1)
                                        print(' cp_agent.agent_res_array ', cp_agent.agent_res_array)

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print(' agent.basket_array ', agent.basket_array)
                    print(' cp_agent.basket_array ', cp_agent.basket_array)

            # the second case is when the cp_agent tries to steal and the agent wants to trade
            if agent_dec == 'trade' and cp_agent_dec == 'steal':

                if agent.tribe == cp_agent.tribe and strat_choice == 'heuristics':

                    fight_back_random_num = random.random()

                    # prop_fight_backs can be above 1 or below 0 so we truncate them:
                    cropped_ag_prop_fb = np.min([1.0, np.max([0, agent.prop_fight_back])])

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n fight_back_random_num: %1.3f' % (fight_back_random_num))
                        print(' cropped_ag_prop_fb: %1.3f' % (cropped_ag_prop_fb))

                    if fight_back_random_num < cropped_ag_prop_fb:  # then the agent decides to fight back

                        agent_dec = 'fight_back'

                        if print_fine_dets == 1 or print_model_2_dets == 1:
                            print('\n agent decides to fight')

                # if the agents' choices remain the same
                if agent_dec == 'trade' and cp_agent_dec == 'steal':

                    cp_agent.basket_array += agent.basket_array
                    agent.basket_array = np.zeros(shape=(1, num_res_founts), dtype=float)

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n agent is a wimp')

                    fight_winner = cp_agent
                    fight_loser = agent

                    #                    # if the agent has successfully stolen from cp_agent then it will ignore cp_agent from now on (no upside to interaction); and
                    #                    # the cp_agent, being bruised fomr the encounter, will ignore the agent
                    #                    agent.ignore_agents_array.append(cp_agent)
                    #                    cp_agent.ignore_agents_array.append(agent)

                    # if there is a formal institution and policing of fights then we include that here
                    if formal_inst:

                        if random.random() < prob_fine:  # then the fight was detected and the agent is punished (from agent_res_array - agent might not have any res in basket)

                            if random.random() < agent_population.mean_ps:  # then there is corruption and the cp_agent pays a bribe

                                cp_agent.agent_res_array[0] += np.array([fine * agent_population.corruption_prop_charge,
                                                                         fine * agent_population.corruption_prop_charge])

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n corruption!')
                                    print(' cp_agent pays bribe of fine * agent_population.corruption_prop_charge =',
                                          fine * agent_population.corruption_prop_charge)

                            else:  # then there is no corruption - pays full fine

                                cp_agent.agent_res_array[0] += np.array([fine, fine])

                                if formal_inst == 'compensate':
                                    agent.agent_res_array[0] -= np.array([fine, fine])

                                    if print_fine_dets == 1 or print_model_2_dets == 1:
                                        print('\n agent was compensated by ', np.array([fine, fine]) * -1)
                                        print(' agent.agent_res_array ', agent.agent_res_array)

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n cp_agent fought and was fined by the police')

                                    print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array)

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n agent.basket_array ', agent.basket_array)
                    print(' cp_agent.basket_array ', cp_agent.basket_array)

            # the third case is when the two agents want to steal / fight (this can arise because they both initially decide to fight;
            # or because one oringinally wanted to trade and then decided to fight back):
            if (agent_dec == 'steal' or agent_dec == 'fight_back') and (
                    cp_agent_dec == 'steal' or cp_agent_dec == 'fight_back'):

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n They fight')

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n y agent.agent_res_array ', agent.agent_res_array)
                    print(' y agent.basket_array ', agent.basket_array)

                    print('\n y cp_agent.agent_res_array ', cp_agent.agent_res_array)
                    print(' y cp_agent.basket_array ', cp_agent.basket_array)

                if fight_skill is not None:

                    sum_skill = agent.fight_skill + cp_agent.fight_skill

                    if sum_skill != 0.0:

                        agent_win_thresh = agent.fight_skill / float(sum_skill)

                    else:

                        agent_win_thresh = 0.5

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n fight based on fight_skills - agent.fight_skill =', agent.fight_skill,
                              'cp_agent.fight_skill =', cp_agent.fight_skill, 'sum_skill =', sum_skill,
                              'agent_win_thresh =', agent_win_thresh)

                elif fight_balance == '50_50':

                    agent_win_thresh = 0.5

                elif fight_balance == 'res_power':

                    agent_mean_res = np.mean(agent.agent_res_array[0])
                    cp_agent_mean_res = np.mean(cp_agent.agent_res_array[0])

                    # this means that if agent has more resources then it will have more chance of winning the fight
                    agent_win_thresh = agent_mean_res / float(agent_mean_res + cp_agent_mean_res)

                    if print_fine_dets == 1:
                        print('\n agent_mean_res =', agent_mean_res)
                        print(' cp_agent_mean_res =', cp_agent_mean_res)
                        print('\n agent_win_thresh =', agent_win_thresh)
                        print(' prob_agent_loses_fight =', 1 - agent_win_thresh)

                if random.random() < agent_win_thresh:

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n agent wins fight')

                    agent.basket_array += cp_agent.basket_array
                    agent.agent_res_array[0] += np.array([fight_cost, fight_cost])

                    cp_agent.basket_array = np.zeros(shape=(1, num_res_founts), dtype=float)
                    cp_agent.agent_res_array[0] += np.array([fight_cost, fight_cost])

                    fight_winner = agent
                    fight_loser = cp_agent

                else:

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n cp_agent wins fight')

                    cp_agent.basket_array += agent.basket_array
                    cp_agent.agent_res_array[0] += np.array([fight_cost, fight_cost])

                    agent.basket_array = np.zeros(shape=(1, num_res_founts), dtype=float)
                    agent.agent_res_array[0] += np.array([fight_cost, fight_cost])

                    fight_winner = cp_agent
                    fight_loser = agent

                #                # if the agent has successfully stolen from cp_agent then it will ignore cp_agent from now on (no upside to interaction); and
                #                # the cp_agent, being bruised fomr the encounter, will ignore the agent
                #                agent.ignore_agents_array.append(cp_agent)
                #                cp_agent.ignore_agents_array.append(agent)

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n x agent.agent_res_array ', agent.agent_res_array)
                    print(' x agent.basket_array ', agent.basket_array)

                    print('\n x cp_agent.agent_res_array ', cp_agent.agent_res_array)
                    print(' x cp_agent.basket_array ', cp_agent.basket_array)

                # if there is a formal institution and policing of fights then we include that here
                if formal_inst:

                    if random.random() < prob_fine:  # then the fight was detected and the agent is punished (from agent_res_array - agent might not have any res in basket)

                        if agent_dec == 'steal':

                            if random.random() < agent_population.mean_ps:  # then there is corruption and the cp_agent pays a bribe (and there is no compensation).  If there is no corruption in model then mean_ps == 0

                                agent.agent_res_array[0] += np.array([fine * agent_population.corruption_prop_charge,
                                                                      fine * agent_population.corruption_prop_charge])

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n corruption!')
                                    print(' agent pays bribe of fine * agent_population.corruption_prop_charge =',
                                          fine * agent_population.corruption_prop_charge)

                            else:  # then there is no corruption - pays full fine

                                agent.agent_res_array[0] += np.array([fine, fine])

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n agent fought and was fined by the police')
                                    print(' agent.agent_res_array ', agent.agent_res_array)

                                if cp_agent_dec == 'fight_back' and formal_inst == 'compensate':

                                    cp_agent.agent_res_array[0] -= np.array([fine, fine])

                                    if print_fine_dets == 1 or print_model_2_dets == 1:
                                        print('\n cp_agent was compensated by ', np.array([fine, fine]) * -1)
                                        print(' cp_agent.agent_res_array ', cp_agent.agent_res_array)

                        if cp_agent_dec == 'steal':

                            if random.random() < agent_population.mean_ps:  # then there is corruption and the cp_agent pays a bribe

                                cp_agent.agent_res_array[0] += np.array([fine * agent_population.corruption_prop_charge,
                                                                         fine * agent_population.corruption_prop_charge])

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n corruption!')
                                    print(' cp_agent pays bribe of fine * agent_population.corruption_prop_charge =',
                                          fine * agent_population.corruption_prop_charge)

                            else:  # then there is no corruption - pays full fine

                                cp_agent.agent_res_array[0] += np.array([fine, fine])

                                if print_fine_dets == 1 or print_model_2_dets == 1:
                                    print('\n cp_agent fought and was fined by the police')
                                    print(' cp_agent.agent_res_array ', cp_agent.agent_res_array)

                                if agent_dec == 'fight_back' and formal_inst == 'compensate':

                                    agent.agent_res_array[0] -= np.array([fine, fine])

                                    if print_fine_dets == 1 or print_model_2_dets == 1:
                                        print('\n agent was compensated by ', np.array([fine, fine]) * -1)
                                        print(' agent.agent_res_array ', agent.agent_res_array)

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n agent.agent_res_array ', agent.agent_res_array)
                    print(' agent.basket_array ', agent.basket_array)

                    print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array)
                    print(' cp_agent.basket_array ', cp_agent.basket_array)

            # if the agents dont trade then we have to create and return these data anyway
            if agents_trade_peacefully == 0:
                remove_agents = np.array([])
                transactions = 0
                traded_array = []
                trans_numbs_array = []

        #        if print_fine_dets == 1:
        #            pause()

        if print_fine_dets == 1:
            print('\n agent', agent, 'agent.ignore_agents_array', agent.ignore_agents_array)
            print(' cp_agent', cp_agent, 'cp_agent.ignore_agents_array', cp_agent.ignore_agents_array)

        if respect_property_rights == 1 or agents_trade_peacefully == 1:

            #            print_fine_dets = 1

            # create variables to record number of transactions (nothing to do with price, it merely counts transactions) gain_pot_cp_low_res_6_prob_weighted
            transactions = 0

            # record all of the transaction numbers in an array
            trans_numbs_array = []

            if print_fine_dets == 1:
                print('\n\n--> Agents start interacting')

                print('\nday =', day)
                print('move =', move)

                print('\nagent.home =', agent.home)
                print('cp_agent.home =', cp_agent.home)

                print('\nagent.grid_trgt =', agent.grid_trgt)
                print('cp_agent.grid_trgt =', cp_agent.grid_trgt)

                print('\nagent.location =', agent.location)
                print('cp_agent.location =', cp_agent.location)

                print('\nagent.trade_loc_rec =\n')

                for move in np.arange(len(agent.trade_loc_rec)):
                    print(agent.trade_loc_rec[move])

                print(agent.location, '<-- agent.location')
                print('\nagent.trgt_loc_rec =\n')

                for move in np.arange(len(agent.trgt_loc_rec)):
                    print(agent.trgt_loc_rec[move])

                print(agent.grid_trgt, '<-- agent.grid_trgt =')

                print('\nINITIAL agent.trading_basket =', agent.trading_basket)
                print('INITIAL cp_agent.trading_basket =', cp_agent.trading_basket)

                print('\nagent.basket_array =', agent.basket_array)
                print('\ncp_agent.basket_array =', cp_agent.basket_array)

                # create arrays to update agents' memory arrays
            rec_array = copy.deepcopy(agent.location)

            # add the round to this array
            rec_array = np.append(rec_array, day)

            # set up an array to record the information corresponding to any transaction
            traded_array = []

            # Create array to record agents we should remove.  Below we also update each agent's sell_array and buy_array
            remove_agents = np.array([])

            if print_dets == 1:
                print('\nrec_array =', rec_array)

            stop_transacting = 0

            iter_loop = 0

            while stop_transacting == 0:

                if print_fine_dets == 1:
                    print('\n\n--> Starting while loop: transactions =', transactions)

                # We have to differentiate between the use of fixed or variable prices to determine trading between agents
                if self.trade_prices == 'variable':

                    use_start_basket = 0
                    agent_res_array = agent.agent_res_array
                    agent_basket_array = agent.basket_array
                    agent_basket_array_start = agent.basket_array_start
                    cp_agent_res_array = cp_agent.agent_res_array
                    cp_agent_basket_array = cp_agent.basket_array
                    cp_agent_basket_array_start = cp_agent.basket_array_start

                    # The function build_tot_cons_surp_array returns the total consumer surplus array and the data for the best transaction
                    if (agent.basket_array[0][0] > 0.0 and cp_agent.basket_array[0][1] > 0.0) or (
                            agent.basket_array[0][1] > 0.0 and cp_agent.basket_array[0][
                        0] > 0):  # then they might trade

                        tot_cons_surp_array, best_trans_data = build_tot_cons_surp_array(self.min_trans_Q, price_mean,
                                                                                         force_prices, fixed_price, day,
                                                                                         dbs, fountain_population,
                                                                                         print_dets, print_fine_dets,
                                                                                         use_start_basket,
                                                                                         agent_res_array,
                                                                                         agent_basket_array,
                                                                                         agent_basket_array_start,
                                                                                         cp_agent_res_array,
                                                                                         cp_agent_basket_array,
                                                                                         cp_agent_basket_array_start)

                    else:  # then they won't trade

                        tot_cons_surp_array, best_trans_data = (
                        [[0.0, 0.0], [0.0, 0.0]], [None, None, None, None, None])

                    # find the maximum change in consumer surplus
                    max_cons_surp_ch = np.max(tot_cons_surp_array)

                    if print_fine_dets == 1:
                        print('\n tot_cons_surp_array:\n', tot_cons_surp_array)
                        print('\n max_cons_surp_ch', max_cons_surp_ch)
                        print('\n best_trans_data =', best_trans_data)

                    # We only carry on if max_cons_surp_ch is positive.  It can't be negative but all cells might be zero in which
                    # case there's no advantage to either agent in transacting
                    if max_cons_surp_ch >= 0.0:

                        agent_sells, agent_buys, tot_trans_ag_sell, tot_trans_ag_buy, trans_agr_MRS = best_trans_data

                        if print_fine_dets == 1:
                            print('\n\n the agents trade')
                            print(' agent_sells =', agent_sells)
                            print(' agent_buys =', agent_buys)
                            print(' tot_trans_ag_sell =', tot_trans_ag_sell)
                            print(' tot_trans_ag_buy =', tot_trans_ag_buy)
                            print(' trans_agr_MRS =', trans_agr_MRS)

                        # record what traded and how much:
                        trans_receipt = np.array(
                            [agent_sells, agent_buys, tot_trans_ag_sell, tot_trans_ag_buy, trans_agr_MRS])

                        # add this to traded_array
                        traded_array.append(trans_receipt)

                        # update some arrays & variables:
                        if agent_sells is not None:
                            agent.basket_array[0][agent_sells] -= tot_trans_ag_sell
                            cp_agent.basket_array[0][agent_sells] += tot_trans_ag_sell
                            agent.trading_basket[0][agent_sells] -= tot_trans_ag_sell
                            cp_agent.trading_basket[0][agent_sells] += tot_trans_ag_sell

                            # Note that as a default we use the amount sold by the agent as the quantity of the transaction
                            transactions += tot_trans_ag_sell

                            agent.basket_array[0][agent_buys] += tot_trans_ag_buy
                            cp_agent.basket_array[0][agent_buys] -= tot_trans_ag_buy
                            agent.trading_basket[0][agent_buys] += tot_trans_ag_buy
                            cp_agent.trading_basket[0][agent_buys] -= tot_trans_ag_buy

                        # create a transaction instance to record all relevant data
                        transaction = Transaction(copy.copy(agent.for_strat_array), copy.copy(cp_agent.for_strat_array),
                                                  copy.deepcopy(agent.location), day, agent_sells, agent_buys,
                                                  copy.copy(agent.home), copy.copy(cp_agent.home), tot_trans_ag_sell,
                                                  tot_trans_ag_buy, move, copy.deepcopy(agent.grid_trgt),
                                                  copy.deepcopy(cp_agent.grid_trgt),
                                                  copy.deepcopy(agent.trading_basket[0]),
                                                  copy.deepcopy(cp_agent.trading_basket[0]),
                                                  copy.deepcopy(agent.trade_loc_rec),
                                                  copy.deepcopy(cp_agent.trade_loc_rec), copy.deepcopy(agent.MRS_array),
                                                  copy.deepcopy(cp_agent.MRS_array), str(agent), str(cp_agent),
                                                  copy.deepcopy(trans_agr_MRS), agent_a_tribe=copy.copy(agent.tribe),
                                                  agent_b_tribe=copy.copy(cp_agent.tribe))

                        agent.loc_mems_array[day].append(len(dbs.trans_db))
                        cp_agent.loc_mems_array[day].append(len(dbs.trans_db))

                        trans_numbs_array.append(len(dbs.trans_db))
                        dbs.trans_db.append(transaction)

                        if print_fine_dets:
                            print('\n trans_numbs_array =', trans_numbs_array)
                            print('\n agent.loc_mems_array[day] =', agent.loc_mems_array[day])
                            print('\n cp_agent.loc_mems_array[day] =', cp_agent.loc_mems_array[day])

                        if len(dbs.start_end_transs[day]) == 0:  # then this is the first transaction

                            dbs.start_end_transs[day] = [len(dbs.trans_db) - 1, len(dbs.trans_db) - 1]

                        else:

                            dbs.start_end_transs[day][1] = len(dbs.trans_db) - 1

                        # How do we decide if either agent wants to remain on the board or leave?  If the agent can sell (a) good(s) and gain
                        # from this then it stays on the grid

                        # update MRS_arrays
                        for ag in [agent, cp_agent]:
                            ag.update_agent_MRS_array(print_dets, print_fine_dets, self)

                    # We stop transacting in two scenarios: either there is no gain to the agents in transacting or there they
                    # are attempting to unwind a preious transaction (MRS crossing)
                    #                    elif max_cons_surp_ch == 0:
                    #
                    #                        if print_fine_dets == 1:
                    #                            print('\nmax_cons_surp_ch == 0 : there is no positive consumer surplus to be gained')
                    #
                    #                        stop_transacting = 1
                    #
                    #                        transaction = None

                    # we set the following, which prevents the agents from immediately trading with each other again: if the two agents trade but wanted to trade more and were constrained by
                    # their basket holdings, their MRSs will adjust but if they then got in to another interaction, they might trade again because the agreed price will change from the first
                    # trade - this can cause lots of iterations of trading, which we avoid on reasonableness grounds.
                    # Note these are only set if the agents try to transact - if they try to steal from each other then these are not set.
                    if respect_property_rights or (
                            respect_property_rights == 0 and max_cons_surp_ch > 0):  # i.e. they actually traded some resources

                        agent.agent_last_traded_with = cp_agent
                        cp_agent.agent_last_traded_with = agent

                #                elif self.trade_prices == 'fixed':
                #
                #                    # create copies of the two trading baskets to record in transactions
                #                    a_tb = copy.deepcopy(agent.trading_basket[0])
                #                    b_tb = copy.deepcopy(cp_agent.trading_basket[0])
                #
                #                    for i in np.arange(num_res_founts):
                #
                #                        if print_fine_dets == 1:
                #                            print('\nfountain (i) = ', i)
                #
                #                        # create cropped versions of trading_baskets
                #                        a_cropped_tb = copy.deepcopy(agent.trading_basket[0])
                #                        b_cropped_tb = copy.deepcopy(cp_agent.trading_basket[0])
                #
                #                        a_cropped_tb = np.delete(a_cropped_tb, i)
                #                        b_cropped_tb = np.delete(b_cropped_tb, i)
                #
                #                        if print_fine_dets == 1:
                #                            print('a_cropped_tb =', a_cropped_tb)
                #                            print('b_cropped_tb =', b_cropped_tb)
                #
                #                        for j in np.arange(num_res_founts - 1):
                #
                #                            if print_fine_dets == 1:
                #                                print('iter j =', j)
                #
                #                            if (agent.trading_basket[0][i] > 0 and cp_agent.trading_basket[0][i] < 0) and (a_cropped_tb[j] < 0 and b_cropped_tb[j] > 0):
                #                            # then a sells (b buys) resource i and a buys (b sells) resource j - change basket_array and also
                #                            # trading_basket.  First we find out how much they exchange:
                #
                #                                tot_trans = np.min([np.abs(agent.trading_basket[0][i]), np.abs(cp_agent.trading_basket[0][i]), np.abs(a_cropped_tb[j]), np.abs(b_cropped_tb[j])])
                #
                #                                if tot_trans > 0:       # only go on if this is true
                #
                #                                    if print_fine_dets == 1:
                #                                        print('tot_trans =', tot_trans)
                #
                #                                    agent.basket_array[0][i] -= tot_trans
                #                                    cp_agent.basket_array[0][i] += tot_trans
                #                                    agent.trading_basket[0][i] -= tot_trans
                #                                    cp_agent.trading_basket[0][i] += tot_trans
                #                                    a_cropped_tb[j] -= tot_trans
                #                                    b_cropped_tb[j] += tot_trans
                #                                    transactions += tot_trans
                #
                #                                    if i <= j:
                #
                #                                        agent.basket_array[0][j + 1] += tot_trans
                #                                        cp_agent.basket_array[0][j + 1] -= tot_trans
                #                                        agent.trading_basket[0][j + 1] += tot_trans
                #                                        cp_agent.trading_basket[0][j + 1] -= tot_trans
                #
                #                                        # record what traded and how much:
                #                                        trans_receipt = np.array([i, j + 1, tot_trans, tot_trans, 1])
                #
                #                                        # add this to traded_array
                #                                        traded_array.append(trans_receipt)
                #
                #                                        # create a transaction instance to record all relevant data
                #                                        transaction = Transaction(copy.copy(agent.for_strat_array), copy.copy(cp_agent.for_strat_array), copy.deepcopy(agent.location), day, i, j + 1, copy.copy(agent.home), copy.copy(cp_agent.home), tot_trans, tot_trans, move, copy.deepcopy(agent.grid_trgt), copy.deepcopy(cp_agent.grid_trgt), copy.deepcopy(a_tb), copy.deepcopy(b_tb), copy.deepcopy(agent.trade_loc_rec), copy.deepcopy(cp_agent.trade_loc_rec), copy.deepcopy(agent.MRS_array), copy.deepcopy(cp_agent.MRS_array), str(agent), str(cp_agent), trans_agr_MRS=1, agent_a_tribe=copy.copy(agent.tribe), agent_b_tribe=copy.copy(cp_agent.tribe))
                #
                #                                        agent.loc_mems_array[day][i][j + 1].append(len(dbs.trans_db))
                #                                        cp_agent.loc_mems_array[day][j + 1][i].append(len(dbs.trans_db))
                #
                #                                        trans_numbs_array.append(len(dbs.trans_db))
                #                                        dbs.trans_db.append(transaction)
                #
                #                                    else:
                #
                #                                        agent.basket_array[0][j] += tot_trans
                #                                        cp_agent.basket_array[0][j] -= tot_trans
                #                                        agent.trading_basket[0][j] += tot_trans
                #                                        cp_agent.trading_basket[0][j] -= tot_trans
                #
                #                                        # record what traded and how much:
                #                                        trans_receipt = np.array([i, j, tot_trans, tot_trans, 1])
                #
                #                                        # add this to traded_array
                #                                        traded_array.append(trans_receipt)
                #
                #                                        # create a transaction instance to record all relevant data
                #                                        transaction = Transaction(copy.copy(agent.for_strat_array), copy.copy(cp_agent.for_strat_array), copy.deepcopy(agent.location), day, i, j, copy.copy(agent.home), copy.copy(cp_agent.home), tot_trans, tot_trans, move, copy.deepcopy(agent.grid_trgt), copy.deepcopy(cp_agent.grid_trgt), copy.deepcopy(a_tb), copy.deepcopy(b_tb), copy.deepcopy(agent.trade_loc_rec), copy.deepcopy(cp_agent.trade_loc_rec), copy.deepcopy(agent.MRS_array), copy.deepcopy(cp_agent.MRS_array), str(agent), str(cp_agent), trans_agr_MRS=1, agent_a_tribe=copy.copy(agent.tribe), agent_b_tribe=copy.copy(cp_agent.tribe))
                #
                #                                        agent.loc_mems_array[day][i][j].append(len(dbs.trans_db))
                #                                        cp_agent.loc_mems_array[day][j][i].append(len(dbs.trans_db))
                #
                #                                        trans_numbs_array.append(len(dbs.trans_db))
                #                                        dbs.trans_db.append(transaction)
                #
                #                            elif (agent.trading_basket[0][i] < 0 and cp_agent.trading_basket[0][i] > 0) and (a_cropped_tb[j] > 0 and b_cropped_tb[j] < 0):
                #                                # then a buys (b sells) resource i and a sells (b buys) resource j - change basket_array and trading_basket.  First we find out how much
                #                                # they exchange
                #
                #                                tot_trans = np.min([np.abs(agent.trading_basket[0][i]), np.abs(cp_agent.trading_basket[0][i]), np.abs(a_cropped_tb[j]), np.abs(b_cropped_tb[j])])
                #
                #                                if tot_trans > 0:       # only go on if this is true
                #
                #                                    if print_fine_dets == 1:
                #                                        print('tot_trans =', tot_trans)
                #
                #                                    agent.basket_array[0][i] += tot_trans
                #                                    cp_agent.basket_array[0][i] -= tot_trans
                #                                    agent.trading_basket[0][i] += tot_trans
                #                                    cp_agent.trading_basket[0][i] -= tot_trans
                #                                    a_cropped_tb[j] += tot_trans
                #                                    b_cropped_tb[j] -= tot_trans
                #                                    transactions += tot_trans
                #
                #                                    if i <= j:
                #
                #                                        if print_fine_dets == 1:
                #                                            print('i <= j')
                #
                #                                        cp_agent.basket_array[0][j + 1] += tot_trans
                #                                        agent.basket_array[0][j + 1] -= tot_trans
                #                                        cp_agent.trading_basket[0][j + 1] += tot_trans
                #                                        agent.trading_basket[0][j + 1] -= tot_trans
                #
                #                                        # record what traded and how much:
                #                                        trans_receipt = np.array([i, j + 1, tot_trans, tot_trans, 1])
                #
                #                                        # add this to traded_array
                #                                        traded_array.append(trans_receipt)
                #
                #                                        # create a transaction instance to record all relevant data
                #                                        transaction = Transaction(copy.copy(agent.for_strat_array), copy.copy(cp_agent.for_strat_array), copy.deepcopy(agent.location), day, j + 1, i, copy.copy(agent.home), copy.copy(cp_agent.home), tot_trans, tot_trans, move, copy.deepcopy(agent.grid_trgt), copy.deepcopy(cp_agent.grid_trgt), copy.deepcopy(a_tb), copy.deepcopy(b_tb), copy.deepcopy(agent.trade_loc_rec), copy.deepcopy(cp_agent.trade_loc_rec), copy.deepcopy(agent.MRS_array), copy.deepcopy(cp_agent.MRS_array), str(agent), str(cp_agent), trans_agr_MRS=1, agent_a_tribe=copy.copy(agent.tribe), agent_b_tribe=copy.copy(cp_agent.tribe))
                #
                #                                        agent.loc_mems_array[day][j + 1][i].append(len(dbs.trans_db))
                #                                        cp_agent.loc_mems_array[day][i][j + 1].append(len(dbs.trans_db))
                #
                #                                        trans_numbs_array.append(len(dbs.trans_db))
                #                                        dbs.trans_db.append(transaction)
                #
                #                                    else:
                #
                #                                        if print_fine_dets == 1:
                #                                            print('i > j')
                #
                #                                        cp_agent.basket_array[0][j] += tot_trans
                #                                        agent.basket_array[0][j] -= tot_trans
                #                                        cp_agent.trading_basket[0][j] += tot_trans
                #                                        agent.trading_basket[0][j] -= tot_trans
                #
                #                                        # record what traded and how much:
                #                                        trans_receipt = np.array([i, j, tot_trans, tot_trans, 1])
                #
                #                                        # add this to traded_array
                #                                        traded_array.append(trans_receipt)
                #
                #                                        # create a transaction instance to record all relevant data
                #                                        transaction = Transaction(copy.copy(agent.for_strat_array), copy.copy(cp_agent.for_strat_array), copy.deepcopy(agent.location), day, j, i, copy.copy(agent.home), copy.copy(cp_agent.home), tot_trans, tot_trans, move, copy.deepcopy(agent.grid_trgt), copy.deepcopy(cp_agent.grid_trgt), copy.deepcopy(a_tb), copy.deepcopy(b_tb), copy.deepcopy(agent.trade_loc_rec), copy.deepcopy(cp_agent.trade_loc_rec), copy.deepcopy(agent.MRS_array), copy.deepcopy(cp_agent.MRS_array), str(agent), str(cp_agent), trans_agr_MRS=1, agent_a_tribe=copy.copy(agent.tribe), agent_b_tribe=copy.copy(cp_agent.tribe))
                #
                #                                        agent.loc_mems_array[day][j][i].append(len(dbs.trans_db))
                #                                        cp_agent.loc_mems_array[day][i][j].append(len(dbs.trans_db))
                #
                #                                        trans_numbs_array.append(len(dbs.trans_db))
                #                                        dbs.trans_db.append(transaction)
                #
                #                    # now we need to determine which agents will remove themselves from the grid i.e. they are totally satisfied after
                #                    # transacting
                #
                #                    if (np.any(agent.trading_basket > 0) and np.any(agent.trading_basket < 0)) == False:
                #                        remove_agents = np.append(remove_agents, agent)
                #
                #                    if (np.any(cp_agent.trading_basket > 0) and np.any(cp_agent.trading_basket < 0)) == False:
                #                        remove_agents = np.append(remove_agents, cp_agent)
                #
                #                    # Here we re-write the agents' sell_array and buy_array
                #                    for ag in [agent, cp_agent]:
                #
                #                        if ag not in remove_agents:
                #
                #                            if print_fine_dets == 1:
                #                                print('\nagent =', ag)
                #                                print('old sell_array =', ag.sell_array)
                #                                print('old buy_array =', ag.buy_array)
                #
                #                            ag.sell_array = []
                #                            ag.buy_array = []
                #
                #                            for res in np.arange(num_res_founts):
                #
                #                                # Update sell_array
                #                                if ag.trading_basket[0][res] > 0:
                #                                    ag.sell_array.append(res)
                #
                #                                # equivalently, update the agent's 'buy_array'
                #                                if ag.trading_basket[0][res] < 0:
                #                                    ag.buy_array.append(res)
                #
                #                            if print_fine_dets == 1:
                #                                print('\nnew sell_array =', ag.sell_array)
                #                                print('new buy_array =', ag.buy_array)
                #
                # This is the end of the 'self.trade_prices == 'fixed'' condition

                if print_fine_dets == 1:
                    print('\nagent.agent_res_array =', agent.agent_res_array)
                    print('POST agent.basket_array =', agent.basket_array)
                    print('agent.aggr_res_array =', agent.aggr_res_array)

                    print('\ncp_agent.agent_res_array =', cp_agent.agent_res_array)
                    print('POST cp_agent.basket_array =', cp_agent.basket_array)
                    print('cp_agent.aggr_res_array =', cp_agent.aggr_res_array)

                    print('\nPOST agent.trading_basket =', agent.trading_basket)
                    print('POST cp_agent.trading_basket =', cp_agent.trading_basket)

                    print('\ntransactions =', transactions)

                    print('\nremove_agents =', remove_agents)

                if print_fine_dets == 1:
                    print('\n[remove_agents, transactions, traded_array, trans_numbs_array] =',
                          [remove_agents, transactions, traded_array, trans_numbs_array])

                    # we only continue the iteration loop if num_res_founts > 2
                if num_res_founts == 2:
                    stop_transacting = 1

                # This is the end of the 'while attempt_to_transact == 1' loop

        # at the end of the interaction, if the agents are respecting property rights, we need to find out the reduced value of the transactions for the agents
        # let's start with the agent - the resource which had been its minimum was agent_min_res at the start
        if respect_property_rights:

            # and find out which resource most defficient in
            agent_min_res_value = np.min(start_agent_tot_ress)
            cp_agent_min_res_value = np.min(start_cp_agent_tot_ress)

            agent_min_res = 0
            cp_agent_min_res = 0

            for res in range(num_res_founts):

                if start_agent_tot_ress[res] == agent_min_res_value:
                    agent_min_res = res

                if start_cp_agent_tot_ress[res] == cp_agent_min_res_value:
                    cp_agent_min_res = res

            # and find out which resource most defficient in
            agent_min_res_value = np.min(start_agent_tot_ress)
            cp_agent_min_res_value = np.min(start_cp_agent_tot_ress)

            start_agent_prop_steal = copy.copy(agent.prop_steal)
            start_agent_prop_fight_back = copy.copy(agent.prop_fight_back)

            start_cp_agent_prop_steal = copy.copy(cp_agent.prop_steal)
            start_cp_agent_prop_fight_back = copy.copy(cp_agent.prop_fight_back)

            end_agent_tot_ress = agent.basket_array[0] + agent.agent_res_array[0]
            end_cp_agent_tot_ress = cp_agent.basket_array[0] + cp_agent.agent_res_array[0]

            agent_ch_ress = end_agent_tot_ress - start_agent_tot_ress
            cp_agent_ch_ress = end_cp_agent_tot_ress - start_cp_agent_tot_ress

            agent_net_benefit = 0

            agent_MRS_array = generate_MRS_array([start_agent_tot_ress], print_fine_dets=0)

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n agent total res_array ', agent.agent_res_array[0] + agent.basket_array[0])
                print(' agent.basket_array[0]', agent.basket_array[0])
                print(' agent.agent_res_array[0]', agent.agent_res_array[0])
                print(' end_agent_tot_ress', end_agent_tot_ress)
                print(' start_agent_tot_ress', start_agent_tot_ress)
                print(' agent_MRS_array\n', agent_MRS_array)
                print(' agent_min_res', agent_min_res)
                print(' iterate over resources to find agent_net_benefit:')
                print(' agent_ch_ress =', agent_ch_ress)
                print(' cp_agent_ch_ress =', cp_agent_ch_ress)

            for res in range(num_res_founts):

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n res ', res)

                if res == agent_min_res:

                    agent_net_benefit += agent_ch_ress[agent_min_res]

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n this is the same resource as min_res so no conversion necessary')
                        print(' agent_ch_ress[agent_min_res] =', agent_ch_ress[agent_min_res])

                else:

                    agent_net_benefit += agent_MRS_array[agent_min_res][res] * agent_ch_ress[res]

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n this is a different resource to min_res')
                        print(' agent_MRS_array[agent_min_res][res]', agent_MRS_array[agent_min_res][res])
                        print(' agent_ch_ress[res]', agent_ch_ress[res])
                        print(' agent_MRS_array[agent_min_res][res] * agent_ch_ress[res]',
                              agent_MRS_array[agent_min_res][res] * agent_ch_ress[res])

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n after iterating: agent_net_benefit = ', agent_net_benefit)

            ch_agent_prop_steal = (adjust_props_r * agent_net_benefit) * agent.prop_steal * (1 - agent.prop_steal)
            ch_agent_prop_fight_back = (adjust_props_r * agent_net_benefit) * agent.prop_fight_back * (
                    1 - agent.prop_fight_back)

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n ch_agent_prop_steal =', ch_agent_prop_steal)
                print(' ch_agent_prop_fight_back =', ch_agent_prop_fight_back)

            # now the same for the cp_agent:
            cp_agent_net_benefit = 0

            cp_agent_MRS_array = generate_MRS_array([start_cp_agent_tot_ress], print_fine_dets=0)

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n\n\n cp_agent total res_array ', cp_agent.agent_res_array[0] + cp_agent.basket_array[0])
                print('\n cp_agent_MRS_array\n', cp_agent_MRS_array)
                print('\n cp_agent_min_res', cp_agent_min_res)
                print('\n iterate over resources to find agent_net_benefit:')

            for res in range(num_res_founts):

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n res ', res)

                if res == cp_agent_min_res:

                    cp_agent_net_benefit += cp_agent_ch_ress[cp_agent_min_res]

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n this is the same resource as min_res so no conversion necessary')
                        print(' cp_agent_ch_ress[cp_agent_min_res] =', cp_agent_ch_ress[cp_agent_min_res])

                else:

                    cp_agent_net_benefit += cp_agent_MRS_array[cp_agent_min_res][res] * cp_agent_ch_ress[res]

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n this is a different resource to min_res')
                        print(' cp_agent_MRS_array[cp_agent_min_res][res]', cp_agent_MRS_array[cp_agent_min_res][res])
                        print(' cp_agent_ch_ress[res]', cp_agent_ch_ress[res])
                        print(' cp_agent_MRS_array[cp_agent_min_res][res] * cp_agent_ch_ress[res]',
                              cp_agent_MRS_array[cp_agent_min_res][res] * cp_agent_ch_ress[res])

            # we also add information to the transaction
            transaction.agent_a_reduced_value = agent_net_benefit
            transaction.agent_b_reduced_value = cp_agent_net_benefit

            if print_fine_dets == 1:
                print('\n after iterating: cp_agent_net_benefit = ', cp_agent_net_benefit)

        # at the end of the interaction, if the agents are not respecting property rights, we must adjust their propensities to steal and fight back.
        if respect_property_rights == 0 and agent_dec != 'none' and cp_agent_dec != 'none':

            #            if agent.tribe != cp_agent.tribe:
            #
            #                end_agent_tot_ress = agent.basket_array[0] + agent.agent_res_array[0]
            #                end_cp_agent_tot_ress = cp_agent.basket_array[0] + cp_agent.agent_res_array[0]
            #
            #                agent_ch_ress = end_agent_tot_ress - start_agent_tot_ress
            #                cp_agent_ch_ress = end_cp_agent_tot_ress - start_cp_agent_tot_ress
            #
            #            print_fine_dets = 1
            #            if agent.tribe == cp_agent.tribe:

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n\n\n\n -------- interaction: end numbers --------- ')

                print('\n start props:\n')
                print(' agent.prop_steal %1.5f' % (agent.prop_steal),
                      '  agent.prop_fight_back %1.5f' % (agent.prop_fight_back))
                print(' cp_agent.prop_steal %1.5f' % (cp_agent.prop_steal),
                      '  cp_agent.prop_fight_back %1.5f' % (cp_agent.prop_fight_back))

                print('\n agent.agent_res_array ', agent.agent_res_array[0])
                print(' agent_start_basket =', agent_start_basket[0])

                print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array[0])
                print(' cp_agent_start_basket =', cp_agent_start_basket[0])

            start_agent_prop_steal = copy.copy(agent.prop_steal)
            start_agent_prop_fight_back = copy.copy(agent.prop_fight_back)

            start_cp_agent_prop_steal = copy.copy(cp_agent.prop_steal)
            start_cp_agent_prop_fight_back = copy.copy(cp_agent.prop_fight_back)

            end_agent_tot_ress = agent.basket_array[0] + agent.agent_res_array[0]
            end_cp_agent_tot_ress = cp_agent.basket_array[0] + cp_agent.agent_res_array[0]

            agent_ch_ress = end_agent_tot_ress - start_agent_tot_ress
            cp_agent_ch_ress = end_cp_agent_tot_ress - start_cp_agent_tot_ress

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n agent_ch_ress', agent_ch_ress)
                print('\n cp_agent_ch_ress', cp_agent_ch_ress)

            # in order to generate a net benefit value for each agent, we find the resource gain (loss) in units of the resource which was its lowest at the start of the interaction.
            # We use the MRS to convert from one resource to another

            # let's start with the agent - the resource which had been its minimum was agent_min_res at the start
            agent_net_benefit = 0

            agent_MRS_array = generate_MRS_array([start_agent_tot_ress], print_fine_dets=0)

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n agent total res_array ', agent.agent_res_array[0] + agent.basket_array[0])
                print('\n agent_MRS_array\n', agent_MRS_array)
                print('\n agent_min_res', agent_min_res)
                print('\n iterate over resources to find agent_net_benefit:')

            for res in range(num_res_founts):

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n res ', res)

                if res == agent_min_res:

                    agent_net_benefit += agent_ch_ress[agent_min_res]

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n this is the same resource as min_res so no conversion necessary')
                        print(' agent_ch_ress[agent_min_res] =', agent_ch_ress[agent_min_res])

                else:

                    agent_net_benefit += agent_MRS_array[agent_min_res][res] * agent_ch_ress[res]

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n this is a different resource to min_res')
                        print(' agent_MRS_array[agent_min_res][res]', agent_MRS_array[agent_min_res][res])
                        print(' agent_ch_ress[res]', agent_ch_ress[res])
                        print(' agent_MRS_array[agent_min_res][res] * agent_ch_ress[res]',
                              agent_MRS_array[agent_min_res][res] * agent_ch_ress[res])

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n after iterating: agent_net_benefit = ', agent_net_benefit)

            ch_agent_prop_steal = (adjust_props_r * agent_net_benefit) * agent.prop_steal * (1 - agent.prop_steal)
            ch_agent_prop_fight_back = (adjust_props_r * agent_net_benefit) * agent.prop_fight_back * (
                        1 - agent.prop_fight_back)

            ch_agent_prop_steal = agent_net_benefit
            ch_agent_prop_fight_back = agent_net_benefit

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n ch_agent_prop_steal =', ch_agent_prop_steal)
                print(' ch_agent_prop_fight_back =', ch_agent_prop_fight_back)

            # now the same for the cp_agent:
            cp_agent_net_benefit = 0

            cp_agent_MRS_array = generate_MRS_array([start_cp_agent_tot_ress], print_fine_dets=0)

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n\n\n cp_agent total res_array ', cp_agent.agent_res_array[0] + cp_agent.basket_array[0])
                print('\n cp_agent_MRS_array\n', cp_agent_MRS_array)
                print('\n cp_agent_min_res', cp_agent_min_res)
                print('\n iterate over resources to find agent_net_benefit:')

            for res in range(num_res_founts):

                if print_fine_dets == 1 or print_model_2_dets == 1:
                    print('\n res ', res)

                if res == cp_agent_min_res:

                    cp_agent_net_benefit += cp_agent_ch_ress[cp_agent_min_res]

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n this is the same resource as min_res so no conversion necessary')
                        print(' cp_agent_ch_ress[cp_agent_min_res] =', cp_agent_ch_ress[cp_agent_min_res])

                else:

                    cp_agent_net_benefit += cp_agent_MRS_array[cp_agent_min_res][res] * cp_agent_ch_ress[res]

                    if print_fine_dets == 1 or print_model_2_dets == 1:
                        print('\n this is a different resource to min_res')
                        print(' cp_agent_MRS_array[cp_agent_min_res][res]', cp_agent_MRS_array[cp_agent_min_res][res])
                        print(' cp_agent_ch_ress[res]', cp_agent_ch_ress[res])
                        print(' cp_agent_MRS_array[cp_agent_min_res][res] * cp_agent_ch_ress[res]',
                              cp_agent_MRS_array[cp_agent_min_res][res] * cp_agent_ch_ress[res])

            if print_fine_dets == 1:
                print('\n after iterating: cp_agent_net_benefit = ', cp_agent_net_benefit)

            # ch_cp_agent_prop_steal = (adjust_props_r * cp_agent_net_benefit) * cp_agent.prop_steal * (
            #             1 - cp_agent.prop_steal)
            # ch_cp_agent_prop_fight_back = (adjust_props_r * cp_agent_net_benefit) * cp_agent.prop_fight_back * (
            #             1 - cp_agent.prop_fight_back)

            ch_cp_agent_prop_steal = cp_agent_net_benefit
            ch_cp_agent_prop_fight_back = cp_agent_net_benefit

            if print_fine_dets == 1 or print_model_2_dets == 1:
                print('\n ch_cp_agent_prop_steal =', ch_cp_agent_prop_steal)
                print(' ch_cp_agent_prop_fight_back =', ch_cp_agent_prop_fight_back)

            # defaults:
            agent_record = None
            cp_agent_record = None

            # Now we have to adjust the agents' propensities to steal and fight back
            if agent_dec == 'steal' and cp_agent_dec == 'steal':  # straight fight - no fighting back here, both chose to steal

                if agent.tribe == cp_agent.tribe and strat_choice == 'heuristics' and (strangers_if_unknown == 0 or (
                        strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and
                        cp_agent.agent_knows_cp_dict[str(agent)])):
                    # the gain to the agent uses a logistic equation - it uses the gain (loss) to the agent plus (minus) the gain (loss) to the cp_agent (* some beta fraction)
                    agent.prop_steal += adjust_props_r * (
                                agent_net_benefit + (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_steal * (
                                                    1 - agent.prop_steal)

                    cp_agent.prop_steal += adjust_props_r * (
                                cp_agent_net_benefit + (agent_net_benefit * agent_intn_beta)) * cp_agent.prop_steal * (
                                                       1 - cp_agent.prop_steal)

                # if we're only changing one agent:
                if agent is agent_population.change_agent:
                    agent.prop_steal += 0.08 * (
                                agent_net_benefit + (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_steal * (
                                                    1 - agent.prop_steal)

                if cp_agent is agent_population.change_agent:
                    cp_agent.prop_steal += 0.08 * (
                                cp_agent_net_benefit + (agent_net_benefit * agent_intn_beta)) * cp_agent.prop_steal * (
                                                       1 - cp_agent.prop_steal)

                agent_record = [str(cp_agent), 1, 0, 1,
                                0]  # [1 is whether other agent fought; [2] is whether they fought back; [3] is whether I fought; [4] is whether I fought back]
                cp_agent_record = [str(agent), 1, 0, 1, 0]

            elif agent_dec == 'steal' and cp_agent_dec == 'fight_back':  # then cp_agent fought back - if it won we add to prop_fight_back; if lost, subtract

                if agent.tribe == cp_agent.tribe and strat_choice == 'heuristics' and (strangers_if_unknown == 0 or (
                        strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and
                        cp_agent.agent_knows_cp_dict[str(agent)])):
                    agent.prop_steal += adjust_props_r * (
                                agent_net_benefit + (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_steal * (
                                                    1 - agent.prop_steal)
                    agent.prop_fight_back += adjust_props_r * (
                                cp_agent_net_benefit * agent_intn_beta) * agent.prop_fight_back * (
                                                         1 - agent.prop_fight_back)

                    cp_agent.prop_steal += adjust_props_r * (
                                (agent_net_benefit * agent_intn_beta) + cp_agent_net_benefit) * cp_agent.prop_steal * (
                                                       1 - cp_agent.prop_steal)
                    cp_agent.prop_fight_back += (adjust_props_r * cp_agent_net_benefit) * cp_agent.prop_fight_back * (
                                1 - cp_agent.prop_fight_back)

                # if we're only changing one agent:
                if agent is agent_population.change_agent:
                    agent.prop_steal += 0.08 * (
                                agent_net_benefit + (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_steal * (
                                                    1 - agent.prop_steal)
                    agent.prop_fight_back += 0.08 * (cp_agent_net_benefit * agent_intn_beta) * agent.prop_fight_back * (
                                1 - agent.prop_fight_back)

                if cp_agent is agent_population.change_agent:
                    cp_agent.prop_steal += 0.08 * (
                                (agent_net_benefit * agent_intn_beta) + cp_agent_net_benefit) * cp_agent.prop_steal * (
                                                       1 - cp_agent.prop_steal)
                    cp_agent.prop_fight_back += (0.08 * cp_agent_net_benefit) * cp_agent.prop_fight_back * (
                                1 - cp_agent.prop_fight_back)

                agent_record = [str(cp_agent), 0, 1, 1, 0]
                cp_agent_record = [str(agent), 1, 0, 0, 1]

            elif agent_dec == 'fight_back' and cp_agent_dec == 'steal':  # then agent fought back - if it won we add to prop_fight_back; if lost, subtract

                if agent.tribe == cp_agent.tribe and strat_choice == 'heuristics' and (strangers_if_unknown == 0 or (
                        strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and
                        cp_agent.agent_knows_cp_dict[str(agent)])):
                    agent.prop_steal += adjust_props_r * (
                                agent_net_benefit + (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_steal * (
                                                    1 - agent.prop_steal)
                    agent.prop_fight_back += (adjust_props_r * agent_net_benefit) * agent.prop_fight_back * (
                                1 - agent.prop_fight_back)

                    cp_agent.prop_steal += adjust_props_r * (
                                (agent_net_benefit * agent_intn_beta) + cp_agent_net_benefit) * cp_agent.prop_steal * (
                                                       1 - cp_agent.prop_steal)
                    cp_agent.prop_fight_back += adjust_props_r * (
                                agent_net_benefit * agent_intn_beta) * cp_agent.prop_fight_back * (
                                                            1 - cp_agent.prop_fight_back)

                # if we're only changing one agent:
                if agent is agent_population.change_agent:
                    agent.prop_steal += 0.08 * (
                                agent_net_benefit + (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_steal * (
                                                    1 - agent.prop_steal)
                    agent.prop_fight_back += (0.08 * agent_net_benefit) * agent.prop_fight_back * (
                                1 - agent.prop_fight_back)

                if cp_agent is agent_population.change_agent:
                    cp_agent.prop_steal += 0.08 * (
                                (agent_net_benefit * agent_intn_beta) + cp_agent_net_benefit) * cp_agent.prop_steal * (
                                                       1 - cp_agent.prop_steal)
                    cp_agent.prop_fight_back += 0.08 * (
                                agent_net_benefit * agent_intn_beta) * cp_agent.prop_fight_back * (
                                                            1 - cp_agent.prop_fight_back)

                agent_record = [str(cp_agent), 1, 0, 0, 1]
                cp_agent_record = [str(agent), 0, 1, 1, 0]

            elif agent_dec == 'steal' and cp_agent_dec == 'trade':  # then cp_agent wimped out: add agent's ch_agent_prop_steal to prop_steal; and cp_agent will have lost
                # out so we subtract loss to increase prop_fight_back

                if agent.tribe == cp_agent.tribe and strat_choice == 'heuristics' and (strangers_if_unknown == 0 or (
                        strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and
                        cp_agent.agent_knows_cp_dict[str(agent)])):
                    agent.prop_steal += adjust_props_r * (
                                agent_net_benefit - (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_steal * (
                                                    1 - agent.prop_steal)
                    agent.prop_fight_back += adjust_props_r * (
                                -1 * (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_fight_back * (
                                                         1 - agent.prop_fight_back)

                    cp_agent.prop_steal += adjust_props_r * (
                                (agent_net_benefit * agent_intn_beta) - cp_agent_net_benefit) * cp_agent.prop_steal * (
                                                       1 - cp_agent.prop_steal)
                    cp_agent.prop_fight_back += adjust_props_r * (
                                -1 * cp_agent_net_benefit) * cp_agent.prop_fight_back * (1 - cp_agent.prop_fight_back)

                # if we're only changing one agent:
                if agent is agent_population.change_agent:
                    agent.prop_steal += 0.08 * (
                                agent_net_benefit - (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_steal * (
                                                    1 - agent.prop_steal)
                    agent.prop_fight_back += 0.08 * (
                                -1 * (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_fight_back * (
                                                         1 - agent.prop_fight_back)

                if cp_agent is agent_population.change_agent:
                    cp_agent.prop_steal += 0.08 * (
                                (agent_net_benefit * agent_intn_beta) - cp_agent_net_benefit) * cp_agent.prop_steal * (
                                                       1 - cp_agent.prop_steal)
                    cp_agent.prop_fight_back += 0.08 * (-1 * cp_agent_net_benefit) * cp_agent.prop_fight_back * (
                                1 - cp_agent.prop_fight_back)

                agent_record = [str(cp_agent), 0, 0, 1, 0]
                cp_agent_record = [str(agent), 1, 0, 0, 0]

            elif agent_dec == 'trade' and cp_agent_dec == 'steal':  # then agent wimped out

                if agent.tribe == cp_agent.tribe and strat_choice == 'heuristics' and (strangers_if_unknown == 0 or (
                        strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and
                        cp_agent.agent_knows_cp_dict[str(agent)])):
                    agent.prop_steal += adjust_props_r * (
                                (cp_agent_net_benefit * agent_intn_beta) - agent_net_benefit) * agent.prop_steal * (
                                                    1 - agent.prop_steal)
                    agent.prop_fight_back += adjust_props_r * (-1 * agent_net_benefit) * agent.prop_fight_back * (
                                1 - agent.prop_fight_back)

                    cp_agent.prop_steal += adjust_props_r * (
                                cp_agent_net_benefit - (agent_net_benefit * agent_intn_beta)) * cp_agent.prop_steal * (
                                                       1 - cp_agent.prop_steal)
                    cp_agent.prop_fight_back += adjust_props_r * (
                                -1 * agent_net_benefit * agent_intn_beta) * cp_agent.prop_fight_back * (
                                                            1 - cp_agent.prop_fight_back)

                # if we're only changing one agent:
                if agent is agent_population.change_agent:
                    agent.prop_steal += 0.08 * (
                                (cp_agent_net_benefit * agent_intn_beta) - agent_net_benefit) * agent.prop_steal * (
                                                    1 - agent.prop_steal)
                    agent.prop_fight_back += 0.08 * (-1 * agent_net_benefit) * agent.prop_fight_back * (
                                1 - agent.prop_fight_back)

                if cp_agent is agent_population.change_agent:
                    cp_agent.prop_steal += 0.08 * (
                                cp_agent_net_benefit - (agent_net_benefit * agent_intn_beta)) * cp_agent.prop_steal * (
                                                       1 - cp_agent.prop_steal)
                    cp_agent.prop_fight_back += 0.08 * (
                                -1 * agent_net_benefit * agent_intn_beta) * cp_agent.prop_fight_back * (
                                                            1 - cp_agent.prop_fight_back)

                agent_record = [str(cp_agent), 1, 0, 0, 0]
                cp_agent_record = [str(agent), 0, 0, 1, 0]

            elif agents_trade_peacefully:

                if agent.tribe == cp_agent.tribe and strat_choice == 'heuristics' and (strangers_if_unknown == 0 or (
                        strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and
                        cp_agent.agent_knows_cp_dict[str(agent)])):
                    agent.prop_steal += -1 * (adjust_props_r * (
                                agent_net_benefit + (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_steal * (
                                                          1 - agent.prop_steal))
                    agent.prop_fight_back += 0

                    cp_agent.prop_steal += -1 * (adjust_props_r * (
                                cp_agent_net_benefit + (agent_net_benefit * agent_intn_beta)) * cp_agent.prop_steal * (
                                                             1 - cp_agent.prop_steal))
                    cp_agent.prop_fight_back += 0

                # if we're only changing one agent:
                if agent is agent_population.change_agent:
                    agent.prop_steal += -1 * (0.08 * (
                                agent_net_benefit + (cp_agent_net_benefit * agent_intn_beta)) * agent.prop_steal * (
                                                          1 - agent.prop_steal))

                if cp_agent is agent_population.change_agent:
                    cp_agent.prop_steal += -1 * (0.08 * (
                                cp_agent_net_benefit + (agent_net_benefit * agent_intn_beta)) * cp_agent.prop_steal * (
                                                             1 - cp_agent.prop_steal))

                # add to reputations dict's
                if str(cp_agent) not in agent.reputations_dict:  # this is where a new entry in the dict occurs

                    agent.reputations_dict[str(cp_agent)] = [np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int)]

                agent.reputations_dict[str(cp_agent)][1][day] += 1

                # now the cp_agent:
                if str(agent) not in cp_agent.reputations_dict:
                    cp_agent.reputations_dict[str(agent)] = [np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int),
                                                             np.zeros(shape=(num_rounds), dtype=int)]

                cp_agent.reputations_dict[str(agent)][1][day] += 1

                # update this also
                agent.agent_knows_cp_dict[str(cp_agent)] = 1
                cp_agent.agent_knows_cp_dict[str(agent)] = 1

                # we update these arrays, which helps us shortcut some of the coding when agents evaluate each other.  We only record trans in last_intn if they have traded
                if transaction.good_a is not None:

                    agent.last_intn = transaction
                    cp_agent.last_intn = transaction

                    # we also update these values - we only update the reputations data when we need to and this is part of that process
                    agent.need_to_update_reps[str(cp_agent)] = 1
                    cp_agent.need_to_update_reps[str(agent)] = 1

                agent.trades_array.append(transaction)
                cp_agent.trades_array.append(transaction)

                # we also add information to the transaction
                transaction.agent_a_reduced_value = agent_net_benefit
                transaction.agent_b_reduced_value = cp_agent_net_benefit

            # set props' floors and ceiling (this means that props cannot get locked in to 1 or 0, which would mean they cannot change)
            if agent.tribe == cp_agent.tribe and strat_choice == 'heuristics' and (strangers_if_unknown == 0 or (
                    strangers_if_unknown and agent.agent_knows_cp_dict[str(cp_agent)] and cp_agent.agent_knows_cp_dict[
                str(agent)])):

                if agent.prop_steal > prop_steal_ceil:
                    agent.prop_steal = prop_steal_ceil

                if agent.prop_steal < prop_steal_floor:
                    agent.prop_steal = prop_steal_floor

                if agent.prop_fight_back > prop_fight_back_ceil:
                    agent.prop_fight_back = prop_fight_back_ceil

                if agent.prop_fight_back < prop_fight_back_floor:
                    agent.prop_fight_back = prop_fight_back_floor

                if cp_agent.prop_steal > prop_steal_ceil:
                    cp_agent.prop_steal = prop_steal_ceil

                if cp_agent.prop_steal < prop_steal_floor:
                    cp_agent.prop_steal = prop_steal_floor

                if cp_agent.prop_fight_back > prop_fight_back_ceil:
                    cp_agent.prop_fight_back = prop_fight_back_ceil

                if cp_agent.prop_fight_back < prop_fight_back_floor:
                    cp_agent.prop_fight_back = prop_fight_back_floor

                if print_fine_dets == 1 or print_model_2_dets == 1:  # or np.abs(cp_agent.prop_steal - start_cp_agent_prop_steal) > 0.25 or np.abs(agent.prop_steal - start_agent_prop_steal) > 0.25) and day > 200:
                    print('\n agent benefit:', agent_net_benefit)
                    print(' cp_agent benefit:', cp_agent_net_benefit)

                    print('\n agent_dec', agent_dec)
                    print('\n cp_agent_dec', cp_agent_dec)

                    print('\n final props:')
                    print('\n agent.prop_steal from %1.5f => %1.5f' % (start_agent_prop_steal, agent.prop_steal),
                          '  agent.prop_fight_back from %1.5f => %1.5f' % (
                          start_agent_prop_fight_back, agent.prop_fight_back))
                    print(
                        '\n cp_agent.prop_steal from %1.5f => %1.5f' % (start_cp_agent_prop_steal, cp_agent.prop_steal),
                        '  cp_agent.prop_fight_back from %1.5f => %1.5f' % (
                        start_cp_agent_prop_fight_back, cp_agent.prop_fight_back))

                    print('\n day =', day)
                    print(' move =', move)

                    print('\n agent.home =', agent.home)
                    print(' cp_agent.home =', cp_agent.home)

                    print('\n agent.grid_trgt =', agent.grid_trgt)
                    print(' cp_agent.grid_trgt =', cp_agent.grid_trgt)

                    print('\n agent.location =', agent.location)
                    print(' cp_agent.location =', cp_agent.location)

                    print('\n agent.agent_res_array ', agent.agent_res_array)
                    print(' agent.basket_array =', agent.basket_array)

                    print('\n cp_agent.agent_res_array ', cp_agent.agent_res_array)
                    print(' cp_agent.basket_array =', cp_agent.basket_array)

                    print('\n self.stranger_int =', self.stranger_int)

                    print('\n agent_dec =', agent_dec, 'res change', agent_ch_ress)
                    print(' cp_agent_dec =', cp_agent_dec, 'res change', cp_agent_ch_ress)

                    if agent == agent_population.tracking_agent:
                        print('\n tracking agent is agent \n')

                    else:
                        print('\n tracking agent is cp_agent \n')

                    pause()

            # now we need to record information about the interaction, if they did not trade - for passing on to others
            if agents_trade_peacefully == 0:

                # if fight_winner is agent:
                #     fight_winner_net_benefit = copy.copy(agent_net_benefit)
                #     fight_loser_net_benefit = copy.copy(cp_agent_net_benefit)
                #
                # elif fight_loser is agent:
                #     fight_winner_net_benefit = copy.copy(cp_agent_net_benefit)
                #     fight_loser_net_benefit = copy.copy(agent_net_benefit)

                # for any of the first 6 scenarions, agents fight - we record this information like so (but not if they trade peacefully)
                fight_num = len(dbs.fights_db)

                fight = Fight_Object(day, fight_num, initiator=str(agent), counterpart=str(cp_agent),
                                     location=copy.copy(agent.location), winner=str(fight_winner),
                                     agent_record=copy.copy(agent_record), cp_agent_record=copy.copy(cp_agent_record),
                                     agent_res_gain=agent_ch_ress, cp_agent_res_gain=cp_agent_ch_ress,
                                     move_num=move, initiator_new_prop_steal=copy.copy(agent.prop_steal),
                                     initiator_new_prop_fight_back=copy.copy(agent.prop_fight_back),
                                     counterpart_new_prop_steal=copy.copy(cp_agent.prop_steal),
                                     counterpart_new_prop_fight_back=copy.copy(cp_agent.prop_fight_back),
                                     initiator_start_prop_steal=initiator_start_prop_steal,
                                     initiator_start_prop_fight_back=initiator_start_prop_fight_back,
                                     counterpart_start_prop_steal=counterpart_start_prop_steal,
                                     counterpart_start_prop_fight_back=counterpart_start_prop_fight_back,
                                     initiator_start_basket=agent_start_basket,
                                     counterpart_start_basket=cp_agent_start_basket, initiator_dec=agent_dec,
                                     counterpart_dec=cp_agent_dec,
                                     initiator_end_basket=copy.copy(agent.basket_array),
                                     counterpart_end_basket=copy.copy(cp_agent.basket_array),
                                     agent_start_res=agent_start_res,
                                     cp_agent_start_res=cp_agent_start_res, agent_a_tribe=agent.tribe,
                                     agent_b_tribe=cp_agent.tribe)

                dbs.fights_db.append(fight)

                # add to the fight object:
                fight.initiator_reduced_value = agent_net_benefit
                fight.counterpart_reduced_value = cp_agent_net_benefit

                agent.loc_fights_array[day].append(fight_num)
                cp_agent.loc_fights_array[day].append(fight_num)

                agent.fights_array.append(agent_record)
                cp_agent.fights_array.append(cp_agent_record)

                if len(dbs.start_end_fights[day]) == 0:  # then this is the first fight of the day

                    dbs.start_end_fights[day] = [fight_num, fight_num]

                else:

                    dbs.start_end_fights[day][1] = fight_num

                # we update these arrays, which helps us shortcut some of the coding when agents evaluate each other
                agent.last_intn = fight
                cp_agent.last_intn = fight

                # the agents also add to their own reputations dictionaries, given their experiences
                # start with agent:
                #                if agent_record == None:

                #                    print('\n agent_dec =', agent_dec, 'cp_agent_dec', cp_agent_dec)

                other_agent, fought, fought_back, i_fought, i_fought_back = agent_record

                if fought == 0:

                    fought_back_tally = 1  # the other agent wanted to trade; I tried to steal; it could have fought back

                else:

                    fought_back_tally = 0  # vice versa

                if other_agent not in agent.reputations_dict:  # this is where a new entry in the dict occurs

                    agent.reputations_dict[other_agent] = [np.zeros(shape=(num_rounds), dtype=int),
                                                           np.zeros(shape=(num_rounds), dtype=int),
                                                           np.zeros(shape=(num_rounds), dtype=int),
                                                           np.zeros(shape=(num_rounds), dtype=int)]

                agent.reputations_dict[other_agent][0][day] += fought
                agent.reputations_dict[other_agent][1][day] += 1
                agent.reputations_dict[other_agent][2][day] += fought_back
                agent.reputations_dict[other_agent][3][day] += fought_back_tally

                # now the cp_agent:
                other_agent, fought, fought_back, i_fought, i_fought_back = cp_agent_record

                if fought == 0:

                    fought_back_tally = 1  # the other agent wanted to trade; I tried to steal; it could have fought back

                else:

                    fought_back_tally = 0  # vice versa

                if other_agent not in cp_agent.reputations_dict:
                    cp_agent.reputations_dict[other_agent] = [np.zeros(shape=(num_rounds), dtype=int),
                                                              np.zeros(shape=(num_rounds), dtype=int),
                                                              np.zeros(shape=(num_rounds), dtype=int),
                                                              np.zeros(shape=(num_rounds), dtype=int)]

                cp_agent.reputations_dict[other_agent][0][day] += fought
                cp_agent.reputations_dict[other_agent][1][day] += 1
                cp_agent.reputations_dict[other_agent][2][day] += fought_back
                cp_agent.reputations_dict[other_agent][3][day] += fought_back_tally

                # update this also
                agent.agent_knows_cp_dict[str(cp_agent)] = 1
                cp_agent.agent_knows_cp_dict[str(agent)] = 1

                # we also update these values - we only update the reputations data when we need to and this is part of that process
                agent.need_to_update_reps[str(cp_agent)] = 1
                cp_agent.need_to_update_reps[str(agent)] = 1

                # if the agents fought, the fight_winner will re-target when the sum of its resources exceeds the total resources at the start of the round;
                # also, we don't want to run this if there has been no change during the transaction, so we include agent_net_benefit != 0; and we don't want to
                # run this if the agent has retargetted and hasn't reached its designated target, i.e., we don't want to change the target

                # if len(fight_winner.positive_locations_dict) > 1:
                #     print_fine_dets = 1

                if print_fine_dets == 1:
                    print('\n\n\n\n np.sum(fight_winner.basket_array) =', np.sum(fight_winner.basket_array),
                          'np.sum(fight_winner.basket_array_start) =', np.sum(fight_winner.basket_array_start))

                    print('\n day', day, 'move', move)
                    print('\n fight_winner.home =', fight_winner.home)
                    print('\n fight_winner.trade_loc_rec:\n')
                    for mo in np.arange(len(fight_winner.trade_loc_rec)):
                        print(mo, fight_winner.trade_loc_rec[mo])

                    print(fight_winner.location, '<-- fight_winner.location')
                    print('\n fight_winner.trgt_loc_rec:\n')

                    for mo in np.arange(len(fight_winner.trgt_loc_rec)):
                        print(mo, fight_winner.trgt_loc_rec[mo])

                    print(fight_winner.grid_trgt, '<-- fight_winner.grid_trgt')
                    print('\n fight_winner.home =', fight_winner.home)
                    print(' fight_winner.location =', fight_winner.location)
                    print(' fight_winner.grid_trgt =', fight_winner.grid_trgt)

                    print('\n fight_loser.home =', fight_loser.home)
                    print('\n fight_loser.trade_loc_rec:\n')
                    for mo in np.arange(len(fight_loser.trade_loc_rec)):
                        print(mo, fight_loser.trade_loc_rec[mo])

                    print(fight_loser.location, '<-- fight_loser.location')
                    print('\n fight_loser.trgt_loc_rec:\n')

                    for mo in np.arange(len(fight_loser.trgt_loc_rec)):
                        print(mo, fight_loser.trgt_loc_rec[mo])

                    print(fight_loser.grid_trgt, '<-- fight_loser.grid_trgt')
                    print('\n fight_loser.home =', fight_loser.home)
                    print(' fight_loser.location =', fight_loser.location)
                    print(' fight_loser.grid_trgt =', fight_loser.grid_trgt)

                    print('\n np.sum(fight_winner.basket_array) =', np.sum(fight_winner.basket_array),
                          'np.sum(fight_winner.basket_array_start) =', np.sum(fight_winner.basket_array_start))
                    print(' agent_net_benefit =', agent_net_benefit)
                    print(' fight_winner.reached_trgt =', fight_winner.reached_trgt)
                    print(' len(fight_winner.positive_locations_dict) =', len(fight_winner.positive_locations_dict))

                if fight_winner.grid_trgt[0] != None:

                    fw_distance_to_trgt = abs_dist_on_torus(fight_winner.location, fight_winner.grid_trgt, town_grid.dimen)

                else:

                    fw_distance_to_trgt = [2, 2]

                if fight_loser.grid_trgt[0] != None:

                    fl_distance_to_trgt = abs_dist_on_torus(fight_loser.location, fight_loser.grid_trgt, town_grid.dimen)

                else:

                    fl_distance_to_trgt = [2, 2]

                if print_fine_dets == 1:
                    print('\n fw_distance_to_trgt =', fw_distance_to_trgt)

                # the fight winner will retarget if (1) the agent has already reached its target (or it's within 1 grid square), and (2) there is at least one other viable target (or it has one target and will switch to random)
                if (fight_winner.reached_trgt or (fight_winner.reached_trgt == 0 and fw_distance_to_trgt[0] <= 1 and fw_distance_to_trgt[1] <= 1)) \
                    and len(fight_winner.positive_locations_dict) > 0:

                    if print_fine_dets == 1:
                        print('\n the fight winner is re-targeting')
                        print('\n pre-retargeting target =', fight_winner.grid_trgt)
                        print(' pre trade_movemnt =', fight_winner.trade_movemnt, '\n')

                    set_agent_target(params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, respect_property_rights, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt,
                                     trade_when_trgt, dbs, track_agent, fight_winner, day, town_grid, trgt_sel, trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, ststst, retarg=1, move=move, has_acted=1,
                                     print_dets=print_dets, print_fine_dets=print_fine_dets, fight_balance=fight_balance, agree_location=agree_location, adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta,
                                     formal_inst=formal_inst, prob_fine=prob_fine, fine=fine, fight_skill=fight_skill, fix_ps_fb_0=fix_ps_fb_0, strat_choice=strat_choice, stranger_int=stranger_int, two_tribes_inst=two_tribes_inst,
                                     strangers_if_unknown=strangers_if_unknown)

                    # can_trade is only 0 after the start of the trading phase and before the agent reaches its target (or is intercepted) so here it is set = 1
                    fight_winner.can_trade = 1
                    fight_winner.reached_tgt_on_move = 0
                    fight_winner.reached_trgt = 0

                    # agent.reached_trgt is 0 when agent is heading to target and 1 after it has reached it, unless moving randomly
                    if fight_winner.trade_movemnt == 'set' and trade_when_trgt == 1 and (fight_winner.grid_trgt[0] == fight_winner.location[0] and fight_winner.grid_trgt[1] == fight_winner.location[1]) == False:

                        fight_winner.reached_trgt = 0

                    else:

                        fight_winner.reached_trgt = 1

                if print_fine_dets:
                    print('\n fight_loser.reached_trgt =', fight_loser.reached_trgt)
                    print(' len(fight_loser.positive_locations_dict)', len(fight_loser.positive_locations_dict))
                    print('\n fl_distance_to_trgt =', fl_distance_to_trgt)

                # for the fight loser, we retarget if the agent has already reached its target (or it's within 1 grid square) - note fl_distance_to_trgt = [2, 2] if fight_loser.trade_movemnt = 'random' :
                if (fight_loser.reached_trgt or (fight_loser.reached_trgt == 0 and fl_distance_to_trgt[0] <= 1 and fl_distance_to_trgt[1] <= 1)) and len(fight_loser.positive_locations_dict) > 0:

                    if print_fine_dets == 1:
                        print('\n the fight loser is re-targeting')

                    set_agent_target(params, price_mean, force_prices, fixed_price, fight_cost, len_reputations_mem, intn_error_std, respect_property_rights, KO_pop, agent_population, keynesian_ratio, trade_prices, trade_movemnt,
                                     trade_when_trgt, dbs, track_agent, fight_loser, day, town_grid, trgt_sel, trade_moves, granular_mem, fountain_population, wait_at_tgt_moves, ststst, retarg=1, move=move, has_acted=1,
                                     print_dets=print_dets, print_fine_dets=print_fine_dets, fight_balance=fight_balance, agree_location=agree_location, adjust_props_r=adjust_props_r, agent_intn_beta=agent_intn_beta,
                                     formal_inst=formal_inst, prob_fine=prob_fine, fine=fine, fight_skill=fight_skill, fix_ps_fb_0=fix_ps_fb_0, strat_choice=strat_choice, stranger_int=stranger_int, two_tribes_inst=two_tribes_inst,
                                     strangers_if_unknown=strangers_if_unknown)

                    # agent.reached_trgt is 0 when agent is heading to target and 1 after it has reached it, unless moving randomly
                    if fight_loser.trade_movemnt == 'set' and trade_when_trgt == 1 and (fight_loser.grid_trgt[0] == fight_loser.location[0] and fight_loser.grid_trgt[1] == fight_loser.location[1]) == False:

                        fight_loser.reached_trgt = 0

                    else:

                        fight_loser.reached_trgt = 1

                    # can_trade is only 0 after the start of the trading phase and before the agent reaches its target (or is intercepted) so here it is set = 1
                    fight_loser.can_trade = 1
                    fight_loser.reached_tgt_on_move = 0

                # print data after retargetting:
                if print_fine_dets:

                    print('\n Retargetting details:')

                    print('\n fight_winner.trade_movemnt =', fight_winner.trade_movemnt)
                    print(' fight_winner.grid_trgt =', fight_winner.grid_trgt)
                    print(' fight_winner.can_trade =', fight_winner.can_trade)
                    print(' fight_winner.reached_trgt =', fight_winner.reached_trgt)
                    print(' fight_winner.reached_tgt_on_move =', fight_winner.reached_tgt_on_move)

                    print('\n fight_loser.trade_movemnt =', fight_loser.trade_movemnt)
                    print(' fight_loser.grid_trgt =', fight_loser.grid_trgt)
                    print(' fight_loser.can_trade =', fight_loser.can_trade)
                    print(' fight_loser.reached_trgt =', fight_loser.reached_trgt)
                    print(' fight_loser.reached_tgt_on_move =', fight_loser.reached_tgt_on_move)

            if print_fine_dets == 1 or print_model_2_dets == 1:
                pause()
                print('\n\n\n')

        # if print_fine_dets == 1 or print_model_2_dets == 1:
        #     pause()
        #     print('\n\n\n')

        return [remove_agents, transactions, traded_array, trans_numbs_array, fight_num]


class TownGrid():

    """A grid representing a town around which agents search for other agents with whom they might trade."""

    def __init__(self, rounds, dimen, trade_moves, print_dets):

        self.dimen = dimen
        self.all_trans_array = np.zeros(shape=(rounds, dimen, dimen))
        self.agents_seen_db = []
        self.unsucc_trans_db = []
        self.trade_moves = trade_moves
        self.grid_accup = np.zeros(shape=(dimen, dimen))

        # this create a grid on which we can place the agents
        self.grid_agents = []
        row = []
        for k in np.arange(self.dimen):
            row.append([])
        for l in np.arange(self.dimen):
            self.grid_agents.append(copy.deepcopy(row))

        if print_dets == 1:
            print('\n** creating an instance of TownGrid **')
            print('\ntowngrid dimension =', dimen, 'x', dimen)
            print('\n** instance of TownGrid has been created **\n')

    def locate_agents(self, agent_population, fountain_population, dbs, print_dets, trade_loc):

        """A method for asigning locations to those agents which attempt to trade."""

#        print_dets = 1

        if print_dets == 1:
            print('\n * asign random locations to agents if trade_loc != 1, and asign home location if trade_loc == 1 *')
            print('trade_loc =', trade_loc)

        for agent in dbs.agent_list:

            if trade_loc == 'random':

                x_coord = np.random.randint(0, self.dimen)
                y_coord = np.random.randint(0, self.dimen)

                agent.location = np.array([x_coord, y_coord])

            elif trade_loc == 'home':

                agent.location = copy.copy(agent.home)

            elif trade_loc == 'fountain':

                at_fountain_num = agent.for_strat_array[0][-1]

                if print_dets == 1:
                    print('\n at_fountain_num', at_fountain_num)

                fountain = fountain_population.pop[at_fountain_num]

                if print_dets == 1:
                    print('fountain', fountain)

                agent.location = copy.copy(fountain.location)

                if print_dets == 1:
                    print('fountain.location', fountain.location)
                    print('agent.location', agent.location)

        if print_dets == 1:
            print('\nlocate_agents is finished')

            input("Press Enter to continue...")


class Databases():

    def __init__(self, rounds, dimen, for_strat_parts, trade_moves, data_folder, init_res_level,
                 print_MRS_std_charts, constitutional_voting, num_experiments,
                 two_tribes, black_shoop_exp, agree_location):

        self.num_rounds = rounds

        # create a database to record initial reserve levels of all fountains: this will vary when famine is explored
        if two_tribes == 0:

            self.init_res_levels = np.zeros(shape=(rounds, num_res_founts))

        elif two_tribes == 1:

            self.init_res_levels = np.zeros(shape=(rounds, 4))

        # this database records most of the main data
        self.main_db = np.zeros(shape=(4 + num_res_founts, rounds))
        self.main_db[0] = np.arange(rounds)

        # create database to record number of agents at each fountain in each time slot
        self.founts_db = np.zeros(shape=((for_strat_parts * num_res_founts) + 1, rounds))
        self.founts_db[0] = np.arange(rounds)

        # create database to record key trading data.  Note: [0] is rounds, [1] is proportion of grid squares with transaction.
        self.key_trading_db = np.zeros(shape=(2, rounds))
        self.key_trading_db[0] = np.arange(rounds)

        # if agents trade, set up a database to record the number of successful trades and number of agents attempting to trade:
        # [0] records number of agents in play; [1] records number of agents attempting to trade in the round; [2] is the
        # number of successful trades in that round; [3] records the proportion of successful trades per person i.e. [2]
        # divided by [1].
        self.trading_db = np.zeros(shape=(7, rounds))

        # create database to record min resource levels of agents
        self.min_res_levels_db = np.zeros(shape=(rounds, dimen, dimen))

        #        # create a clustering database: [0] = rounds, [1] = clustering coeff, [2] = x_coord of cluster centre, [3] = y_coord
        #        self.clustering_db = np.zeros(shape=(2, rounds))
        #        self.clustering_db[0] = np.arange(rounds)
        #
        #        # create cluster centre db
        #        self.cluster_centre_db = np.zeros(shape=(3, rounds))
        #        self.cluster_centre_db[0] = np.arange(rounds)

        # create a database to record agents' average age
        self.ag_age_db = np.zeros(shape=(2, rounds), dtype=int)
        self.ag_age_db[0] = np.arange(rounds)

        # create database with this number of arrays plus one more to record the average & one to include rounds
        self.for_spec_db = np.zeros(shape=(for_strat_parts + 3, rounds))
        self.for_spec_db[0] = np.arange(rounds)

        # create arrays which records the resource levels of each fountain at the beginning and end of each time slot
        if two_tribes == 0:

            self.res_level_array = np.zeros(shape=(for_strat_parts, num_res_founts))
            self.res_level_array_ends = np.zeros(shape=(for_strat_parts, num_res_founts))

        elif two_tribes == 1:

            self.res_level_array = np.zeros(shape=(for_strat_parts, 4))
            self.res_level_array_ends = np.zeros(shape=(for_strat_parts, 4))

            self.pop_sharks = np.zeros(shape=rounds)
            self.pop_jets = np.zeros(shape=rounds)

            self.res_founts_sharks = np.zeros(shape=(num_res_founts, rounds))
            self.res_founts_jets = np.zeros(shape=(num_res_founts, rounds))

        # create a list which tracks which agents want to trade after foraging
        self.agent_list = []

        # create a variable to track the total number of goods on sale in each round
        self.total_on_sale = 0

        # Create a transactions database to record all transactions
        self.trans_db = []

        # Create a database which records transactions in each day
        self.transs_daily_db = [[] for i in range(rounds)]

        # Create a similar database for fights
        self.fights_daily_db = [[] for i in range(rounds)]

        # this array is used to record the names of the dead agents in each round :-)
        self.davy_jones_locker = []

        #        net_transs_db = []
        #        twod_array = []
        #        row = []
        #        for k in np.arange(num_res_founts):
        #            row.append(np.array([0.0, 0.0]))
        #        for l in np.arange(num_res_founts):
        #            twod_array.append(copy.deepcopy(row))
        #        for j in np.arange(rounds):
        #            net_transs_db.append(copy.deepcopy(twod_array))
        #
        #        self.net_transs_db = net_transs_db

        self.SD_equilibrium_data_1d = np.zeros(shape=(rounds, num_res_founts, num_res_founts, 2))

        self.net_net_transs_db = np.zeros(shape=(rounds, num_res_founts))

        if two_tribes:
            self.net_net_transs_db_sharks = np.zeros(shape=(rounds, num_res_founts))
            self.net_net_transs_db_jets = np.zeros(shape=(rounds, num_res_founts))

        self.net_trans_MRSs = np.zeros(shape=(rounds, num_res_founts, num_res_founts))

        #        self.all_transs_array = [[] for i in range(num_res_founts)]

        #        self.all_transs_array_1_res = [[[] for i in range(num_res_founts)] for j in range(num_res_founts)]

        self.tot_trans = np.zeros(shape=(rounds, num_res_founts))

        self.tot_trans_1_res = np.zeros(shape=(rounds, num_res_founts, num_res_founts))

        # This database records foraging strategy array data - one list for each round
        self.for_strat_db = [[] for i in range(rounds)]

        if two_tribes:
            self.for_strat_db_sharks = [[] for i in range(rounds)]
            self.for_strat_db_jets = [[] for i in range(rounds)]

        # Create a database to record all the mean price history (working prices not chart prices)
        self.mean_price_history = np.zeros(shape=(num_res_founts, num_res_founts, rounds))
        self.price_history_std = np.zeros(shape=(num_res_founts, num_res_founts, rounds))

        if two_tribes:
            self.mean_price_history_sharks = np.zeros(shape=(num_res_founts, num_res_founts, rounds))
            self.price_history_std_sharks = np.zeros(shape=(num_res_founts, num_res_founts, rounds))

            self.mean_price_history_jets = np.zeros(shape=(num_res_founts, num_res_founts, rounds))
            self.price_history_std_jets = np.zeros(shape=(num_res_founts, num_res_founts, rounds))

        # Creat an array to record optimal basket turnover (from constrained optimization technique)
        self.optimal_bskt_turnover = np.zeros(shape=(rounds, num_res_founts))

        if two_tribes:
            self.optimal_bskt_turnover_sharks = np.zeros(shape=(rounds, num_res_founts))
            self.optimal_bskt_turnover_jets = np.zeros(shape=(rounds, num_res_founts))

        # Create an array to record the errors in the optimal basket turnover calcs (measure of accuracy)
        self.optimal_bskt_errors = np.zeros(shape=(rounds, num_res_founts))

        # And create an array to record the number of iterations gone through in order to find optimal basket turnover (measure of accuracy)
        self.optimal_bskt_iters = np.zeros(shape=(rounds))

        # Creat an array to record optimal price array (from constrained optimization technique) - we record these as chart prices
        self.optimal_price_array = np.zeros(shape=(rounds, num_res_founts, num_res_founts))

        if two_tribes:
            self.optimal_price_array_sharks = np.zeros(shape=(rounds, num_res_founts, num_res_founts))
            self.optimal_price_array_jets = np.zeros(shape=(rounds, num_res_founts, num_res_founts))

        # Create an array to record the proportion of net_net_transs_db / optimal_bskt_turnover
        self.net_turnover_prop = np.zeros(shape=(rounds, num_res_founts))

        if two_tribes:
            self.net_turnover_prop_sharks = np.zeros(shape=(rounds, num_res_founts))
            self.net_turnover_prop_jets = np.zeros(shape=(rounds, num_res_founts))

        # Create an array to record agent MRSs over all moves
        self.MRS_moves_array = [[[[] for move in np.arange(trade_moves)] for res_1 in np.arange(num_res_founts)] for
                                res_2 in np.arange(num_res_founts)]

        # we only want this database if we're printing specific charts
        if print_MRS_std_charts == 1:
            self.MRS_STDs_array = np.zeros(shape=(num_res_founts, num_res_founts, 2, rounds))

        self.live_agents = [[] for i in np.arange(rounds)]

        self.copy_ags_max_det_probs = [[] for i in np.arange(rounds)]
        self.copy_ags_res_arrays = [[] for i in np.arange(rounds)]

        self.transactions_record = np.zeros(shape=(dimen, dimen, rounds))

        self.three_d_SD_data = np.array([])

        self.aggr_three_d_data = np.array([])

        self.abs_three_d_data = np.array([])

        self.min_3d_array = np.array([])

        self.best_prices_array = np.array([])

        self.prices_array_0_2 = np.array([])
        self.prices_array_1_2 = np.array([])

        self.prices_array_0_2_prev = np.array([])
        self.prices_array_1_2_prev = np.array([])

        # create max and min boundaries for prices
        self.bound_p02_min = 0.0
        self.bound_p02_max = 5.0
        self.bound_p12_min = 0.0
        self.bound_p12_max = 5.0

        # This is an array which counts the home locations of dead agents
        self.dead_ags_grid_counter = np.zeros(shape=(dimen, dimen), dtype=int)

        self.proposed_KI_loc = [int(0), int(0)]

        # This is a text file for making any notes
        self.notes_file = '%s/00_notes_file.txt' % (data_folder)

        # This is a file for making any notes about the creation of a Keynesian Institution
        self.KI_notes_file = '%s/00_KI_notes_file.txt' % (data_folder)

        with open(self.KI_notes_file, 'a') as myfile:
            myfile.write(
                "This text file is for recording notes concerning the proposal of any Keynesian Institutions\n")

        self.agent_summary_notes_file = '%s/00_ag_sum_notes_file.txt' % (data_folder)

        with open(self.agent_summary_notes_file, 'a') as myfile:
            myfile.write("This text file records data about agents\n")

        self.sign_locs_notes_file = '%s/00_sign_locs_notes_file.txt' % (data_folder)

        with open(self.sign_locs_notes_file, 'a') as myfile:
            myfile.write(
                "This text file records data about significant market locations, i.e., where transactions occurred\n")

        self.serviced_locations = np.zeros(shape=(rounds))

        # This database records all market locations (defined as locations where > 2 agents have transacted)
        self.sign_mkt_locs = [[] for i in range(rounds)]
        # This record all sign locations - whether transactions or fights
        self.sign_locs = [[] for i in range(rounds)]

        # for the purposes of recording iterations in the optimization technique, and also time - delete when evaluation done
        self.opt_iters_record = np.zeros(shape=(rounds))
        self.opt_time_record = np.zeros(shape=(rounds))

        # create two arrays - to record each agents' x_1 and x_2 in the optimization process
        self.agent_x_1_grid = np.array([])
        self.agent_x_2_grid = np.array([])
        self.agent_obj_vals = np.array([])

        # copies of relevant arrays
        self.agent_x_1_grid_copy = np.array([])
        self.agent_x_2_grid_copy = np.array([])

        # as above but records previous round's data
        self.agent_x_1_grid_prev = np.array([])
        self.agent_x_2_grid_prev = np.array([])
        self.agent_obj_vals_prev = np.array([])

        # create two arrays - to record each agents' x_1 and x_2 in the optimization process - old process
        self.agent_x_1_grid_old = np.array([])
        self.agent_x_2_grid_old = np.array([])
        self.agent_obj_vals_old = np.array([])

        self.agents_x_min_max = np.zeros(shape=(16, 4), dtype=np.float32)

        self.problem_agents = np.array([16], dtype=int)
        self.problem_grids = []
        self.max_diffs = []

        self.i_corner_min_prev = np.array([])
        self.i_corner_max_prev = np.array([])
        self.j_corner_min_prev = np.array([])
        self.j_corner_max_prev = np.array([])

        # we create an array with 3 elements: the round in which a (10 round MA) turnover ratio of 90%, 95% and 99% were hit
        self.mkt_emerged_round = np.zeros(shape=3, dtype=int)

        self.foutain_levels = np.zeros(shape=(num_res_founts, rounds))

        # we need to record the initial values of foutains - we assume all at init_res_level - this will get changed if there is a famine
        self.fountains_init_levels_hist = np.full((num_res_founts, rounds), init_res_level, dtype=int)

        self.last_round_trans_data = np.zeros(shape=(dimen, dimen), dtype=np.float64)

        self.num_perfect_specs = np.zeros(shape=(4, rounds))
        self.num_perfect_specs[0] = np.arange(rounds)

        if constitutional_voting == 1:
            self.constitutional_agents = [[] for i in range(num_experiments + 1)]
            self.constitutional_min_ress = [[] for i in range(num_experiments + 1)]

        self.trades_array_ags = [[[] for j in range(dimen)] for i in range(dimen)]
        self.fights_array_ags = [[[] for j in range(dimen)] for i in range(dimen)]

        self.fights_db = []

        self.mean_prop_steal_hist = np.arange(rounds)
        self.mean_prop_fight_back_hist = np.arange(rounds)

        # this records, for each round, the first and last transaction number
        self.start_end_transs = [[] for i in range(rounds)]

        self.latest_trans = None

        # now the same with fights
        self.start_end_fights = [[] for i in range(rounds)]

        self.latest_fights = None

        self.prop_steal_db = [[] for i in range(rounds)]
        self.prop_fight_back_db = [[] for i in range(rounds)]

        self.prop_steal_mean_db = [[] for i in range(rounds)]
        self.prop_fb_mean_db = [[] for i in range(rounds)]

        if two_tribes:
            self.prop_steal_mean_db_sharks = [[] for i in range(rounds)]
            self.prop_fb_mean_db_sharks = [[] for i in range(rounds)]

            self.prop_steal_mean_db_jets = [[] for i in range(rounds)]
            self.prop_fb_mean_db_jets = [[] for i in range(rounds)]

        self.prop_steal_std_db = [[] for i in range(rounds)]
        self.prop_fb_std_db = [[] for i in range(rounds)]

        if two_tribes:
            self.prop_steal_std_db_sharks = [[] for i in range(rounds)]
            self.prop_fb_std_db_sharks = [[] for i in range(rounds)]

            self.prop_steal_std_db_jets = [[] for i in range(rounds)]
            self.prop_fb_std_db_jets = [[] for i in range(rounds)]

        self.prop_steal_mean_above_50_db = [[] for i in range(rounds)]
        self.prop_fb_mean_above_50_db = [[] for i in range(rounds)]
        self.prop_steal_mean_below_50_db = [[] for i in range(rounds)]
        self.prop_fb_mean_below_50_db = [[] for i in range(rounds)]

        self.num_ints_each_round = np.zeros(
            shape=(7, rounds))  # for 6 scenarios but we align scenarios with indices so [0] always zero
        self.num_fight_each_round = np.zeros(shape=rounds)

        if two_tribes:
            self.num_ints_each_round_sharks = np.zeros(
                shape=(7, rounds))  # for 6 scenarios but we align scenarios with indices so [0] always zero
            self.num_fight_each_round_sharks = np.zeros(shape=rounds)

            self.num_ints_each_round_jets = np.zeros(
                shape=(7, rounds))  # for 6 scenarios but we align scenarios with indices so [0] always zero
            self.num_fight_each_round_jets = np.zeros(shape=rounds)

            self.num_ints_each_round_inter = np.zeros(
                shape=(7, rounds))  # for 6 scenarios but we align scenarios with indices so [0] always zero
            self.num_fight_each_round_inter = np.zeros(shape=rounds)

        # for some plotly charts we record the urls
        self.agents_prop_steal_url = ''
        self.agents_prop_fb_url = ''
        self.prop_steal_above_below_50_url = ''
        self.prop_fb_above_below_50_url = ''
        self.props_means_url = ''
        self.trans_and_fights_url = ''
        self.fight_types_url = ''
        self.fight_skill_url = ''

        self.trans_and_fights_url_sharks = ''
        self.fight_types_url_sharks = ''
        self.fight_skill_url_sharks = ''

        self.trans_and_fights_url_jets = ''
        self.fight_types_url_jets = ''
        self.fight_skill_url_jets = ''

        self.trans_and_fights_url_inter = ''
        self.fight_types_url_inter = ''
        self.fight_skill_url_inter = ''

        if agree_location:
            self.agreed_locs = [[] for i in range(rounds)]

        self.games_type_dict = dict()
        self.games_type_dict_2 = dict()
        self.games_type_dict_3 = dict()
        self.games_type_considered_dict = dict()
        self.classic_games_considered = dict()
        self.classic_games_seen = dict()

        # dictionary to record data for locations agents targetted
        self.grid_trgt_hist_dict = dict()

        # in which round did all living agents visit the same square?
        self.round_all_ags_one_trgt = None

        # record births and deaths - just note down the round in which an agent was born or died
        self.birth_dates = []
        self.death_dates = []

    def update_net_transs_db(self, day, print_dets, print_fine_dets, fountain_population, agent_population, town_grid,
                             daily_succ_trans, two_tribes, respect_property_rights):

        """This method updates the class's net_transs_db, which occurs at the end of trading."""

        # if day > 100:
        #     print_fine_dets = 1

        # Here I find the net sales of the resources by the agents - record in self.net_net_transs_db[day][resource]
        for agent in self.agent_list:

            if print_fine_dets == 1:
                print('\n agent =', agent)

            for res in np.arange(num_res_founts):

                if print_fine_dets == 1:
                    print(' res =', res)
                    print(' agent.basket_array_start_hist[day][res]', agent.basket_array_start_hist[day][res])
                    print(' agent.basket_array[0][res]', agent.basket_array[0][res])

                agent_sale = agent.basket_array_start_hist[day][res] - agent.basket_array[0][res]

                if agent_sale > 0:

                    self.net_net_transs_db[day][res] += agent_sale

                    if two_tribes:

                        if agent.tribe == 'sharks':

                            self.net_net_transs_db_sharks[day][res] += agent_sale

                        elif agent.tribe == 'jets':

                            self.net_net_transs_db_jets[day][res] += agent_sale

        if print_fine_dets == 1:
            print('\n self.net_net_transs_db[day]', self.net_net_transs_db[day])
        #            print(' self.net_net_transs_db_sharks[day][res]', self.net_net_transs_db_sharks[day][res])
        #            print(' self.net_net_transs_db_jets[day][res]', self.net_net_transs_db_jets[day][res])

        # In order to find the weighted mean prices we simply need to find the total sales of two resources and divide one by the other:
        # price of res_0 = sales of good 1 / sales of good 0 (this is the chart price of res_0: the number of res_1 units requird to buy one unit of res_0)
        #        total_gross_sales_numerator = np.zeros(shape=(num_res_founts, num_res_founts), dtype=np.float64)
        #        total_gross_sales_denominator = np.zeros(shape=(num_res_founts, num_res_founts), dtype=np.float64)

        # calculate the number of successful transactions (i.e., where the agents exchanged resources)
        num_succ_trans = 0

        for trans_num in daily_succ_trans:

            transaction = self.trans_db[trans_num]

            if transaction.good_a is not None:

                num_succ_trans += 1

        # create matrix to record all transaction price data for the day
        all_trans_prices = np.zeros(
            shape=(num_res_founts, num_res_founts, num_succ_trans),
            dtype=np.float64)

        #        print('\n daily_succ_trans', daily_succ_trans)

        if two_tribes:

            daily_succ_trans_sharks = []
            daily_succ_trans_jets = []

            for trans_num in daily_succ_trans:

                transaction = self.trans_db[trans_num]

                if transaction.good_a is not None:

                    if transaction.agent_a_tribe == 'sharks' and transaction.agent_b_tribe == 'sharks':

                        daily_succ_trans_sharks.append(trans_num)

                    elif transaction.agent_a_tribe == 'jets' and transaction.agent_b_tribe == 'jets':

                        daily_succ_trans_jets.append(trans_num)

            all_trans_prices_sharks = np.zeros(shape=(
            num_res_founts, num_res_founts, len(daily_succ_trans_sharks)),
                                               dtype=np.float64)

            all_trans_prices_jets = np.zeros(shape=(
            num_res_founts, num_res_founts, len(daily_succ_trans_jets)),
                                             dtype=np.float64)

            if print_fine_dets == 1:
                print('\n daily_succ_trans', daily_succ_trans)
                print('\n daily_succ_trans_sharks', daily_succ_trans_sharks)
                print('\n daily_succ_trans_jets', daily_succ_trans_jets)

        #        row = []
        #        for k in np.arange(num_res_founts):
        #            row.append([])
        #        for l in np.arange(num_res_founts):
        #            all_trans_prices.append(copy.deepcopy(row))

        #        num_check = np.zeros(shape=(num_res_founts, num_res_founts, len(daily_succ_trans)), dtype=np.float64)
        #        row = []
        #        for k in np.arange(num_res_founts):
        #            row.append([])
        #        for l in np.arange(num_res_founts):
        #            num_check.append(copy.deepcopy(row))

        #        denom_check = np.zeros(shape=(num_res_founts, num_res_founts, len(daily_succ_trans)), dtype=np.float64)
        #        row = []
        #        for k in np.arange(num_res_founts):
        #            row.append([])
        #        for l in np.arange(num_res_founts):
        #            denom_check.append(copy.deepcopy(row))

        trans_counter = 0

        for trans_num in daily_succ_trans:

            transaction = self.trans_db[trans_num]

            #            print_fine_dets = 1

            if print_fine_dets == 1:
                print('\n trans_num =', trans_num)
                print(' transaction.good_a =', transaction.good_a)
                print(' transaction.good_b =', transaction.good_b)
                print(' transaction.tot_trans_ag_sell =', transaction.tot_trans_ag_sell)
                print(' transaction.tot_trans_ag_buy =', transaction.tot_trans_ag_buy)

                print('\n transaction.good_a is not None: ', transaction.good_a is not None)

                pause()

            #            total_gross_sales_numerator[transaction.good_a][transaction.good_b] += transaction.tot_trans_ag_sell
            #            total_gross_sales_denominator[transaction.good_b][transaction.good_a] += transaction.tot_trans_ag_sell
            #
            #            total_gross_sales_numerator[transaction.good_b][transaction.good_a] += transaction.tot_trans_ag_buy
            #            total_gross_sales_denominator[transaction.good_a][transaction.good_b] += transaction.tot_trans_ag_buy
            #
            #            num_check[transaction.good_a][transaction.good_b][trans_counter] = transaction.tot_trans_ag_sell
            #            num_check[transaction.good_b][transaction.good_a][trans_counter] = transaction.tot_trans_ag_buy
            #
            #            denom_check[transaction.good_b][transaction.good_a][trans_counter] = transaction.tot_trans_ag_sell
            #            denom_check[transaction.good_a][transaction.good_b][trans_counter] = transaction.tot_trans_ag_buy

            if transaction.good_a is not None:
                all_trans_prices[transaction.good_a][transaction.good_b][trans_counter] = transaction.tot_trans_ag_sell / float(transaction.tot_trans_ag_buy)
                all_trans_prices[transaction.good_b][transaction.good_a][trans_counter] = transaction.tot_trans_ag_buy / float(transaction.tot_trans_ag_sell)

                trans_counter += 1

        # we repeat this process if we have two tribes...
        if two_tribes:

            trans_counter = 0

            for trans_num in daily_succ_trans_sharks:

                transaction = self.trans_db[trans_num]

                if transaction.good_a is not None:
                    all_trans_prices_sharks[transaction.good_a][transaction.good_b][
                        trans_counter] = transaction.tot_trans_ag_sell / float(transaction.tot_trans_ag_buy)
                    all_trans_prices_sharks[transaction.good_b][transaction.good_a][
                        trans_counter] = transaction.tot_trans_ag_buy / float(transaction.tot_trans_ag_sell)

                trans_counter += 1

            trans_counter = 0

            for trans_num in daily_succ_trans_jets:

                transaction = self.trans_db[trans_num]

                if transaction.good_a is not None:
                    all_trans_prices_jets[transaction.good_a][transaction.good_b][
                        trans_counter] = transaction.tot_trans_ag_sell / float(transaction.tot_trans_ag_buy)
                    all_trans_prices_jets[transaction.good_b][transaction.good_a][
                        trans_counter] = transaction.tot_trans_ag_buy / float(transaction.tot_trans_ag_sell)

                trans_counter += 1

            if print_fine_dets == 1:
                print('\n all_trans_prices', all_trans_prices)
                print('\n all_trans_prices_sharks', all_trans_prices_sharks)
                print('\n all_trans_prices_jets', all_trans_prices_jets)

        if print_fine_dets == 1:
            #            print('\n num_check =', num_check)
            #            print('\n denom_check =', denom_check)
            #            print('\n\n total_gross_sales_numerator =', total_gross_sales_numerator)
            #            print('\n total_gross_sales_denominator =', total_gross_sales_denominator)
            #            print('\n num_check / denom_check :', num_check / denom_check)
            print('\n all_trans_prices =', all_trans_prices)

        # we use this data to generated the mean weighted prices, which is
        #        mean_prices_array = np.zeros(shape=(num_res_founts, num_res_founts))
        # print('\n all_trans_prices:', all_trans_prices)

        for res_1 in np.arange(num_res_founts):

            for res_2 in np.arange(num_res_founts):

                if res_1 != res_2 and len(all_trans_prices[res_1][res_2]) > 0 and np.max(all_trans_prices[res_1][res_2]) > 0.0:  # ie there are some transactions

                    # print('\n all_trans_prices[res_1][res_2]:', all_trans_prices[res_1][res_2])

                    working_prices_array = copy.copy(all_trans_prices[res_1][res_2])

                    # print('\n 1 / working_prices_array :', 1 / working_prices_array)

                    chart_prices_array = 1 / working_prices_array

                    chart_price_mean = np.mean(chart_prices_array)
                    chart_price_std = np.std(chart_prices_array)

                    # We record the price as a working price
                    self.mean_price_history[res_1][res_2][day] = chart_price_mean
                    self.price_history_std[res_1][res_2][day] = chart_price_std

                    if print_fine_dets == 1:
                        print('\n\n\n res_1', res_1, 'res_2', res_2, 'chart_price_mean =', chart_price_mean, 'std',
                              chart_price_std)

                    if print_fine_dets == 1:
                        print('\n chart_price_mean', chart_price_mean, 'chart_price_std', chart_price_std)

                else:

                    self.mean_price_history[res_1][res_2][day] = 1000

        # pause()

        # repeat the above process is we have 2 tribes
        if two_tribes:

            for res_1 in np.arange(num_res_founts):

                for res_2 in np.arange(num_res_founts):

                    if res_1 != res_2 and len(all_trans_prices_sharks[res_1][res_2]) > 0 and np.max(
                            all_trans_prices_sharks[res_1][res_2]) > 0.0:  # ie there are some transactions

                        working_prices_array_sharks = copy.copy(all_trans_prices_sharks[res_1][res_2])

                        chart_prices_array_sharks = 1 / working_prices_array_sharks

                        chart_price_mean_sharks = np.mean(chart_prices_array_sharks)
                        chart_price_std_sharks = np.std(chart_prices_array_sharks)

                        # We record the price as a working price
                        self.mean_price_history_sharks[res_1][res_2][day] = chart_price_mean_sharks
                        self.price_history_std_sharks[res_1][res_2][day] = chart_price_std_sharks

                        if print_fine_dets == 1:
                            print('\n chart_price_mean_sharks', chart_price_mean_sharks, 'chart_price_std_sharks',
                                  chart_price_std_sharks)

                    else:

                        self.mean_price_history_sharks[res_1][res_2][day] = 1000

            for res_1 in np.arange(num_res_founts):

                for res_2 in np.arange(num_res_founts):

                    if res_1 != res_2 and len(all_trans_prices_jets[res_1][res_2]) > 0 and np.max(
                            all_trans_prices_jets[res_1][res_2]) > 0.0:  # ie there are some transactions

                        working_prices_array_jets = copy.copy(all_trans_prices_jets[res_1][res_2])

                        chart_prices_array_jets = 1 / working_prices_array_jets

                        chart_price_mean_jets = np.mean(chart_prices_array_jets)
                        chart_price_std_jets = np.std(chart_prices_array_jets)

                        # We record the price as a working price
                        self.mean_price_history_jets[res_1][res_2][day] = chart_price_mean_jets
                        self.price_history_std_jets[res_1][res_2][day] = chart_price_std_jets

                        if print_fine_dets == 1:
                            print('\n chart_price_mean_jets', chart_price_mean_jets, 'chart_price_std_jets',
                                  chart_price_std_jets)

                    else:

                        self.mean_price_history_jets[res_1][res_2][day] = 1000

        # Now we update self.net_turnover_prop
        for res in np.arange(num_res_founts):

            self.net_turnover_prop[day][res] = self.net_net_transs_db[day][res] / self.optimal_bskt_turnover[day][res]

            if two_tribes:
                self.net_turnover_prop_sharks[day][res] = self.net_net_transs_db_sharks[day][res] / \
                                                          self.optimal_bskt_turnover_sharks[day][res]
                self.net_turnover_prop_jets[day][res] = self.net_net_transs_db_jets[day][res] / \
                                                        self.optimal_bskt_turnover_jets[day][res]

        if print_fine_dets == 1:
            print('self.optimal_bskt_turnover[day][res] =', self.optimal_bskt_turnover[day][res])
            print('self.net_turnover_prop[day][res] =', self.net_turnover_prop[day][res])

        #            input("Press Enter to continue...")

        # Create array to record net transactions
        #        net_transs = []
        #        row = []
        #        for k in np.arange(num_res_founts):
        #            row.append(np.array([0.0, 0.0]))
        #        for l in np.arange(num_res_founts):
        #            net_transs.append(copy.deepcopy(row))

        # blank the array which record all transactions:
        #        self.all_transs_array = [[] for i in range(num_res_founts)]
        # and blank the array which records the granular transactions:
        #        self.all_transs_array_1_res = [[[] for i in range(num_res_founts)] for j in range(num_res_founts)]
        #        # Create an array to record which transactions we've already recorded, to prevent double counting
        #        all_trans_register = []

        #        # Unpack from self.transs_daily_db[day], which will have all of the day's transactions - all this section does is add to self.all_transs_array_1_res
        #        for trans_num in self.transs_daily_db[day]:
        #
        #            if print_fine_dets == 1:
        #                print('\ntrans_num =', trans_num)
        #
        #            trans = self.trans_db[trans_num]
        #
        #            # Add the amount sold to self.tot_trans_1_res
        #            self.tot_trans_1_res[day][trans.good_a][trans.good_b] += trans.tot_trans_ag_sell        # internal
        #            # Find the chart price
        #            chart_price = trans.tot_trans_ag_buy / float(trans.tot_trans_ag_sell)       # internal
        #            # Unpack Location
        #            locn = trans.location       # internal
        #
        #            self.all_transs_array_1_res[trans.good_a][trans.good_b].append([chart_price, self.tot_trans_1_res[day][trans.good_a][trans.good_b], trans.tot_trans_ag_sell, locn])
        #
        #            # For the database with data for one res versus all others:
        #            self.tot_trans[day][trans.good_a] += trans.tot_trans_ag_sell       # internal
        #            self.all_transs_array[trans.good_a].append([chart_price, self.tot_trans[day][trans.good_a]])       # internal
        #
        #            # We record the bilateral transaction data the other way round too:
        #            # Add the amount sold to self.tot_trans_1_res
        #            self.tot_trans_1_res[day][trans.good_b][trans.good_a] += trans.tot_trans_ag_buy       # internal
        #            # Find the chart price
        #            chart_price = trans.tot_trans_ag_sell / trans.tot_trans_ag_buy       # internal
        #
        #            self.all_transs_array_1_res[trans.good_b][trans.good_a].append([chart_price, self.tot_trans_1_res[day][trans.good_b][trans.good_a], trans.tot_trans_ag_buy, locn])

        # This is the end of the iteration over agents

        #        # Now we update self.all_chart_transs_1_res_adj and self.mean_price_history:
        #        self.all_chart_transs_1_res_adj = [[[] for i in range(num_res_founts)] for j in range(num_res_founts)]
        #
        #        for res_1 in np.arange(num_res_founts):
        #
        #            for res_2 in np.arange(num_res_founts):
        #
        #                if res_1 != res_2:
        #
        #                    all_chart_transs_1_res = self.all_transs_array_1_res[res_1][res_2]       # internal
        #
        #                    if print_fine_dets == 1:
        #                        print('\nxx all_chart_transs_1_res =\n', all_chart_transs_1_res)
        #
        #                    # If we want to show weighted average prices we have to adjust all_chart_transs_1_res:
        #
        #                    mean_chart_price = 0       # internal
        #
        #                    for index in np.arange(len(all_chart_transs_1_res)):
        #
        #                        mean_chart_price = 0
        #                        denom = all_chart_transs_1_res[index][1]       # internal
        #                        cumul_weight = 0       # internal
        #                        if print_fine_dets == 1:
        #                            print('\nindex =', index)
        #                            print('all_chart_transs_1_res[index] =', all_chart_transs_1_res[index])
        #                            print('denom =', denom)
        #
        #                        for ind in np.arange(index + 1):
        #
        #                            if print_fine_dets == 1:
        #                                print('ind =', ind)
        #
        #                            weight = all_chart_transs_1_res[ind][2] / float(denom)
        #                            mean_chart_price += weight * all_chart_transs_1_res[ind][0]
        #                            cumul_weight += weight
        #
        #                            if print_fine_dets == 1:
        #                                print('all_chart_transs_1_res[ind][2] =', all_chart_transs_1_res[ind][2])
        #                                print('weight =', weight)
        #                                print('cumul_weight =', cumul_weight)
        #                                print('mean_chart_price =', mean_chart_price)
        #
        #                        self.all_chart_transs_1_res_adj[res_1][res_2].append([mean_chart_price, all_chart_transs_1_res[index][1]])

        # Now we update the agents' personal arrays: total_actual_agent_sales, total_optimal_agent_sales, personal_turnover_ratio
        for agent in self.agent_list:

            if print_fine_dets == 1:
                print('\n\n\n agent =', agent)

            total_optimal_agent_sales = 0

            for res in np.arange(num_res_founts):

                res_opt_trans = agent.optimal_transs_systemic[day][res]

                if res_opt_trans > 0:
                    total_optimal_agent_sales += res_opt_trans

            agent.total_optimal_agent_sales[day] = total_optimal_agent_sales

            # we take different approaches, depending on respect for property rights
            if respect_property_rights == 0:

                # here, the agent must have been (net) mugged or it didn't see a change in its basket (not trans, no fights where it gained)
                if agent.basket_array[0][0] <= agent.basket_array_start[0][0] and agent.basket_array[0][1] <= \
                        agent.basket_array_start[0][1]:

                    agent.total_actual_agent_sales[day] = 0.0
                    agent.personal_turnover_ratio[day] = 0.0

                # here the agent has net mugged (an)other(s) - we treat this 'as if' the agent sold everything it wanted to
                elif (agent.basket_array[0][0] > agent.basket_array_start[0][0] and agent.basket_array[0][1] >
                      agent.basket_array_start[0][1]) or \
                        (agent.basket_array[0][0] > agent.basket_array_start[0][0] and agent.basket_array[0][1] ==
                         agent.basket_array_start[0][1]) or \
                        (agent.basket_array[0][0] == agent.basket_array_start[0][0] and agent.basket_array[0][1] >
                         agent.basket_array_start[0][1]):

                    agent.total_actual_agent_sales[day] = total_optimal_agent_sales
                    agent.personal_turnover_ratio[day] = 1.0

                else:

                    # there are 7 of the total 9 scenarios above - else covers the remaining two where one resource went up and the other down.
                    # here we copy the conventional approach by measuring the total 'sales' and comparing it to the optimal.  Note this is a conservative stratgy
                    # because if the changes are the reverse of the optimal then we get torunover ratio of 0; but if they are the same way round then we treat the whole thing
                    # 'as if' they sold

                    # Create a variable to record net sales of goods (we will ignore purchases)
                    total_actual_agent_sales = 0

                    for res in np.arange(num_res_founts):

                        # the net transactions for this resource =
                        res_trans = agent.basket_array_start[0][res] - agent.basket_array[0][res]

                        if res_trans > 0:  # then the agent sold this resource

                            total_actual_agent_sales += res_trans

                    agent.total_actual_agent_sales[day] = total_actual_agent_sales

                    # note to self: for sims with 2 resources, the ratio of sales and demands will not be the same because trans prices will differ from the mkt clearing price
                    if total_optimal_agent_sales > 0:  # We can get / zero (note default value is zero):

                        agent.personal_turnover_ratio[day] = total_actual_agent_sales / float(total_optimal_agent_sales)

                    if print_fine_dets == 1:
                        print('\n agent.personal_turnover_ratio[day] =', agent.personal_turnover_ratio[day])

            #                if print_fine_dets == 1:

            #                if day > 10:
            #
            #                    print('\n self.optimal_price_array[day][0][1] =', self.optimal_price_array[day][0][1])
            #                    print('\n agent.agent_res_array[0] =', agent.agent_res_array[0])
            #                    print('\n agent.basket_array_start[0] =', agent.basket_array_start[0])
            #                    print(' agent.basket_array[0] =', agent.basket_array[0])
            #                    print('\n agent.total_optimal_agent_sales[day] =', agent.total_optimal_agent_sales[day])
            #                    print(' agent.total_actual_agent_sales[day] =', agent.total_actual_agent_sales[day])
            #                    print(' agent.personal_turnover_ratio[day] =', agent.personal_turnover_ratio[day])
            #
            #                    pause()

            else:

                # Create a variable to record net sales of goods (we will ignore purchases)
                total_actual_agent_sales = 0

                for res in np.arange(num_res_founts):

                    if print_fine_dets == 1:
                        print('\n\n res =', res)
                        print('\n agent.basket_array_start[0] =', agent.basket_array_start[0])
                        print('\n agent.basket_array[0] =', agent.basket_array[0])
                        print('\n agent.basket_array_start[0][res] =', agent.basket_array_start[0][res])
                        print('\n agent.basket_array[0][res] =', agent.basket_array[0][res])

                    # the net transactions for this resource =
                    res_trans = agent.basket_array_start[0][res] - agent.basket_array[0][res]

                    if print_fine_dets == 1:
                        print('\n res_trans =', res_trans)

                    if res_trans > 0:  # then the agent sold this resource

                        total_actual_agent_sales += res_trans

                agent.total_actual_agent_sales[day] = total_actual_agent_sales

                if print_fine_dets == 1:
                    print('\n\n total_actual_agent_sales =', total_actual_agent_sales)

                # note to self: for sims with 2 resources, the ratio of sales and demands will not be the same because trans prices will differ from the mkt clearing price
                if total_optimal_agent_sales > 0:  # We can get / zero (note default value is zero):

                    agent.personal_turnover_ratio[day] = total_actual_agent_sales / float(total_optimal_agent_sales)

                if print_fine_dets == 1:
                    print('\n agent.personal_turnover_ratio[day] =', agent.personal_turnover_ratio[day])


class Transaction():

    """This is a class for recording a transaction between agents."""

    # the class is initiated with a starting population:
    def __init__(self, ag_for_strat_array, cp_for_strat_array, location, day, good_a, good_b, agent_a_home, agent_b_home, tot_trans_ag_sell, tot_trans_ag_buy, move_num, agent_a_trgt, agent_b_trgt,
                 a_tb, b_tb, a_loc_rec, b_loc_rec, a_MRS_array, b_MRS_array, agent_a, agent_b, trans_agr_MRS, agent_a_tribe, agent_b_tribe):

        self.location = location
        self.day = day
        self.good_a = good_a        # this is what agent_a is selling
        self.good_b = good_b        # this is what agent_a is buying
        self.agent_a_home = agent_a_home
        self.agent_b_home = agent_b_home
        self.tot_trans_ag_sell = tot_trans_ag_sell      # total number of goods to have passed hands (agent sells)
        self.tot_trans_ag_buy = tot_trans_ag_buy      # total number of goods to have passed hands (agent buys)
        self.move_num = move_num
        self.agent_a_trgt = agent_a_trgt
        self.agent_b_trgt = agent_b_trgt
        self.a_tb = a_tb                # agent a's trading basket
        self.b_tb = b_tb                # agent b's trading basket
        self.a_loc_rec = a_loc_rec
        self.b_loc_rec = b_loc_rec
        self.a_MRS_array = a_MRS_array
        self.b_MRS_array = b_MRS_array
        self.trans_agr_MRS = trans_agr_MRS
        self.ag_for_strat_array = ag_for_strat_array
        self.cp_for_strat_array = cp_for_strat_array
        self.agent_a = agent_a
        self.agent_b = agent_b
        self.agent_a_tribe = agent_a_tribe
        self.agent_b_tribe = agent_b_tribe


class Fight_Object():

    def __init__(self, day, fight_num, initiator, counterpart, location, winner, agent_record, cp_agent_record, agent_res_gain, cp_agent_res_gain, move_num,
                 initiator_new_prop_steal, initiator_new_prop_fight_back, counterpart_new_prop_steal, counterpart_new_prop_fight_back,
                 initiator_start_prop_steal, initiator_start_prop_fight_back, counterpart_start_prop_steal, counterpart_start_prop_fight_back,
                 initiator_start_basket, counterpart_start_basket, initiator_dec, counterpart_dec, initiator_end_basket, counterpart_end_basket,
                 agent_start_res, cp_agent_start_res, agent_a_tribe, agent_b_tribe):

        self.day = day
        self.fight_num = fight_num
        self.initiator = initiator
        self.counterpart = counterpart
        self.location = location
        self.winner = winner
        self.agent_record = agent_record
        self.cp_agent_record = cp_agent_record
        self.agent_res_gain = agent_res_gain
        self.cp_agent_res_gain = cp_agent_res_gain
        self.move_num = move_num
        self.initiator_new_prop_steal = initiator_new_prop_steal
        self.initiator_new_prop_fight_back = initiator_new_prop_fight_back
        self.counterpart_new_prop_steal = counterpart_new_prop_steal
        self.counterpart_new_prop_fight_back = counterpart_new_prop_fight_back
        self.initiator_start_prop_steal = initiator_start_prop_steal
        self.initiator_start_prop_fight_back = initiator_start_prop_fight_back
        self.counterpart_start_prop_steal = counterpart_start_prop_steal
        self.counterpart_start_prop_fight_back = counterpart_start_prop_fight_back
        self.initiator_start_basket = initiator_start_basket
        self.counterpart_start_basket = counterpart_start_basket
        self.initiator_dec = initiator_dec
        self.counterpart_dec = counterpart_dec
        self.initiator_end_basket = initiator_end_basket
        self.counterpart_end_basket = counterpart_end_basket
        self.agent_start_res = agent_start_res
        self.cp_agent_start_res = cp_agent_start_res
        self.agent_a_tribe = agent_a_tribe
        self.agent_b_tribe = agent_b_tribe


class Fountain():

    """A class for instantiating a resource fountain."""

    def __init__(self, init_res_level, dimen, trade_loc, rounds, tribe):

        self.init_res_level = init_res_level
        self.res_level = init_res_level    # resource level of the foutain
        self.highest_prices = np.zeros(shape=(rounds))      # measure is working price

        if trade_loc == 'fountain':

            self.location = [random.randint(0, dimen - 1), random.randint(0, dimen - 1)]

        self.tribe = tribe


class Resource_Fountain_Population():

    """This is a class for managing a population of resource fountains."""

    # the class is initiated with a starting population:
    def __init__(self, start_population, two_tribes):

        self.pop = start_population

        if two_tribes == 1:

            self.pop_0 = [start_population[0], start_population[1]]         # these will have tags for 'sharks'
            self.pop_1 = [start_population[2], start_population[3]]         # these will have 'jets' tags


class Keynesian_Object_Population():

    def __init__(self):

        self.pop = []
        self.KI_stiffs = []


class Keynesian_Object():

    def __init__(self, day_created, loc, folder, notes_file, pre_dead_ags_grid, post_dead_ags_grid, target_agents,
                 trgt_locations):

        self.day_created = day_created
        self.loc = loc
        self.folder = folder
        self.notes_file = notes_file
        self.pre_dead_ags_grid = pre_dead_ags_grid
        self.post_dead_ags_grid = post_dead_ags_grid
        self.target_agents = target_agents
        self.trgt_locations = trgt_locations

    def write_to_notes(self, text):

        with open(self.notes_file, 'a') as myfile:
            myfile.write(text)

        myfile.close()

    def add_initial_text(self, fountain_population, trade_prices, granular_mem, print_fine_dets, print_dets, dbs,
                         town_grid, day, wait_at_tgt_moves):

        has_acted = 0
        move = 0

        text = '\n\n\nTarget Live Agents - Home, Foraging Strategies and Starting Res Arrays:\n'

        self.write_to_notes(text)

        for ag in self.target_agents:
            text = '\n%s  |  [%2.0f, %2.0f]  |  %s  |  %s' % (
            ag, ag.home[0], ag.home[1], ag.for_strat_array[0], ag.agent_res_array)
            self.write_to_notes(text)

        text = '\n\n\nLikely locations to visit prior, excluding proposed KI\n'
        self.write_to_notes(text)

        for agent in self.target_agents:

            text = '\n\nAgent %s (home %s)\n' % (agent, agent.home)
            self.write_to_notes(text)

            start_round = np.max([0, day - agent.agent_mem_length])
            end_round = day

            locs_array = np.zeros(shape=(town_grid.dimen, town_grid.dimen))

            for sell in np.arange(num_res_founts):
                for buy in np.arange(num_res_founts):

                    look_in_mem = 0
                    if trade_prices == 'fixed':

                        if granular_mem == 0 or (
                                granular_mem == 1 and sell in agent.sell_array and buy in agent.buy_array) or (
                                granular_mem == 1 and sell in agent.buy_array and buy in agent.sell_array):
                            look_in_mem = 1

                    elif trade_prices == 'variable':

                        if granular_mem == 0 or (granular_mem == 1 and agent.MRS_array[sell][buy] != 1):
                            look_in_mem = 1

                    if look_in_mem == 1:

                        for trans_numb in [cell for array in agent.loc_mems_array_cp[start_round: end_round] for cell in
                                           array[sell][buy]]:

                            trans = dbs.trans_db[trans_numb]

                            # We need to check if the agent can reach this location from its current position.  This function
                            # considers the agent's current location and the location in the trans and returns 1 if the agent
                            # can make it to that location
                            if within_striking_dist(wait_at_target_til_end, town_grid, agent.location, wait_at_tgt_moves, agent.agent_vision,
                                                    trans.location, move, has_acted, print_dets=0) == 1:
                                x_coord = trans.location[0]
                                y_coord = trans.location[1]

                                locs_array[x_coord][y_coord] += 1

            tot_locs = np.sum(locs_array)

            for x_coord in np.arange(town_grid.dimen):

                for y_coord in np.arange(town_grid.dimen):

                    if locs_array[x_coord][y_coord] > 0:
                        text = '\nLocation: [%2.0f, %2.0f] = %3.1f' % (
                        x_coord, y_coord, (locs_array[x_coord][y_coord] / float(tot_locs)) * 100)
                        self.write_to_notes(text)

        text = '\n\n\nHistory of grid square wrt transactions to date at the KI location\n'
        self.write_to_notes(text)

        there_is_hist = 0

        for trans in dbs.trans_db:

            if trans.tot_trans_ag_sell is not None and trans.location[0] == self.loc[0] and trans.location[1] == \
                    self.loc[1]:
                text = '\nday = %s  |  move_num = %s  |  agent A sold %s  |  agent B sold %s' % (
                trans.day, trans.move_num, trans.tot_trans_ag_sell, trans.tot_trans_ag_buy)

                there_is_hist = 1

        if there_is_hist == 0:
            text = '\n-----> There have been no transactions at this square\n'
            self.write_to_notes(text)

        text = '\n\n\nTransaction Information at the KI Location after it was proposed\n'
        self.write_to_notes(text)


